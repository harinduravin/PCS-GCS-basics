{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### This notebook includes the basic joint GCS and PCS using Gumbel-softmax differentiable sampling technique. Initialization with a known constellation is required when bit metric decoding is used. In this notebook we add PAS constraint, upsampling, filtering and PAPR.",
   "id": "fb35ea6ed6fac986"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:01.664828Z",
     "start_time": "2026-02-05T11:01:58.980407Z"
    }
   },
   "cell_type": "code",
   "source": "%reset",
   "id": "d14db8af2d023429",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:04.504261Z",
     "start_time": "2026-02-05T11:02:04.499183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization\n",
    "from tensorflow.nn import relu\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "import sionna as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc"
   ],
   "id": "94a33a2197e0db9f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:04.906405Z",
     "start_time": "2026-02-05T11:02:04.765068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(len(devices))"
   ],
   "id": "85a9b0913e8d91f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:05.193087Z",
     "start_time": "2026-02-05T11:02:05.187801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "symbol_points_qam64 = np.array([-1.08012344973464 + 1.08012344973464j\n",
    ",-1.08012344973464 + 0.771516749810460j\n",
    ",-1.08012344973464 + 0.154303349962092j\n",
    ",-1.08012344973464 + 0.462910049886276j\n",
    ",-0.771516749810460 + 1.08012344973464j\n",
    ",-0.771516749810460 + 0.771516749810460j\n",
    ",-0.771516749810460 + 0.154303349962092j\n",
    ",-0.771516749810460 + 0.462910049886276j\n",
    ",-0.154303349962092 + 1.08012344973464j\n",
    ",-0.154303349962092 + 0.771516749810460j\n",
    ",-0.154303349962092 + 0.154303349962092j\n",
    ",-0.154303349962092 + 0.462910049886276j\n",
    ",-0.462910049886276 + 1.08012344973464j\n",
    ",-0.462910049886276 + 0.771516749810460j\n",
    ",-0.462910049886276 + 0.154303349962092j\n",
    ",-0.462910049886276 + 0.462910049886276j\n",
    ",-1.08012344973464 - 1.08012344973464j\n",
    ",-1.08012344973464 - 0.771516749810460j\n",
    ",-1.08012344973464 - 0.154303349962092j\n",
    ",-1.08012344973464 - 0.462910049886276j\n",
    ",-0.771516749810460 - 1.08012344973464j\n",
    ",-0.771516749810460 - 0.771516749810460j\n",
    ",-0.771516749810460 - 0.154303349962092j\n",
    ",-0.771516749810460 - 0.462910049886276j\n",
    ",-0.154303349962092 - 1.08012344973464j\n",
    ",-0.154303349962092 - 0.771516749810460j\n",
    ",-0.154303349962092 - 0.154303349962092j\n",
    ",-0.154303349962092 - 0.462910049886276j\n",
    ",-0.462910049886276 - 1.08012344973464j\n",
    ",-0.462910049886276 - 0.771516749810460j\n",
    ",-0.462910049886276 - 0.154303349962092j\n",
    ",-0.462910049886276 - 0.462910049886276j\n",
    ",1.08012344973464 + 1.08012344973464j\n",
    ",1.08012344973464 + 0.771516749810460j\n",
    ",1.08012344973464 + 0.154303349962092j\n",
    ",1.08012344973464 + 0.462910049886276j\n",
    ",0.771516749810460 + 1.08012344973464j\n",
    ",0.771516749810460 + 0.771516749810460j\n",
    ",0.771516749810460 + 0.154303349962092j\n",
    ",0.771516749810460 + 0.462910049886276j\n",
    ",0.154303349962092 + 1.08012344973464j\n",
    ",0.154303349962092 + 0.771516749810460j\n",
    ",0.154303349962092 + 0.154303349962092j\n",
    ",0.154303349962092 + 0.462910049886276j\n",
    ",0.462910049886276 + 1.08012344973464j\n",
    ",0.462910049886276 + 0.771516749810460j\n",
    ",0.462910049886276 + 0.154303349962092j\n",
    ",0.462910049886276 + 0.462910049886276j\n",
    ",1.08012344973464 - 1.08012344973464j\n",
    ",1.08012344973464 - 0.771516749810460j\n",
    ",1.08012344973464 - 0.154303349962092j\n",
    ",1.08012344973464 - 0.462910049886276j\n",
    ",0.771516749810460 - 1.08012344973464j\n",
    ",0.771516749810460 - 0.771516749810460j\n",
    ",0.771516749810460 - 0.154303349962092j\n",
    ",0.771516749810460 - 0.462910049886276j\n",
    ",0.154303349962092 - 1.08012344973464j\n",
    ",0.154303349962092 - 0.771516749810460j\n",
    ",0.154303349962092 - 0.154303349962092j\n",
    ",0.154303349962092 - 0.462910049886276j\n",
    ",0.462910049886276 - 1.08012344973464j\n",
    ",0.462910049886276 - 0.771516749810460j\n",
    ",0.462910049886276 - 0.154303349962092j\n",
    ",0.462910049886276 - 0.462910049886276j])"
   ],
   "id": "6fa2fb7c269177e5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:05.979940Z",
     "start_time": "2026-02-05T11:02:05.972677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_constellation(points, probabilities):\n",
    "\n",
    "    # Compute the power of the constellation\n",
    "    power = np.sum(probabilities * np.abs(points)**2)\n",
    "    # Normalize the constellation points\n",
    "    normalized_points = points / np.sqrt(power)\n",
    "    return normalized_points\n",
    "\n",
    "def plot_constellation_wlabels(points, probabilities, plot_title):\n",
    "\n",
    "    points = np.asarray(points)\n",
    "    probabilities = np.asarray(probabilities).flatten()\n",
    "\n",
    "    # Scale marker sizes for visibility\n",
    "    marker_sizes = 300 * probabilities / max(probabilities)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(points.real, points.imag, s=marker_sizes, alpha=0.7, c='b', edgecolors='k')\n",
    "\n",
    "    # Annotate with 6-bit binary labels\n",
    "    for i, pt in enumerate(points):\n",
    "        label = format(i, '06b')  # 6-bit binary string\n",
    "        plt.text(pt.real + 0.05, pt.imag + 0.05, label, fontsize=9, ha='left', va='bottom', color='darkred')\n",
    "\n",
    "    # Add grid and formatting\n",
    "    plt.axhline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "    plt.axvline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.xlabel(\"In-phase\")\n",
    "    plt.ylabel(\"Quadrature\")\n",
    "    plt.title(plot_title)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n"
   ],
   "id": "165fb00f0b1fbdd7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:07.562609Z",
     "start_time": "2026-02-05T11:02:07.557649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Modulator(Layer):\n",
    "\n",
    "    def __init__(self, constellation, N,  parity_k, **kwargs):\n",
    "        super(Modulator, self).__init__(**kwargs)\n",
    "\n",
    "        # Define the real and imaginary parts of the constellation as trainable variables\n",
    "        # self.constellation_real = tf.Variable(constellation.real, dtype=tf.float32, trainable=True)\n",
    "        # self.constellation_imag = tf.Variable(constellation.imag, dtype=tf.float32, trainable=True)\n",
    "        self.constellation_real_init = constellation.real\n",
    "        self.constellation_imag_init = constellation.imag\n",
    "        self.parity_k = parity_k\n",
    "        self.N = N\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.constellation_real = self.add_weight(\n",
    "            name=\"constellation_real\",\n",
    "            shape=self.constellation_real_init.shape,\n",
    "            initializer=tf.constant_initializer(self.constellation_real_init),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.constellation_imag = self.add_weight(\n",
    "            name=\"constellation_imag\",\n",
    "            shape=self.constellation_imag_init.shape,\n",
    "            initializer=tf.constant_initializer(self.constellation_imag_init),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, s, probabilities):\n",
    "        # Combine the real and imaginary parts into a complex-valued constellation\n",
    "        constellation_combined = tf.complex(self.constellation_real, self.constellation_imag)\n",
    "\n",
    "        # Expand the signal dimension to align for matrix multiplication\n",
    "        s = tf.expand_dims(s, axis=-1)\n",
    "\n",
    "        # Normalize the constellation\n",
    "        normalization_constants = tf.sqrt(\n",
    "            tf.reduce_sum(tf.reshape((2**parity_k)*probabilities * tf.abs(constellation_combined) ** 2,(1,(2**self.parity_k),int(self.N/(2**self.parity_k)))), 2)\n",
    "        )\n",
    "        normalization_constants = tf.expand_dims(normalization_constants, axis=2)\n",
    "        normalization_constants = tf.complex(tf.reshape(tf.tile(normalization_constants,(1,1,int(self.N/(2**self.parity_k)))),(1,self.N)),0.0)\n",
    "        norm_constellation = constellation_combined / normalization_constants\n",
    "\n",
    "        # print('norm_constellation',norm_constellation.shape)\n",
    "        # print('s',s.shape)\n",
    "        # Compute the modulated signal\n",
    "        x_real = tf.matmul(tf.math.real(norm_constellation), s)\n",
    "        x_imag = tf.matmul(tf.math.imag(norm_constellation), s)\n",
    "        x = tf.complex(x_real, x_imag)\n",
    "\n",
    "        return tf.squeeze(x, axis=[-1, -2])"
   ],
   "id": "cd5fb2aef2d2e247",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:08.101992Z",
     "start_time": "2026-02-05T11:02:08.095459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Demodulator_bitwise(Layer):\n",
    "    def __init__(self, bits_per_symbol):\n",
    "        super(Demodulator_bitwise, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')  # First Dense Layer\n",
    "        self.dense2 = Dense(128, activation='relu')  # Second Dense Layer\n",
    "        self.dense3 = Dense(bits_per_symbol, activation='sigmoid')                      # Output Dense Layer\n",
    "        # self.snr_db = snr_db                        # SNR in dB\n",
    "\n",
    "    def call(self, y, batch_size, block_size):\n",
    "        # Ensure complex-valued input is split into real and imaginary parts\n",
    "        y_real = tf.math.real(y)\n",
    "        y_imag = tf.math.imag(y)\n",
    "\n",
    "        # Create and broadcast SNR tensor\n",
    "        snr_tensor = tf.constant([[1]], dtype=tf.float32)\n",
    "        brd_snr_tensor = tf.broadcast_to(snr_tensor, [batch_size, block_size, 1])\n",
    "\n",
    "        # Concatenate real, imaginary, and SNR tensors along the last dimension\n",
    "        y_real = tf.expand_dims(y_real,axis=-1)\n",
    "        y_imag = tf.expand_dims(y_imag,axis=-1)\n",
    "        # print('y_real',y_real.shape)\n",
    "        # print('y_imag',y_imag.shape)\n",
    "        # print('brd_snr_tensor',brd_snr_tensor.shape)\n",
    "        stack_input = tf.concat([y_real, y_imag, brd_snr_tensor], axis=2)\n",
    "\n",
    "        ## print('brd_snr_tensor.shape: ',brd_snr_tensor)\n",
    "\n",
    "        # Pass the stacked input through the dense layers\n",
    "        x = self.dense1(stack_input)\n",
    "        x = self.dense2(x)\n",
    "        logits = self.dense3(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "4f3cb0e20be2f872",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:08.634836Z",
     "start_time": "2026-02-05T11:02:08.630488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SamplingMechanism(Layer):\n",
    "    def __init__(self, N, tau, parity_k):\n",
    "        super(SamplingMechanism, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(int(N/(2**parity_k)), activation=None)\n",
    "        self.tau = tau\n",
    "        # self.snr_db = snr_db\n",
    "        self.parity_k = parity_k\n",
    "        self.N = N\n",
    "\n",
    "    def call(self, batch_size, block_size):\n",
    "        # Create a tensor with the SNR value\n",
    "        snr_tensor = tf.constant([[1]], dtype=tf.float32)\n",
    "        # Pass the SNR value through the first dense layer\n",
    "        a = self.dense1(snr_tensor)\n",
    "\n",
    "        # Pass through the second dense layer\n",
    "        logits = self.dense2(a)\n",
    "        # print('1',logits.shape)\n",
    "        #\n",
    "        # Copying the logits 2**parity_k times to constrain according to PAS\n",
    "        logits = tf.tile(logits, [1, 2**self.parity_k])\n",
    "        # print('2',logits.shape)\n",
    "\n",
    "        # Compute softmax output\n",
    "        softmax_out = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "        logits = tf.expand_dims(logits, axis=1)\n",
    "        # print('3',logits.shape)\n",
    "        logits = tf.tile(logits, [batch_size, block_size, 1])\n",
    "\n",
    "        # Compute Gumbel-Softmax with straight-through sampling\n",
    "        gumbel_dist = -tf.math.log(-tf.math.log(tf.random.uniform(tf.shape(logits), 0, 1) + 1e-20) + 1e-20)\n",
    "        gumbel_logits = logits + gumbel_dist\n",
    "        gumbel_softmax = tf.nn.softmax(gumbel_logits / self.tau, axis=-1)\n",
    "\n",
    "        max_value = tf.argmax(gumbel_softmax, axis=-1)\n",
    "        # print(gumbel_softmax.shape)\n",
    "\n",
    "        # Step 2: Compare each value in gumbel_softmax with the max_value\n",
    "        hard_sample = tf.one_hot(max_value, depth=self.N, dtype=tf.float32)\n",
    "        # print(\"hard_sample:\", hard_sample)\n",
    "\n",
    "        straight_through = gumbel_softmax + tf.stop_gradient(hard_sample - gumbel_softmax)\n",
    "\n",
    "        return straight_through, softmax_out\n",
    "\n"
   ],
   "id": "1648e1ad972a2a54",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:09.319428Z",
     "start_time": "2026-02-05T11:02:09.309144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EndToEndSystem_bitwise(Model):\n",
    "    def __init__(self, N, constellation, batch_size, block_size, bits_per_symbol, parity_k, use_upsampling_filtering, tau=1.0):\n",
    "        super(EndToEndSystem_bitwise, self).__init__()\n",
    "        # self.No = 1/(10**(snr_db/10))\n",
    "        self.sampling = SamplingMechanism(N, tau, parity_k)\n",
    "        self.batch_size = batch_size\n",
    "        self.block_size = block_size\n",
    "        self.papr_batch_size = batch_size\n",
    "        self.modulator = Modulator(constellation,N,parity_k)\n",
    "        self.channel = sn.phy.channel.AWGN()\n",
    "        self.demodulator = Demodulator_bitwise(bits_per_symbol)\n",
    "        self.loss_fn = BinaryCrossentropy(from_logits=False, reduction='none', axis=[0, 1])\n",
    "        self.bits_per_symbol = bits_per_symbol\n",
    "        self.parity_k = parity_k\n",
    "        self.use_upsampling_filtering = use_upsampling_filtering\n",
    "        self.upsampler = sn.phy.signal.Upsampling(samples_per_symbol=4)\n",
    "        self.tx_filter = sn.phy.signal.RootRaisedCosineFilter(beta=0.3,\n",
    "                                                         samples_per_symbol=4,\n",
    "                                                         span_in_symbols=32)\n",
    "        self.rx_filter = sn.phy.signal.RootRaisedCosineFilter(beta=0.3,\n",
    "                                                         samples_per_symbol=4,\n",
    "                                                         span_in_symbols=32)\n",
    "        self.downsampler = sn.phy.signal.Downsampling(samples_per_symbol=4,\n",
    "                                                      offset = self.rx_filter.length - 1,\n",
    "\n",
    "                                                 num_symbols=tf.cast(block_size, tf.int32))\n",
    "    def call(self, No):\n",
    "        # Sampling mechanism generates symbol indices and shaping probabilities\n",
    "\n",
    "        s, shaping_probs = self.sampling(batch_size = self.batch_size, block_size = self.block_size)\n",
    "        indices = tf.argmax(s, axis=2, output_type=tf.int64)  # use int64 here!\n",
    "        # Step 2: Convert to binary bits\n",
    "        shifts = tf.range(self.bits_per_symbol - 1, -1, -1, dtype=tf.int64)  # also int64\n",
    "        # Right shift and mask\n",
    "        bit_repr = tf.bitwise.right_shift(\n",
    "            tf.expand_dims(indices, -1), shifts\n",
    "        ) & 1\n",
    "\n",
    "        # Modulate the symbols\n",
    "        x_mod = self.modulator(s, shaping_probs)\n",
    "\n",
    "        if self.use_upsampling_filtering:\n",
    "            x_up = self.upsampler(x_mod)\n",
    "            x_tx_filt = self.tx_filter(x_up)\n",
    "            y_channel = self.channel(x_tx_filt, No)\n",
    "            y_rx_filt = self.rx_filter(y_channel)\n",
    "            y = self.downsampler(y_rx_filt)\n",
    "        else:\n",
    "            # Transmit through the channel\n",
    "            y = self.channel(x_mod, No)\n",
    "\n",
    "        # Demodulate the received signal\n",
    "        logits = self.demodulator(y, batch_size = self.batch_size, block_size = self.block_size)\n",
    "\n",
    "        loss_ordinary = tf.reduce_sum(self.loss_fn(bit_repr,logits))\n",
    "        entropy_value = -tf.reduce_sum(shaping_probs * tf.math.log(shaping_probs))\n",
    "        loss = loss_ordinary - entropy_value\n",
    "\n",
    "        return loss, loss_ordinary, entropy_value, shaping_probs\n",
    "\n",
    "    @tf.function\n",
    "    def compute_power_to_average_power_samples(self):\n",
    "        s_power, shaping_probs_power = self.sampling( batch_size = self.papr_batch_size, block_size = self.block_size)\n",
    "        x_power = self.modulator(s_power, shaping_probs_power)\n",
    "        x_up_power = self.upsampler(x_power)\n",
    "        x_tx_filt_power = self.tx_filter(x_up_power)  # 'same' for discarding the edges\n",
    "        p_x = tf.square(tf.abs(x_tx_filt_power))\n",
    "        power_samples = p_x / tf.reduce_mean(p_x)\n",
    "        return power_samples"
   ],
   "id": "fa23a995fdf976ba",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:02:10.517094Z",
     "start_time": "2026-02-05T11:02:10.501539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Inner loop\n",
    "@tf.function\n",
    "def _inner_loop(lambd_papr, mu, step, num_it, excess_power_target, papr_threshold, No):\n",
    "    # We need to initialize c...\n",
    "    excess_power = 0.0\n",
    "    c_excess_power = excess_power\n",
    "    L = 0.0\n",
    "\n",
    "    k = tf.constant(0, tf.int32)\n",
    "    while tf.less(k, num_it):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss,loss_ordinary, entropy_value,_ = model(No)\n",
    "\n",
    "            if use_upsampling_filtering:\n",
    "                powers = model.compute_power_to_average_power_samples()\n",
    "                excess_power = tf.reduce_mean(tf.nn.relu(powers[:,64:-64]  - papr_threshold))\n",
    "                excess_power = tf.math.log(excess_power + 1e-12) / tf.math.log(10.)\n",
    "\n",
    "                c_excess_power = excess_power - excess_power_target\n",
    "                c_excess_power = tf.maximum(c_excess_power,lambd_papr / mu)\n",
    "\n",
    "            # Augmented Lagrangian\n",
    "            L = loss - lambd_papr * c_excess_power + 0.5 * mu * (\n",
    "                tf.square(c_excess_power))\n",
    "\n",
    "        # Computing and applying gradients\n",
    "        weights = model.trainable_weights\n",
    "        grads = tape.gradient(L, weights)\n",
    "        grads, glob_norm = tf.clip_by_global_norm(grads, 0.1)\n",
    "        optimizer.apply_gradients(zip(grads, weights))\n",
    "        # Print progress\n",
    "        if k % 50 == 0:\n",
    "          tf.print('Iteration',k,'L', L / np.log(2),'loss', loss / np.log(2), 'loss_ordinary', loss_ordinary / np.log(2), 'entropy_value', entropy_value / np.log(2),'glob_norm',glob_norm)\n",
    "\n",
    "        k = k + 1\n",
    "        step = step + 1\n",
    "\n",
    "        if use_upsampling_filtering:\n",
    "            powers = model.compute_power_to_average_power_samples()\n",
    "            excess_power = tf.reduce_mean(tf.nn.relu(powers[:,64:-64]  - papr_threshold))\n",
    "            excess_power = tf.math.log(excess_power + 1e-12) / tf.math.log(10.)\n",
    "            c_excess_power = excess_power - excess_power_target\n",
    "            c_excess_power = tf.maximum(c_excess_power,lambd_papr / mu)\n",
    "\n",
    "    return c_excess_power, step\n",
    "\n"
   ],
   "id": "4100b728e0635c5f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### One-time training",
   "id": "ad2ccb670d69199c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:03:57.706458Z",
     "start_time": "2026-02-05T11:02:22.576778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################\n",
    "# Train function\n",
    "###############################\n",
    "N = 64  # Number of classes (symbols)\n",
    "bits_per_symbol = int(np.log2(N))\n",
    "\n",
    "parity_k = 2\n",
    "use_upsampling_filtering = True  # Remove 'false' this after testing without upsampling and filtering\n",
    "\n",
    "constellation = symbol_points_qam64\n",
    "\n",
    "snr_db = 15  # SNR in dB\n",
    "\n",
    "tau = 10\n",
    "\n",
    "# Batch size\n",
    "batch_size = 25\n",
    "block_size = 200\n",
    "\n",
    "model = EndToEndSystem_bitwise(N, constellation, batch_size, block_size, bits_per_symbol, parity_k, use_upsampling_filtering, tau)\n",
    "\n",
    "No = tf.convert_to_tensor(1/(10**(snr_db/10)),tf.float32)\n",
    "# _,_,_,_ = model(No)\n",
    "\n",
    "excess_power_target = -3.5 #B\n",
    "papr_threshold_db = 6.0 #dB\n",
    "papr_threshold = tf.math.pow(10.0, papr_threshold_db / 10.0)\n",
    "# We define a new optimizer at every rune\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Outer-loop\n",
    "# Lagrange multiplier\n",
    "lambd_papr = tf.Variable(tf.constant(0.0, tf.float32), trainable=False, dtype=tf.float32)\n",
    "\n",
    "# Penalty parameter\n",
    "mu = tf.Variable(0.01, trainable=False, dtype=tf.float32)\n",
    "\n",
    "step = tf.constant(0, tf.int32)\n",
    "for i in range(50):\n",
    "\n",
    "    # Find a local minimizer (increase the first number of iterations if using random initializations)\n",
    "    if i == 0:\n",
    "        num_it = 5000\n",
    "    else:\n",
    "        num_it = 250\n",
    "    c_excess_power, step = _inner_loop(lambd_papr, mu, step, num_it,\n",
    "                                       excess_power_target, papr_threshold, No)\n",
    "\n",
    "    # Update Lagrange multipliers\n",
    "    tf.print('-------------------------------------------------------')\n",
    "    tf.print('-------------------------------------------------------')\n",
    "    tf.print('Progress ',i,' % ','c_excess_power',c_excess_power,'lambd_papr',lambd_papr,'mu',mu)\n",
    "    tf.print('-------------------------------------------------------')\n",
    "    tf.print('-------------------------------------------------------')\n",
    "    lambd_papr = lambd_papr - mu * c_excess_power\n",
    "\n",
    "    # Update penalty parameter\n",
    "    mu = mu*1.003"
   ],
   "id": "602c4ea5e22ef067",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770289346.778038    5059 cuda_dnn.cc:529] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 L 0.0514732786 loss 0.0495523289 loss_ordinary 6.03341818 entropy_value 5.98386574 glob_norm 0.638585269\n",
      "Iteration 50 L -2.04631448 loss -2.04708576 loss_ordinary 3.92624187 entropy_value 5.97332764 glob_norm 0.490432\n",
      "Iteration 100 L -3.50042343 loss -3.50101542 loss_ordinary 2.46475601 entropy_value 5.9657712 glob_norm 0.290839285\n",
      "Iteration 150 L -3.92008 loss -3.92065716 loss_ordinary 2.05205536 entropy_value 5.97271252 glob_norm 0.33071357\n",
      "Iteration 200 L -4.1067009 loss -4.10868835 loss_ordinary 1.83982873 entropy_value 5.94851732 glob_norm 0.488460541\n",
      "Iteration 250 L -4.29772 loss -4.30353785 loss_ordinary 1.59114408 entropy_value 5.89468193 glob_norm 0.305090636\n",
      "Iteration 300 L -4.48750973 loss -4.49850416 loss_ordinary 1.30737579 entropy_value 5.80587959 glob_norm 0.433810443\n",
      "Iteration 350 L -4.66460943 loss -4.67788792 loss_ordinary 1.07011211 entropy_value 5.748 glob_norm 0.362071246\n",
      "Iteration 400 L -4.75054502 loss -4.76587248 loss_ordinary 0.952432692 entropy_value 5.71830511 glob_norm 0.322074622\n",
      "Iteration 450 L -4.79208755 loss -4.80706215 loss_ordinary 0.887608707 entropy_value 5.69467068 glob_norm 0.47395134\n",
      "Iteration 500 L -4.84685326 loss -4.86143494 loss_ordinary 0.825363278 entropy_value 5.6867981 glob_norm 0.566908479\n",
      "Iteration 550 L -4.87277937 loss -4.88757 loss_ordinary 0.795473218 entropy_value 5.683043 glob_norm 0.250243187\n",
      "Iteration 600 L -4.8176 loss -4.83161116 loss_ordinary 0.843990386 entropy_value 5.67560148 glob_norm 0.365518719\n",
      "Iteration 650 L -4.83402443 loss -4.8499074 loss_ordinary 0.819761336 entropy_value 5.6696682 glob_norm 0.584327221\n",
      "Iteration 700 L -4.81956482 loss -4.83448029 loss_ordinary 0.828394055 entropy_value 5.66287422 glob_norm 0.398801297\n",
      "Iteration 750 L -4.85626841 loss -4.87143135 loss_ordinary 0.789546132 entropy_value 5.66097736 glob_norm 0.489569753\n",
      "Iteration 800 L -4.87980413 loss -4.89425182 loss_ordinary 0.765746713 entropy_value 5.65999842 glob_norm 0.443213612\n",
      "Iteration 850 L -4.8477993 loss -4.86592722 loss_ordinary 0.790220618 entropy_value 5.65614796 glob_norm 0.332790285\n",
      "Iteration 900 L -4.89010859 loss -4.905931 loss_ordinary 0.755433261 entropy_value 5.66136408 glob_norm 0.412803411\n",
      "Iteration 950 L -4.88297415 loss -4.89960527 loss_ordinary 0.75266093 entropy_value 5.6522665 glob_norm 0.441218883\n",
      "Iteration 1000 L -4.87312317 loss -4.88768578 loss_ordinary 0.765672743 entropy_value 5.65335846 glob_norm 0.470542818\n",
      "Iteration 1050 L -4.88845968 loss -4.90402174 loss_ordinary 0.74136287 entropy_value 5.64538479 glob_norm 0.284582794\n",
      "Iteration 1100 L -4.85699511 loss -4.87406492 loss_ordinary 0.771294713 entropy_value 5.64535952 glob_norm 0.422240645\n",
      "Iteration 1150 L -4.86701345 loss -4.88326025 loss_ordinary 0.768527 entropy_value 5.6517868 glob_norm 0.479827315\n",
      "Iteration 1200 L -4.8940134 loss -4.90976381 loss_ordinary 0.738453925 entropy_value 5.64821768 glob_norm 0.529233217\n",
      "Iteration 1250 L -4.87705517 loss -4.8917017 loss_ordinary 0.759939551 entropy_value 5.65164137 glob_norm 0.417942852\n",
      "Iteration 1300 L -4.87074375 loss -4.8881011 loss_ordinary 0.757931 entropy_value 5.64603233 glob_norm 0.515645683\n",
      "Iteration 1350 L -4.87657 loss -4.89068651 loss_ordinary 0.754293382 entropy_value 5.64497948 glob_norm 0.544742167\n",
      "Iteration 1400 L -4.86709785 loss -4.88345 loss_ordinary 0.757822096 entropy_value 5.64127254 glob_norm 0.451974571\n",
      "Iteration 1450 L -4.90459347 loss -4.91959095 loss_ordinary 0.727175117 entropy_value 5.64676666 glob_norm 0.481336862\n",
      "Iteration 1500 L -4.90292931 loss -4.91834593 loss_ordinary 0.726847708 entropy_value 5.64519358 glob_norm 0.535116732\n",
      "Iteration 1550 L -4.86977625 loss -4.8873291 loss_ordinary 0.750430405 entropy_value 5.63775969 glob_norm 0.404256523\n",
      "Iteration 1600 L -4.88308477 loss -4.89884663 loss_ordinary 0.751353681 entropy_value 5.65020037 glob_norm 0.333326161\n",
      "Iteration 1650 L -4.8705492 loss -4.88681555 loss_ordinary 0.753301 entropy_value 5.64011669 glob_norm 0.414295495\n",
      "Iteration 1700 L -4.86375284 loss -4.8803606 loss_ordinary 0.756001 entropy_value 5.6363616 glob_norm 0.608722\n",
      "Iteration 1750 L -4.86931705 loss -4.8847456 loss_ordinary 0.754868448 entropy_value 5.63961363 glob_norm 0.472727478\n",
      "Iteration 1800 L -4.89498138 loss -4.9122963 loss_ordinary 0.726151526 entropy_value 5.63844824 glob_norm 0.332978308\n",
      "Iteration 1850 L -4.879076 loss -4.89516354 loss_ordinary 0.739586115 entropy_value 5.63475 glob_norm 0.38830179\n",
      "Iteration 1900 L -4.86662626 loss -4.8837986 loss_ordinary 0.762958348 entropy_value 5.64675665 glob_norm 0.35851571\n",
      "Iteration 1950 L -4.89736557 loss -4.91544533 loss_ordinary 0.724535406 entropy_value 5.63998079 glob_norm 0.385555953\n",
      "Iteration 2000 L -4.91854572 loss -4.93612719 loss_ordinary 0.698931813 entropy_value 5.6350584 glob_norm 0.434072644\n",
      "Iteration 2050 L -4.86249399 loss -4.87937403 loss_ordinary 0.763841152 entropy_value 5.64321518 glob_norm 0.337156087\n",
      "Iteration 2100 L -4.89552641 loss -4.91101265 loss_ordinary 0.724054 entropy_value 5.63506699 glob_norm 0.415912092\n",
      "Iteration 2150 L -4.87729883 loss -4.89388371 loss_ordinary 0.741650343 entropy_value 5.63553381 glob_norm 0.613091469\n",
      "Iteration 2200 L -4.86142111 loss -4.87704659 loss_ordinary 0.763977349 entropy_value 5.64102411 glob_norm 0.365367472\n",
      "Iteration 2250 L -4.88555861 loss -4.90192032 loss_ordinary 0.738977969 entropy_value 5.64089823 glob_norm 0.458972961\n",
      "Iteration 2300 L -4.85859394 loss -4.87484074 loss_ordinary 0.76522243 entropy_value 5.64006281 glob_norm 0.505658031\n",
      "Iteration 2350 L -4.87865305 loss -4.89428663 loss_ordinary 0.743536949 entropy_value 5.63782358 glob_norm 0.357014775\n",
      "Iteration 2400 L -4.9074955 loss -4.92588282 loss_ordinary 0.718533516 entropy_value 5.64441633 glob_norm 0.428336769\n",
      "Iteration 2450 L -4.86379671 loss -4.88161516 loss_ordinary 0.755602 entropy_value 5.63721704 glob_norm 0.395414203\n",
      "Iteration 2500 L -4.89745235 loss -4.91342545 loss_ordinary 0.722290337 entropy_value 5.63571596 glob_norm 0.293712914\n",
      "Iteration 2550 L -4.87535 loss -4.89239407 loss_ordinary 0.74819237 entropy_value 5.64058638 glob_norm 0.430888385\n",
      "Iteration 2600 L -4.88845444 loss -4.90435076 loss_ordinary 0.735065103 entropy_value 5.63941574 glob_norm 0.432837516\n",
      "Iteration 2650 L -4.87510872 loss -4.89073706 loss_ordinary 0.745198429 entropy_value 5.63593531 glob_norm 0.512683511\n",
      "Iteration 2700 L -4.87855768 loss -4.89402962 loss_ordinary 0.742366433 entropy_value 5.63639593 glob_norm 0.304051399\n",
      "Iteration 2750 L -4.89712811 loss -4.91360807 loss_ordinary 0.726845562 entropy_value 5.64045382 glob_norm 0.324243605\n",
      "Iteration 2800 L -4.8524127 loss -4.86734772 loss_ordinary 0.768664896 entropy_value 5.63601255 glob_norm 0.389146686\n",
      "Iteration 2850 L -4.86203051 loss -4.87998486 loss_ordinary 0.753493726 entropy_value 5.63347864 glob_norm 0.337703794\n",
      "Iteration 2900 L -4.89358282 loss -4.91044044 loss_ordinary 0.726261675 entropy_value 5.63670206 glob_norm 0.635437608\n",
      "Iteration 2950 L -4.85881662 loss -4.87613678 loss_ordinary 0.753351927 entropy_value 5.62948895 glob_norm 0.757575572\n",
      "Iteration 3000 L -4.89189291 loss -4.90910721 loss_ordinary 0.728549302 entropy_value 5.63765669 glob_norm 0.422550797\n",
      "Iteration 3050 L -4.87281752 loss -4.88975096 loss_ordinary 0.75216043 entropy_value 5.64191151 glob_norm 0.490846753\n",
      "Iteration 3100 L -4.87488174 loss -4.89205694 loss_ordinary 0.741015792 entropy_value 5.63307285 glob_norm 0.691699326\n",
      "Iteration 3150 L -4.86946821 loss -4.886343 loss_ordinary 0.756008565 entropy_value 5.64235163 glob_norm 0.532835841\n",
      "Iteration 3200 L -4.85549545 loss -4.87142372 loss_ordinary 0.768565 entropy_value 5.63998842 glob_norm 0.397403419\n",
      "Iteration 3250 L -4.88026667 loss -4.89687729 loss_ordinary 0.748569965 entropy_value 5.64544725 glob_norm 0.402068138\n",
      "Iteration 3300 L -4.87203598 loss -4.88827133 loss_ordinary 0.750714242 entropy_value 5.63898563 glob_norm 0.464844525\n",
      "Iteration 3350 L -4.87437057 loss -4.89088154 loss_ordinary 0.752901793 entropy_value 5.64378309 glob_norm 0.331811756\n",
      "Iteration 3400 L -4.91479063 loss -4.932271 loss_ordinary 0.701732397 entropy_value 5.63400316 glob_norm 0.2949121\n",
      "Iteration 3450 L -4.90126657 loss -4.9174881 loss_ordinary 0.720657468 entropy_value 5.63814592 glob_norm 0.323424369\n",
      "Iteration 3500 L -4.87494946 loss -4.89043236 loss_ordinary 0.746489 entropy_value 5.63692141 glob_norm 0.383059651\n",
      "Iteration 3550 L -4.8799715 loss -4.89766693 loss_ordinary 0.739171803 entropy_value 5.63683844 glob_norm 0.346643358\n",
      "Iteration 3600 L -4.87859917 loss -4.89557695 loss_ordinary 0.744204462 entropy_value 5.63978148 glob_norm 0.277908176\n",
      "Iteration 3650 L -4.87687874 loss -4.89292717 loss_ordinary 0.741442 entropy_value 5.63436937 glob_norm 0.386998385\n",
      "Iteration 3700 L -4.87294626 loss -4.89264679 loss_ordinary 0.747780144 entropy_value 5.64042711 glob_norm 0.474568307\n",
      "Iteration 3750 L -4.88192749 loss -4.89582682 loss_ordinary 0.742071331 entropy_value 5.63789797 glob_norm 0.332320303\n",
      "Iteration 3800 L -4.88594294 loss -4.90225649 loss_ordinary 0.738163471 entropy_value 5.64042 glob_norm 0.423113614\n",
      "Iteration 3850 L -4.89261246 loss -4.90989256 loss_ordinary 0.717333198 entropy_value 5.62722588 glob_norm 0.598439276\n",
      "Iteration 3900 L -4.90225 loss -4.91821766 loss_ordinary 0.722156286 entropy_value 5.64037371 glob_norm 0.284565032\n",
      "Iteration 3950 L -4.89663363 loss -4.91307592 loss_ordinary 0.727090776 entropy_value 5.64016676 glob_norm 0.277447402\n",
      "Iteration 4000 L -4.87344 loss -4.88958454 loss_ordinary 0.750245333 entropy_value 5.63982964 glob_norm 0.442792296\n",
      "Iteration 4050 L -4.87594032 loss -4.89230442 loss_ordinary 0.737203956 entropy_value 5.6295085 glob_norm 0.383616954\n",
      "Iteration 4100 L -4.87380648 loss -4.89093494 loss_ordinary 0.744139 entropy_value 5.63507414 glob_norm 0.52912581\n",
      "Iteration 4150 L -4.87744522 loss -4.89424372 loss_ordinary 0.73762995 entropy_value 5.63187361 glob_norm 0.544389427\n",
      "Iteration 4200 L -4.88153696 loss -4.89711428 loss_ordinary 0.734174669 entropy_value 5.63128901 glob_norm 0.489611238\n",
      "Iteration 4250 L -4.86979485 loss -4.88602448 loss_ordinary 0.748875499 entropy_value 5.6349 glob_norm 0.530813217\n",
      "Iteration 4300 L -4.85661173 loss -4.87440586 loss_ordinary 0.757710636 entropy_value 5.63211679 glob_norm 0.337463528\n",
      "Iteration 4350 L -4.92778254 loss -4.94422 loss_ordinary 0.689991951 entropy_value 5.63421202 glob_norm 0.358479\n",
      "Iteration 4400 L -4.87013674 loss -4.88756514 loss_ordinary 0.743111908 entropy_value 5.63067675 glob_norm 0.594195962\n",
      "Iteration 4450 L -4.85534143 loss -4.87133884 loss_ordinary 0.770603836 entropy_value 5.64194298 glob_norm 0.430866778\n",
      "Iteration 4500 L -4.85117292 loss -4.8683362 loss_ordinary 0.773610473 entropy_value 5.64194632 glob_norm 0.493134141\n",
      "Iteration 4550 L -4.87423 loss -4.89240122 loss_ordinary 0.74210763 entropy_value 5.63450909 glob_norm 0.409099162\n",
      "Iteration 4600 L -4.89332962 loss -4.90993834 loss_ordinary 0.719584286 entropy_value 5.6295228 glob_norm 0.450122178\n",
      "Iteration 4650 L -4.8759656 loss -4.89159918 loss_ordinary 0.744858801 entropy_value 5.6364584 glob_norm 0.349031329\n",
      "Iteration 4700 L -4.85865355 loss -4.87484598 loss_ordinary 0.769032478 entropy_value 5.64387798 glob_norm 0.355494559\n",
      "Iteration 4750 L -4.87311268 loss -4.88959885 loss_ordinary 0.751349688 entropy_value 5.64094877 glob_norm 0.447481096\n",
      "Iteration 4800 L -4.86999035 loss -4.88747358 loss_ordinary 0.743360579 entropy_value 5.63083458 glob_norm 0.446317852\n",
      "Iteration 4850 L -4.87781811 loss -4.89445162 loss_ordinary 0.733730197 entropy_value 5.62818193 glob_norm 0.495381296\n",
      "Iteration 4900 L -4.8823719 loss -4.90014601 loss_ordinary 0.73738265 entropy_value 5.63752842 glob_norm 0.297410399\n",
      "Iteration 4950 L -4.87195492 loss -4.88944244 loss_ordinary 0.74883157 entropy_value 5.63827419 glob_norm 0.57966125\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 1.48742819 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8324337 loss -4.88286591 loss_ordinary 0.752581 entropy_value 5.63544703 glob_norm 0.334641576\n",
      "Iteration 50 L -4.83469 loss -4.88053 loss_ordinary 0.762308419 entropy_value 5.642838 glob_norm 0.309966683\n",
      "Iteration 100 L -4.86995649 loss -4.91457 loss_ordinary 0.731706381 entropy_value 5.646276 glob_norm 0.341364503\n",
      "Iteration 150 L -4.86784649 loss -4.91357 loss_ordinary 0.730673194 entropy_value 5.64424276 glob_norm 0.638152599\n",
      "Iteration 200 L -4.84149361 loss -4.88819313 loss_ordinary 0.752961516 entropy_value 5.64115477 glob_norm 0.391868979\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 1.43267202 lambd_papr -0.0148742814 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.79480553 loss -4.86735344 loss_ordinary 0.780398548 entropy_value 5.64775181 glob_norm 0.400860667\n",
      "Iteration 50 L -4.84911299 loss -4.91225529 loss_ordinary 0.741659582 entropy_value 5.65391493 glob_norm 0.442589819\n",
      "Iteration 100 L -4.79719687 loss -4.86002111 loss_ordinary 0.797389627 entropy_value 5.65741062 glob_norm 0.643602908\n",
      "Iteration 150 L -4.8232 loss -4.8898 loss_ordinary 0.772507906 entropy_value 5.66230774 glob_norm 0.428591728\n",
      "Iteration 200 L -4.81001091 loss -4.88074112 loss_ordinary 0.779024124 entropy_value 5.65976477 glob_norm 0.455224067\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 1.19686341 lambd_papr -0.0292439815 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.77778578 loss -4.86445761 loss_ordinary 0.799490929 entropy_value 5.66394854 glob_norm 0.775958121\n",
      "Iteration 50 L -4.81008101 loss -4.89207 loss_ordinary 0.775935411 entropy_value 5.66800547 glob_norm 0.425931543\n",
      "Iteration 100 L -4.7817688 loss -4.86609268 loss_ordinary 0.801409483 entropy_value 5.6675024 glob_norm 0.388436198\n",
      "Iteration 150 L -4.8122263 loss -4.89361095 loss_ordinary 0.781370044 entropy_value 5.67498112 glob_norm 0.495699733\n",
      "Iteration 200 L -4.79796171 loss -4.87469292 loss_ordinary 0.807570338 entropy_value 5.68226337 glob_norm 0.475147694\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 1.14272952 lambd_papr -0.0412845351 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.738873 loss -4.83104181 loss_ordinary 0.84902364 entropy_value 5.68006563 glob_norm 0.4855735\n",
      "Iteration 50 L -4.76078463 loss -4.84921551 loss_ordinary 0.839347959 entropy_value 5.68856335 glob_norm 0.350662738\n",
      "Iteration 100 L -4.78135729 loss -4.86211681 loss_ordinary 0.820077181 entropy_value 5.68219376 glob_norm 0.486894071\n",
      "Iteration 150 L -4.72920656 loss -4.8195653 loss_ordinary 0.864247382 entropy_value 5.68381262 glob_norm 0.309981495\n",
      "Iteration 200 L -4.7840538 loss -4.8723278 loss_ordinary 0.823156536 entropy_value 5.69548416 glob_norm 0.472679079\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 1.01134419 lambd_papr -0.0528149828 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.75461388 loss -4.84900904 loss_ordinary 0.846023262 entropy_value 5.69503212 glob_norm 0.590667605\n",
      "Iteration 50 L -4.74176025 loss -4.83402634 loss_ordinary 0.856644869 entropy_value 5.69067144 glob_norm 0.410875827\n",
      "Iteration 100 L -4.72667 loss -4.82680655 loss_ordinary 0.875025868 entropy_value 5.70183229 glob_norm 0.38320598\n",
      "Iteration 150 L -4.7303 loss -4.83498478 loss_ordinary 0.868268311 entropy_value 5.70325327 glob_norm 0.65942347\n",
      "Iteration 200 L -4.77502489 loss -4.87952662 loss_ordinary 0.809767425 entropy_value 5.68929386 glob_norm 0.437419623\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.933523178 lambd_papr -0.0630503297 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7504878 loss -4.84103 loss_ordinary 0.860389113 entropy_value 5.70141935 glob_norm 0.494436473\n",
      "Iteration 50 L -4.73573542 loss -4.82887459 loss_ordinary 0.876670718 entropy_value 5.70554495 glob_norm 0.442988247\n",
      "Iteration 100 L -4.78315783 loss -4.88154364 loss_ordinary 0.823833764 entropy_value 5.7053771 glob_norm 0.379871309\n",
      "Iteration 150 L -4.73934364 loss -4.84309053 loss_ordinary 0.867064774 entropy_value 5.71015501 glob_norm 0.520670354\n",
      "Iteration 200 L -4.76963711 loss -4.86121464 loss_ordinary 0.843537569 entropy_value 5.70475197 glob_norm 0.520295918\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0.959070921 lambd_papr -0.0725264326 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76373 loss -4.85015774 loss_ordinary 0.862764 entropy_value 5.71292162 glob_norm 0.32970351\n",
      "Iteration 50 L -4.73912621 loss -4.83751917 loss_ordinary 0.873207092 entropy_value 5.71072626 glob_norm 0.477000177\n",
      "Iteration 100 L -4.73316622 loss -4.83384943 loss_ordinary 0.881997108 entropy_value 5.71584654 glob_norm 0.571865916\n",
      "Iteration 150 L -4.72332525 loss -4.81791115 loss_ordinary 0.902887583 entropy_value 5.72079849 glob_norm 0.417552382\n",
      "Iteration 200 L -4.7349267 loss -4.8227582 loss_ordinary 0.897490501 entropy_value 5.7202487 glob_norm 0.537395239\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0.763257504 lambd_papr -0.0822910741 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72899151 loss -4.83525848 loss_ordinary 0.882759094 entropy_value 5.71801758 glob_norm 0.340682119\n",
      "Iteration 50 L -4.71589375 loss -4.82341862 loss_ordinary 0.902186036 entropy_value 5.72560453 glob_norm 0.417597175\n",
      "Iteration 100 L -4.71598482 loss -4.82507849 loss_ordinary 0.897867143 entropy_value 5.72294569 glob_norm 0.537969232\n",
      "Iteration 150 L -4.76543045 loss -4.83431387 loss_ordinary 0.89472717 entropy_value 5.7290411 glob_norm 0.412754118\n",
      "Iteration 200 L -4.75937319 loss -4.83208704 loss_ordinary 0.896478474 entropy_value 5.72856569 glob_norm 0.485710472\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.531587601 lambd_papr -0.0900853872 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72066975 loss -4.81424713 loss_ordinary 0.91778177 entropy_value 5.73202896 glob_norm 0.573267043\n",
      "Iteration 50 L -4.72806358 loss -4.82906151 loss_ordinary 0.900149107 entropy_value 5.72921085 glob_norm 0.445040107\n",
      "Iteration 100 L -4.72411776 loss -4.81465483 loss_ordinary 0.910299838 entropy_value 5.72495461 glob_norm 0.431894481\n",
      "Iteration 150 L -4.68229485 loss -4.79933834 loss_ordinary 0.929135382 entropy_value 5.72847366 glob_norm 0.388713509\n",
      "Iteration 200 L -4.72833 loss -4.81509542 loss_ordinary 0.92031306 entropy_value 5.73540831 glob_norm 0.50171\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0.662087917 lambd_papr -0.0955301896 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68041229 loss -4.79232931 loss_ordinary 0.931969166 entropy_value 5.72429848 glob_norm 0.517506123\n",
      "Iteration 50 L -4.68744087 loss -4.79090118 loss_ordinary 0.939201176 entropy_value 5.73010254 glob_norm 0.626437426\n",
      "Iteration 100 L -4.71479559 loss -4.81848574 loss_ordinary 0.91274178 entropy_value 5.7312274 glob_norm 0.467807293\n",
      "Iteration 150 L -4.67280865 loss -4.77928209 loss_ordinary 0.953850508 entropy_value 5.73313284 glob_norm 0.464246094\n",
      "Iteration 200 L -4.69405365 loss -4.80919 loss_ordinary 0.92934227 entropy_value 5.73853207 glob_norm 0.53632766\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.527776241 lambd_papr -0.102331996 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.69732857 loss -4.79442263 loss_ordinary 0.942687035 entropy_value 5.73710966 glob_norm 0.522778273\n",
      "Iteration 50 L -4.70788574 loss -4.82745314 loss_ordinary 0.908936381 entropy_value 5.73638964 glob_norm 0.531909406\n",
      "Iteration 100 L -4.76633263 loss -4.8367877 loss_ordinary 0.903455436 entropy_value 5.74024296 glob_norm 0.514361739\n",
      "Iteration 150 L -4.70083666 loss -4.79089308 loss_ordinary 0.949463844 entropy_value 5.74035692 glob_norm 0.368359149\n",
      "Iteration 200 L -4.73846245 loss -4.83021164 loss_ordinary 0.908400655 entropy_value 5.73861217 glob_norm 0.585865319\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0.547792196 lambd_papr -0.107770249 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70418024 loss -4.80415487 loss_ordinary 0.938808382 entropy_value 5.74296331 glob_norm 0.487596065\n",
      "Iteration 50 L -4.72250175 loss -4.80072689 loss_ordinary 0.936447084 entropy_value 5.73717403 glob_norm 0.43440333\n",
      "Iteration 100 L -4.75102568 loss -4.79168558 loss_ordinary 0.950562716 entropy_value 5.74224806 glob_norm 0.432011157\n",
      "Iteration 150 L -4.71572447 loss -4.78931379 loss_ordinary 0.953894556 entropy_value 5.74320841 glob_norm 0.473455042\n",
      "Iteration 200 L -4.68659163 loss -4.79819059 loss_ordinary 0.945850372 entropy_value 5.74404144 glob_norm 0.58583492\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.344994783 lambd_papr -0.113431677 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74814653 loss -4.84168911 loss_ordinary 0.900385499 entropy_value 5.74207449 glob_norm 0.389254689\n",
      "Iteration 50 L -4.74459314 loss -4.80290222 loss_ordinary 0.948177338 entropy_value 5.75108 glob_norm 0.529291809\n",
      "Iteration 100 L -4.69619 loss -4.79636574 loss_ordinary 0.951416075 entropy_value 5.74778175 glob_norm 0.651129305\n",
      "Iteration 150 L -4.71603918 loss -4.80835533 loss_ordinary 0.937044621 entropy_value 5.74540043 glob_norm 0.659760714\n",
      "Iteration 200 L -4.72968435 loss -4.79762173 loss_ordinary 0.951404214 entropy_value 5.74902582 glob_norm 0.374169827\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.351388454 lambd_papr -0.117007896 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68432713 loss -4.79233503 loss_ordinary 0.957923591 entropy_value 5.75025845 glob_norm 0.520038605\n",
      "Iteration 50 L -4.71476364 loss -4.79882479 loss_ordinary 0.955257177 entropy_value 5.75408173 glob_norm 0.342461\n",
      "Iteration 100 L -4.68503284 loss -4.76971149 loss_ordinary 0.984749675 entropy_value 5.75446081 glob_norm 0.569052458\n",
      "Iteration 150 L -4.77102757 loss -4.83368254 loss_ordinary 0.922296703 entropy_value 5.75597906 glob_norm 0.515046179\n",
      "Iteration 200 L -4.73420954 loss -4.83038044 loss_ordinary 0.915917516 entropy_value 5.74629784 glob_norm 0.304662257\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.291014433 lambd_papr -0.120661318 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72937059 loss -4.82061815 loss_ordinary 0.930334 entropy_value 5.75095177 glob_norm 0.509238958\n",
      "Iteration 50 L -4.75820732 loss -4.81094837 loss_ordinary 0.940475762 entropy_value 5.75142431 glob_norm 0.517392039\n",
      "Iteration 100 L -4.72533178 loss -4.82206106 loss_ordinary 0.931468 entropy_value 5.75352907 glob_norm 0.306792647\n",
      "Iteration 150 L -4.68368 loss -4.76265717 loss_ordinary 0.99964726 entropy_value 5.76230431 glob_norm 0.51193887\n",
      "Iteration 200 L -4.71586514 loss -4.79872847 loss_ordinary 0.950818121 entropy_value 5.74954653 glob_norm 0.621394515\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.510422707 lambd_papr -0.123696104 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72189856 loss -4.7797451 loss_ordinary 0.978432178 entropy_value 5.75817728 glob_norm 0.359787941\n",
      "Iteration 50 L -4.77087307 loss -4.81208563 loss_ordinary 0.947977483 entropy_value 5.76006269 glob_norm 0.588270366\n",
      "Iteration 100 L -4.71913242 loss -4.79217482 loss_ordinary 0.965904415 entropy_value 5.75807905 glob_norm 0.472192079\n",
      "Iteration 150 L -4.78714323 loss -4.79421568 loss_ordinary 0.967450559 entropy_value 5.7616663 glob_norm 0.72827822\n",
      "Iteration 200 L -4.72572517 loss -4.78261518 loss_ordinary 0.977649629 entropy_value 5.76026487 glob_norm 0.503231347\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0.4567976 lambd_papr -0.129034907 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67785597 loss -4.76712 loss_ordinary 0.993090153 entropy_value 5.76021 glob_norm 0.630435348\n",
      "Iteration 50 L -4.72156954 loss -4.77142525 loss_ordinary 0.991344273 entropy_value 5.7627697 glob_norm 0.478540838\n",
      "Iteration 100 L -4.68516874 loss -4.71388 loss_ordinary 1.0532124 entropy_value 5.76709223 glob_norm 0.468386918\n",
      "Iteration 150 L -4.68196297 loss -4.74740505 loss_ordinary 1.02140498 entropy_value 5.76881 glob_norm 0.593095422\n",
      "Iteration 200 L -4.68342924 loss -4.7390728 loss_ordinary 1.03527796 entropy_value 5.77435112 glob_norm 0.777210176\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0.396136284 lambd_papr -0.13382715 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.6870575 loss -4.79482651 loss_ordinary 0.977435172 entropy_value 5.7722621 glob_norm 0.624105632\n",
      "Iteration 50 L -4.72316456 loss -4.77781391 loss_ordinary 0.990448415 entropy_value 5.76826239 glob_norm 0.529593885\n",
      "Iteration 100 L -4.66998911 loss -4.71287441 loss_ordinary 1.06347954 entropy_value 5.77635384 glob_norm 0.469255567\n",
      "Iteration 150 L -4.71126366 loss -4.76146841 loss_ordinary 1.01111662 entropy_value 5.77258539 glob_norm 0.513685763\n",
      "Iteration 200 L -4.74812365 loss -4.77673 loss_ordinary 0.99544245 entropy_value 5.77217245 glob_norm 0.639134347\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0.38538146 lambd_papr -0.137995467 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74078798 loss -4.77111673 loss_ordinary 1.00375199 entropy_value 5.77486849 glob_norm 0.519601822\n",
      "Iteration 50 L -4.70190334 loss -4.77063847 loss_ordinary 1.00899279 entropy_value 5.77963114 glob_norm 0.555546701\n",
      "Iteration 100 L -4.68285084 loss -4.75429678 loss_ordinary 1.02296031 entropy_value 5.77725697 glob_norm 0.587159574\n",
      "Iteration 150 L -4.73332071 loss -4.7559433 loss_ordinary 1.02524519 entropy_value 5.78118849 glob_norm 0.402907491\n",
      "Iteration 200 L -4.72692156 loss -4.73565245 loss_ordinary 1.05065906 entropy_value 5.78631163 glob_norm 0.428325117\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0.186440706 lambd_papr -0.142062783 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67951775 loss -4.73152781 loss_ordinary 1.04696131 entropy_value 5.77848911 glob_norm 0.626184583\n",
      "Iteration 50 L -4.72253704 loss -4.72903395 loss_ordinary 1.05775452 entropy_value 5.78678846 glob_norm 0.575184345\n",
      "Iteration 100 L -4.69251347 loss -4.73609352 loss_ordinary 1.04329944 entropy_value 5.7793932 glob_norm 0.554512262\n",
      "Iteration 150 L -4.7419591 loss -4.72952509 loss_ordinary 1.05834568 entropy_value 5.78787041 glob_norm 0.56556958\n",
      "Iteration 200 L -4.78547716 loss -4.77741385 loss_ordinary 1.00606346 entropy_value 5.78347731 glob_norm 0.532229304\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.320275307 lambd_papr -0.144036382 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72577381 loss -4.75532579 loss_ordinary 1.02384663 entropy_value 5.77917194 glob_norm 0.567107737\n",
      "Iteration 50 L -4.79595375 loss -4.76142693 loss_ordinary 1.02152693 entropy_value 5.78295374 glob_norm 0.779303372\n",
      "Iteration 100 L -4.7141037 loss -4.71322727 loss_ordinary 1.07298172 entropy_value 5.78620911 glob_norm 0.568881929\n",
      "Iteration 150 L -4.71473455 loss -4.74475241 loss_ordinary 1.04973888 entropy_value 5.79449081 glob_norm 0.81531024\n",
      "Iteration 200 L -4.68524647 loss -4.73454523 loss_ordinary 1.05460143 entropy_value 5.78914642 glob_norm 0.45866403\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -0.0126955509 lambd_papr -0.147436872 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.66180515 loss -4.69930935 loss_ordinary 1.08809459 entropy_value 5.78740406 glob_norm 0.50371033\n",
      "Iteration 50 L -4.62513304 loss -4.68705559 loss_ordinary 1.10251629 entropy_value 5.78957176 glob_norm 0.475216329\n",
      "Iteration 100 L -4.71558285 loss -4.71550703 loss_ordinary 1.07924497 entropy_value 5.79475164 glob_norm 0.809323549\n",
      "Iteration 150 L -4.66631413 loss -4.71995115 loss_ordinary 1.07237923 entropy_value 5.79233027 glob_norm 0.380261719\n",
      "Iteration 200 L -4.71083164 loss -4.73339462 loss_ordinary 1.06000435 entropy_value 5.79339933 glob_norm 0.683328927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power 0.0415127277 lambd_papr -0.147301674 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7299943 loss -4.73087072 loss_ordinary 1.06466115 entropy_value 5.79553175 glob_norm 0.572383642\n",
      "Iteration 50 L -4.65846491 loss -4.71421 loss_ordinary 1.07486725 entropy_value 5.78907776 glob_norm 0.473840028\n",
      "Iteration 100 L -4.65502739 loss -4.7108283 loss_ordinary 1.08490181 entropy_value 5.79573 glob_norm 0.634271502\n",
      "Iteration 150 L -4.73075438 loss -4.76128817 loss_ordinary 1.03176427 entropy_value 5.79305267 glob_norm 0.521574616\n",
      "Iteration 200 L -4.76322174 loss -4.73541117 loss_ordinary 1.05672443 entropy_value 5.79213572 glob_norm 0.5238415\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power -0.178673744 lambd_papr -0.147745088 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76360512 loss -4.74391842 loss_ordinary 1.05636835 entropy_value 5.80028677 glob_norm 0.571472883\n",
      "Iteration 50 L -4.69705486 loss -4.69546127 loss_ordinary 1.10248518 entropy_value 5.79794645 glob_norm 0.740815461\n",
      "Iteration 100 L -4.72543812 loss -4.74653387 loss_ordinary 1.04670966 entropy_value 5.79324389 glob_norm 0.480544388\n",
      "Iteration 150 L -4.71893024 loss -4.7228322 loss_ordinary 1.07577646 entropy_value 5.79860878 glob_norm 0.475998253\n",
      "Iteration 200 L -4.72454834 loss -4.71278286 loss_ordinary 1.08150983 entropy_value 5.79429293 glob_norm 0.58314687\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.223968506 lambd_papr -0.145830914 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.69634819 loss -4.71397829 loss_ordinary 1.08059812 entropy_value 5.79457617 glob_norm 0.721943915\n",
      "Iteration 50 L -4.73739767 loss -4.74061251 loss_ordinary 1.05706 entropy_value 5.79767275 glob_norm 0.651097476\n",
      "Iteration 100 L -4.78025436 loss -4.74378061 loss_ordinary 1.04945838 entropy_value 5.79323912 glob_norm 0.817807555\n",
      "Iteration 150 L -4.71721697 loss -4.6801281 loss_ordinary 1.11741388 entropy_value 5.7975421 glob_norm 0.660662174\n",
      "Iteration 200 L -4.77343512 loss -4.7180028 loss_ordinary 1.08123708 entropy_value 5.79923964 glob_norm 0.85084337\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power 0.156033039 lambd_papr -0.148237541 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.65919065 loss -4.71227837 loss_ordinary 1.08572245 entropy_value 5.79800081 glob_norm 0.764999688\n",
      "Iteration 50 L -4.70649767 loss -4.7361145 loss_ordinary 1.05786598 entropy_value 5.7939806 glob_norm 0.592663944\n",
      "Iteration 100 L -4.71289396 loss -4.73376894 loss_ordinary 1.06571853 entropy_value 5.79948759 glob_norm 0.721193492\n",
      "Iteration 150 L -4.67567348 loss -4.69886303 loss_ordinary 1.1019479 entropy_value 5.80081081 glob_norm 0.452455163\n",
      "Iteration 200 L -4.76760054 loss -4.71001 loss_ordinary 1.08951044 entropy_value 5.79952049 glob_norm 0.687739849\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.118550062 lambd_papr -0.149919212 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70580339 loss -4.72268057 loss_ordinary 1.08064985 entropy_value 5.80333042 glob_norm 0.769155264\n",
      "Iteration 50 L -4.73205614 loss -4.73363543 loss_ordinary 1.06097031 entropy_value 5.79460573 glob_norm 0.716673493\n",
      "Iteration 100 L -4.73763514 loss -4.74137878 loss_ordinary 1.05590796 entropy_value 5.79728651 glob_norm 0.619462669\n",
      "Iteration 150 L -4.63971615 loss -4.68608093 loss_ordinary 1.11360288 entropy_value 5.79968357 glob_norm 0.754313052\n",
      "Iteration 200 L -4.75797415 loss -4.73225164 loss_ordinary 1.06515741 entropy_value 5.79740906 glob_norm 0.617187321\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0.0731878281 lambd_papr -0.151200742 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.80123901 loss -4.71400356 loss_ordinary 1.09024179 entropy_value 5.804245 glob_norm 0.767067\n",
      "Iteration 50 L -4.79564428 loss -4.72611904 loss_ordinary 1.07832968 entropy_value 5.8044486 glob_norm 0.704098821\n",
      "Iteration 100 L -4.6993165 loss -4.71434927 loss_ordinary 1.09077203 entropy_value 5.80512142 glob_norm 0.644328952\n",
      "Iteration 150 L -4.70721674 loss -4.70854807 loss_ordinary 1.09617305 entropy_value 5.80472136 glob_norm 0.738713\n",
      "Iteration 200 L -4.77389765 loss -4.68569946 loss_ordinary 1.12411845 entropy_value 5.80981827 glob_norm 0.842830479\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0.0201921463 lambd_papr -0.151994273 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72641325 loss -4.74937057 loss_ordinary 1.05594778 entropy_value 5.80531836 glob_norm 0.553811\n",
      "Iteration 50 L -4.781 loss -4.72468233 loss_ordinary 1.07744932 entropy_value 5.80213165 glob_norm 0.727565944\n",
      "Iteration 100 L -4.71746445 loss -4.6962347 loss_ordinary 1.11747062 entropy_value 5.81370544 glob_norm 0.607370079\n",
      "Iteration 150 L -4.7505393 loss -4.707335 loss_ordinary 1.10012352 entropy_value 5.8074584 glob_norm 0.728444278\n",
      "Iteration 200 L -4.7339735 loss -4.73032141 loss_ordinary 1.07873118 entropy_value 5.80905247 glob_norm 0.516883194\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0.0347967148 lambd_papr -0.152213857 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71661901 loss -4.72002125 loss_ordinary 1.087026 entropy_value 5.80704689 glob_norm 0.610642612\n",
      "Iteration 50 L -4.68686724 loss -4.67790556 loss_ordinary 1.1266346 entropy_value 5.80454 glob_norm 0.661708117\n",
      "Iteration 100 L -4.70650625 loss -4.70451784 loss_ordinary 1.1021899 entropy_value 5.80670786 glob_norm 0.575226128\n",
      "Iteration 150 L -4.75046 loss -4.733953 loss_ordinary 1.0714829 entropy_value 5.80543613 glob_norm 0.712450147\n",
      "Iteration 200 L -4.74262333 loss -4.72599077 loss_ordinary 1.07833099 entropy_value 5.80432224 glob_norm 0.62999922\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power -0.0164487362 lambd_papr -0.152593404 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68983126 loss -4.69374132 loss_ordinary 1.1160152 entropy_value 5.80975676 glob_norm 0.486691535\n",
      "Iteration 50 L -4.77813148 loss -4.72539806 loss_ordinary 1.08563542 entropy_value 5.81103373 glob_norm 0.559479773\n",
      "Iteration 100 L -4.71539307 loss -4.67602587 loss_ordinary 1.13228095 entropy_value 5.80830669 glob_norm 0.524626672\n",
      "Iteration 150 L -4.69869375 loss -4.68723106 loss_ordinary 1.12927747 entropy_value 5.81650829 glob_norm 0.534926474\n",
      "Iteration 200 L -4.68372774 loss -4.69589043 loss_ordinary 1.11854947 entropy_value 5.81444025 glob_norm 0.521608472\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power -0.355542898 lambd_papr -0.152413458 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.6726532 loss -4.67256403 loss_ordinary 1.14416 entropy_value 5.8167243 glob_norm 0.48889029\n",
      "Iteration 50 L -4.68075085 loss -4.65690184 loss_ordinary 1.15320659 entropy_value 5.81010818 glob_norm 0.493195772\n",
      "Iteration 100 L -4.68294525 loss -4.71187 loss_ordinary 1.09898865 entropy_value 5.81085873 glob_norm 0.576449692\n",
      "Iteration 150 L -4.80969191 loss -4.71191502 loss_ordinary 1.09805346 entropy_value 5.80996895 glob_norm 0.893776894\n",
      "Iteration 200 L -4.72654915 loss -4.68796206 loss_ordinary 1.12562907 entropy_value 5.81359148 glob_norm 0.860434771\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power -0.236899853 lambd_papr -0.148512051 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70852709 loss -4.6693821 loss_ordinary 1.13894033 entropy_value 5.80832243 glob_norm 0.615436673\n",
      "Iteration 50 L -4.69714928 loss -4.70052195 loss_ordinary 1.1083616 entropy_value 5.80888319 glob_norm 0.508809507\n",
      "Iteration 100 L -4.74682283 loss -4.69721413 loss_ordinary 1.10963809 entropy_value 5.80685234 glob_norm 0.661459625\n",
      "Iteration 150 L -4.72491932 loss -4.70641327 loss_ordinary 1.10127318 entropy_value 5.80768633 glob_norm 0.481509477\n",
      "Iteration 200 L -4.6973381 loss -4.67211723 loss_ordinary 1.13447654 entropy_value 5.80659389 glob_norm 0.649681211\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power -0.269208908 lambd_papr -0.14590472 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76296091 loss -4.72828913 loss_ordinary 1.07534802 entropy_value 5.80363703 glob_norm 0.49534139\n",
      "Iteration 50 L -4.75528526 loss -4.7277751 loss_ordinary 1.07424104 entropy_value 5.80201626 glob_norm 0.597840607\n",
      "Iteration 100 L -4.66475773 loss -4.66836119 loss_ordinary 1.13741803 entropy_value 5.80577946 glob_norm 0.591162145\n",
      "Iteration 150 L -4.71446562 loss -4.72252035 loss_ordinary 1.08318794 entropy_value 5.80570841 glob_norm 0.572912335\n",
      "Iteration 200 L -4.69774532 loss -4.69978 loss_ordinary 1.10178554 entropy_value 5.80156565 glob_norm 0.50820744\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0.00147390366 lambd_papr -0.142932907 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71675396 loss -4.70785427 loss_ordinary 1.09367096 entropy_value 5.80152512 glob_norm 0.469712615\n",
      "Iteration 50 L -4.73513746 loss -4.71171522 loss_ordinary 1.09332943 entropy_value 5.80504465 glob_norm 0.578340173\n",
      "Iteration 100 L -4.72763586 loss -4.75103569 loss_ordinary 1.05003405 entropy_value 5.80106974 glob_norm 0.749665618\n",
      "Iteration 150 L -4.75349569 loss -4.73889875 loss_ordinary 1.05571735 entropy_value 5.79461622 glob_norm 0.544766247\n",
      "Iteration 200 L -4.71224928 loss -4.69239807 loss_ordinary 1.10835993 entropy_value 5.80075788 glob_norm 0.778038144\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power -0.292696 lambd_papr -0.142949224 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76511192 loss -4.73122215 loss_ordinary 1.06788 entropy_value 5.79910231 glob_norm 0.51039046\n",
      "Iteration 50 L -4.71124458 loss -4.73016214 loss_ordinary 1.06861317 entropy_value 5.7987752 glob_norm 0.745542407\n",
      "Iteration 100 L -4.65646 loss -4.71002531 loss_ordinary 1.08785093 entropy_value 5.79787636 glob_norm 0.581178069\n",
      "Iteration 150 L -4.74834156 loss -4.75037622 loss_ordinary 1.05083096 entropy_value 5.80120707 glob_norm 0.478021413\n",
      "Iteration 200 L -4.71199226 loss -4.7371459 loss_ordinary 1.06110454 entropy_value 5.79825068 glob_norm 0.588624537\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.12005496 lambd_papr -0.139698729 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.73703671 loss -4.73468 loss_ordinary 1.06491661 entropy_value 5.79959679 glob_norm 0.580666661\n",
      "Iteration 50 L -4.72713137 loss -4.72593784 loss_ordinary 1.07105124 entropy_value 5.79698896 glob_norm 0.488113463\n",
      "Iteration 100 L -4.76741362 loss -4.72681665 loss_ordinary 1.07343388 entropy_value 5.80025053 glob_norm 0.78743732\n",
      "Iteration 150 L -4.74631357 loss -4.7393856 loss_ordinary 1.05717671 entropy_value 5.79656219 glob_norm 0.804165423\n",
      "Iteration 200 L -4.80322552 loss -4.77346849 loss_ordinary 1.02059257 entropy_value 5.79406118 glob_norm 0.504557\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power 0.147619486 lambd_papr -0.141035989 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71847868 loss -4.71662617 loss_ordinary 1.07375944 entropy_value 5.79038525 glob_norm 0.59846133\n",
      "Iteration 50 L -4.7589941 loss -4.7157 loss_ordinary 1.07917118 entropy_value 5.79487133 glob_norm 0.498485148\n",
      "Iteration 100 L -4.76135778 loss -4.75971127 loss_ordinary 1.0354718 entropy_value 5.79518318 glob_norm 0.669352174\n",
      "Iteration 150 L -4.68757296 loss -4.70470524 loss_ordinary 1.09507954 entropy_value 5.79978466 glob_norm 0.617906451\n",
      "Iteration 200 L -4.76739836 loss -4.76023149 loss_ordinary 1.03605747 entropy_value 5.79628944 glob_norm 0.464188\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.205076933 lambd_papr -0.142685205 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71328306 loss -4.75323915 loss_ordinary 1.0506593 entropy_value 5.80389833 glob_norm 0.562016666\n",
      "Iteration 50 L -4.69092846 loss -4.71144438 loss_ordinary 1.08800793 entropy_value 5.7994523 glob_norm 0.449241489\n",
      "Iteration 100 L -4.72953749 loss -4.70883799 loss_ordinary 1.08562899 entropy_value 5.79446697 glob_norm 0.733664393\n",
      "Iteration 150 L -4.68645525 loss -4.69286108 loss_ordinary 1.10376751 entropy_value 5.79662848 glob_norm 0.636304557\n",
      "Iteration 200 L -4.74025679 loss -4.71549749 loss_ordinary 1.09166849 entropy_value 5.8071661 glob_norm 0.711887\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.138308287 lambd_papr -0.144983217 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.79231882 loss -4.74587 loss_ordinary 1.05657661 entropy_value 5.80244684 glob_norm 0.621754229\n",
      "Iteration 50 L -4.73571253 loss -4.69557667 loss_ordinary 1.10901129 entropy_value 5.80458784 glob_norm 0.53042537\n",
      "Iteration 100 L -4.66083145 loss -4.71265411 loss_ordinary 1.09170926 entropy_value 5.80436325 glob_norm 0.417118371\n",
      "Iteration 150 L -4.68739462 loss -4.6983819 loss_ordinary 1.11063886 entropy_value 5.809021 glob_norm 0.686091\n",
      "Iteration 200 L -4.68722486 loss -4.70722485 loss_ordinary 1.09975934 entropy_value 5.80698442 glob_norm 0.508275688\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0.045648098 lambd_papr -0.143428743 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.65423727 loss -4.67900181 loss_ordinary 1.1226939 entropy_value 5.80169582 glob_norm 0.553384304\n",
      "Iteration 50 L -4.72346 loss -4.69588804 loss_ordinary 1.10703409 entropy_value 5.80292225 glob_norm 0.620219529\n",
      "Iteration 100 L -4.62421322 loss -4.6710844 loss_ordinary 1.1306051 entropy_value 5.80168962 glob_norm 0.570018\n",
      "Iteration 150 L -4.73394442 loss -4.70313215 loss_ordinary 1.10142732 entropy_value 5.80455971 glob_norm 0.59632349\n",
      "Iteration 200 L -4.75719452 loss -4.70431137 loss_ordinary 1.09679091 entropy_value 5.80110216 glob_norm 0.571158588\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power -0.197713852 lambd_papr -0.143943325 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70717859 loss -4.68960142 loss_ordinary 1.11843932 entropy_value 5.80804062 glob_norm 0.579963744\n",
      "Iteration 50 L -4.82836771 loss -4.73652792 loss_ordinary 1.06804025 entropy_value 5.80456829 glob_norm 0.696831346\n",
      "Iteration 100 L -4.65604 loss -4.70343256 loss_ordinary 1.09925246 entropy_value 5.80268478 glob_norm 0.561975241\n",
      "Iteration 150 L -4.68456841 loss -4.72100782 loss_ordinary 1.08400798 entropy_value 5.80501556 glob_norm 0.540056\n",
      "Iteration 200 L -4.70996 loss -4.70963049 loss_ordinary 1.09474397 entropy_value 5.80437469 glob_norm 0.691169143\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power -0.0969131 lambd_papr -0.141707823 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76138306 loss -4.73971748 loss_ordinary 1.05898988 entropy_value 5.79870749 glob_norm 0.486180484\n",
      "Iteration 50 L -4.72290707 loss -4.74578762 loss_ordinary 1.05524838 entropy_value 5.80103588 glob_norm 0.53966254\n",
      "Iteration 100 L -4.7079463 loss -4.70474052 loss_ordinary 1.09364212 entropy_value 5.79838276 glob_norm 0.81839329\n",
      "Iteration 150 L -4.73103857 loss -4.70775843 loss_ordinary 1.09498155 entropy_value 5.80274 glob_norm 0.559492767\n",
      "Iteration 200 L -4.76771545 loss -4.75670624 loss_ordinary 1.04081392 entropy_value 5.79752 glob_norm 0.598360777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.175009727 lambd_papr -0.140608758 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67917633 loss -4.7263279 loss_ordinary 1.07308948 entropy_value 5.7994175 glob_norm 0.453017473\n",
      "Iteration 50 L -4.71014404 loss -4.71306467 loss_ordinary 1.08177495 entropy_value 5.79484 glob_norm 0.634655118\n",
      "Iteration 100 L -4.72735357 loss -4.73994112 loss_ordinary 1.05446935 entropy_value 5.79441071 glob_norm 0.458836913\n",
      "Iteration 150 L -4.67830133 loss -4.72325087 loss_ordinary 1.07261586 entropy_value 5.79586697 glob_norm 0.451951385\n",
      "Iteration 200 L -4.6628871 loss -4.68762064 loss_ordinary 1.11103439 entropy_value 5.79865503 glob_norm 0.490340799\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.171746731 lambd_papr -0.138618067 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67586374 loss -4.68491173 loss_ordinary 1.11226249 entropy_value 5.79717398 glob_norm 0.541890204\n",
      "Iteration 50 L -4.68624496 loss -4.69357586 loss_ordinary 1.09909427 entropy_value 5.79267025 glob_norm 0.577327192\n",
      "Iteration 100 L -4.7551918 loss -4.75300074 loss_ordinary 1.04592526 entropy_value 5.79892588 glob_norm 0.483160675\n",
      "Iteration 150 L -4.71173477 loss -4.70369053 loss_ordinary 1.09051096 entropy_value 5.79420137 glob_norm 0.485738635\n",
      "Iteration 200 L -4.72439289 loss -4.71787834 loss_ordinary 1.08045316 entropy_value 5.79833174 glob_norm 0.572705328\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power -0.572414398 lambd_papr -0.140577495 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.77345419 loss -4.75006437 loss_ordinary 1.05191946 entropy_value 5.80198383 glob_norm 0.618096\n",
      "Iteration 50 L -4.75525093 loss -4.72458363 loss_ordinary 1.0769726 entropy_value 5.80155611 glob_norm 0.655790567\n",
      "Iteration 100 L -4.74975348 loss -4.72363091 loss_ordinary 1.07233262 entropy_value 5.79596329 glob_norm 0.578256607\n",
      "Iteration 150 L -4.74673033 loss -4.72663116 loss_ordinary 1.06929278 entropy_value 5.79592419 glob_norm 0.874792159\n",
      "Iteration 200 L -4.75141859 loss -4.75528049 loss_ordinary 1.03507912 entropy_value 5.7903595 glob_norm 0.513352156\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power 0.0935349464 lambd_papr -0.134027317 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7056284 loss -4.72156239 loss_ordinary 1.06763768 entropy_value 5.78920031 glob_norm 0.498997509\n",
      "Iteration 50 L -4.75657082 loss -4.7376585 loss_ordinary 1.05036783 entropy_value 5.78802633 glob_norm 0.50928992\n",
      "Iteration 100 L -4.67986298 loss -4.70102119 loss_ordinary 1.09465015 entropy_value 5.79567146 glob_norm 0.747855544\n",
      "Iteration 150 L -4.74447107 loss -4.75809669 loss_ordinary 1.03276539 entropy_value 5.79086208 glob_norm 0.463453472\n",
      "Iteration 200 L -4.80541658 loss -4.77426863 loss_ordinary 1.01401436 entropy_value 5.78828287 glob_norm 0.61918819\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.145387173 lambd_papr -0.135100856 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7008 loss -4.71771526 loss_ordinary 1.0707351 entropy_value 5.78845024 glob_norm 0.659473419\n",
      "Iteration 50 L -4.69491577 loss -4.7111187 loss_ordinary 1.07900214 entropy_value 5.7901206 glob_norm 0.480579525\n",
      "Iteration 100 L -4.70430136 loss -4.74218512 loss_ordinary 1.0417372 entropy_value 5.7839222 glob_norm 0.568862677\n",
      "Iteration 150 L -4.80303764 loss -4.73919 loss_ordinary 1.05414975 entropy_value 5.79334 glob_norm 0.694581389\n",
      "Iteration 200 L -4.74020767 loss -4.73012 loss_ordinary 1.06249082 entropy_value 5.79261065 glob_norm 0.533692539\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0.111536741 lambd_papr -0.136774525 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71816254 loss -4.72479105 loss_ordinary 1.06892085 entropy_value 5.79371214 glob_norm 0.548742533\n",
      "Iteration 50 L -4.78396654 loss -4.74421883 loss_ordinary 1.04642463 entropy_value 5.79064322 glob_norm 0.69355\n",
      "Iteration 100 L -4.70829105 loss -4.73849058 loss_ordinary 1.05837524 entropy_value 5.79686594 glob_norm 0.451821744\n",
      "Iteration 150 L -4.76460457 loss -4.74170923 loss_ordinary 1.05100346 entropy_value 5.79271269 glob_norm 0.693939865\n",
      "Iteration 200 L -4.75428963 loss -4.718606 loss_ordinary 1.07127011 entropy_value 5.78987646 glob_norm 0.829583168\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.00827169418 lambd_papr -0.138062373 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T11:05:55.594318Z",
     "start_time": "2026-02-05T11:05:55.042326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.GradientTape(persistent=False) as tape:\n",
    "#     tape.watch(model.trainable_variables)  # Ensure variables are watched if needed, but no gradients will be calculated\n",
    "    _,_,_,shaping_probs = model(No)\n",
    "\n",
    "\n",
    "# Define constellation points (complex numbers)\n",
    "points = model.modulator.constellation_real.numpy()+ 1j*model.modulator.constellation_imag.numpy()\n",
    "\n",
    "# Define probabilities for each point\n",
    "probabilities = shaping_probs.numpy()\n",
    "\n",
    "# plt.savefig('const.pdf')\n",
    "\n",
    "# Normalize the constellation\n",
    "normalized_points = normalize_constellation(points, probabilities)\n",
    "\n",
    "title_plot = f\"Normalized Constellation (SNR={snr_db} dB, PAPR={papr_threshold_db} dB, Excess power target={excess_power_target} B)\"\n",
    "# Plot the constellation\n",
    "plot_constellation_wlabels(normalized_points, probabilities, title_plot)\n",
    "file_name = f\"snr_{snr_db}_PAPR_{papr_threshold_db}_target_{excess_power_target}\"\n",
    "print(probabilities)\n",
    "print(file_name)\n"
   ],
   "id": "a1005cf3b0059289",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00747281 0.00845111 0.00831834 0.00833981 0.00852739 0.01209077\n",
      "  0.01578151 0.01451036 0.00848929 0.01605102 0.03814739 0.02842476\n",
      "  0.0085794  0.01505467 0.0282027  0.02355867 0.00747281 0.00845111\n",
      "  0.00831834 0.00833981 0.00852739 0.01209077 0.01578151 0.01451036\n",
      "  0.00848929 0.01605102 0.03814739 0.02842476 0.0085794  0.01505467\n",
      "  0.0282027  0.02355867 0.00747281 0.00845111 0.00831834 0.00833981\n",
      "  0.00852739 0.01209077 0.01578151 0.01451036 0.00848929 0.01605102\n",
      "  0.03814739 0.02842476 0.0085794  0.01505467 0.0282027  0.02355867\n",
      "  0.00747281 0.00845111 0.00831834 0.00833981 0.00852739 0.01209077\n",
      "  0.01578151 0.01451036 0.00848929 0.01605102 0.03814739 0.02842476\n",
      "  0.0085794  0.01505467 0.0282027  0.02355867]]\n",
      "snr_15_PAPR_6.0_target_-3.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T10:40:25.963673Z",
     "start_time": "2026-02-05T10:40:25.961695Z"
    }
   },
   "cell_type": "markdown",
   "source": "### Training for several SNR and PAPR values",
   "id": "5200e4ffd808cf74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T19:56:35.846102Z",
     "start_time": "2026-02-04T19:56:35.839659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def run_experiment(snr_db, papr_threshold_db):\n",
    "    print(f\"\\n===== Running SNR={snr_db} dB | PAPR={papr_threshold_db} dB =====\\n\")\n",
    "\n",
    "    No_ = tf.convert_to_tensor(1/(10**(snr_db/10)),tf.float32)\n",
    "    papr_threshold_ = tf.math.pow(10.0, papr_threshold_db / 10.0)\n",
    "    excess_power_target_ = -3.5 #B\n",
    "\n",
    "\n",
    "\n",
    "    lambd_papr = tf.Variable(tf.constant(0.0, tf.float32), trainable=False, dtype=tf.float32)\n",
    "    mu = tf.Variable(0.01, trainable=False, dtype=tf.float32)\n",
    "    step = tf.constant(0, tf.int32)\n",
    "\n",
    "    for i in range(50):\n",
    "        if i == 0:\n",
    "            num_it = 5000\n",
    "        else:\n",
    "            num_it = 500\n",
    "        c_excess_power, step = _inner_loop(lambd_papr, mu, step,\n",
    "                                           num_it, excess_power_target_,\n",
    "                                           papr_threshold_, No_)\n",
    "\n",
    "        # Update Lagrange multipliers\n",
    "        tf.print('-------------------------------------------------------')\n",
    "        tf.print('-------------------------------------------------------')\n",
    "        tf.print('Progress ',i,' % ','c_excess_power',c_excess_power,'lambd_papr',lambd_papr,'mu',mu)\n",
    "        tf.print('-------------------------------------------------------')\n",
    "        tf.print('-------------------------------------------------------')\n",
    "        lambd_papr = lambd_papr - mu * c_excess_power\n",
    "\n",
    "        # Update penalty parameter\n",
    "        mu = mu*1.003\n",
    "\n",
    "    # ------------------\n",
    "    # Save constellation\n",
    "    # ------------------\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, _, _, shaping_probs = model(No_)\n",
    "\n",
    "    points = (\n",
    "        model.modulator.constellation_real.numpy()\n",
    "        + 1j * model.modulator.constellation_imag.numpy()\n",
    "    )\n",
    "    probs = shaping_probs.numpy()\n",
    "\n",
    "    normalized_points = normalize_constellation(points, probs)\n",
    "\n",
    "    exp_name = f\"snr_{snr_db}_papr_{papr_threshold_db}\"\n",
    "    # np.save(f\"{RESULTS_DIR}/{exp_name}_points.npy\", normalized_points)\n",
    "    # np.save(f\"{RESULTS_DIR}/{exp_name}_probs.npy\", probs)\n",
    "\n",
    "    plt.figure()\n",
    "    plot_constellation_wlabels(\n",
    "        normalized_points,\n",
    "        probs,\n",
    "        f\"SNR={snr_db} dB, PAPR={papr_threshold_db} dB\"\n",
    "    )\n",
    "    plt.savefig(f\"{RESULTS_DIR}/{exp_name}_constellation.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------\n",
    "    # Compute & save CCDF\n",
    "    # ------------------\n",
    "    powers = tf.reshape(\n",
    "        model.compute_power_to_average_power_samples(), [-1]\n",
    "    )\n",
    "    powers_db = 10 * tf.math.log(powers + 1e-12) / tf.math.log(10.)\n",
    "\n",
    "    x_sorted = np.sort(powers_db.numpy())\n",
    "    ccdf = 1.0 - np.arange(1, len(x_sorted) + 1) / len(x_sorted)\n",
    "\n",
    "    np.savez(\n",
    "        f\"{RESULTS_DIR}/{exp_name}.npz\",\n",
    "        snr_db=snr_db,\n",
    "        papr_db=papr_threshold_db,\n",
    "        constellation_points=normalized_points,\n",
    "        constellation_probabilities=probs,\n",
    "        ccdf_x_db=x_sorted,\n",
    "        ccdf_y=ccdf\n",
    "    )\n",
    "\n",
    "\n",
    "    # np.save(f\"{RESULTS_DIR}/{exp_name}_ccdf_x.npy\", x_sorted)\n",
    "    # np.save(f\"{RESULTS_DIR}/{exp_name}_ccdf_y.npy\", ccdf)\n",
    "\n",
    "\n",
    "    print(f\"Finished {exp_name}\")\n"
   ],
   "id": "1de75d6b05dccb63",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T20:16:11.894433Z",
     "start_time": "2026-02-04T19:56:38.900365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snr_list = [13, 15, 17]\n",
    "papr_list = [6.0, 7.0, 8.0]\n",
    "\n",
    "N = 64  # Number of classes (symbols)\n",
    "bits_per_symbol = int(np.log2(N))\n",
    "parity_k = 2\n",
    "use_upsampling_filtering = True  # Remove 'false' this after testing without upsampling and filtering\n",
    "constellation = symbol_points_qam64\n",
    "\n",
    "tau = 10\n",
    "snr_db = 15\n",
    "No = tf.convert_to_tensor(1/(10**(snr_db/10)),tf.float32)\n",
    "# Batch size\n",
    "batch_size = 25\n",
    "block_size = 200\n",
    "model = EndToEndSystem_bitwise(N, constellation,\n",
    "                                batch_size, block_size,\n",
    "                               bits_per_symbol, parity_k,\n",
    "                               use_upsampling_filtering, tau)\n",
    "_,_,_,_ = model(No)\n",
    "initial_weights = model.get_weights()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "RESULTS_DIR = \"results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "for snr_db in snr_list:\n",
    "    for papr_db in papr_list:\n",
    "        model.set_weights(initial_weights)\n",
    "        optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "        run_experiment(snr_db, papr_db)\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"ALL EXPERIMENTS FINISHED\")\n"
   ],
   "id": "f0d77769c1f86f29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running SNR=13 dB | PAPR=6.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0203832667 loss 0.0187584907 loss_ordinary 6.00994205 entropy_value 5.99118328 glob_norm 0.632064879\n",
      "Iteration 50 L -2.04581642 loss -2.04705095 loss_ordinary 3.92117763 entropy_value 5.96822834 glob_norm 0.475318789\n",
      "Iteration 100 L -3.34753 loss -3.34753 loss_ordinary 2.60504293 entropy_value 5.95257282 glob_norm 0.327991843\n",
      "Iteration 150 L -3.70779157 loss -3.70840478 loss_ordinary 2.24957919 entropy_value 5.95798397 glob_norm 0.302352\n",
      "Iteration 200 L -3.77171421 loss -3.77321053 loss_ordinary 2.17585087 entropy_value 5.94906139 glob_norm 0.38323155\n",
      "Iteration 250 L -3.83674622 loss -3.83984184 loss_ordinary 2.09005308 entropy_value 5.92989492 glob_norm 0.405189902\n",
      "Iteration 300 L -3.89600182 loss -3.89901519 loss_ordinary 2.00788164 entropy_value 5.90689659 glob_norm 0.282104671\n",
      "Iteration 350 L -3.92744398 loss -3.93254972 loss_ordinary 1.94035852 entropy_value 5.87290812 glob_norm 0.373495787\n",
      "Iteration 400 L -4.01752329 loss -4.0238328 loss_ordinary 1.80503988 entropy_value 5.8288722 glob_norm 0.397715539\n",
      "Iteration 450 L -4.09908867 loss -4.10985231 loss_ordinary 1.66417491 entropy_value 5.77402735 glob_norm 0.424233586\n",
      "Iteration 500 L -4.13897562 loss -4.15190887 loss_ordinary 1.56780469 entropy_value 5.71971321 glob_norm 0.287063628\n",
      "Iteration 550 L -4.17111588 loss -4.18577623 loss_ordinary 1.48972762 entropy_value 5.67550373 glob_norm 0.453678787\n",
      "Iteration 600 L -4.21054792 loss -4.22659826 loss_ordinary 1.40966964 entropy_value 5.63626766 glob_norm 0.416947216\n",
      "Iteration 650 L -4.26843309 loss -4.28486156 loss_ordinary 1.3160578 entropy_value 5.60091972 glob_norm 0.30113\n",
      "Iteration 700 L -4.25587702 loss -4.27222729 loss_ordinary 1.31432772 entropy_value 5.586555 glob_norm 0.275298685\n",
      "Iteration 750 L -4.24202538 loss -4.25945568 loss_ordinary 1.28426516 entropy_value 5.5437212 glob_norm 0.424965829\n",
      "Iteration 800 L -4.27851534 loss -4.2976594 loss_ordinary 1.23570585 entropy_value 5.53336477 glob_norm 0.442504436\n",
      "Iteration 850 L -4.28725243 loss -4.30551291 loss_ordinary 1.20150161 entropy_value 5.50701427 glob_norm 0.490067273\n",
      "Iteration 900 L -4.28235435 loss -4.30284309 loss_ordinary 1.19258368 entropy_value 5.49542713 glob_norm 0.55785352\n",
      "Iteration 950 L -4.30098152 loss -4.32103634 loss_ordinary 1.16499555 entropy_value 5.48603201 glob_norm 0.495583981\n",
      "Iteration 1000 L -4.31167173 loss -4.33161879 loss_ordinary 1.14763951 entropy_value 5.47925806 glob_norm 0.278153181\n",
      "Iteration 1050 L -4.31302357 loss -4.33145857 loss_ordinary 1.12677372 entropy_value 5.4582324 glob_norm 0.357822657\n",
      "Iteration 1100 L -4.31547308 loss -4.33584785 loss_ordinary 1.13713849 entropy_value 5.47298622 glob_norm 0.469715238\n",
      "Iteration 1150 L -4.33995962 loss -4.36136532 loss_ordinary 1.07761991 entropy_value 5.43898487 glob_norm 0.500934899\n",
      "Iteration 1200 L -4.30296 loss -4.32440662 loss_ordinary 1.12408602 entropy_value 5.44849253 glob_norm 0.290226966\n",
      "Iteration 1250 L -4.28961182 loss -4.31119442 loss_ordinary 1.12982404 entropy_value 5.44101906 glob_norm 0.391244352\n",
      "Iteration 1300 L -4.31651258 loss -4.33872366 loss_ordinary 1.10272098 entropy_value 5.44144487 glob_norm 0.628349185\n",
      "Iteration 1350 L -4.31790543 loss -4.34081411 loss_ordinary 1.10046208 entropy_value 5.44127607 glob_norm 0.635130942\n",
      "Iteration 1400 L -4.28487349 loss -4.30670595 loss_ordinary 1.12636077 entropy_value 5.43306684 glob_norm 0.373119\n",
      "Iteration 1450 L -4.31234932 loss -4.33415461 loss_ordinary 1.0927999 entropy_value 5.42695427 glob_norm 0.451167792\n",
      "Iteration 1500 L -4.28753519 loss -4.30936432 loss_ordinary 1.11321199 entropy_value 5.42257643 glob_norm 0.479659826\n",
      "Iteration 1550 L -4.26247454 loss -4.28590965 loss_ordinary 1.15435719 entropy_value 5.44026661 glob_norm 0.431679398\n",
      "Iteration 1600 L -4.30412579 loss -4.32511234 loss_ordinary 1.10393834 entropy_value 5.42905045 glob_norm 0.445773214\n",
      "Iteration 1650 L -4.2954731 loss -4.31821203 loss_ordinary 1.10379243 entropy_value 5.42200422 glob_norm 0.383542\n",
      "Iteration 1700 L -4.31514168 loss -4.33675766 loss_ordinary 1.07977986 entropy_value 5.41653776 glob_norm 0.433614492\n",
      "Iteration 1750 L -4.30793095 loss -4.32908058 loss_ordinary 1.09355187 entropy_value 5.42263222 glob_norm 0.520081341\n",
      "Iteration 1800 L -4.3481245 loss -4.36949825 loss_ordinary 1.06223333 entropy_value 5.43173122 glob_norm 0.501270235\n",
      "Iteration 1850 L -4.30389595 loss -4.32365084 loss_ordinary 1.10457838 entropy_value 5.42822933 glob_norm 0.555677474\n",
      "Iteration 1900 L -4.34977436 loss -4.37209177 loss_ordinary 1.05300605 entropy_value 5.42509794 glob_norm 0.334480554\n",
      "Iteration 1950 L -4.29595518 loss -4.3177309 loss_ordinary 1.10338044 entropy_value 5.42111111 glob_norm 0.378128827\n",
      "Iteration 2000 L -4.30717707 loss -4.32888746 loss_ordinary 1.0872457 entropy_value 5.4161334 glob_norm 0.588359773\n",
      "Iteration 2050 L -4.26426 loss -4.28481722 loss_ordinary 1.14264977 entropy_value 5.42746687 glob_norm 0.393969774\n",
      "Iteration 2100 L -4.30995512 loss -4.33374453 loss_ordinary 1.08071053 entropy_value 5.41445541 glob_norm 0.430419743\n",
      "Iteration 2150 L -4.34973907 loss -4.37038612 loss_ordinary 1.04382646 entropy_value 5.4142127 glob_norm 0.558560967\n",
      "Iteration 2200 L -4.31568909 loss -4.33735752 loss_ordinary 1.08672071 entropy_value 5.42407799 glob_norm 0.448102325\n",
      "Iteration 2250 L -4.29932451 loss -4.3218832 loss_ordinary 1.09145224 entropy_value 5.41333532 glob_norm 0.527345717\n",
      "Iteration 2300 L -4.3175745 loss -4.33810568 loss_ordinary 1.0764606 entropy_value 5.41456604 glob_norm 0.349082112\n",
      "Iteration 2350 L -4.27626467 loss -4.2973175 loss_ordinary 1.11954749 entropy_value 5.41686487 glob_norm 0.318347335\n",
      "Iteration 2400 L -4.32512093 loss -4.34839916 loss_ordinary 1.07166195 entropy_value 5.42006111 glob_norm 0.330803454\n",
      "Iteration 2450 L -4.34078 loss -4.36370182 loss_ordinary 1.05305755 entropy_value 5.41675949 glob_norm 0.471879095\n",
      "Iteration 2500 L -4.32087517 loss -4.34194851 loss_ordinary 1.08266556 entropy_value 5.42461395 glob_norm 0.316335052\n",
      "Iteration 2550 L -4.3012042 loss -4.32392216 loss_ordinary 1.09765661 entropy_value 5.42157841 glob_norm 0.499085814\n",
      "Iteration 2600 L -4.29460812 loss -4.31654549 loss_ordinary 1.08066916 entropy_value 5.39721441 glob_norm 0.377512485\n",
      "Iteration 2650 L -4.33530712 loss -4.3567028 loss_ordinary 1.0615977 entropy_value 5.4183 glob_norm 0.492717147\n",
      "Iteration 2700 L -4.33400631 loss -4.35534763 loss_ordinary 1.04996073 entropy_value 5.40530825 glob_norm 0.55904603\n",
      "Iteration 2750 L -4.30242348 loss -4.32411 loss_ordinary 1.09310961 entropy_value 5.41721964 glob_norm 0.52771306\n",
      "Iteration 2800 L -4.29548931 loss -4.31911087 loss_ordinary 1.08502448 entropy_value 5.40413523 glob_norm 0.395240515\n",
      "Iteration 2850 L -4.30254364 loss -4.32598 loss_ordinary 1.0896107 entropy_value 5.41559076 glob_norm 0.425233692\n",
      "Iteration 2900 L -4.28966951 loss -4.31201696 loss_ordinary 1.10182846 entropy_value 5.41384506 glob_norm 0.538196623\n",
      "Iteration 2950 L -4.2602911 loss -4.28452253 loss_ordinary 1.11917925 entropy_value 5.40370178 glob_norm 0.681364059\n",
      "Iteration 3000 L -4.33202457 loss -4.35466099 loss_ordinary 1.05356538 entropy_value 5.40822601 glob_norm 0.423639148\n",
      "Iteration 3050 L -4.3264823 loss -4.34877443 loss_ordinary 1.06820416 entropy_value 5.41697836 glob_norm 0.324503034\n",
      "Iteration 3100 L -4.32559156 loss -4.34650326 loss_ordinary 1.0751518 entropy_value 5.4216547 glob_norm 0.533342302\n",
      "Iteration 3150 L -4.2990346 loss -4.32049227 loss_ordinary 1.09703553 entropy_value 5.41752815 glob_norm 0.456375539\n",
      "Iteration 3200 L -4.31440496 loss -4.33538961 loss_ordinary 1.07738411 entropy_value 5.41277361 glob_norm 0.355475\n",
      "Iteration 3250 L -4.3019352 loss -4.32353687 loss_ordinary 1.08485723 entropy_value 5.40839386 glob_norm 0.321390361\n",
      "Iteration 3300 L -4.29964876 loss -4.3228 loss_ordinary 1.08918691 entropy_value 5.4119873 glob_norm 0.382612288\n",
      "Iteration 3350 L -4.31262636 loss -4.33337259 loss_ordinary 1.07407928 entropy_value 5.40745163 glob_norm 0.355810434\n",
      "Iteration 3400 L -4.30176926 loss -4.32573462 loss_ordinary 1.08430982 entropy_value 5.41004419 glob_norm 0.418947756\n",
      "Iteration 3450 L -4.32538939 loss -4.3478322 loss_ordinary 1.0666101 entropy_value 5.41444254 glob_norm 0.461768597\n",
      "Iteration 3500 L -4.30702448 loss -4.3314333 loss_ordinary 1.0763216 entropy_value 5.40775442 glob_norm 0.401250154\n",
      "Iteration 3550 L -4.32945442 loss -4.35224676 loss_ordinary 1.07565463 entropy_value 5.42790127 glob_norm 0.502943516\n",
      "Iteration 3600 L -4.32985973 loss -4.35197973 loss_ordinary 1.06813407 entropy_value 5.42011356 glob_norm 0.306236863\n",
      "Iteration 3650 L -4.2939806 loss -4.3177247 loss_ordinary 1.09335935 entropy_value 5.4110837 glob_norm 0.377100855\n",
      "Iteration 3700 L -4.31807089 loss -4.34093952 loss_ordinary 1.08196592 entropy_value 5.42290545 glob_norm 0.60599041\n",
      "Iteration 3750 L -4.3129921 loss -4.33438396 loss_ordinary 1.08221245 entropy_value 5.41659641 glob_norm 0.326497763\n",
      "Iteration 3800 L -4.31463242 loss -4.33627748 loss_ordinary 1.07680988 entropy_value 5.41308737 glob_norm 0.481901914\n",
      "Iteration 3850 L -4.31086874 loss -4.33243704 loss_ordinary 1.08416414 entropy_value 5.41660118 glob_norm 0.409373403\n",
      "Iteration 3900 L -4.30287218 loss -4.3256917 loss_ordinary 1.08817744 entropy_value 5.41386938 glob_norm 0.570862055\n",
      "Iteration 3950 L -4.25804472 loss -4.27991915 loss_ordinary 1.14029574 entropy_value 5.42021465 glob_norm 0.554039061\n",
      "Iteration 4000 L -4.31381655 loss -4.3364 loss_ordinary 1.07386637 entropy_value 5.4102664 glob_norm 0.454240352\n",
      "Iteration 4050 L -4.31774426 loss -4.34029293 loss_ordinary 1.07678509 entropy_value 5.41707802 glob_norm 0.413285732\n",
      "Iteration 4100 L -4.2988534 loss -4.32129812 loss_ordinary 1.09096396 entropy_value 5.41226196 glob_norm 0.37554872\n",
      "Iteration 4150 L -4.31866503 loss -4.34177971 loss_ordinary 1.07689667 entropy_value 5.41867638 glob_norm 0.535248041\n",
      "Iteration 4200 L -4.2749877 loss -4.298388 loss_ordinary 1.11420393 entropy_value 5.41259193 glob_norm 0.46108\n",
      "Iteration 4250 L -4.3319 loss -4.351964 loss_ordinary 1.05998683 entropy_value 5.41195107 glob_norm 0.585623503\n",
      "Iteration 4300 L -4.31957865 loss -4.34276533 loss_ordinary 1.07150877 entropy_value 5.41427374 glob_norm 0.472796023\n",
      "Iteration 4350 L -4.28715849 loss -4.31029701 loss_ordinary 1.10832191 entropy_value 5.41861916 glob_norm 0.420603\n",
      "Iteration 4400 L -4.35121584 loss -4.37356091 loss_ordinary 1.04405451 entropy_value 5.41761541 glob_norm 0.50048089\n",
      "Iteration 4450 L -4.29394484 loss -4.31597805 loss_ordinary 1.10215974 entropy_value 5.41813803 glob_norm 0.432496071\n",
      "Iteration 4500 L -4.32005119 loss -4.34241247 loss_ordinary 1.0687151 entropy_value 5.41112757 glob_norm 0.355482757\n",
      "Iteration 4550 L -4.33081722 loss -4.35320568 loss_ordinary 1.06112683 entropy_value 5.41433239 glob_norm 0.526293933\n",
      "Iteration 4600 L -4.34989738 loss -4.37056732 loss_ordinary 1.04741824 entropy_value 5.41798544 glob_norm 0.342725903\n",
      "Iteration 4650 L -4.29788 loss -4.32054 loss_ordinary 1.0796479 entropy_value 5.40018797 glob_norm 0.42513898\n",
      "Iteration 4700 L -4.31318378 loss -4.33632421 loss_ordinary 1.07491267 entropy_value 5.41123676 glob_norm 0.390705019\n",
      "Iteration 4750 L -4.2995162 loss -4.32075691 loss_ordinary 1.09670854 entropy_value 5.41746569 glob_norm 0.460058331\n",
      "Iteration 4800 L -4.29921484 loss -4.32248068 loss_ordinary 1.08957887 entropy_value 5.41205931 glob_norm 0.432071596\n",
      "Iteration 4850 L -4.30911827 loss -4.33217096 loss_ordinary 1.08799326 entropy_value 5.42016411 glob_norm 0.358566821\n",
      "Iteration 4900 L -4.33739948 loss -4.3606 loss_ordinary 1.05126 entropy_value 5.41186 glob_norm 0.380476743\n",
      "Iteration 4950 L -4.34325027 loss -4.3652916 loss_ordinary 1.04171777 entropy_value 5.40700912 glob_norm 0.40338093\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 1.73261654 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26099348 loss -4.32751131 loss_ordinary 1.07844758 entropy_value 5.40595865 glob_norm 0.37654373\n",
      "Iteration 50 L -4.29603 loss -4.35713243 loss_ordinary 1.07355988 entropy_value 5.4306922 glob_norm 0.48437202\n",
      "Iteration 100 L -4.32076406 loss -4.38574028 loss_ordinary 1.04840851 entropy_value 5.43414879 glob_norm 0.376277447\n",
      "Iteration 150 L -4.28620958 loss -4.34318733 loss_ordinary 1.09611607 entropy_value 5.43930292 glob_norm 0.3065404\n",
      "Iteration 200 L -4.29289961 loss -4.35480642 loss_ordinary 1.08948863 entropy_value 5.44429493 glob_norm 0.426052868\n",
      "Iteration 250 L -4.25501585 loss -4.31501579 loss_ordinary 1.13003349 entropy_value 5.44504929 glob_norm 0.31047827\n",
      "Iteration 300 L -4.24967289 loss -4.31246948 loss_ordinary 1.13725889 entropy_value 5.44972849 glob_norm 0.453423858\n",
      "Iteration 350 L -4.24960136 loss -4.31340456 loss_ordinary 1.13545096 entropy_value 5.4488554 glob_norm 0.41790098\n",
      "Iteration 400 L -4.24665165 loss -4.31171513 loss_ordinary 1.14492369 entropy_value 5.45663881 glob_norm 0.523679137\n",
      "Iteration 450 L -4.25986242 loss -4.32368374 loss_ordinary 1.12301791 entropy_value 5.44670153 glob_norm 0.406054527\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 1.59956741 lambd_papr -0.017326165 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.24217415 loss -4.3372345 loss_ordinary 1.11701238 entropy_value 5.45424652 glob_norm 0.528434336\n",
      "Iteration 50 L -4.23936462 loss -4.33086729 loss_ordinary 1.13239384 entropy_value 5.46326113 glob_norm 0.41507858\n",
      "Iteration 100 L -4.20268583 loss -4.30242443 loss_ordinary 1.17947137 entropy_value 5.48189592 glob_norm 0.487891078\n",
      "Iteration 150 L -4.24817 loss -4.34003878 loss_ordinary 1.1358707 entropy_value 5.47590923 glob_norm 0.400556147\n",
      "Iteration 200 L -4.18825531 loss -4.28043509 loss_ordinary 1.20605767 entropy_value 5.48649263 glob_norm 0.450482756\n",
      "Iteration 250 L -4.24289083 loss -4.33147335 loss_ordinary 1.15600479 entropy_value 5.48747826 glob_norm 0.438661098\n",
      "Iteration 300 L -4.25128698 loss -4.34221935 loss_ordinary 1.14935875 entropy_value 5.4915781 glob_norm 0.416136682\n",
      "Iteration 350 L -4.26608419 loss -4.35878134 loss_ordinary 1.12786925 entropy_value 5.48665047 glob_norm 0.406369984\n",
      "Iteration 400 L -4.22569752 loss -4.31151295 loss_ordinary 1.18772829 entropy_value 5.49924135 glob_norm 0.540881\n",
      "Iteration 450 L -4.22194386 loss -4.31110954 loss_ordinary 1.19082904 entropy_value 5.50193834 glob_norm 0.370330423\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 1.55029809 lambd_papr -0.0333698243 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.20025778 loss -4.31969833 loss_ordinary 1.17711413 entropy_value 5.49681282 glob_norm 0.351369739\n",
      "Iteration 50 L -4.22748756 loss -4.34618187 loss_ordinary 1.17304778 entropy_value 5.51922941 glob_norm 0.346263587\n",
      "Iteration 100 L -4.20377207 loss -4.31036901 loss_ordinary 1.22210169 entropy_value 5.5324707 glob_norm 0.421305567\n",
      "Iteration 150 L -4.21139 loss -4.32009077 loss_ordinary 1.21122456 entropy_value 5.53131533 glob_norm 0.390669376\n",
      "Iteration 200 L -4.1694 loss -4.27497911 loss_ordinary 1.26403117 entropy_value 5.53901052 glob_norm 0.555990219\n",
      "Iteration 250 L -4.21509647 loss -4.31830502 loss_ordinary 1.2262001 entropy_value 5.54450512 glob_norm 0.4651528\n",
      "Iteration 300 L -4.18014 loss -4.27612543 loss_ordinary 1.27085161 entropy_value 5.54697704 glob_norm 0.623617589\n",
      "Iteration 350 L -4.22008228 loss -4.32101393 loss_ordinary 1.23319864 entropy_value 5.55421209 glob_norm 0.456384808\n",
      "Iteration 400 L -4.17868042 loss -4.27849054 loss_ordinary 1.27186584 entropy_value 5.55035686 glob_norm 0.442956954\n",
      "Iteration 450 L -4.21602631 loss -4.30986166 loss_ordinary 1.2477982 entropy_value 5.55765963 glob_norm 0.31500867\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 1.19617319 lambd_papr -0.0489659607 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.19713497 loss -4.31504631 loss_ordinary 1.23877549 entropy_value 5.55382204 glob_norm 0.470389277\n",
      "Iteration 50 L -4.1901207 loss -4.30108213 loss_ordinary 1.26584589 entropy_value 5.56692791 glob_norm 0.544886947\n",
      "Iteration 100 L -4.19118738 loss -4.28418255 loss_ordinary 1.30094457 entropy_value 5.58512735 glob_norm 0.432854861\n",
      "Iteration 150 L -4.16756392 loss -4.27870655 loss_ordinary 1.30296016 entropy_value 5.58166647 glob_norm 0.431094378\n",
      "Iteration 200 L -4.19608402 loss -4.30759764 loss_ordinary 1.28042984 entropy_value 5.58802748 glob_norm 0.351872474\n",
      "Iteration 250 L -4.1531682 loss -4.25529671 loss_ordinary 1.33608723 entropy_value 5.59138393 glob_norm 0.3234905\n",
      "Iteration 300 L -4.20239973 loss -4.30349827 loss_ordinary 1.28552675 entropy_value 5.58902454 glob_norm 0.411708742\n",
      "Iteration 350 L -4.22028685 loss -4.32684755 loss_ordinary 1.25567365 entropy_value 5.58252096 glob_norm 0.415130645\n",
      "Iteration 400 L -4.17103481 loss -4.28269625 loss_ordinary 1.30188882 entropy_value 5.58458519 glob_norm 0.522888\n",
      "Iteration 450 L -4.17062759 loss -4.26226854 loss_ordinary 1.32437456 entropy_value 5.58664322 glob_norm 0.442001939\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 1.11093354 lambd_papr -0.0610356703 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.19404745 loss -4.30469418 loss_ordinary 1.28770721 entropy_value 5.59240103 glob_norm 0.49627167\n",
      "Iteration 50 L -4.17113733 loss -4.2747879 loss_ordinary 1.32928801 entropy_value 5.60407591 glob_norm 0.583601177\n",
      "Iteration 100 L -4.19289255 loss -4.30438852 loss_ordinary 1.29995799 entropy_value 5.60434675 glob_norm 0.342219025\n",
      "Iteration 150 L -4.17884111 loss -4.28770924 loss_ordinary 1.32526875 entropy_value 5.61297798 glob_norm 0.4978517\n",
      "Iteration 200 L -4.18396854 loss -4.29154062 loss_ordinary 1.32623959 entropy_value 5.61778 glob_norm 0.391329646\n",
      "Iteration 250 L -4.19607353 loss -4.28967905 loss_ordinary 1.32206786 entropy_value 5.61174726 glob_norm 0.373616457\n",
      "Iteration 300 L -4.1788435 loss -4.27393436 loss_ordinary 1.35079706 entropy_value 5.62473154 glob_norm 0.508847713\n",
      "Iteration 350 L -4.14166975 loss -4.24272871 loss_ordinary 1.36850965 entropy_value 5.61123848 glob_norm 0.418499976\n",
      "Iteration 400 L -4.18202972 loss -4.277565 loss_ordinary 1.34173274 entropy_value 5.61929798 glob_norm 0.554119587\n",
      "Iteration 450 L -4.16002798 loss -4.25512791 loss_ordinary 1.36383259 entropy_value 5.61896086 glob_norm 0.460262477\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.871940851 lambd_papr -0.0722789168 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.15670967 loss -4.2672348 loss_ordinary 1.35037351 entropy_value 5.61760855 glob_norm 0.466663659\n",
      "Iteration 50 L -4.18471813 loss -4.28464174 loss_ordinary 1.33621156 entropy_value 5.62085295 glob_norm 0.404050231\n",
      "Iteration 100 L -4.14343739 loss -4.24500227 loss_ordinary 1.39142334 entropy_value 5.63642597 glob_norm 0.549591303\n",
      "Iteration 150 L -4.16616631 loss -4.26532602 loss_ordinary 1.3659817 entropy_value 5.6313076 glob_norm 0.339023\n",
      "Iteration 200 L -4.14315176 loss -4.24471188 loss_ordinary 1.38680458 entropy_value 5.63151693 glob_norm 0.411863476\n",
      "Iteration 250 L -4.17185783 loss -4.25769806 loss_ordinary 1.37422788 entropy_value 5.63192606 glob_norm 0.513454616\n",
      "Iteration 300 L -4.12611485 loss -4.24085665 loss_ordinary 1.38667238 entropy_value 5.62752914 glob_norm 0.451117486\n",
      "Iteration 350 L -4.14083433 loss -4.24371 loss_ordinary 1.3919791 entropy_value 5.63568926 glob_norm 0.438063145\n",
      "Iteration 400 L -4.17661381 loss -4.27827263 loss_ordinary 1.34902382 entropy_value 5.62729645 glob_norm 0.347134233\n",
      "Iteration 450 L -4.14202547 loss -4.23934937 loss_ordinary 1.39431787 entropy_value 5.63366747 glob_norm 0.592839599\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0.696871042 lambd_papr -0.0811299 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.15476036 loss -4.27638912 loss_ordinary 1.36169183 entropy_value 5.63808107 glob_norm 0.509086609\n",
      "Iteration 50 L -4.12352085 loss -4.2304287 loss_ordinary 1.4034574 entropy_value 5.63388634 glob_norm 0.724920154\n",
      "Iteration 100 L -4.15856171 loss -4.25942612 loss_ordinary 1.38515854 entropy_value 5.64458466 glob_norm 0.3071343\n",
      "Iteration 150 L -4.12983 loss -4.23234701 loss_ordinary 1.41716313 entropy_value 5.64951038 glob_norm 0.461889088\n",
      "Iteration 200 L -4.1484046 loss -4.21479 loss_ordinary 1.42783558 entropy_value 5.64262533 glob_norm 0.452261984\n",
      "Iteration 250 L -4.18937778 loss -4.262537 loss_ordinary 1.3860476 entropy_value 5.64858437 glob_norm 0.695191622\n",
      "Iteration 300 L -4.12926912 loss -4.22713375 loss_ordinary 1.42084384 entropy_value 5.64797783 glob_norm 0.394496143\n",
      "Iteration 350 L -4.15429 loss -4.25514507 loss_ordinary 1.39251637 entropy_value 5.64766169 glob_norm 0.39278549\n",
      "Iteration 400 L -4.1645627 loss -4.24548721 loss_ordinary 1.40408015 entropy_value 5.6495676 glob_norm 0.444380224\n",
      "Iteration 450 L -4.15947819 loss -4.24442101 loss_ordinary 1.40345764 entropy_value 5.64787865 glob_norm 0.277973592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0.800679922 lambd_papr -0.0882249922 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.09626484 loss -4.21166277 loss_ordinary 1.43459153 entropy_value 5.64625454 glob_norm 0.460884929\n",
      "Iteration 50 L -4.17213726 loss -4.23850679 loss_ordinary 1.42534649 entropy_value 5.66385317 glob_norm 0.524759829\n",
      "Iteration 100 L -4.15291643 loss -4.26000118 loss_ordinary 1.39932394 entropy_value 5.65932512 glob_norm 0.413281888\n",
      "Iteration 150 L -4.16772461 loss -4.26901436 loss_ordinary 1.39101422 entropy_value 5.66002893 glob_norm 0.411451697\n",
      "Iteration 200 L -4.13187504 loss -4.21068716 loss_ordinary 1.4610709 entropy_value 5.67175817 glob_norm 0.592853606\n",
      "Iteration 250 L -4.09356403 loss -4.19895411 loss_ordinary 1.4599402 entropy_value 5.65889454 glob_norm 0.398086637\n",
      "Iteration 300 L -4.13911676 loss -4.23009396 loss_ordinary 1.43061 entropy_value 5.66070414 glob_norm 0.732828\n",
      "Iteration 350 L -4.12471533 loss -4.23739529 loss_ordinary 1.41633737 entropy_value 5.6537323 glob_norm 0.433261096\n",
      "Iteration 400 L -4.15843773 loss -4.25137472 loss_ordinary 1.41841936 entropy_value 5.66979408 glob_norm 0.322946519\n",
      "Iteration 450 L -4.13673115 loss -4.23345041 loss_ordinary 1.42961621 entropy_value 5.66306686 glob_norm 0.667364359\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.712791443 lambd_papr -0.096401453 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.15581131 loss -4.23795366 loss_ordinary 1.42993927 entropy_value 5.66789341 glob_norm 0.448889405\n",
      "Iteration 50 L -4.17756081 loss -4.25997496 loss_ordinary 1.40195394 entropy_value 5.66192913 glob_norm 0.432908475\n",
      "Iteration 100 L -4.15333939 loss -4.24246883 loss_ordinary 1.43191564 entropy_value 5.67438459 glob_norm 0.329021603\n",
      "Iteration 150 L -4.11881161 loss -4.22051525 loss_ordinary 1.45784509 entropy_value 5.67836094 glob_norm 0.596328735\n",
      "Iteration 200 L -4.10476971 loss -4.16234827 loss_ordinary 1.51572466 entropy_value 5.67807293 glob_norm 0.522821784\n",
      "Iteration 250 L -4.1506896 loss -4.22009802 loss_ordinary 1.45775199 entropy_value 5.67785 glob_norm 0.571731389\n",
      "Iteration 300 L -4.15460634 loss -4.24021339 loss_ordinary 1.43784189 entropy_value 5.67805529 glob_norm 0.59430486\n",
      "Iteration 350 L -4.12798071 loss -4.20881462 loss_ordinary 1.46557009 entropy_value 5.67438459 glob_norm 0.506930053\n",
      "Iteration 400 L -4.15609837 loss -4.22718811 loss_ordinary 1.45020342 entropy_value 5.67739153 glob_norm 0.476379782\n",
      "Iteration 450 L -4.13444662 loss -4.21802378 loss_ordinary 1.4635247 entropy_value 5.68154812 glob_norm 0.373079777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0.60923481 lambd_papr -0.103702247 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.1543808 loss -4.24125767 loss_ordinary 1.44024253 entropy_value 5.68150043 glob_norm 0.394255817\n",
      "Iteration 50 L -4.12315 loss -4.2213397 loss_ordinary 1.45604384 entropy_value 5.67738342 glob_norm 0.536575\n",
      "Iteration 100 L -4.14008093 loss -4.22268391 loss_ordinary 1.46476352 entropy_value 5.68744755 glob_norm 0.477031797\n",
      "Iteration 150 L -4.15018082 loss -4.22296762 loss_ordinary 1.47116125 entropy_value 5.69412899 glob_norm 0.552237391\n",
      "Iteration 200 L -4.10069942 loss -4.20383263 loss_ordinary 1.48579609 entropy_value 5.68962812 glob_norm 0.619454801\n",
      "Iteration 250 L -4.12027693 loss -4.2111659 loss_ordinary 1.48262513 entropy_value 5.69379091 glob_norm 0.467980146\n",
      "Iteration 300 L -4.16650915 loss -4.21123886 loss_ordinary 1.48234546 entropy_value 5.69358444 glob_norm 0.39155215\n",
      "Iteration 350 L -4.08219099 loss -4.15452862 loss_ordinary 1.54803419 entropy_value 5.70256281 glob_norm 0.606104672\n",
      "Iteration 400 L -4.14037657 loss -4.20636415 loss_ordinary 1.48745835 entropy_value 5.69382286 glob_norm 0.483234644\n",
      "Iteration 450 L -4.19668913 loss -4.22996569 loss_ordinary 1.46552026 entropy_value 5.69548607 glob_norm 0.444945455\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.493757486 lambd_papr -0.109961078 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.10647774 loss -4.20610237 loss_ordinary 1.48746729 entropy_value 5.69356966 glob_norm 0.580185831\n",
      "Iteration 50 L -4.10804 loss -4.18599033 loss_ordinary 1.51487732 entropy_value 5.70086765 glob_norm 0.434233487\n",
      "Iteration 100 L -4.13740158 loss -4.19579506 loss_ordinary 1.50556839 entropy_value 5.70136356 glob_norm 0.449303806\n",
      "Iteration 150 L -4.17131138 loss -4.21789169 loss_ordinary 1.48927975 entropy_value 5.70717144 glob_norm 0.430017859\n",
      "Iteration 200 L -4.1180644 loss -4.21607876 loss_ordinary 1.49263632 entropy_value 5.70871496 glob_norm 0.499457717\n",
      "Iteration 250 L -4.0835638 loss -4.18207359 loss_ordinary 1.5280627 entropy_value 5.71013641 glob_norm 0.352350891\n",
      "Iteration 300 L -4.1236577 loss -4.17745447 loss_ordinary 1.53919041 entropy_value 5.71664476 glob_norm 0.649603724\n",
      "Iteration 350 L -4.18502235 loss -4.21421242 loss_ordinary 1.50014877 entropy_value 5.71436167 glob_norm 0.564162374\n",
      "Iteration 400 L -4.13527727 loss -4.206532 loss_ordinary 1.50311184 entropy_value 5.70964384 glob_norm 0.508856475\n",
      "Iteration 450 L -4.13429928 loss -4.17690659 loss_ordinary 1.53228939 entropy_value 5.70919561 glob_norm 0.527403891\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0.322128296 lambd_papr -0.115048796 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.12539291 loss -4.19739771 loss_ordinary 1.51950526 entropy_value 5.71690273 glob_norm 0.467409581\n",
      "Iteration 50 L -4.1080637 loss -4.18229389 loss_ordinary 1.53207958 entropy_value 5.71437311 glob_norm 0.486023843\n",
      "Iteration 100 L -4.14403152 loss -4.22409439 loss_ordinary 1.48950565 entropy_value 5.7136 glob_norm 0.545238376\n",
      "Iteration 150 L -4.17362642 loss -4.20709133 loss_ordinary 1.5111469 entropy_value 5.71823788 glob_norm 0.532058179\n",
      "Iteration 200 L -4.10081768 loss -4.12955 loss_ordinary 1.59092069 entropy_value 5.72047091 glob_norm 0.462333739\n",
      "Iteration 250 L -4.19679642 loss -4.20868826 loss_ordinary 1.51089752 entropy_value 5.7195859 glob_norm 0.459249407\n",
      "Iteration 300 L -4.08349705 loss -4.14415741 loss_ordinary 1.57750452 entropy_value 5.72166157 glob_norm 0.57456547\n",
      "Iteration 350 L -4.10940695 loss -4.15854406 loss_ordinary 1.57002187 entropy_value 5.72856569 glob_norm 0.665563464\n",
      "Iteration 400 L -4.15701103 loss -4.17753029 loss_ordinary 1.54305029 entropy_value 5.72058058 glob_norm 0.459966302\n",
      "Iteration 450 L -4.16454792 loss -4.19430208 loss_ordinary 1.52007031 entropy_value 5.71437263 glob_norm 0.57087028\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.139793634 lambd_papr -0.118377991 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.15142059 loss -4.19008303 loss_ordinary 1.53600073 entropy_value 5.72608376 glob_norm 0.372056425\n",
      "Iteration 50 L -4.11231232 loss -4.17210627 loss_ordinary 1.54990733 entropy_value 5.72201347 glob_norm 0.589672625\n",
      "Iteration 100 L -4.11013937 loss -4.17048502 loss_ordinary 1.55358458 entropy_value 5.7240696 glob_norm 0.453347355\n",
      "Iteration 150 L -4.11608076 loss -4.15513086 loss_ordinary 1.56648862 entropy_value 5.72161961 glob_norm 0.443203866\n",
      "Iteration 200 L -4.13040733 loss -4.18851 loss_ordinary 1.54265893 entropy_value 5.73116922 glob_norm 0.570875406\n",
      "Iteration 250 L -4.13478708 loss -4.16742659 loss_ordinary 1.56554461 entropy_value 5.73297119 glob_norm 0.507514298\n",
      "Iteration 300 L -4.17154217 loss -4.20220327 loss_ordinary 1.53089154 entropy_value 5.73309469 glob_norm 0.401444525\n",
      "Iteration 350 L -4.09961796 loss -4.18564701 loss_ordinary 1.54279304 entropy_value 5.72844 glob_norm 0.412198603\n",
      "Iteration 400 L -4.11220121 loss -4.14478111 loss_ordinary 1.59235978 entropy_value 5.73714113 glob_norm 0.645240545\n",
      "Iteration 450 L -4.17051 loss -4.19199705 loss_ordinary 1.54375076 entropy_value 5.73574829 glob_norm 0.610463262\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.160624504 lambd_papr -0.119827092 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.16428566 loss -4.20143223 loss_ordinary 1.53579164 entropy_value 5.7372241 glob_norm 0.510080218\n",
      "Iteration 50 L -4.12201595 loss -4.17705727 loss_ordinary 1.55555832 entropy_value 5.73261595 glob_norm 0.373510659\n",
      "Iteration 100 L -4.17563534 loss -4.16567039 loss_ordinary 1.56842399 entropy_value 5.73409462 glob_norm 0.692635119\n",
      "Iteration 150 L -4.21176434 loss -4.1988821 loss_ordinary 1.54076457 entropy_value 5.73964643 glob_norm 0.798198819\n",
      "Iteration 200 L -4.15033293 loss -4.16026163 loss_ordinary 1.58352339 entropy_value 5.7437849 glob_norm 0.492827028\n",
      "Iteration 250 L -4.11204 loss -4.19038343 loss_ordinary 1.5508467 entropy_value 5.74123 glob_norm 0.353307873\n",
      "Iteration 300 L -4.1146431 loss -4.145679 loss_ordinary 1.59342134 entropy_value 5.7391 glob_norm 0.503325164\n",
      "Iteration 350 L -4.13931036 loss -4.15804863 loss_ordinary 1.58060384 entropy_value 5.73865223 glob_norm 0.385214031\n",
      "Iteration 400 L -4.15643311 loss -4.15551853 loss_ordinary 1.58840561 entropy_value 5.74392414 glob_norm 0.5336079\n",
      "Iteration 450 L -4.09119129 loss -4.13870382 loss_ordinary 1.60382903 entropy_value 5.74253273 glob_norm 0.562728465\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power -0.0177028179 lambd_papr -0.121497124 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.11795712 loss -4.14592218 loss_ordinary 1.59551573 entropy_value 5.74143791 glob_norm 0.613064\n",
      "Iteration 50 L -4.23443031 loss -4.16010571 loss_ordinary 1.58558905 entropy_value 5.74569464 glob_norm 0.810764372\n",
      "Iteration 100 L -4.08350706 loss -4.15221405 loss_ordinary 1.59291649 entropy_value 5.74513054 glob_norm 0.646168888\n",
      "Iteration 150 L -4.09328461 loss -4.10830545 loss_ordinary 1.63934755 entropy_value 5.74765301 glob_norm 0.498183608\n",
      "Iteration 200 L -4.08335972 loss -4.15265083 loss_ordinary 1.59614038 entropy_value 5.74879122 glob_norm 0.409573734\n",
      "Iteration 250 L -4.17947149 loss -4.14027262 loss_ordinary 1.60743201 entropy_value 5.74770498 glob_norm 0.662372231\n",
      "Iteration 300 L -4.16941786 loss -4.15490294 loss_ordinary 1.59228241 entropy_value 5.74718523 glob_norm 0.568954051\n",
      "Iteration 350 L -4.14654636 loss -4.18112326 loss_ordinary 1.5692333 entropy_value 5.75035667 glob_norm 0.558045447\n",
      "Iteration 400 L -4.12687 loss -4.1639533 loss_ordinary 1.58138013 entropy_value 5.74533319 glob_norm 0.39733395\n",
      "Iteration 450 L -4.12873363 loss -4.15933609 loss_ordinary 1.58600855 entropy_value 5.74534464 glob_norm 0.47271812\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.120089054 lambd_papr -0.121312514 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.12604761 loss -4.14592 loss_ordinary 1.59609568 entropy_value 5.74201536 glob_norm 0.458963543\n",
      "Iteration 50 L -4.12928343 loss -4.15774298 loss_ordinary 1.58836687 entropy_value 5.74611044 glob_norm 0.437466949\n",
      "Iteration 100 L -4.14623976 loss -4.168262 loss_ordinary 1.58537149 entropy_value 5.7536335 glob_norm 0.646474421\n",
      "Iteration 150 L -4.15702915 loss -4.1314435 loss_ordinary 1.62054646 entropy_value 5.75199 glob_norm 0.491027176\n",
      "Iteration 200 L -4.13754 loss -4.15727139 loss_ordinary 1.60266876 entropy_value 5.75994 glob_norm 0.538713574\n",
      "Iteration 250 L -4.08378458 loss -4.09139442 loss_ordinary 1.6675477 entropy_value 5.75894213 glob_norm 0.607661605\n",
      "Iteration 300 L -4.0879612 loss -4.12969494 loss_ordinary 1.62231576 entropy_value 5.75201082 glob_norm 0.52932626\n",
      "Iteration 350 L -4.15352297 loss -4.1643672 loss_ordinary 1.5882715 entropy_value 5.75263882 glob_norm 0.700467229\n",
      "Iteration 400 L -4.13565207 loss -4.14443 loss_ordinary 1.60965693 entropy_value 5.75408697 glob_norm 0.726091623\n",
      "Iteration 450 L -4.13497734 loss -4.13424635 loss_ordinary 1.61731982 entropy_value 5.75156641 glob_norm 0.592048049\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power -0.0683829784 lambd_papr -0.122568592 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.18056822 loss -4.16504908 loss_ordinary 1.58563364 entropy_value 5.75068235 glob_norm 0.527991\n",
      "Iteration 50 L -4.13797665 loss -4.16298771 loss_ordinary 1.59773123 entropy_value 5.76071882 glob_norm 0.669294953\n",
      "Iteration 100 L -4.18281078 loss -4.17030954 loss_ordinary 1.5910641 entropy_value 5.76137352 glob_norm 0.568257034\n",
      "Iteration 150 L -4.12721634 loss -4.15132141 loss_ordinary 1.60376704 entropy_value 5.75508833 glob_norm 0.442996144\n",
      "Iteration 200 L -4.11675358 loss -4.11766243 loss_ordinary 1.63199544 entropy_value 5.74965763 glob_norm 0.693030834\n",
      "Iteration 250 L -4.14310265 loss -4.13800526 loss_ordinary 1.61960292 entropy_value 5.75760794 glob_norm 0.417461038\n",
      "Iteration 300 L -4.1420269 loss -4.15155506 loss_ordinary 1.60519528 entropy_value 5.75675 glob_norm 0.467347413\n",
      "Iteration 350 L -4.12390471 loss -4.12366438 loss_ordinary 1.63395572 entropy_value 5.75762033 glob_norm 0.521799684\n",
      "Iteration 400 L -4.10342121 loss -4.13510418 loss_ordinary 1.62332463 entropy_value 5.75842905 glob_norm 0.426375568\n",
      "Iteration 450 L -4.15321636 loss -4.15880585 loss_ordinary 1.6004734 entropy_value 5.75927925 glob_norm 0.59165144\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0.144794464 lambd_papr -0.121851191 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.09895945 loss -4.10493946 loss_ordinary 1.65842175 entropy_value 5.76336145 glob_norm 0.604918659\n",
      "Iteration 50 L -4.09038973 loss -4.1071763 loss_ordinary 1.64406025 entropy_value 5.75123644 glob_norm 0.494929343\n",
      "Iteration 100 L -4.22207975 loss -4.18407297 loss_ordinary 1.58180356 entropy_value 5.76587629 glob_norm 0.660240293\n",
      "Iteration 150 L -4.11687469 loss -4.12642097 loss_ordinary 1.63253498 entropy_value 5.75895596 glob_norm 0.460391909\n",
      "Iteration 200 L -4.08514595 loss -4.11621332 loss_ordinary 1.6468178 entropy_value 5.76303101 glob_norm 0.586161911\n",
      "Iteration 250 L -4.19150448 loss -4.14406776 loss_ordinary 1.61925948 entropy_value 5.76332712 glob_norm 0.721631944\n",
      "Iteration 300 L -4.14887047 loss -4.12390566 loss_ordinary 1.65038896 entropy_value 5.77429485 glob_norm 0.530735433\n",
      "Iteration 350 L -4.12561703 loss -4.09474611 loss_ordinary 1.67718542 entropy_value 5.77193165 glob_norm 0.591794193\n",
      "Iteration 400 L -4.16148043 loss -4.10767221 loss_ordinary 1.6675421 entropy_value 5.77521467 glob_norm 0.55592519\n",
      "Iteration 450 L -4.17472076 loss -4.14131308 loss_ordinary 1.63303876 entropy_value 5.7743516 glob_norm 0.542645276\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0.0493605137 lambd_papr -0.123374783 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17931318 loss -4.15120697 loss_ordinary 1.62430179 entropy_value 5.77550888 glob_norm 0.739231288\n",
      "Iteration 50 L -4.07939529 loss -4.08605146 loss_ordinary 1.6870029 entropy_value 5.7730546 glob_norm 0.548395336\n",
      "Iteration 100 L -4.07871246 loss -4.08542585 loss_ordinary 1.68451297 entropy_value 5.76993895 glob_norm 0.498255312\n",
      "Iteration 150 L -4.20754051 loss -4.13158607 loss_ordinary 1.6381098 entropy_value 5.76969576 glob_norm 0.653752446\n",
      "Iteration 200 L -4.10832167 loss -4.11409807 loss_ordinary 1.65660048 entropy_value 5.77069855 glob_norm 0.432073653\n",
      "Iteration 250 L -4.21333122 loss -4.14560127 loss_ordinary 1.6265825 entropy_value 5.77218342 glob_norm 0.62462604\n",
      "Iteration 300 L -4.09290838 loss -4.09591 loss_ordinary 1.6775074 entropy_value 5.77341747 glob_norm 0.570238\n",
      "Iteration 350 L -4.13447952 loss -4.09145641 loss_ordinary 1.68307376 entropy_value 5.77453 glob_norm 0.7012344\n",
      "Iteration 400 L -4.10036755 loss -4.09371471 loss_ordinary 1.68117642 entropy_value 5.77489138 glob_norm 0.691509783\n",
      "Iteration 450 L -4.0733366 loss -4.10463715 loss_ordinary 1.67197883 entropy_value 5.77661562 glob_norm 0.414159954\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power -0.269379616 lambd_papr -0.123895735 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.16468334 loss -4.13651609 loss_ordinary 1.6381743 entropy_value 5.77469 glob_norm 0.568076909\n",
      "Iteration 50 L -4.11000061 loss -4.09978724 loss_ordinary 1.6780206 entropy_value 5.77780819 glob_norm 0.645422578\n",
      "Iteration 100 L -4.13914919 loss -4.11240578 loss_ordinary 1.65943372 entropy_value 5.77183962 glob_norm 0.619805336\n",
      "Iteration 150 L -4.19804192 loss -4.13052225 loss_ordinary 1.64932835 entropy_value 5.77985048 glob_norm 0.654748082\n",
      "Iteration 200 L -4.11892033 loss -4.10654545 loss_ordinary 1.66570425 entropy_value 5.7722497 glob_norm 0.505123\n",
      "Iteration 250 L -4.15383959 loss -4.10965967 loss_ordinary 1.66249573 entropy_value 5.77215528 glob_norm 0.482493281\n",
      "Iteration 300 L -4.18140411 loss -4.11006308 loss_ordinary 1.66352725 entropy_value 5.77359 glob_norm 0.791391313\n",
      "Iteration 350 L -4.11250877 loss -4.09515572 loss_ordinary 1.67887747 entropy_value 5.77403355 glob_norm 0.579295\n",
      "Iteration 400 L -4.11877203 loss -4.14097071 loss_ordinary 1.63275635 entropy_value 5.77372742 glob_norm 1.02544868\n",
      "Iteration 450 L -4.14442253 loss -4.11674 loss_ordinary 1.65683115 entropy_value 5.77357149 glob_norm 0.456612468\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.179968596 lambd_papr -0.121044174 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.21860266 loss -4.13227272 loss_ordinary 1.63702762 entropy_value 5.7693 glob_norm 0.627932131\n",
      "Iteration 50 L -4.1947484 loss -4.1208744 loss_ordinary 1.65526211 entropy_value 5.7761364 glob_norm 0.801573\n",
      "Iteration 100 L -4.18050289 loss -4.12204933 loss_ordinary 1.65628445 entropy_value 5.77833366 glob_norm 0.59302\n",
      "Iteration 150 L -4.11657 loss -4.08564329 loss_ordinary 1.68925345 entropy_value 5.77489662 glob_norm 0.70645\n",
      "Iteration 200 L -4.11580563 loss -4.09867764 loss_ordinary 1.67577899 entropy_value 5.7744565 glob_norm 0.499041587\n",
      "Iteration 250 L -4.18143415 loss -4.14236736 loss_ordinary 1.64147615 entropy_value 5.78384304 glob_norm 0.595019579\n",
      "Iteration 300 L -4.17996025 loss -4.16281033 loss_ordinary 1.61368501 entropy_value 5.77649546 glob_norm 0.520325303\n",
      "Iteration 350 L -4.12058783 loss -4.1043458 loss_ordinary 1.67306232 entropy_value 5.77740812 glob_norm 0.471639693\n",
      "Iteration 400 L -4.11544895 loss -4.09515858 loss_ordinary 1.68491399 entropy_value 5.78007269 glob_norm 0.582832217\n",
      "Iteration 450 L -4.11745214 loss -4.08549786 loss_ordinary 1.70263255 entropy_value 5.78813028 glob_norm 0.654424667\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -0.305284739 lambd_papr -0.122954972 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.10370493 loss -4.06238222 loss_ordinary 1.73017919 entropy_value 5.79256153 glob_norm 0.56520611\n",
      "Iteration 50 L -4.11502934 loss -4.0888586 loss_ordinary 1.6949681 entropy_value 5.78382683 glob_norm 0.580749333\n",
      "Iteration 100 L -4.18603516 loss -4.12845516 loss_ordinary 1.65722561 entropy_value 5.78568077 glob_norm 0.666124\n",
      "Iteration 150 L -4.14521646 loss -4.09706 loss_ordinary 1.68833959 entropy_value 5.7854 glob_norm 0.707525432\n",
      "Iteration 200 L -4.21510696 loss -4.13488483 loss_ordinary 1.64705896 entropy_value 5.7819438 glob_norm 0.55047524\n",
      "Iteration 250 L -4.12493801 loss -4.1157155 loss_ordinary 1.66821241 entropy_value 5.78392792 glob_norm 0.467394531\n",
      "Iteration 300 L -4.17659092 loss -4.13875389 loss_ordinary 1.64389241 entropy_value 5.78264618 glob_norm 0.687247932\n",
      "Iteration 350 L -4.12115192 loss -4.1084218 loss_ordinary 1.67506564 entropy_value 5.78348732 glob_norm 0.447113842\n",
      "Iteration 400 L -4.1300168 loss -4.10763168 loss_ordinary 1.67461848 entropy_value 5.78225 glob_norm 0.545562327\n",
      "Iteration 450 L -4.09973526 loss -4.10333347 loss_ordinary 1.68026912 entropy_value 5.78360224 glob_norm 0.43472752\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power -0.390581369 lambd_papr -0.119703911 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.1578021 loss -4.08980656 loss_ordinary 1.69161379 entropy_value 5.78142 glob_norm 0.715590596\n",
      "Iteration 50 L -4.18691778 loss -4.06924 loss_ordinary 1.7216866 entropy_value 5.79092693 glob_norm 0.829601824\n",
      "Iteration 100 L -4.09518099 loss -4.08119726 loss_ordinary 1.70598328 entropy_value 5.78718042 glob_norm 0.541195571\n",
      "Iteration 150 L -4.13481379 loss -4.09111452 loss_ordinary 1.68959022 entropy_value 5.78070498 glob_norm 0.480161101\n",
      "Iteration 200 L -4.14892387 loss -4.12155628 loss_ordinary 1.66185975 entropy_value 5.78341579 glob_norm 0.624764085\n",
      "Iteration 250 L -4.18384027 loss -4.18316889 loss_ordinary 1.59545052 entropy_value 5.77862 glob_norm 0.716488\n",
      "Iteration 300 L -4.13128233 loss -4.09598351 loss_ordinary 1.67436802 entropy_value 5.77035141 glob_norm 0.636002958\n",
      "Iteration 350 L -4.16537 loss -4.11187029 loss_ordinary 1.65848684 entropy_value 5.77035713 glob_norm 0.57888031\n",
      "Iteration 400 L -4.12463 loss -4.12425089 loss_ordinary 1.65757465 entropy_value 5.78182554 glob_norm 0.510852516\n",
      "Iteration 450 L -4.18345213 loss -4.12553549 loss_ordinary 1.65213037 entropy_value 5.77766562 glob_norm 0.519231856\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power -0.0565605164 lambd_papr -0.115532026 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.1815896 loss -4.13521433 loss_ordinary 1.63608027 entropy_value 5.77129459 glob_norm 0.654289424\n",
      "Iteration 50 L -4.1311903 loss -4.11202097 loss_ordinary 1.66287577 entropy_value 5.77489662 glob_norm 0.439090401\n",
      "Iteration 100 L -4.16240454 loss -4.13644361 loss_ordinary 1.63768625 entropy_value 5.77412939 glob_norm 0.505836606\n",
      "Iteration 150 L -4.08475685 loss -4.09697151 loss_ordinary 1.67236793 entropy_value 5.76933908 glob_norm 0.463538796\n",
      "Iteration 200 L -4.19877958 loss -4.15267754 loss_ordinary 1.61113417 entropy_value 5.76381159 glob_norm 0.565399528\n",
      "Iteration 250 L -4.08879566 loss -4.10695 loss_ordinary 1.66220176 entropy_value 5.76915169 glob_norm 0.519359946\n",
      "Iteration 300 L -4.15715742 loss -4.14288044 loss_ordinary 1.62569439 entropy_value 5.76857471 glob_norm 0.462713391\n",
      "Iteration 350 L -4.15519714 loss -4.15557957 loss_ordinary 1.61154747 entropy_value 5.76712704 glob_norm 0.798489213\n",
      "Iteration 400 L -4.18741274 loss -4.11221 loss_ordinary 1.65428102 entropy_value 5.76649094 glob_norm 0.535401762\n",
      "Iteration 450 L -4.0730195 loss -4.07596874 loss_ordinary 1.69214368 entropy_value 5.76811266 glob_norm 0.595212102\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power -0.0177071095 lambd_papr -0.114926077 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.08318043 loss -4.10827494 loss_ordinary 1.65915406 entropy_value 5.76742935 glob_norm 0.488141268\n",
      "Iteration 50 L -4.11628723 loss -4.14162827 loss_ordinary 1.6174885 entropy_value 5.75911713 glob_norm 0.535550594\n",
      "Iteration 100 L -4.11687469 loss -4.1247859 loss_ordinary 1.63811028 entropy_value 5.76289654 glob_norm 0.492892355\n",
      "Iteration 150 L -4.16132832 loss -4.13069487 loss_ordinary 1.6354996 entropy_value 5.76619434 glob_norm 0.60053575\n",
      "Iteration 200 L -4.11140776 loss -4.11984491 loss_ordinary 1.6350497 entropy_value 5.75489426 glob_norm 0.55261904\n",
      "Iteration 250 L -4.12901926 loss -4.12137079 loss_ordinary 1.63547933 entropy_value 5.75685024 glob_norm 0.422371507\n",
      "Iteration 300 L -4.15789652 loss -4.16082716 loss_ordinary 1.59557199 entropy_value 5.75639868 glob_norm 0.537461579\n",
      "Iteration 350 L -4.11163759 loss -4.12000751 loss_ordinary 1.63592684 entropy_value 5.75593424 glob_norm 0.51130724\n",
      "Iteration 400 L -4.18818378 loss -4.15350056 loss_ordinary 1.59887731 entropy_value 5.75237799 glob_norm 0.403841108\n",
      "Iteration 450 L -4.12024593 loss -4.11395407 loss_ordinary 1.64527369 entropy_value 5.75922775 glob_norm 0.511915505\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power -0.163256645 lambd_papr -0.114735804 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.1492238 loss -4.15408325 loss_ordinary 1.59549212 entropy_value 5.74957561 glob_norm 0.465863496\n",
      "Iteration 50 L -4.16918087 loss -4.14954615 loss_ordinary 1.60068619 entropy_value 5.75023222 glob_norm 0.582472086\n",
      "Iteration 100 L -4.14218473 loss -4.14368439 loss_ordinary 1.60872364 entropy_value 5.75240803 glob_norm 0.639072239\n",
      "Iteration 150 L -4.1772213 loss -4.13738537 loss_ordinary 1.61194181 entropy_value 5.74932718 glob_norm 0.769262612\n",
      "Iteration 200 L -4.18429 loss -4.17068434 loss_ordinary 1.57897663 entropy_value 5.74966097 glob_norm 0.649449706\n",
      "Iteration 250 L -4.13817596 loss -4.10844612 loss_ordinary 1.64152122 entropy_value 5.74996758 glob_norm 0.640084863\n",
      "Iteration 300 L -4.11883545 loss -4.1145196 loss_ordinary 1.63563085 entropy_value 5.75015068 glob_norm 0.567762434\n",
      "Iteration 350 L -4.11818552 loss -4.16136026 loss_ordinary 1.59127569 entropy_value 5.75263596 glob_norm 0.350983828\n",
      "Iteration 400 L -4.15949583 loss -4.18619061 loss_ordinary 1.56038737 entropy_value 5.74657822 glob_norm 0.380555391\n",
      "Iteration 450 L -4.16770267 loss -4.14233 loss_ordinary 1.61102962 entropy_value 5.75336 glob_norm 0.603389859\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.224422932 lambd_papr -0.112976283 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.16614246 loss -4.1716876 loss_ordinary 1.57771206 entropy_value 5.74939966 glob_norm 0.530953407\n",
      "Iteration 50 L -4.14203215 loss -4.17379284 loss_ordinary 1.57803333 entropy_value 5.75182629 glob_norm 0.563132107\n",
      "Iteration 100 L -4.10652447 loss -4.11530828 loss_ordinary 1.62659276 entropy_value 5.74190092 glob_norm 0.512844205\n",
      "Iteration 150 L -4.14978647 loss -4.14467 loss_ordinary 1.60100329 entropy_value 5.74567318 glob_norm 0.53131038\n",
      "Iteration 200 L -4.21051931 loss -4.15428543 loss_ordinary 1.59949052 entropy_value 5.75377607 glob_norm 0.586362839\n",
      "Iteration 250 L -4.17803478 loss -4.10989809 loss_ordinary 1.64707041 entropy_value 5.75696898 glob_norm 0.819229126\n",
      "Iteration 300 L -4.16459703 loss -4.14486027 loss_ordinary 1.60658979 entropy_value 5.75145 glob_norm 0.544973552\n",
      "Iteration 350 L -4.11994 loss -4.12536144 loss_ordinary 1.63015163 entropy_value 5.75551319 glob_norm 0.429582894\n",
      "Iteration 400 L -4.08923435 loss -4.11867189 loss_ordinary 1.63884592 entropy_value 5.75751781 glob_norm 0.653040349\n",
      "Iteration 450 L -4.14240789 loss -4.14393759 loss_ordinary 1.6133163 entropy_value 5.75725365 glob_norm 0.596112549\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0.161947727 lambd_papr -0.115402289 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.19652 loss -4.16525888 loss_ordinary 1.5864166 entropy_value 5.75167561 glob_norm 0.592276216\n",
      "Iteration 50 L -4.19680166 loss -4.14672041 loss_ordinary 1.60917497 entropy_value 5.75589514 glob_norm 0.601220846\n",
      "Iteration 100 L -4.16841936 loss -4.15326595 loss_ordinary 1.60414505 entropy_value 5.757411 glob_norm 0.440933734\n",
      "Iteration 150 L -4.10957909 loss -4.11705 loss_ordinary 1.64589739 entropy_value 5.76294756 glob_norm 0.669235468\n",
      "Iteration 200 L -4.17389631 loss -4.17543936 loss_ordinary 1.58059025 entropy_value 5.75602961 glob_norm 0.443230808\n",
      "Iteration 250 L -4.1729331 loss -4.17432833 loss_ordinary 1.58220577 entropy_value 5.7565341 glob_norm 0.502241135\n",
      "Iteration 300 L -4.14832878 loss -4.15602398 loss_ordinary 1.60633552 entropy_value 5.76235962 glob_norm 0.613422275\n",
      "Iteration 350 L -4.12860107 loss -4.14249182 loss_ordinary 1.61261714 entropy_value 5.75510883 glob_norm 0.727679551\n",
      "Iteration 400 L -4.15839767 loss -4.11918592 loss_ordinary 1.64622343 entropy_value 5.76540947 glob_norm 0.851268172\n",
      "Iteration 450 L -4.13753605 loss -4.11591434 loss_ordinary 1.6421504 entropy_value 5.75806475 glob_norm 0.565237403\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power -0.0517165661 lambd_papr -0.117158189 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17417049 loss -4.12985897 loss_ordinary 1.63699794 entropy_value 5.76685667 glob_norm 0.568892598\n",
      "Iteration 50 L -4.10366535 loss -4.1218648 loss_ordinary 1.64130235 entropy_value 5.7631669 glob_norm 0.496342838\n",
      "Iteration 100 L -4.12029028 loss -4.13870478 loss_ordinary 1.61880922 entropy_value 5.757514 glob_norm 0.505846739\n",
      "Iteration 150 L -4.12600851 loss -4.08636332 loss_ordinary 1.67431056 entropy_value 5.76067352 glob_norm 0.521098197\n",
      "Iteration 200 L -4.1309104 loss -4.13374901 loss_ordinary 1.62485063 entropy_value 5.75859928 glob_norm 0.518008351\n",
      "Iteration 250 L -4.20270681 loss -4.11817217 loss_ordinary 1.6460793 entropy_value 5.76425171 glob_norm 0.56830585\n",
      "Iteration 300 L -4.13086557 loss -4.13157225 loss_ordinary 1.62821722 entropy_value 5.75978947 glob_norm 0.626892\n",
      "Iteration 350 L -4.1234808 loss -4.11728334 loss_ordinary 1.63892722 entropy_value 5.75621033 glob_norm 0.544853568\n",
      "Iteration 400 L -4.10345507 loss -4.11482096 loss_ordinary 1.64000916 entropy_value 5.75483036 glob_norm 0.548243165\n",
      "Iteration 450 L -4.15090418 loss -4.16448355 loss_ordinary 1.59574449 entropy_value 5.76022816 glob_norm 0.365013629\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power -0.155302763 lambd_papr -0.116595775 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17541456 loss -4.13862944 loss_ordinary 1.61949909 entropy_value 5.75812817 glob_norm 0.647385\n",
      "Iteration 50 L -4.12166309 loss -4.14116716 loss_ordinary 1.61542094 entropy_value 5.75658798 glob_norm 0.674402595\n",
      "Iteration 100 L -4.15279388 loss -4.15572453 loss_ordinary 1.60213709 entropy_value 5.75786161 glob_norm 0.756218791\n",
      "Iteration 150 L -4.15289116 loss -4.1736908 loss_ordinary 1.58577085 entropy_value 5.7594614 glob_norm 0.673642933\n",
      "Iteration 200 L -4.14696455 loss -4.14182234 loss_ordinary 1.61439562 entropy_value 5.75621796 glob_norm 0.426112145\n",
      "Iteration 250 L -4.17901182 loss -4.14798594 loss_ordinary 1.60925126 entropy_value 5.75723696 glob_norm 0.506893158\n",
      "Iteration 300 L -4.08146238 loss -4.10809946 loss_ordinary 1.64458954 entropy_value 5.75268888 glob_norm 0.573601663\n",
      "Iteration 350 L -4.14517355 loss -4.16843748 loss_ordinary 1.58174741 entropy_value 5.75018501 glob_norm 0.662443876\n",
      "Iteration 400 L -4.1130743 loss -4.13262272 loss_ordinary 1.62042964 entropy_value 5.75305223 glob_norm 0.515221298\n",
      "Iteration 450 L -4.09198332 loss -4.09640837 loss_ordinary 1.6566211 entropy_value 5.75302935 glob_norm 0.439486176\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.109089136 lambd_papr -0.114901803 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.16350603 loss -4.17973709 loss_ordinary 1.56533742 entropy_value 5.74507427 glob_norm 0.569943845\n",
      "Iteration 50 L -4.127213 loss -4.14852333 loss_ordinary 1.59931898 entropy_value 5.74784184 glob_norm 0.539473891\n",
      "Iteration 100 L -4.08788061 loss -4.13263512 loss_ordinary 1.61458719 entropy_value 5.74722242 glob_norm 0.605408072\n",
      "Iteration 150 L -4.11798811 loss -4.13228226 loss_ordinary 1.61470723 entropy_value 5.74698925 glob_norm 0.462830752\n",
      "Iteration 200 L -4.15548277 loss -4.14374256 loss_ordinary 1.60560024 entropy_value 5.74934292 glob_norm 0.601216257\n",
      "Iteration 250 L -4.13347244 loss -4.17271328 loss_ordinary 1.5801692 entropy_value 5.752882 glob_norm 0.65830636\n",
      "Iteration 300 L -4.14932156 loss -4.14249372 loss_ordinary 1.60967088 entropy_value 5.75216484 glob_norm 0.615436852\n",
      "Iteration 350 L -4.12671041 loss -4.14572334 loss_ordinary 1.61152732 entropy_value 5.75725079 glob_norm 0.345430166\n",
      "Iteration 400 L -4.13750744 loss -4.15023 loss_ordinary 1.60496438 entropy_value 5.75519419 glob_norm 0.531892359\n",
      "Iteration 450 L -4.1456418 loss -4.1558938 loss_ordinary 1.59694767 entropy_value 5.75284147 glob_norm 0.479380608\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power -0.0211052895 lambd_papr -0.116095267 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17159605 loss -4.16962 loss_ordinary 1.58129203 entropy_value 5.75091219 glob_norm 0.613368154\n",
      "Iteration 50 L -4.19583368 loss -4.15863228 loss_ordinary 1.58863473 entropy_value 5.74726677 glob_norm 0.661659479\n",
      "Iteration 100 L -4.1309247 loss -4.15156126 loss_ordinary 1.6009841 entropy_value 5.75254488 glob_norm 0.469279796\n",
      "Iteration 150 L -4.08870125 loss -4.11395693 loss_ordinary 1.64340293 entropy_value 5.75736 glob_norm 0.66249907\n",
      "Iteration 200 L -4.11778069 loss -4.13807058 loss_ordinary 1.6129427 entropy_value 5.75101328 glob_norm 0.398914635\n",
      "Iteration 250 L -4.18550444 loss -4.14658403 loss_ordinary 1.60638523 entropy_value 5.75296926 glob_norm 0.497342318\n",
      "Iteration 300 L -4.15912294 loss -4.16386 loss_ordinary 1.58476198 entropy_value 5.74862194 glob_norm 0.632992864\n",
      "Iteration 350 L -4.11682558 loss -4.13590479 loss_ordinary 1.62122381 entropy_value 5.75712824 glob_norm 0.517989457\n",
      "Iteration 400 L -4.12027788 loss -4.12966681 loss_ordinary 1.63148034 entropy_value 5.76114702 glob_norm 0.528786957\n",
      "Iteration 450 L -4.23945189 loss -4.16084146 loss_ordinary 1.59757543 entropy_value 5.75841713 glob_norm 0.650761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0.0628643 lambd_papr -0.115863673 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.10170317 loss -4.10045481 loss_ordinary 1.66511917 entropy_value 5.76557398 glob_norm 0.641248524\n",
      "Iteration 50 L -4.11727142 loss -4.12141514 loss_ordinary 1.6317662 entropy_value 5.75318146 glob_norm 0.540169895\n",
      "Iteration 100 L -4.14532757 loss -4.14653444 loss_ordinary 1.61527622 entropy_value 5.7618103 glob_norm 0.604845226\n",
      "Iteration 150 L -4.19557905 loss -4.14159107 loss_ordinary 1.6180172 entropy_value 5.75960827 glob_norm 0.574026644\n",
      "Iteration 200 L -4.14433575 loss -4.14228249 loss_ordinary 1.61713302 entropy_value 5.75941563 glob_norm 0.505116\n",
      "Iteration 250 L -4.11858749 loss -4.12092495 loss_ordinary 1.63913858 entropy_value 5.76006365 glob_norm 0.467125416\n",
      "Iteration 300 L -4.11945486 loss -4.12420559 loss_ordinary 1.63239431 entropy_value 5.7566 glob_norm 0.439689398\n",
      "Iteration 350 L -4.11614323 loss -4.11483192 loss_ordinary 1.6456424 entropy_value 5.76047421 glob_norm 0.560645759\n",
      "Iteration 400 L -4.16458511 loss -4.17360401 loss_ordinary 1.59074092 entropy_value 5.76434517 glob_norm 0.875357687\n",
      "Iteration 450 L -4.12598276 loss -4.14301682 loss_ordinary 1.61444116 entropy_value 5.75745773 glob_norm 0.299300253\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.207392693 lambd_papr -0.116555557 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.12526131 loss -4.1581378 loss_ordinary 1.600196 entropy_value 5.75833416 glob_norm 0.434153318\n",
      "Iteration 50 L -4.10306406 loss -4.11386156 loss_ordinary 1.64291418 entropy_value 5.75677586 glob_norm 0.438574493\n",
      "Iteration 100 L -4.10622883 loss -4.13656044 loss_ordinary 1.62490106 entropy_value 5.76146126 glob_norm 0.511258125\n",
      "Iteration 150 L -4.09327698 loss -4.12616348 loss_ordinary 1.63622594 entropy_value 5.76238966 glob_norm 0.44494018\n",
      "Iteration 200 L -4.16786242 loss -4.13814402 loss_ordinary 1.61806571 entropy_value 5.75621 glob_norm 0.407319844\n",
      "Iteration 250 L -4.11188173 loss -4.10582685 loss_ordinary 1.65965593 entropy_value 5.7654829 glob_norm 0.489441216\n",
      "Iteration 300 L -4.11495686 loss -4.09652328 loss_ordinary 1.66485775 entropy_value 5.76138067 glob_norm 0.558723688\n",
      "Iteration 350 L -4.08073139 loss -4.10807371 loss_ordinary 1.65927076 entropy_value 5.767344 glob_norm 0.451969862\n",
      "Iteration 400 L -4.13184071 loss -4.13215113 loss_ordinary 1.63028991 entropy_value 5.76244116 glob_norm 0.430800527\n",
      "Iteration 450 L -4.14474583 loss -4.13566351 loss_ordinary 1.63365281 entropy_value 5.76931667 glob_norm 0.597448885\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power -0.139960051 lambd_papr -0.118844971 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.10421 loss -4.09160709 loss_ordinary 1.68089724 entropy_value 5.77250385 glob_norm 0.404159844\n",
      "Iteration 50 L -4.14472437 loss -4.15107203 loss_ordinary 1.61806095 entropy_value 5.76913261 glob_norm 0.670158267\n",
      "Iteration 100 L -4.13468075 loss -4.11465263 loss_ordinary 1.65668046 entropy_value 5.77133322 glob_norm 0.530793846\n",
      "Iteration 150 L -4.19592142 loss -4.14532137 loss_ordinary 1.62679768 entropy_value 5.77211857 glob_norm 0.454948694\n",
      "Iteration 200 L -4.10254288 loss -4.10498142 loss_ordinary 1.66830122 entropy_value 5.773283 glob_norm 0.390208602\n",
      "Iteration 250 L -4.16489315 loss -4.12233353 loss_ordinary 1.64675415 entropy_value 5.76908779 glob_norm 0.523164093\n",
      "Iteration 300 L -4.09894228 loss -4.10582066 loss_ordinary 1.65330398 entropy_value 5.75912476 glob_norm 0.629371643\n",
      "Iteration 350 L -4.16335821 loss -4.15142632 loss_ordinary 1.61623812 entropy_value 5.76766443 glob_norm 0.679996729\n",
      "Iteration 400 L -4.15388346 loss -4.11741304 loss_ordinary 1.65000451 entropy_value 5.76741743 glob_norm 0.582511842\n",
      "Iteration 450 L -4.15045118 loss -4.11136532 loss_ordinary 1.65590227 entropy_value 5.7672677 glob_norm 0.574486\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0.147461414 lambd_papr -0.11729531 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.09587383 loss -4.10123873 loss_ordinary 1.66290259 entropy_value 5.76414156 glob_norm 0.506978035\n",
      "Iteration 50 L -4.15815306 loss -4.15389061 loss_ordinary 1.61490607 entropy_value 5.76879692 glob_norm 0.496290952\n",
      "Iteration 100 L -4.13018751 loss -4.11899233 loss_ordinary 1.64778674 entropy_value 5.76677895 glob_norm 0.54699\n",
      "Iteration 150 L -4.2459507 loss -4.13019133 loss_ordinary 1.63741255 entropy_value 5.76760387 glob_norm 0.78170073\n",
      "Iteration 200 L -4.17463779 loss -4.12517738 loss_ordinary 1.64485705 entropy_value 5.77003431 glob_norm 0.600530267\n",
      "Iteration 250 L -4.1287694 loss -4.12537956 loss_ordinary 1.64288902 entropy_value 5.76826859 glob_norm 0.597018957\n",
      "Iteration 300 L -4.13229227 loss -4.11277914 loss_ordinary 1.65419757 entropy_value 5.76697683 glob_norm 0.595395923\n",
      "Iteration 350 L -4.0696578 loss -4.07340813 loss_ordinary 1.69764018 entropy_value 5.77104855 glob_norm 0.63839\n",
      "Iteration 400 L -4.13810253 loss -4.09971714 loss_ordinary 1.67610133 entropy_value 5.77581835 glob_norm 0.429335147\n",
      "Iteration 450 L -4.16652632 loss -4.11768723 loss_ordinary 1.65771544 entropy_value 5.77540207 glob_norm 0.626906395\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power -0.13863349 lambd_papr -0.118932925 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.12746668 loss -4.09189939 loss_ordinary 1.68830109 entropy_value 5.78020048 glob_norm 0.695721507\n",
      "Iteration 50 L -4.13340807 loss -4.11649704 loss_ordinary 1.66500902 entropy_value 5.78150654 glob_norm 0.491145045\n",
      "Iteration 100 L -4.10615444 loss -4.12992811 loss_ordinary 1.64426279 entropy_value 5.7741909 glob_norm 0.522974253\n",
      "Iteration 150 L -4.10046721 loss -4.09621954 loss_ordinary 1.67868388 entropy_value 5.77490377 glob_norm 0.581569076\n",
      "Iteration 200 L -4.10391188 loss -4.09151173 loss_ordinary 1.685184 entropy_value 5.77669573 glob_norm 0.483691037\n",
      "Iteration 250 L -4.15948725 loss -4.13772297 loss_ordinary 1.64208603 entropy_value 5.779809 glob_norm 0.463557035\n",
      "Iteration 300 L -4.1326251 loss -4.11121655 loss_ordinary 1.66553295 entropy_value 5.77674913 glob_norm 0.625892758\n",
      "Iteration 350 L -4.18325377 loss -4.13346863 loss_ordinary 1.63936269 entropy_value 5.77283144 glob_norm 0.74270165\n",
      "Iteration 400 L -4.21282196 loss -4.14243746 loss_ordinary 1.64037347 entropy_value 5.78281069 glob_norm 0.667376518\n",
      "Iteration 450 L -4.14813328 loss -4.0825634 loss_ordinary 1.69021225 entropy_value 5.77277565 glob_norm 0.578386724\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power -0.0208411217 lambd_papr -0.117388733 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.19274 loss -4.13622856 loss_ordinary 1.6332866 entropy_value 5.76951551 glob_norm 0.646081448\n",
      "Iteration 50 L -4.22325802 loss -4.09681416 loss_ordinary 1.67849529 entropy_value 5.77530956 glob_norm 0.87538439\n",
      "Iteration 100 L -4.11732244 loss -4.08894825 loss_ordinary 1.69079208 entropy_value 5.77974033 glob_norm 0.491675645\n",
      "Iteration 150 L -4.18277407 loss -4.12451458 loss_ordinary 1.65434062 entropy_value 5.77885485 glob_norm 0.537207\n",
      "Iteration 200 L -4.20494699 loss -4.06746483 loss_ordinary 1.71732867 entropy_value 5.78479338 glob_norm 0.888562\n",
      "Iteration 250 L -4.13509703 loss -4.09785032 loss_ordinary 1.68493366 entropy_value 5.78278399 glob_norm 0.640218914\n",
      "Iteration 300 L -4.12107277 loss -4.09706926 loss_ordinary 1.68060684 entropy_value 5.77767611 glob_norm 0.679567516\n",
      "Iteration 350 L -4.10351515 loss -4.09820795 loss_ordinary 1.67346585 entropy_value 5.77167368 glob_norm 0.554199934\n",
      "Iteration 400 L -4.13643074 loss -4.09640598 loss_ordinary 1.68412662 entropy_value 5.78053284 glob_norm 0.50487721\n",
      "Iteration 450 L -4.09395 loss -4.10481596 loss_ordinary 1.67572355 entropy_value 5.78054 glob_norm 0.614254951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power -0.0947122574 lambd_papr -0.117155895 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.16787434 loss -4.09876871 loss_ordinary 1.67789984 entropy_value 5.77666855 glob_norm 0.589324713\n",
      "Iteration 50 L -4.13754797 loss -4.12510395 loss_ordinary 1.65412533 entropy_value 5.77922916 glob_norm 0.440398723\n",
      "Iteration 100 L -4.13092327 loss -4.14288473 loss_ordinary 1.63628697 entropy_value 5.77917147 glob_norm 0.562437236\n",
      "Iteration 150 L -4.1580224 loss -4.12552166 loss_ordinary 1.65106332 entropy_value 5.77658463 glob_norm 0.489764422\n",
      "Iteration 200 L -4.16837835 loss -4.10485935 loss_ordinary 1.66922283 entropy_value 5.77408218 glob_norm 0.668672085\n",
      "Iteration 250 L -4.13882351 loss -4.11542416 loss_ordinary 1.66502857 entropy_value 5.78045321 glob_norm 0.55376631\n",
      "Iteration 300 L -4.0902667 loss -4.07474518 loss_ordinary 1.69552445 entropy_value 5.77026939 glob_norm 0.507660806\n",
      "Iteration 350 L -4.0951 loss -4.09375715 loss_ordinary 1.68234873 entropy_value 5.77610588 glob_norm 0.416091263\n",
      "Iteration 400 L -4.09779835 loss -4.08682251 loss_ordinary 1.69391561 entropy_value 5.78073788 glob_norm 0.78689748\n",
      "Iteration 450 L -4.12637854 loss -4.11820841 loss_ordinary 1.65291715 entropy_value 5.77112532 glob_norm 0.445483714\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.336714983 lambd_papr -0.116094582 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.10906172 loss -4.10212 loss_ordinary 1.67265439 entropy_value 5.77477407 glob_norm 0.410883039\n",
      "Iteration 50 L -4.19380188 loss -4.13772869 loss_ordinary 1.63040149 entropy_value 5.7681303 glob_norm 0.576532\n",
      "Iteration 100 L -4.09862041 loss -4.13465834 loss_ordinary 1.63356888 entropy_value 5.7682271 glob_norm 0.500480831\n",
      "Iteration 150 L -4.11226797 loss -4.11376095 loss_ordinary 1.65159714 entropy_value 5.76535797 glob_norm 0.687065601\n",
      "Iteration 200 L -4.1630373 loss -4.09212732 loss_ordinary 1.67602837 entropy_value 5.76815557 glob_norm 0.540146172\n",
      "Iteration 250 L -4.07051277 loss -4.10007334 loss_ordinary 1.66878843 entropy_value 5.76886129 glob_norm 0.598484039\n",
      "Iteration 300 L -4.15597 loss -4.12680054 loss_ordinary 1.64343452 entropy_value 5.77023506 glob_norm 0.449847937\n",
      "Iteration 350 L -4.11131954 loss -4.13919258 loss_ordinary 1.63037896 entropy_value 5.7695713 glob_norm 0.406871378\n",
      "Iteration 400 L -4.17488 loss -4.1261487 loss_ordinary 1.63569331 entropy_value 5.76184177 glob_norm 0.73354429\n",
      "Iteration 450 L -4.18719912 loss -4.11916828 loss_ordinary 1.65336967 entropy_value 5.77253771 glob_norm 0.643345058\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0.163600922 lambd_papr -0.112310164 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17729664 loss -4.14143038 loss_ordinary 1.6252768 entropy_value 5.76670694 glob_norm 0.647903\n",
      "Iteration 50 L -4.09338665 loss -4.08647537 loss_ordinary 1.68773818 entropy_value 5.77421331 glob_norm 0.607280731\n",
      "Iteration 100 L -4.12418 loss -4.12829971 loss_ordinary 1.64934194 entropy_value 5.7776413 glob_norm 0.501599967\n",
      "Iteration 150 L -4.18930721 loss -4.10606527 loss_ordinary 1.66556942 entropy_value 5.77163458 glob_norm 0.907699347\n",
      "Iteration 200 L -4.09877491 loss -4.09285736 loss_ordinary 1.67450213 entropy_value 5.76735973 glob_norm 0.501199305\n",
      "Iteration 250 L -4.14283466 loss -4.1548667 loss_ordinary 1.6134938 entropy_value 5.76836061 glob_norm 0.462538898\n",
      "Iteration 300 L -4.14968777 loss -4.11981678 loss_ordinary 1.648543 entropy_value 5.76836 glob_norm 0.695748031\n",
      "Iteration 350 L -4.09641 loss -4.12566328 loss_ordinary 1.64118671 entropy_value 5.76685 glob_norm 0.482810467\n",
      "Iteration 400 L -4.1424489 loss -4.13568401 loss_ordinary 1.62854528 entropy_value 5.7642293 glob_norm 0.50923717\n",
      "Iteration 450 L -4.16849279 loss -4.14962053 loss_ordinary 1.61604643 entropy_value 5.76566744 glob_norm 0.682593048\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0.170576096 lambd_papr -0.114154428 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.11706591 loss -4.13759947 loss_ordinary 1.62175369 entropy_value 5.75935316 glob_norm 0.488412023\n",
      "Iteration 50 L -4.13366413 loss -4.15488482 loss_ordinary 1.60736 entropy_value 5.7622447 glob_norm 0.535600126\n",
      "Iteration 100 L -4.15743065 loss -4.14715052 loss_ordinary 1.61922908 entropy_value 5.76637936 glob_norm 0.586883485\n",
      "Iteration 150 L -4.11396074 loss -4.09979773 loss_ordinary 1.65796566 entropy_value 5.75776339 glob_norm 0.499185\n",
      "Iteration 200 L -4.18931437 loss -4.14081955 loss_ordinary 1.62537241 entropy_value 5.76619196 glob_norm 0.529901624\n",
      "Iteration 250 L -4.15175 loss -4.10345459 loss_ordinary 1.66967845 entropy_value 5.7731328 glob_norm 0.454889387\n",
      "Iteration 300 L -4.14231157 loss -4.13767815 loss_ordinary 1.62667966 entropy_value 5.76435804 glob_norm 0.528991342\n",
      "Iteration 350 L -4.19308758 loss -4.13335371 loss_ordinary 1.63466382 entropy_value 5.76801777 glob_norm 0.634094775\n",
      "Iteration 400 L -4.17390347 loss -4.11921215 loss_ordinary 1.65359104 entropy_value 5.77280331 glob_norm 0.530061483\n",
      "Iteration 450 L -4.18293524 loss -4.13592386 loss_ordinary 1.63688099 entropy_value 5.77280474 glob_norm 0.813795269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power -0.125494957 lambd_papr -0.116083093 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.20909739 loss -4.16789103 loss_ordinary 1.59874928 entropy_value 5.76664 glob_norm 0.442164332\n",
      "Iteration 50 L -4.13422966 loss -4.13409281 loss_ordinary 1.63437402 entropy_value 5.76846647 glob_norm 0.515633225\n",
      "Iteration 100 L -4.14815807 loss -4.1612916 loss_ordinary 1.59913135 entropy_value 5.76042318 glob_norm 0.402684212\n",
      "Iteration 150 L -4.13116789 loss -4.14900827 loss_ordinary 1.61382222 entropy_value 5.76283073 glob_norm 0.523660958\n",
      "Iteration 200 L -4.13236904 loss -4.12475634 loss_ordinary 1.64196134 entropy_value 5.76671791 glob_norm 0.696119428\n",
      "Iteration 250 L -4.1176219 loss -4.12295389 loss_ordinary 1.64244688 entropy_value 5.76540041 glob_norm 0.639535546\n",
      "Iteration 300 L -4.12795734 loss -4.09382153 loss_ordinary 1.67397368 entropy_value 5.76779461 glob_norm 0.705966771\n",
      "Iteration 350 L -4.05755949 loss -4.08283567 loss_ordinary 1.68821955 entropy_value 5.77105522 glob_norm 0.46172145\n",
      "Iteration 400 L -4.07890129 loss -4.08354759 loss_ordinary 1.67994547 entropy_value 5.76349306 glob_norm 0.682323813\n",
      "Iteration 450 L -4.03344774 loss -4.09229374 loss_ordinary 1.66946757 entropy_value 5.76176119 glob_norm 0.461071491\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power 0.0618944168 lambd_papr -0.114659891 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.17217875 loss -4.14853811 loss_ordinary 1.60704839 entropy_value 5.75558662 glob_norm 0.803299069\n",
      "Iteration 50 L -4.20780373 loss -4.12619543 loss_ordinary 1.63354206 entropy_value 5.75973749 glob_norm 0.63158524\n",
      "Iteration 100 L -4.12735701 loss -4.12849092 loss_ordinary 1.63719642 entropy_value 5.76568747 glob_norm 0.479813755\n",
      "Iteration 150 L -4.16512203 loss -4.1330452 loss_ordinary 1.63583016 entropy_value 5.76887512 glob_norm 0.577994585\n",
      "Iteration 200 L -4.17008781 loss -4.16401482 loss_ordinary 1.60654187 entropy_value 5.77055645 glob_norm 0.44285056\n",
      "Iteration 250 L -4.17876196 loss -4.14895296 loss_ordinary 1.61315179 entropy_value 5.76210451 glob_norm 0.628457308\n",
      "Iteration 300 L -4.16654158 loss -4.14419651 loss_ordinary 1.622967 entropy_value 5.76716328 glob_norm 0.487719327\n",
      "Iteration 350 L -4.1175909 loss -4.10929918 loss_ordinary 1.65917373 entropy_value 5.76847267 glob_norm 0.448111802\n",
      "Iteration 400 L -4.13174534 loss -4.13204908 loss_ordinary 1.63615382 entropy_value 5.76820326 glob_norm 0.529906452\n",
      "Iteration 450 L -4.11529493 loss -4.13270378 loss_ordinary 1.62989819 entropy_value 5.76260185 glob_norm 0.668766916\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power -0.647918224 lambd_papr -0.115363918 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.13684 loss -4.12157679 loss_ordinary 1.64876735 entropy_value 5.77034378 glob_norm 0.405640423\n",
      "Iteration 50 L -4.18739748 loss -4.13809538 loss_ordinary 1.62004733 entropy_value 5.75814295 glob_norm 0.731301129\n",
      "Iteration 100 L -4.1493 loss -4.13723612 loss_ordinary 1.62069392 entropy_value 5.75793028 glob_norm 0.833964229\n",
      "Iteration 150 L -4.11638403 loss -4.12520361 loss_ordinary 1.63008487 entropy_value 5.7552886 glob_norm 0.553581059\n",
      "Iteration 200 L -4.11665821 loss -4.13832092 loss_ordinary 1.60893774 entropy_value 5.74725866 glob_norm 0.401004046\n",
      "Iteration 250 L -4.15944195 loss -4.17215347 loss_ordinary 1.57025492 entropy_value 5.74240828 glob_norm 0.496132165\n",
      "Iteration 300 L -4.10991287 loss -4.14646053 loss_ordinary 1.60183573 entropy_value 5.74829626 glob_norm 0.533448696\n",
      "Iteration 350 L -4.13628435 loss -4.17334032 loss_ordinary 1.56513536 entropy_value 5.73847532 glob_norm 0.39471215\n",
      "Iteration 400 L -4.14423656 loss -4.18008089 loss_ordinary 1.55728447 entropy_value 5.73736572 glob_norm 0.644902766\n",
      "Iteration 450 L -4.19461393 loss -4.18579674 loss_ordinary 1.55828798 entropy_value 5.74408484 glob_norm 0.610035479\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power -0.00451922417 lambd_papr -0.107971922 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.09233522 loss -4.14906788 loss_ordinary 1.58457172 entropy_value 5.73363972 glob_norm 0.359556973\n",
      "Iteration 50 L -4.19686937 loss -4.1738987 loss_ordinary 1.55910039 entropy_value 5.73299885 glob_norm 0.555858\n",
      "Iteration 100 L -4.17964125 loss -4.19314909 loss_ordinary 1.54127932 entropy_value 5.73442841 glob_norm 0.375944644\n",
      "Iteration 150 L -4.1356225 loss -4.1610775 loss_ordinary 1.57516539 entropy_value 5.73624277 glob_norm 0.431443214\n",
      "Iteration 200 L -4.18266821 loss -4.16620874 loss_ordinary 1.56348705 entropy_value 5.7296958 glob_norm 0.669671118\n",
      "Iteration 250 L -4.1317873 loss -4.17932272 loss_ordinary 1.55726147 entropy_value 5.73658466 glob_norm 0.303532\n",
      "Iteration 300 L -4.13200188 loss -4.14518213 loss_ordinary 1.59026992 entropy_value 5.73545218 glob_norm 0.565585375\n",
      "Iteration 350 L -4.19173765 loss -4.20738077 loss_ordinary 1.52584076 entropy_value 5.73322153 glob_norm 0.411623\n",
      "Iteration 400 L -4.14295197 loss -4.20641899 loss_ordinary 1.51445544 entropy_value 5.72087431 glob_norm 0.605460823\n",
      "Iteration 450 L -4.15500975 loss -4.17513418 loss_ordinary 1.55598533 entropy_value 5.73111916 glob_norm 0.447282165\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power 0.328190565 lambd_papr -0.107920207 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.13149261 loss -4.154 loss_ordinary 1.57185328 entropy_value 5.72585297 glob_norm 0.547029257\n",
      "Iteration 50 L -4.13104725 loss -4.15202665 loss_ordinary 1.5852294 entropy_value 5.73725605 glob_norm 0.425938249\n",
      "Iteration 100 L -4.09584045 loss -4.17691374 loss_ordinary 1.5484668 entropy_value 5.72538042 glob_norm 0.353044\n",
      "Iteration 150 L -4.11486244 loss -4.16215038 loss_ordinary 1.56756437 entropy_value 5.72971487 glob_norm 0.601973414\n",
      "Iteration 200 L -4.12616396 loss -4.15991497 loss_ordinary 1.56648588 entropy_value 5.72640085 glob_norm 0.684072852\n",
      "Iteration 250 L -4.18565464 loss -4.16128206 loss_ordinary 1.5751487 entropy_value 5.73643 glob_norm 0.669454515\n",
      "Iteration 300 L -4.14731216 loss -4.17690754 loss_ordinary 1.55632067 entropy_value 5.73322821 glob_norm 0.515459239\n",
      "Iteration 350 L -4.16761494 loss -4.18656969 loss_ordinary 1.55285227 entropy_value 5.73942232 glob_norm 0.595968187\n",
      "Iteration 400 L -4.15357494 loss -4.18192434 loss_ordinary 1.55255342 entropy_value 5.73447752 glob_norm 0.481483489\n",
      "Iteration 450 L -4.20850706 loss -4.18906403 loss_ordinary 1.54376841 entropy_value 5.73283243 glob_norm 0.444587439\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.221628666 lambd_papr -0.111686982 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.13763142 loss -4.1598897 loss_ordinary 1.58135843 entropy_value 5.74124813 glob_norm 0.467886\n",
      "Iteration 50 L -4.21809387 loss -4.22391796 loss_ordinary 1.51035023 entropy_value 5.73426819 glob_norm 0.53602469\n",
      "Iteration 100 L -4.1531415 loss -4.15953112 loss_ordinary 1.58136702 entropy_value 5.74089813 glob_norm 0.428884178\n",
      "Iteration 150 L -4.1327796 loss -4.1638236 loss_ordinary 1.5787704 entropy_value 5.74259424 glob_norm 0.412703335\n",
      "Iteration 200 L -4.21432161 loss -4.1709938 loss_ordinary 1.57168508 entropy_value 5.74267864 glob_norm 0.509452879\n",
      "Iteration 250 L -4.192945 loss -4.20217705 loss_ordinary 1.53307605 entropy_value 5.73525333 glob_norm 0.357214689\n",
      "Iteration 300 L -4.16736364 loss -4.18597937 loss_ordinary 1.55477297 entropy_value 5.7407527 glob_norm 0.469608128\n",
      "Iteration 350 L -4.16785622 loss -4.16583586 loss_ordinary 1.58061445 entropy_value 5.74645042 glob_norm 0.638919294\n",
      "Iteration 400 L -4.11703444 loss -4.15573 loss_ordinary 1.59006834 entropy_value 5.74579811 glob_norm 0.610324144\n",
      "Iteration 450 L -4.17523956 loss -4.1708951 loss_ordinary 1.57255566 entropy_value 5.74345064 glob_norm 0.50679785\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0.0554232597 lambd_papr -0.114238337 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.1500597 loss -4.16898775 loss_ordinary 1.57434332 entropy_value 5.74333096 glob_norm 0.559979558\n",
      "Iteration 50 L -4.1252532 loss -4.13695431 loss_ordinary 1.61462021 entropy_value 5.75157452 glob_norm 0.520604074\n",
      "Iteration 100 L -4.1535635 loss -4.16398287 loss_ordinary 1.58097386 entropy_value 5.74495697 glob_norm 0.623906374\n",
      "Iteration 150 L -4.16093683 loss -4.16941166 loss_ordinary 1.57085764 entropy_value 5.74026966 glob_norm 0.581993401\n",
      "Iteration 200 L -4.1240468 loss -4.1513195 loss_ordinary 1.60023212 entropy_value 5.75155163 glob_norm 0.417618632\n",
      "Iteration 250 L -4.12608433 loss -4.18006182 loss_ordinary 1.57157743 entropy_value 5.75163889 glob_norm 0.439544946\n",
      "Iteration 300 L -4.27019262 loss -4.22351694 loss_ordinary 1.51742029 entropy_value 5.74093676 glob_norm 0.627566159\n",
      "Iteration 350 L -4.09325027 loss -4.14199257 loss_ordinary 1.60447085 entropy_value 5.7464633 glob_norm 0.457178205\n",
      "Iteration 400 L -4.1875782 loss -4.18438196 loss_ordinary 1.5607487 entropy_value 5.74513054 glob_norm 0.428353041\n",
      "Iteration 450 L -4.11920166 loss -4.14003944 loss_ordinary 1.60842776 entropy_value 5.74846697 glob_norm 0.680150747\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.269833803 lambd_papr -0.114878275 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_13_papr_6.0\n",
      "\n",
      "===== Running SNR=13 dB | PAPR=7.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0162681825 loss 0.0162681825 loss_ordinary 6.00745153 entropy_value 5.99118328 glob_norm 0.625135064\n",
      "Iteration 50 L -2.74524665 loss -2.74524665 loss_ordinary 3.21856 entropy_value 5.96380663 glob_norm 0.397310138\n",
      "Iteration 100 L -3.62634158 loss -3.62634158 loss_ordinary 2.31374025 entropy_value 5.94008207 glob_norm 0.286973387\n",
      "Iteration 150 L -3.78108358 loss -3.78108358 loss_ordinary 2.15490842 entropy_value 5.93599224 glob_norm 0.326761484\n",
      "Iteration 200 L -3.84668732 loss -3.84668732 loss_ordinary 2.07221389 entropy_value 5.91890097 glob_norm 0.42455\n",
      "Iteration 250 L -3.94299245 loss -3.94299245 loss_ordinary 1.94089854 entropy_value 5.88389111 glob_norm 0.460490346\n",
      "Iteration 300 L -4.01130152 loss -4.01130152 loss_ordinary 1.81282353 entropy_value 5.82412481 glob_norm 0.447970092\n",
      "Iteration 350 L -4.08257 loss -4.08286238 loss_ordinary 1.64303625 entropy_value 5.72589827 glob_norm 0.328758478\n",
      "Iteration 400 L -4.20100069 loss -4.20366669 loss_ordinary 1.4209379 entropy_value 5.6246047 glob_norm 0.320326596\n",
      "Iteration 450 L -4.25175285 loss -4.25714731 loss_ordinary 1.31188262 entropy_value 5.56903 glob_norm 0.369285643\n",
      "Iteration 500 L -4.2902422 loss -4.29754591 loss_ordinary 1.2236495 entropy_value 5.52119493 glob_norm 0.258716464\n",
      "Iteration 550 L -4.2585063 loss -4.26406336 loss_ordinary 1.23864472 entropy_value 5.50270844 glob_norm 0.449915081\n",
      "Iteration 600 L -4.28142881 loss -4.28599691 loss_ordinary 1.21107852 entropy_value 5.49707556 glob_norm 0.445032686\n",
      "Iteration 650 L -4.34248781 loss -4.3468008 loss_ordinary 1.13034379 entropy_value 5.47714424 glob_norm 0.317422718\n",
      "Iteration 700 L -4.2968545 loss -4.30325079 loss_ordinary 1.16176045 entropy_value 5.4650116 glob_norm 0.320063293\n",
      "Iteration 750 L -4.32233143 loss -4.32814407 loss_ordinary 1.1226356 entropy_value 5.45077944 glob_norm 0.42872557\n",
      "Iteration 800 L -4.36124754 loss -4.36653566 loss_ordinary 1.08158672 entropy_value 5.44812202 glob_norm 0.388190597\n",
      "Iteration 850 L -4.32442617 loss -4.33083916 loss_ordinary 1.12939727 entropy_value 5.46023655 glob_norm 0.466530651\n",
      "Iteration 900 L -4.32734537 loss -4.33283377 loss_ordinary 1.11211085 entropy_value 5.44494438 glob_norm 0.321804494\n",
      "Iteration 950 L -4.32503557 loss -4.33348656 loss_ordinary 1.10450637 entropy_value 5.43799305 glob_norm 0.327424765\n",
      "Iteration 1000 L -4.33827209 loss -4.34584284 loss_ordinary 1.09425247 entropy_value 5.44009542 glob_norm 0.371116191\n",
      "Iteration 1050 L -4.30550289 loss -4.30964279 loss_ordinary 1.13015318 entropy_value 5.43979597 glob_norm 0.370455623\n",
      "Iteration 1100 L -4.32549667 loss -4.33236456 loss_ordinary 1.10632682 entropy_value 5.43869162 glob_norm 0.329481542\n",
      "Iteration 1150 L -4.30596495 loss -4.31256533 loss_ordinary 1.12152684 entropy_value 5.43409204 glob_norm 0.567824662\n",
      "Iteration 1200 L -4.33594608 loss -4.3454566 loss_ordinary 1.08070886 entropy_value 5.42616558 glob_norm 0.389054865\n",
      "Iteration 1250 L -4.32012796 loss -4.32829475 loss_ordinary 1.10338 entropy_value 5.43167448 glob_norm 0.393464983\n",
      "Iteration 1300 L -4.35128641 loss -4.35729694 loss_ordinary 1.06694639 entropy_value 5.42424345 glob_norm 0.250889093\n",
      "Iteration 1350 L -4.31790495 loss -4.32578278 loss_ordinary 1.0933013 entropy_value 5.4190836 glob_norm 0.367994905\n",
      "Iteration 1400 L -4.34170151 loss -4.34954071 loss_ordinary 1.07318485 entropy_value 5.4227252 glob_norm 0.362141103\n",
      "Iteration 1450 L -4.31481171 loss -4.32090187 loss_ordinary 1.11058152 entropy_value 5.43148327 glob_norm 0.505289078\n",
      "Iteration 1500 L -4.34125805 loss -4.34800911 loss_ordinary 1.0777415 entropy_value 5.42575073 glob_norm 0.481060475\n",
      "Iteration 1550 L -4.33393812 loss -4.34044838 loss_ordinary 1.07192826 entropy_value 5.4123764 glob_norm 0.407190889\n",
      "Iteration 1600 L -4.34821463 loss -4.35358047 loss_ordinary 1.06141376 entropy_value 5.41499424 glob_norm 0.362469196\n",
      "Iteration 1650 L -4.34266901 loss -4.35000038 loss_ordinary 1.07323325 entropy_value 5.42323399 glob_norm 0.50738734\n",
      "Iteration 1700 L -4.29509258 loss -4.30382729 loss_ordinary 1.12369382 entropy_value 5.42752123 glob_norm 0.723071337\n",
      "Iteration 1750 L -4.3265233 loss -4.3344264 loss_ordinary 1.08783031 entropy_value 5.42225647 glob_norm 0.539401591\n",
      "Iteration 1800 L -4.34167385 loss -4.35131645 loss_ordinary 1.07201385 entropy_value 5.42333031 glob_norm 0.453468382\n",
      "Iteration 1850 L -4.33096 loss -4.33707285 loss_ordinary 1.08489394 entropy_value 5.42196703 glob_norm 0.3533324\n",
      "Iteration 1900 L -4.31925631 loss -4.32748461 loss_ordinary 1.09632552 entropy_value 5.42381048 glob_norm 0.387532324\n",
      "Iteration 1950 L -4.32176733 loss -4.32954645 loss_ordinary 1.08471215 entropy_value 5.41425848 glob_norm 0.481078893\n",
      "Iteration 2000 L -4.33164215 loss -4.33975363 loss_ordinary 1.07390106 entropy_value 5.4136548 glob_norm 0.426780909\n",
      "Iteration 2050 L -4.32658625 loss -4.33391333 loss_ordinary 1.0851053 entropy_value 5.41901875 glob_norm 0.331578821\n",
      "Iteration 2100 L -4.32107401 loss -4.3272171 loss_ordinary 1.09246838 entropy_value 5.41968584 glob_norm 0.326554149\n",
      "Iteration 2150 L -4.31665277 loss -4.32452631 loss_ordinary 1.09661078 entropy_value 5.42113686 glob_norm 0.362380028\n",
      "Iteration 2200 L -4.29067135 loss -4.29794598 loss_ordinary 1.12499082 entropy_value 5.42293692 glob_norm 0.43205002\n",
      "Iteration 2250 L -4.35242558 loss -4.36064196 loss_ordinary 1.05085182 entropy_value 5.41149378 glob_norm 0.261854261\n",
      "Iteration 2300 L -4.30529308 loss -4.31201315 loss_ordinary 1.1117909 entropy_value 5.42380428 glob_norm 0.395322174\n",
      "Iteration 2350 L -4.33731318 loss -4.34448338 loss_ordinary 1.0828476 entropy_value 5.42733097 glob_norm 0.316243\n",
      "Iteration 2400 L -4.32810307 loss -4.33416557 loss_ordinary 1.08502901 entropy_value 5.41919422 glob_norm 0.460793674\n",
      "Iteration 2450 L -4.35237408 loss -4.35986 loss_ordinary 1.05320609 entropy_value 5.41306591 glob_norm 0.497600883\n",
      "Iteration 2500 L -4.31439543 loss -4.32144737 loss_ordinary 1.09847581 entropy_value 5.41992331 glob_norm 0.352671087\n",
      "Iteration 2550 L -4.30866241 loss -4.31759119 loss_ordinary 1.09302282 entropy_value 5.41061449 glob_norm 0.355285078\n",
      "Iteration 2600 L -4.3392415 loss -4.3459506 loss_ordinary 1.06760848 entropy_value 5.41355896 glob_norm 0.40852657\n",
      "Iteration 2650 L -4.35545206 loss -4.36325884 loss_ordinary 1.04896891 entropy_value 5.41222811 glob_norm 0.457196802\n",
      "Iteration 2700 L -4.3243289 loss -4.33329344 loss_ordinary 1.09091592 entropy_value 5.42420912 glob_norm 0.516944647\n",
      "Iteration 2750 L -4.32382631 loss -4.33089685 loss_ordinary 1.09083521 entropy_value 5.42173147 glob_norm 0.44426\n",
      "Iteration 2800 L -4.34816694 loss -4.35419273 loss_ordinary 1.06333482 entropy_value 5.4175272 glob_norm 0.361821949\n",
      "Iteration 2850 L -4.33202505 loss -4.33862066 loss_ordinary 1.07504201 entropy_value 5.41366243 glob_norm 0.276195168\n",
      "Iteration 2900 L -4.34442949 loss -4.35035515 loss_ordinary 1.07219672 entropy_value 5.42255163 glob_norm 0.39958179\n",
      "Iteration 2950 L -4.29865313 loss -4.30304289 loss_ordinary 1.11612201 entropy_value 5.41916513 glob_norm 0.473311901\n",
      "Iteration 3000 L -4.34939575 loss -4.35743141 loss_ordinary 1.0589844 entropy_value 5.41641617 glob_norm 0.350589395\n",
      "Iteration 3050 L -4.31692076 loss -4.32449579 loss_ordinary 1.09768295 entropy_value 5.42217875 glob_norm 0.446769178\n",
      "Iteration 3100 L -4.38880205 loss -4.39490366 loss_ordinary 1.02237618 entropy_value 5.41728 glob_norm 0.412595242\n",
      "Iteration 3150 L -4.35106754 loss -4.35751 loss_ordinary 1.05182707 entropy_value 5.40933704 glob_norm 0.327521\n",
      "Iteration 3200 L -4.32241488 loss -4.32916927 loss_ordinary 1.08391523 entropy_value 5.41308451 glob_norm 0.393618435\n",
      "Iteration 3250 L -4.34115219 loss -4.34907436 loss_ordinary 1.06326687 entropy_value 5.41234159 glob_norm 0.372960776\n",
      "Iteration 3300 L -4.32247162 loss -4.3308053 loss_ordinary 1.09310484 entropy_value 5.42391 glob_norm 0.467588127\n",
      "Iteration 3350 L -4.34346724 loss -4.34813118 loss_ordinary 1.0636214 entropy_value 5.4117527 glob_norm 0.348338455\n",
      "Iteration 3400 L -4.30941248 loss -4.31704807 loss_ordinary 1.10187972 entropy_value 5.41892767 glob_norm 0.367421567\n",
      "Iteration 3450 L -4.35065317 loss -4.35716677 loss_ordinary 1.06522548 entropy_value 5.42239237 glob_norm 0.281902373\n",
      "Iteration 3500 L -4.34225655 loss -4.34971714 loss_ordinary 1.06835723 entropy_value 5.41807413 glob_norm 0.469313771\n",
      "Iteration 3550 L -4.32272148 loss -4.32996368 loss_ordinary 1.09101629 entropy_value 5.42098 glob_norm 0.336165279\n",
      "Iteration 3600 L -4.32176685 loss -4.32915258 loss_ordinary 1.08683872 entropy_value 5.41599131 glob_norm 0.308469355\n",
      "Iteration 3650 L -4.30518866 loss -4.31028414 loss_ordinary 1.1059134 entropy_value 5.41619778 glob_norm 0.529503524\n",
      "Iteration 3700 L -4.32697773 loss -4.33453465 loss_ordinary 1.08375764 entropy_value 5.41829205 glob_norm 0.413718969\n",
      "Iteration 3750 L -4.31473923 loss -4.32385635 loss_ordinary 1.09073877 entropy_value 5.41459513 glob_norm 0.33778125\n",
      "Iteration 3800 L -4.32591248 loss -4.33392334 loss_ordinary 1.08341205 entropy_value 5.41733551 glob_norm 0.3357279\n",
      "Iteration 3850 L -4.30278206 loss -4.30920124 loss_ordinary 1.10702813 entropy_value 5.41622972 glob_norm 0.263624042\n",
      "Iteration 3900 L -4.30002832 loss -4.30715084 loss_ordinary 1.10836661 entropy_value 5.41551733 glob_norm 0.373130113\n",
      "Iteration 3950 L -4.35869741 loss -4.36451387 loss_ordinary 1.04754972 entropy_value 5.4120636 glob_norm 0.442411333\n",
      "Iteration 4000 L -4.35860252 loss -4.36498451 loss_ordinary 1.05316365 entropy_value 5.41814804 glob_norm 0.406251073\n",
      "Iteration 4050 L -4.33242226 loss -4.34023 loss_ordinary 1.07408786 entropy_value 5.41431761 glob_norm 0.289619446\n",
      "Iteration 4100 L -4.29272175 loss -4.29970264 loss_ordinary 1.12022829 entropy_value 5.41993093 glob_norm 0.418862879\n",
      "Iteration 4150 L -4.35294151 loss -4.36015558 loss_ordinary 1.05332577 entropy_value 5.41348171 glob_norm 0.280484676\n",
      "Iteration 4200 L -4.34075928 loss -4.34776974 loss_ordinary 1.06501067 entropy_value 5.41278028 glob_norm 0.288097829\n",
      "Iteration 4250 L -4.32789707 loss -4.3349 loss_ordinary 1.075544 entropy_value 5.41044378 glob_norm 0.390164137\n",
      "Iteration 4300 L -4.31690168 loss -4.32176304 loss_ordinary 1.0944922 entropy_value 5.416255 glob_norm 0.384084076\n",
      "Iteration 4350 L -4.30300808 loss -4.31029654 loss_ordinary 1.11242449 entropy_value 5.42272139 glob_norm 0.513982058\n",
      "Iteration 4400 L -4.31558371 loss -4.32405233 loss_ordinary 1.09344447 entropy_value 5.41749716 glob_norm 0.356485307\n",
      "Iteration 4450 L -4.30169439 loss -4.30953455 loss_ordinary 1.10977948 entropy_value 5.41931343 glob_norm 0.313715935\n",
      "Iteration 4500 L -4.32108831 loss -4.32694769 loss_ordinary 1.08067358 entropy_value 5.40762138 glob_norm 0.293181658\n",
      "Iteration 4550 L -4.30879879 loss -4.31584835 loss_ordinary 1.09905732 entropy_value 5.41490555 glob_norm 0.351696819\n",
      "Iteration 4600 L -4.31932688 loss -4.32591486 loss_ordinary 1.10338771 entropy_value 5.42930222 glob_norm 0.294657081\n",
      "Iteration 4650 L -4.27137232 loss -4.27731037 loss_ordinary 1.14188278 entropy_value 5.41919327 glob_norm 0.558563292\n",
      "Iteration 4700 L -4.32205153 loss -4.32944345 loss_ordinary 1.09335637 entropy_value 5.42279959 glob_norm 0.399886161\n",
      "Iteration 4750 L -4.3288455 loss -4.3345356 loss_ordinary 1.08434474 entropy_value 5.41888 glob_norm 0.357907\n",
      "Iteration 4800 L -4.32115316 loss -4.32884121 loss_ordinary 1.09159088 entropy_value 5.42043209 glob_norm 0.443341672\n",
      "Iteration 4850 L -4.32757521 loss -4.33573 loss_ordinary 1.08086121 entropy_value 5.41659164 glob_norm 0.238428012\n",
      "Iteration 4900 L -4.3398838 loss -4.34701967 loss_ordinary 1.07230306 entropy_value 5.41932249 glob_norm 0.335545123\n",
      "Iteration 4950 L -4.30584908 loss -4.31288719 loss_ordinary 1.11045933 entropy_value 5.42334652 glob_norm 0.322813421\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 1.00821066 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32446051 loss -4.34580374 loss_ordinary 1.07933247 entropy_value 5.42513609 glob_norm 0.320178092\n",
      "Iteration 50 L -4.31095648 loss -4.32877684 loss_ordinary 1.09579813 entropy_value 5.42457485 glob_norm 0.396505445\n",
      "Iteration 100 L -4.32484531 loss -4.33787251 loss_ordinary 1.09809697 entropy_value 5.43596935 glob_norm 0.412251055\n",
      "Iteration 150 L -4.30874443 loss -4.32664537 loss_ordinary 1.10445797 entropy_value 5.43110323 glob_norm 0.339609474\n",
      "Iteration 200 L -4.33065796 loss -4.34596348 loss_ordinary 1.10057402 entropy_value 5.44653797 glob_norm 0.567601144\n",
      "Iteration 250 L -4.32247543 loss -4.33520079 loss_ordinary 1.11904931 entropy_value 5.45425034 glob_norm 0.55146873\n",
      "Iteration 300 L -4.30875635 loss -4.32500124 loss_ordinary 1.12839675 entropy_value 5.45339823 glob_norm 0.349606454\n",
      "Iteration 350 L -4.31564522 loss -4.33497858 loss_ordinary 1.11646593 entropy_value 5.45144463 glob_norm 0.624022901\n",
      "Iteration 400 L -4.31341553 loss -4.32646036 loss_ordinary 1.12975276 entropy_value 5.456213 glob_norm 0.454909652\n",
      "Iteration 450 L -4.28453779 loss -4.29208183 loss_ordinary 1.17483509 entropy_value 5.46691704 glob_norm 0.437788397\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 0.682369471 lambd_papr -0.0100821061 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31249285 loss -4.33481407 loss_ordinary 1.11953759 entropy_value 5.45435143 glob_norm 0.412618369\n",
      "Iteration 50 L -4.2565527 loss -4.27833128 loss_ordinary 1.18515992 entropy_value 5.46349144 glob_norm 0.469833255\n",
      "Iteration 100 L -4.31207228 loss -4.31842518 loss_ordinary 1.15874493 entropy_value 5.47717 glob_norm 0.360405415\n",
      "Iteration 150 L -4.3022933 loss -4.32143402 loss_ordinary 1.15518379 entropy_value 5.47661734 glob_norm 0.294524968\n",
      "Iteration 200 L -4.331604 loss -4.3463006 loss_ordinary 1.13422644 entropy_value 5.4805274 glob_norm 0.445964187\n",
      "Iteration 250 L -4.31119156 loss -4.32581711 loss_ordinary 1.14500725 entropy_value 5.47082424 glob_norm 0.484577924\n",
      "Iteration 300 L -4.28674507 loss -4.29985189 loss_ordinary 1.16949749 entropy_value 5.46934938 glob_norm 0.550623238\n",
      "Iteration 350 L -4.29826307 loss -4.31518364 loss_ordinary 1.16551352 entropy_value 5.48069715 glob_norm 0.475733727\n",
      "Iteration 400 L -4.32147121 loss -4.34027195 loss_ordinary 1.13902116 entropy_value 5.47929287 glob_norm 0.291817665\n",
      "Iteration 450 L -4.31872845 loss -4.33362293 loss_ordinary 1.14573 entropy_value 5.47935295 glob_norm 0.285882682\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0.321733952 lambd_papr -0.0169262718 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28431702 loss -4.30128622 loss_ordinary 1.18742096 entropy_value 5.48870707 glob_norm 0.373009592\n",
      "Iteration 50 L -4.31982851 loss -4.3332 loss_ordinary 1.14760578 entropy_value 5.48080587 glob_norm 0.313823819\n",
      "Iteration 100 L -4.31624651 loss -4.32794809 loss_ordinary 1.15934694 entropy_value 5.48729467 glob_norm 0.271259367\n",
      "Iteration 150 L -4.30236578 loss -4.31177616 loss_ordinary 1.18811083 entropy_value 5.49988699 glob_norm 0.474354476\n",
      "Iteration 200 L -4.28238297 loss -4.29549837 loss_ordinary 1.19654036 entropy_value 5.49203873 glob_norm 0.302335978\n",
      "Iteration 250 L -4.33139181 loss -4.34038115 loss_ordinary 1.15494275 entropy_value 5.49532366 glob_norm 0.319505721\n",
      "Iteration 300 L -4.30796957 loss -4.31721401 loss_ordinary 1.17091882 entropy_value 5.48813295 glob_norm 0.286127418\n",
      "Iteration 350 L -4.3235631 loss -4.33817959 loss_ordinary 1.1523453 entropy_value 5.49052477 glob_norm 0.287591815\n",
      "Iteration 400 L -4.28890848 loss -4.2980032 loss_ordinary 1.19566524 entropy_value 5.49366856 glob_norm 0.499347329\n",
      "Iteration 450 L -4.30416155 loss -4.31197214 loss_ordinary 1.18570614 entropy_value 5.49767876 glob_norm 0.329669684\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0.422170639 lambd_papr -0.0201629438 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26241 loss -4.27831888 loss_ordinary 1.21311593 entropy_value 5.49143505 glob_norm 0.339577\n",
      "Iteration 50 L -4.29787064 loss -4.30726671 loss_ordinary 1.19738889 entropy_value 5.50465584 glob_norm 0.345786035\n",
      "Iteration 100 L -4.33522844 loss -4.3345089 loss_ordinary 1.15943146 entropy_value 5.49394083 glob_norm 0.381919235\n",
      "Iteration 150 L -4.29730654 loss -4.31035423 loss_ordinary 1.19563401 entropy_value 5.50598812 glob_norm 0.357874483\n",
      "Iteration 200 L -4.3352437 loss -4.34999514 loss_ordinary 1.15358603 entropy_value 5.50358105 glob_norm 0.324331045\n",
      "Iteration 250 L -4.29638624 loss -4.31454706 loss_ordinary 1.18770254 entropy_value 5.50224972 glob_norm 0.329852879\n",
      "Iteration 300 L -4.26726913 loss -4.28212357 loss_ordinary 1.22322559 entropy_value 5.50534916 glob_norm 0.487710953\n",
      "Iteration 350 L -4.32283497 loss -4.32529116 loss_ordinary 1.17194927 entropy_value 5.49724054 glob_norm 0.401370347\n",
      "Iteration 400 L -4.30536556 loss -4.31274748 loss_ordinary 1.19912887 entropy_value 5.51187658 glob_norm 0.366920829\n",
      "Iteration 450 L -4.28990793 loss -4.30898285 loss_ordinary 1.19435048 entropy_value 5.50333309 glob_norm 0.319176257\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0.304783344 lambd_papr -0.0244227592 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31238461 loss -4.32345343 loss_ordinary 1.18489742 entropy_value 5.50835085 glob_norm 0.333715945\n",
      "Iteration 50 L -4.32936239 loss -4.34354973 loss_ordinary 1.16615653 entropy_value 5.5097065 glob_norm 0.342561275\n",
      "Iteration 100 L -4.30087376 loss -4.31268072 loss_ordinary 1.19805658 entropy_value 5.51073694 glob_norm 0.512991607\n",
      "Iteration 150 L -4.32892895 loss -4.34101725 loss_ordinary 1.16614795 entropy_value 5.50716543 glob_norm 0.263078541\n",
      "Iteration 200 L -4.32913256 loss -4.33864784 loss_ordinary 1.18128586 entropy_value 5.5199337 glob_norm 0.371039361\n",
      "Iteration 250 L -4.31088 loss -4.30406523 loss_ordinary 1.20934117 entropy_value 5.51340628 glob_norm 0.425224334\n",
      "Iteration 300 L -4.31198692 loss -4.31760836 loss_ordinary 1.20131207 entropy_value 5.51892042 glob_norm 0.244369835\n",
      "Iteration 350 L -4.29532814 loss -4.30409575 loss_ordinary 1.21841884 entropy_value 5.52251434 glob_norm 0.382397443\n",
      "Iteration 400 L -4.32933664 loss -4.34282112 loss_ordinary 1.18283963 entropy_value 5.52566099 glob_norm 0.319923729\n",
      "Iteration 450 L -4.32648 loss -4.33381701 loss_ordinary 1.18308675 entropy_value 5.5169034 glob_norm 0.430490524\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.162844181 lambd_papr -0.0275073312 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33130646 loss -4.33500576 loss_ordinary 1.1736393 entropy_value 5.50864506 glob_norm 0.302362204\n",
      "Iteration 50 L -4.29751396 loss -4.30474377 loss_ordinary 1.21812356 entropy_value 5.5228672 glob_norm 0.358073056\n",
      "Iteration 100 L -4.23880959 loss -4.25928736 loss_ordinary 1.2619859 entropy_value 5.52127314 glob_norm 0.37106657\n",
      "Iteration 150 L -4.30148363 loss -4.31040096 loss_ordinary 1.21095228 entropy_value 5.52135277 glob_norm 0.528043091\n",
      "Iteration 200 L -4.33936644 loss -4.33291912 loss_ordinary 1.190732 entropy_value 5.52365112 glob_norm 0.437166601\n",
      "Iteration 250 L -4.28490162 loss -4.286201 loss_ordinary 1.23885691 entropy_value 5.52505779 glob_norm 0.44901666\n",
      "Iteration 300 L -4.2767787 loss -4.28179693 loss_ordinary 1.23558533 entropy_value 5.51738214 glob_norm 0.347656488\n",
      "Iteration 350 L -4.31949091 loss -4.33171892 loss_ordinary 1.18623352 entropy_value 5.51795197 glob_norm 0.422179401\n",
      "Iteration 400 L -4.27963 loss -4.29361248 loss_ordinary 1.23049533 entropy_value 5.52410793 glob_norm 0.332019448\n",
      "Iteration 450 L -4.31451 loss -4.32240057 loss_ordinary 1.19430864 entropy_value 5.51670933 glob_norm 0.332761139\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0.186438799 lambd_papr -0.0291603468 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26098347 loss -4.27175617 loss_ordinary 1.25691819 entropy_value 5.5286746 glob_norm 0.403706253\n",
      "Iteration 50 L -4.33118534 loss -4.32554388 loss_ordinary 1.19525039 entropy_value 5.52079439 glob_norm 0.42353484\n",
      "Iteration 100 L -4.3153 loss -4.31915665 loss_ordinary 1.20284021 entropy_value 5.52199697 glob_norm 0.378729641\n",
      "Iteration 150 L -4.28074026 loss -4.29096413 loss_ordinary 1.23693085 entropy_value 5.52789497 glob_norm 0.374924153\n",
      "Iteration 200 L -4.3259716 loss -4.3360424 loss_ordinary 1.18941259 entropy_value 5.525455 glob_norm 0.456705451\n",
      "Iteration 250 L -4.30886173 loss -4.32006168 loss_ordinary 1.20379269 entropy_value 5.52385426 glob_norm 0.446387023\n",
      "Iteration 300 L -4.30756044 loss -4.32002163 loss_ordinary 1.20254874 entropy_value 5.52257061 glob_norm 0.529052436\n",
      "Iteration 350 L -4.31843758 loss -4.31307 loss_ordinary 1.21021 entropy_value 5.52327967 glob_norm 0.455803782\n",
      "Iteration 400 L -4.33729219 loss -4.33131599 loss_ordinary 1.19180274 entropy_value 5.5231185 glob_norm 0.479922414\n",
      "Iteration 450 L -4.32061863 loss -4.32555676 loss_ordinary 1.20022547 entropy_value 5.52578259 glob_norm 0.384305537\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power -0.151594639 lambd_papr -0.0310585462 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.27501488 loss -4.28722811 loss_ordinary 1.24511778 entropy_value 5.53234625 glob_norm 0.409104705\n",
      "Iteration 50 L -4.29585361 loss -4.3177824 loss_ordinary 1.21611965 entropy_value 5.53390217 glob_norm 0.404040217\n",
      "Iteration 100 L -4.30024 loss -4.31609154 loss_ordinary 1.21280241 entropy_value 5.52889395 glob_norm 0.336987972\n",
      "Iteration 150 L -4.28423166 loss -4.29813528 loss_ordinary 1.22944462 entropy_value 5.52758 glob_norm 0.430843472\n",
      "Iteration 200 L -4.26918888 loss -4.29487944 loss_ordinary 1.22889519 entropy_value 5.52377462 glob_norm 0.501499712\n",
      "Iteration 250 L -4.34619093 loss -4.34617901 loss_ordinary 1.18016398 entropy_value 5.52634287 glob_norm 0.386702836\n",
      "Iteration 300 L -4.2766161 loss -4.29419899 loss_ordinary 1.22864389 entropy_value 5.52284288 glob_norm 0.476890355\n",
      "Iteration 350 L -4.27491045 loss -4.28248692 loss_ordinary 1.23627543 entropy_value 5.51876211 glob_norm 0.34756\n",
      "Iteration 400 L -4.2825861 loss -4.29881716 loss_ordinary 1.22432268 entropy_value 5.52314 glob_norm 0.318460763\n",
      "Iteration 450 L -4.28562307 loss -4.30374 loss_ordinary 1.22030461 entropy_value 5.52404499 glob_norm 0.359944969\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.0269727707 lambd_papr -0.0295104776 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31421232 loss -4.30535603 loss_ordinary 1.22476196 entropy_value 5.53011799 glob_norm 0.48195073\n",
      "Iteration 50 L -4.30418873 loss -4.31812954 loss_ordinary 1.20441663 entropy_value 5.52254581 glob_norm 0.409122676\n",
      "Iteration 100 L -4.29224443 loss -4.29743385 loss_ordinary 1.23063183 entropy_value 5.52806568 glob_norm 0.441663593\n",
      "Iteration 150 L -4.32898903 loss -4.32915068 loss_ordinary 1.19411933 entropy_value 5.52326965 glob_norm 0.296953648\n",
      "Iteration 200 L -4.31885147 loss -4.31822157 loss_ordinary 1.21052063 entropy_value 5.52874184 glob_norm 0.369729966\n",
      "Iteration 250 L -4.28347158 loss -4.29428864 loss_ordinary 1.22588325 entropy_value 5.52017212 glob_norm 0.356302142\n",
      "Iteration 300 L -4.28959322 loss -4.2954793 loss_ordinary 1.23186815 entropy_value 5.52734756 glob_norm 0.453532368\n",
      "Iteration 350 L -4.29473877 loss -4.30846262 loss_ordinary 1.21502745 entropy_value 5.52349 glob_norm 0.307382822\n",
      "Iteration 400 L -4.25178051 loss -4.2692194 loss_ordinary 1.25519693 entropy_value 5.52441645 glob_norm 0.407078624\n",
      "Iteration 450 L -4.31684065 loss -4.31199265 loss_ordinary 1.20946097 entropy_value 5.52145386 glob_norm 0.314789712\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power -0.180135965 lambd_papr -0.0297867469 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28689432 loss -4.29925442 loss_ordinary 1.22493708 entropy_value 5.52419186 glob_norm 0.456766665\n",
      "Iteration 50 L -4.30618763 loss -4.31590796 loss_ordinary 1.21322489 entropy_value 5.52913284 glob_norm 0.400658041\n",
      "Iteration 100 L -4.2994113 loss -4.31432581 loss_ordinary 1.20341182 entropy_value 5.51773739 glob_norm 0.413267374\n",
      "Iteration 150 L -4.30371761 loss -4.2888422 loss_ordinary 1.24188828 entropy_value 5.53073072 glob_norm 0.456312746\n",
      "Iteration 200 L -4.30925941 loss -4.3197732 loss_ordinary 1.20609462 entropy_value 5.52586794 glob_norm 0.347450972\n",
      "Iteration 250 L -4.27286673 loss -4.2953949 loss_ordinary 1.22284985 entropy_value 5.51824474 glob_norm 0.359544367\n",
      "Iteration 300 L -4.28644896 loss -4.28308821 loss_ordinary 1.23569584 entropy_value 5.51878405 glob_norm 0.514469922\n",
      "Iteration 350 L -4.26314497 loss -4.27182436 loss_ordinary 1.24674177 entropy_value 5.51856613 glob_norm 0.523372233\n",
      "Iteration 400 L -4.29894161 loss -4.30731487 loss_ordinary 1.21871877 entropy_value 5.52603388 glob_norm 0.333084762\n",
      "Iteration 450 L -4.31364346 loss -4.32838202 loss_ordinary 1.18805921 entropy_value 5.51644135 glob_norm 0.349777341\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.427056313 lambd_papr -0.0279361624 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26812315 loss -4.29179239 loss_ordinary 1.23015356 entropy_value 5.52194595 glob_norm 0.276962161\n",
      "Iteration 50 L -4.2803092 loss -4.29034805 loss_ordinary 1.2295754 entropy_value 5.51992321 glob_norm 0.590019584\n",
      "Iteration 100 L -4.28380299 loss -4.29005766 loss_ordinary 1.24018991 entropy_value 5.53024769 glob_norm 0.354567\n",
      "Iteration 150 L -4.30119896 loss -4.30647516 loss_ordinary 1.22264338 entropy_value 5.52911854 glob_norm 0.391247809\n",
      "Iteration 200 L -4.29137039 loss -4.28893185 loss_ordinary 1.23873007 entropy_value 5.5276618 glob_norm 0.591736734\n",
      "Iteration 250 L -4.29511 loss -4.30473614 loss_ordinary 1.22683442 entropy_value 5.53157091 glob_norm 0.36804536\n",
      "Iteration 300 L -4.2933774 loss -4.30015802 loss_ordinary 1.22402608 entropy_value 5.52418375 glob_norm 0.391095877\n",
      "Iteration 350 L -4.32730103 loss -4.32335091 loss_ordinary 1.21198583 entropy_value 5.53533697 glob_norm 0.397388756\n",
      "Iteration 400 L -4.27675867 loss -4.2917366 loss_ordinary 1.23992991 entropy_value 5.53166628 glob_norm 0.384304136\n",
      "Iteration 450 L -4.29073811 loss -4.30204248 loss_ordinary 1.21657741 entropy_value 5.51862 glob_norm 0.449712604\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power -0.00183653831 lambd_papr -0.0323365852 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.30937767 loss -4.31978464 loss_ordinary 1.21021175 entropy_value 5.52999592 glob_norm 0.625956416\n",
      "Iteration 50 L -4.27305841 loss -4.27885866 loss_ordinary 1.25962245 entropy_value 5.53848124 glob_norm 0.35305053\n",
      "Iteration 100 L -4.30329084 loss -4.31723738 loss_ordinary 1.21513212 entropy_value 5.53236961 glob_norm 0.340966642\n",
      "Iteration 150 L -4.36072922 loss -4.34500122 loss_ordinary 1.19205201 entropy_value 5.53705311 glob_norm 0.351696789\n",
      "Iteration 200 L -4.27373171 loss -4.28316259 loss_ordinary 1.2394731 entropy_value 5.52263546 glob_norm 0.398634166\n",
      "Iteration 250 L -4.28227854 loss -4.29728556 loss_ordinary 1.23218155 entropy_value 5.52946711 glob_norm 0.452750981\n",
      "Iteration 300 L -4.31334352 loss -4.3090086 loss_ordinary 1.22083962 entropy_value 5.5298481 glob_norm 0.356991559\n",
      "Iteration 350 L -4.29783773 loss -4.2985754 loss_ordinary 1.2437439 entropy_value 5.54232 glob_norm 0.455089122\n",
      "Iteration 400 L -4.31441402 loss -4.31840372 loss_ordinary 1.2082684 entropy_value 5.52667236 glob_norm 0.424280286\n",
      "Iteration 450 L -4.31949282 loss -4.31588173 loss_ordinary 1.21196413 entropy_value 5.52784586 glob_norm 0.311746269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.308314323 lambd_papr -0.0323176049 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32931566 loss -4.32571697 loss_ordinary 1.19557011 entropy_value 5.52128744 glob_norm 0.537452281\n",
      "Iteration 50 L -4.29503489 loss -4.30852318 loss_ordinary 1.21409166 entropy_value 5.52261448 glob_norm 0.500968\n",
      "Iteration 100 L -4.28384686 loss -4.29481506 loss_ordinary 1.24613523 entropy_value 5.5409503 glob_norm 0.319063753\n",
      "Iteration 150 L -4.31526327 loss -4.30820131 loss_ordinary 1.22752666 entropy_value 5.53572798 glob_norm 0.376847088\n",
      "Iteration 200 L -4.36214209 loss -4.35196638 loss_ordinary 1.18865204 entropy_value 5.5406189 glob_norm 0.323060542\n",
      "Iteration 250 L -4.29134703 loss -4.29691029 loss_ordinary 1.24955213 entropy_value 5.54646206 glob_norm 0.517962396\n",
      "Iteration 300 L -4.27890778 loss -4.30033684 loss_ordinary 1.23487389 entropy_value 5.53521061 glob_norm 0.441881418\n",
      "Iteration 350 L -4.30007648 loss -4.31570244 loss_ordinary 1.2238301 entropy_value 5.53953218 glob_norm 0.315062463\n",
      "Iteration 400 L -4.26315212 loss -4.27185297 loss_ordinary 1.27113271 entropy_value 5.54298544 glob_norm 0.469319433\n",
      "Iteration 450 L -4.28803778 loss -4.29377604 loss_ordinary 1.2516216 entropy_value 5.54539776 glob_norm 0.418904096\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power -0.180088758 lambd_papr -0.035513591 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.24720621 loss -4.2551403 loss_ordinary 1.30080378 entropy_value 5.55594397 glob_norm 0.31742838\n",
      "Iteration 50 L -4.28031635 loss -4.29393435 loss_ordinary 1.24409473 entropy_value 5.53802919 glob_norm 0.308263063\n",
      "Iteration 100 L -4.36043882 loss -4.36034918 loss_ordinary 1.18615949 entropy_value 5.54650831 glob_norm 0.340642571\n",
      "Iteration 150 L -4.30961084 loss -4.31761217 loss_ordinary 1.20773268 entropy_value 5.52534485 glob_norm 0.399579465\n",
      "Iteration 200 L -4.29648209 loss -4.30162859 loss_ordinary 1.22741663 entropy_value 5.5290451 glob_norm 0.346876383\n",
      "Iteration 250 L -4.32627153 loss -4.31922865 loss_ordinary 1.21006119 entropy_value 5.52928972 glob_norm 0.465265155\n",
      "Iteration 300 L -4.29800749 loss -4.29873371 loss_ordinary 1.23321378 entropy_value 5.53194761 glob_norm 0.39064604\n",
      "Iteration 350 L -4.25850868 loss -4.25926924 loss_ordinary 1.26811147 entropy_value 5.52738047 glob_norm 0.497698277\n",
      "Iteration 400 L -4.27733898 loss -4.28862238 loss_ordinary 1.24451578 entropy_value 5.5331378 glob_norm 0.344755799\n",
      "Iteration 450 L -4.30159712 loss -4.30045176 loss_ordinary 1.23900104 entropy_value 5.53945255 glob_norm 0.423411936\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.254529238 lambd_papr -0.0336411893 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31947899 loss -4.31913519 loss_ordinary 1.22256064 entropy_value 5.54169559 glob_norm 0.481611609\n",
      "Iteration 50 L -4.32825 loss -4.34349823 loss_ordinary 1.19830573 entropy_value 5.54180384 glob_norm 0.393905193\n",
      "Iteration 100 L -4.27290154 loss -4.28008 loss_ordinary 1.26428568 entropy_value 5.54436541 glob_norm 0.330025017\n",
      "Iteration 150 L -4.28082371 loss -4.28351116 loss_ordinary 1.26257861 entropy_value 5.54608965 glob_norm 0.405923933\n",
      "Iteration 200 L -4.29073095 loss -4.29651737 loss_ordinary 1.25963748 entropy_value 5.55615473 glob_norm 0.412645936\n",
      "Iteration 250 L -4.29011106 loss -4.28558874 loss_ordinary 1.26637638 entropy_value 5.55196524 glob_norm 0.636797547\n",
      "Iteration 300 L -4.28637218 loss -4.29643631 loss_ordinary 1.25458086 entropy_value 5.55101728 glob_norm 0.348762214\n",
      "Iteration 350 L -4.28721046 loss -4.29663038 loss_ordinary 1.25089204 entropy_value 5.54752254 glob_norm 0.340882808\n",
      "Iteration 400 L -4.31341553 loss -4.30865622 loss_ordinary 1.23251164 entropy_value 5.54116774 glob_norm 0.291189492\n",
      "Iteration 450 L -4.29532433 loss -4.29313421 loss_ordinary 1.23983276 entropy_value 5.53296661 glob_norm 0.350599468\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.338886738 lambd_papr -0.0362954959 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32966948 loss -4.30297041 loss_ordinary 1.23930323 entropy_value 5.54227352 glob_norm 0.475435644\n",
      "Iteration 50 L -4.29144621 loss -4.30011082 loss_ordinary 1.24654078 entropy_value 5.54665184 glob_norm 0.463172317\n",
      "Iteration 100 L -4.31230164 loss -4.31172895 loss_ordinary 1.23968601 entropy_value 5.55141497 glob_norm 0.418197483\n",
      "Iteration 150 L -4.2689805 loss -4.2711916 loss_ordinary 1.28062522 entropy_value 5.55181694 glob_norm 0.41376549\n",
      "Iteration 200 L -4.32244825 loss -4.32109833 loss_ordinary 1.23935664 entropy_value 5.56045532 glob_norm 0.361624807\n",
      "Iteration 250 L -4.29596138 loss -4.3022418 loss_ordinary 1.24465561 entropy_value 5.54689741 glob_norm 0.376954347\n",
      "Iteration 300 L -4.3264184 loss -4.33625269 loss_ordinary 1.21595168 entropy_value 5.55220461 glob_norm 0.340794295\n",
      "Iteration 350 L -4.30399752 loss -4.29847908 loss_ordinary 1.25791109 entropy_value 5.55639029 glob_norm 0.408007652\n",
      "Iteration 400 L -4.34230566 loss -4.30677319 loss_ordinary 1.2546494 entropy_value 5.56142235 glob_norm 0.57280457\n",
      "Iteration 450 L -4.31230259 loss -4.30412149 loss_ordinary 1.25307775 entropy_value 5.55719948 glob_norm 0.344701439\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0.107076883 lambd_papr -0.0398401096 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26983118 loss -4.27203751 loss_ordinary 1.28395808 entropy_value 5.55599594 glob_norm 0.505472124\n",
      "Iteration 50 L -4.25729322 loss -4.25778675 loss_ordinary 1.30157 entropy_value 5.55935717 glob_norm 0.450361341\n",
      "Iteration 100 L -4.3156991 loss -4.31785059 loss_ordinary 1.23962 entropy_value 5.5574708 glob_norm 0.304425925\n",
      "Iteration 150 L -4.30793095 loss -4.29947758 loss_ordinary 1.26347637 entropy_value 5.56295395 glob_norm 0.364273816\n",
      "Iteration 200 L -4.28943729 loss -4.29378319 loss_ordinary 1.26858974 entropy_value 5.56237268 glob_norm 0.300301403\n",
      "Iteration 250 L -4.27998066 loss -4.24984 loss_ordinary 1.31647432 entropy_value 5.56631422 glob_norm 0.371283233\n",
      "Iteration 300 L -4.31613827 loss -4.3065877 loss_ordinary 1.25601399 entropy_value 5.56260204 glob_norm 0.391396046\n",
      "Iteration 350 L -4.28523779 loss -4.27171183 loss_ordinary 1.28517067 entropy_value 5.55688238 glob_norm 0.473188907\n",
      "Iteration 400 L -4.28483868 loss -4.27825499 loss_ordinary 1.28617382 entropy_value 5.56442881 glob_norm 0.457146347\n",
      "Iteration 450 L -4.30834913 loss -4.29914951 loss_ordinary 1.26536489 entropy_value 5.56451416 glob_norm 0.400444239\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0.210520029 lambd_papr -0.0409634486 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3467288 loss -4.33312273 loss_ordinary 1.22974217 entropy_value 5.56286526 glob_norm 0.366859525\n",
      "Iteration 50 L -4.31975269 loss -4.33307743 loss_ordinary 1.2302984 entropy_value 5.56337595 glob_norm 0.296176255\n",
      "Iteration 100 L -4.2732749 loss -4.27459669 loss_ordinary 1.28727615 entropy_value 5.56187296 glob_norm 0.311322302\n",
      "Iteration 150 L -4.28523922 loss -4.2872715 loss_ordinary 1.27419627 entropy_value 5.56146812 glob_norm 0.435567647\n",
      "Iteration 200 L -4.29814577 loss -4.29697752 loss_ordinary 1.26280653 entropy_value 5.55978441 glob_norm 0.388893872\n",
      "Iteration 250 L -4.32588243 loss -4.30790663 loss_ordinary 1.26423085 entropy_value 5.57213783 glob_norm 0.336013138\n",
      "Iteration 300 L -4.32334328 loss -4.2907238 loss_ordinary 1.27893245 entropy_value 5.56965637 glob_norm 0.358686745\n",
      "Iteration 350 L -4.29137945 loss -4.29183197 loss_ordinary 1.2773788 entropy_value 5.56921101 glob_norm 0.420418829\n",
      "Iteration 400 L -4.32395792 loss -4.31191301 loss_ordinary 1.26178384 entropy_value 5.57369709 glob_norm 0.442483723\n",
      "Iteration 450 L -4.30813313 loss -4.28969049 loss_ordinary 1.27931106 entropy_value 5.56900167 glob_norm 0.33103919\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power -0.86370182 lambd_papr -0.0431786291 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35004711 loss -4.34688807 loss_ordinary 1.22332275 entropy_value 5.57021093 glob_norm 0.365870029\n",
      "Iteration 50 L -4.31525898 loss -4.32516289 loss_ordinary 1.23462534 entropy_value 5.55978823 glob_norm 0.342196226\n",
      "Iteration 100 L -4.30233049 loss -4.29597759 loss_ordinary 1.2582972 entropy_value 5.55427504 glob_norm 0.393504977\n",
      "Iteration 150 L -4.28178072 loss -4.28677 loss_ordinary 1.26399648 entropy_value 5.55076599 glob_norm 0.304110676\n",
      "Iteration 200 L -4.3132453 loss -4.32442808 loss_ordinary 1.21782684 entropy_value 5.54225492 glob_norm 0.297732592\n",
      "Iteration 250 L -4.26197577 loss -4.27521324 loss_ordinary 1.26410067 entropy_value 5.53931427 glob_norm 0.48698917\n",
      "Iteration 300 L -4.28709888 loss -4.28719234 loss_ordinary 1.2554481 entropy_value 5.54264 glob_norm 0.460182846\n",
      "Iteration 350 L -4.28824 loss -4.2959981 loss_ordinary 1.23981225 entropy_value 5.53581 glob_norm 0.473055452\n",
      "Iteration 400 L -4.31991053 loss -4.32863 loss_ordinary 1.21419704 entropy_value 5.54282665 glob_norm 0.324379832\n",
      "Iteration 450 L -4.30318832 loss -4.31031322 loss_ordinary 1.23299694 entropy_value 5.54331 glob_norm 0.307632208\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power -0.186898947 lambd_papr -0.0340631232 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32949591 loss -4.33344555 loss_ordinary 1.20633721 entropy_value 5.53978252 glob_norm 0.40058288\n",
      "Iteration 50 L -4.31340694 loss -4.30755043 loss_ordinary 1.22792757 entropy_value 5.53547812 glob_norm 0.581466854\n",
      "Iteration 100 L -4.28694391 loss -4.28570318 loss_ordinary 1.24327838 entropy_value 5.52898121 glob_norm 0.564295053\n",
      "Iteration 150 L -4.29649401 loss -4.29645061 loss_ordinary 1.23797154 entropy_value 5.5344224 glob_norm 0.372520804\n",
      "Iteration 200 L -4.32771587 loss -4.31425238 loss_ordinary 1.21207142 entropy_value 5.5263238 glob_norm 0.329580814\n",
      "Iteration 250 L -4.33306313 loss -4.32826614 loss_ordinary 1.19824791 entropy_value 5.52651405 glob_norm 0.445102185\n",
      "Iteration 300 L -4.27918768 loss -4.29290724 loss_ordinary 1.24851501 entropy_value 5.54142189 glob_norm 0.343335956\n",
      "Iteration 350 L -4.29243422 loss -4.30198097 loss_ordinary 1.22324491 entropy_value 5.52522564 glob_norm 0.396251\n",
      "Iteration 400 L -4.32723284 loss -4.33594608 loss_ordinary 1.19922018 entropy_value 5.53516626 glob_norm 0.308230877\n",
      "Iteration 450 L -4.29066133 loss -4.3002 loss_ordinary 1.23254216 entropy_value 5.5327425 glob_norm 0.37539953\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.171447754 lambd_papr -0.0320846736 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3319211 loss -4.32792234 loss_ordinary 1.2071594 entropy_value 5.53508186 glob_norm 0.470019698\n",
      "Iteration 50 L -4.28705025 loss -4.30021572 loss_ordinary 1.23630643 entropy_value 5.53652191 glob_norm 0.430883408\n",
      "Iteration 100 L -4.32094431 loss -4.33102274 loss_ordinary 1.20154119 entropy_value 5.53256416 glob_norm 0.434067905\n",
      "Iteration 150 L -4.29970884 loss -4.28560066 loss_ordinary 1.24722433 entropy_value 5.53282547 glob_norm 0.412033141\n",
      "Iteration 200 L -4.32314396 loss -4.31819725 loss_ordinary 1.22087419 entropy_value 5.53907156 glob_norm 0.464390904\n",
      "Iteration 250 L -4.29376316 loss -4.29251432 loss_ordinary 1.24017048 entropy_value 5.5326848 glob_norm 0.384697348\n",
      "Iteration 300 L -4.2748313 loss -4.27186346 loss_ordinary 1.27217662 entropy_value 5.54404 glob_norm 0.426938385\n",
      "Iteration 350 L -4.27723742 loss -4.27508736 loss_ordinary 1.26754773 entropy_value 5.54263544 glob_norm 0.273126\n",
      "Iteration 400 L -4.27633524 loss -4.2851572 loss_ordinary 1.24727452 entropy_value 5.5324316 glob_norm 0.280837\n",
      "Iteration 450 L -4.28564405 loss -4.28820896 loss_ordinary 1.2523216 entropy_value 5.54053068 glob_norm 0.415044606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power 0.163936138 lambd_papr -0.0339050069 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.30027056 loss -4.30935526 loss_ordinary 1.22445905 entropy_value 5.53381395 glob_norm 0.413037956\n",
      "Iteration 50 L -4.29872227 loss -4.30789518 loss_ordinary 1.22744834 entropy_value 5.53534365 glob_norm 0.640492678\n",
      "Iteration 100 L -4.28146791 loss -4.28056288 loss_ordinary 1.25995159 entropy_value 5.54051447 glob_norm 0.305491686\n",
      "Iteration 150 L -4.31069899 loss -4.30802488 loss_ordinary 1.24186695 entropy_value 5.54989195 glob_norm 0.551403284\n",
      "Iteration 200 L -4.26760817 loss -4.28397322 loss_ordinary 1.26026344 entropy_value 5.54423666 glob_norm 0.451675713\n",
      "Iteration 250 L -4.31622696 loss -4.30541372 loss_ordinary 1.23865426 entropy_value 5.54406786 glob_norm 0.401063174\n",
      "Iteration 300 L -4.29865 loss -4.29159307 loss_ordinary 1.25542176 entropy_value 5.54701471 glob_norm 0.350870341\n",
      "Iteration 350 L -4.29763937 loss -4.31239033 loss_ordinary 1.22833931 entropy_value 5.54072952 glob_norm 0.389710218\n",
      "Iteration 400 L -4.27325439 loss -4.26259041 loss_ordinary 1.27193391 entropy_value 5.53452492 glob_norm 0.43685919\n",
      "Iteration 450 L -4.31096792 loss -4.30220604 loss_ordinary 1.24117124 entropy_value 5.54337692 glob_norm 0.55122757\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power -0.442652 lambd_papr -0.0356508084 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28905296 loss -4.29034472 loss_ordinary 1.24294841 entropy_value 5.53329277 glob_norm 0.340430349\n",
      "Iteration 50 L -4.28233 loss -4.28760862 loss_ordinary 1.25351644 entropy_value 5.5411253 glob_norm 0.343000561\n",
      "Iteration 100 L -4.33588219 loss -4.33724403 loss_ordinary 1.19759691 entropy_value 5.53484106 glob_norm 0.329488605\n",
      "Iteration 150 L -4.28972578 loss -4.28123236 loss_ordinary 1.24970269 entropy_value 5.53093529 glob_norm 0.43285203\n",
      "Iteration 200 L -4.31499386 loss -4.3153677 loss_ordinary 1.21771562 entropy_value 5.53308344 glob_norm 0.340515316\n",
      "Iteration 250 L -4.31563234 loss -4.3161397 loss_ordinary 1.20313287 entropy_value 5.5192728 glob_norm 0.398495376\n",
      "Iteration 300 L -4.28822 loss -4.29123592 loss_ordinary 1.24016666 entropy_value 5.53140259 glob_norm 0.355260432\n",
      "Iteration 350 L -4.2622633 loss -4.27479029 loss_ordinary 1.24958789 entropy_value 5.5243783 glob_norm 0.400813133\n",
      "Iteration 400 L -4.30279589 loss -4.32020855 loss_ordinary 1.20797551 entropy_value 5.52818394 glob_norm 0.368966728\n",
      "Iteration 450 L -4.33861971 loss -4.33212376 loss_ordinary 1.19022739 entropy_value 5.52235126 glob_norm 0.305861503\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0.296744585 lambd_papr -0.0309227463 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.29126263 loss -4.30012131 loss_ordinary 1.23381245 entropy_value 5.53393364 glob_norm 0.31989643\n",
      "Iteration 50 L -4.30102444 loss -4.31418133 loss_ordinary 1.21738589 entropy_value 5.5315671 glob_norm 0.473947406\n",
      "Iteration 100 L -4.29764652 loss -4.29730463 loss_ordinary 1.23715818 entropy_value 5.53446293 glob_norm 0.432146341\n",
      "Iteration 150 L -4.30837107 loss -4.31366253 loss_ordinary 1.21246922 entropy_value 5.52613211 glob_norm 0.415706724\n",
      "Iteration 200 L -4.32380152 loss -4.32939768 loss_ordinary 1.20549548 entropy_value 5.53489304 glob_norm 0.408753365\n",
      "Iteration 250 L -4.28735876 loss -4.29466963 loss_ordinary 1.23259676 entropy_value 5.52726603 glob_norm 0.357650518\n",
      "Iteration 300 L -4.27862597 loss -4.28040028 loss_ordinary 1.25436425 entropy_value 5.53476429 glob_norm 0.427987933\n",
      "Iteration 350 L -4.34342432 loss -4.34046221 loss_ordinary 1.20353127 entropy_value 5.54399347 glob_norm 0.365899563\n",
      "Iteration 400 L -4.2825489 loss -4.28061724 loss_ordinary 1.25670254 entropy_value 5.53731966 glob_norm 0.410375684\n",
      "Iteration 450 L -4.35743666 loss -4.31365108 loss_ordinary 1.22115481 entropy_value 5.53480577 glob_norm 0.450438887\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.0595915318 lambd_papr -0.0341018476 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28853416 loss -4.29572535 loss_ordinary 1.23844409 entropy_value 5.53416967 glob_norm 0.325419277\n",
      "Iteration 50 L -4.307446 loss -4.31007 loss_ordinary 1.22480869 entropy_value 5.53487921 glob_norm 0.365103841\n",
      "Iteration 100 L -4.3072052 loss -4.30605602 loss_ordinary 1.2258755 entropy_value 5.5319314 glob_norm 0.347451687\n",
      "Iteration 150 L -4.31212139 loss -4.30550051 loss_ordinary 1.23514497 entropy_value 5.54064512 glob_norm 0.517783344\n",
      "Iteration 200 L -4.32932043 loss -4.33081818 loss_ordinary 1.20637596 entropy_value 5.53719425 glob_norm 0.550003111\n",
      "Iteration 250 L -4.30301428 loss -4.31162739 loss_ordinary 1.22871721 entropy_value 5.54034472 glob_norm 0.433782637\n",
      "Iteration 300 L -4.33154202 loss -4.34992075 loss_ordinary 1.19159627 entropy_value 5.54151678 glob_norm 0.290817827\n",
      "Iteration 350 L -4.25445604 loss -4.26195431 loss_ordinary 1.27693725 entropy_value 5.53889179 glob_norm 0.388997525\n",
      "Iteration 400 L -4.27205896 loss -4.29058647 loss_ordinary 1.25412786 entropy_value 5.54471397 glob_norm 0.295858145\n",
      "Iteration 450 L -4.28987026 loss -4.299891 loss_ordinary 1.23244929 entropy_value 5.53234 glob_norm 0.373068124\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power -0.145305395 lambd_papr -0.034742184 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.29570913 loss -4.302001 loss_ordinary 1.22808874 entropy_value 5.53009 glob_norm 0.389179707\n",
      "Iteration 50 L -4.28887844 loss -4.30953789 loss_ordinary 1.21751428 entropy_value 5.52705193 glob_norm 0.386106044\n",
      "Iteration 100 L -4.29698753 loss -4.2989 loss_ordinary 1.23829138 entropy_value 5.53719187 glob_norm 0.429692149\n",
      "Iteration 150 L -4.33234835 loss -4.32753277 loss_ordinary 1.20778167 entropy_value 5.53531456 glob_norm 0.533852458\n",
      "Iteration 200 L -4.29015446 loss -4.30293798 loss_ordinary 1.23723781 entropy_value 5.54017544 glob_norm 0.29912892\n",
      "Iteration 250 L -4.25397158 loss -4.25035238 loss_ordinary 1.28575361 entropy_value 5.53610611 glob_norm 0.559094906\n",
      "Iteration 300 L -4.28499 loss -4.28373766 loss_ordinary 1.25000262 entropy_value 5.53374 glob_norm 0.500874877\n",
      "Iteration 350 L -4.28245831 loss -4.29478312 loss_ordinary 1.24554241 entropy_value 5.54032516 glob_norm 0.406468838\n",
      "Iteration 400 L -4.27310371 loss -4.28331041 loss_ordinary 1.25248063 entropy_value 5.53579092 glob_norm 0.347129256\n",
      "Iteration 450 L -4.28833389 loss -4.28197575 loss_ordinary 1.25453043 entropy_value 5.53650618 glob_norm 0.410200179\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power -0.155133247 lambd_papr -0.0331761353 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32437325 loss -4.31228781 loss_ordinary 1.21716964 entropy_value 5.52945757 glob_norm 0.39432767\n",
      "Iteration 50 L -4.28409052 loss -4.29798555 loss_ordinary 1.23797333 entropy_value 5.53595924 glob_norm 0.348624974\n",
      "Iteration 100 L -4.32037592 loss -4.31403112 loss_ordinary 1.21526039 entropy_value 5.52929163 glob_norm 0.356505156\n",
      "Iteration 150 L -4.29666567 loss -4.29992342 loss_ordinary 1.23206854 entropy_value 5.53199196 glob_norm 0.527563572\n",
      "Iteration 200 L -4.26561832 loss -4.28477144 loss_ordinary 1.24855626 entropy_value 5.53332758 glob_norm 0.384908259\n",
      "Iteration 250 L -4.29830027 loss -4.29300117 loss_ordinary 1.23859072 entropy_value 5.53159189 glob_norm 0.382245123\n",
      "Iteration 300 L -4.31131887 loss -4.31304407 loss_ordinary 1.21831405 entropy_value 5.53135824 glob_norm 0.319705814\n",
      "Iteration 350 L -4.30381346 loss -4.30885744 loss_ordinary 1.22729075 entropy_value 5.53614807 glob_norm 0.277843475\n",
      "Iteration 400 L -4.2983284 loss -4.30192614 loss_ordinary 1.23158598 entropy_value 5.53351212 glob_norm 0.395500541\n",
      "Iteration 450 L -4.301929 loss -4.32482243 loss_ordinary 1.20872033 entropy_value 5.53354263 glob_norm 0.275740027\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0.342751265 lambd_papr -0.0314991511 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28176689 loss -4.28968334 loss_ordinary 1.23304248 entropy_value 5.52272606 glob_norm 0.346134901\n",
      "Iteration 50 L -4.28180265 loss -4.29085541 loss_ordinary 1.24660683 entropy_value 5.53746223 glob_norm 0.382931113\n",
      "Iteration 100 L -4.28240824 loss -4.28264809 loss_ordinary 1.25496268 entropy_value 5.53761101 glob_norm 0.332949638\n",
      "Iteration 150 L -4.29445934 loss -4.27601 loss_ordinary 1.2652241 entropy_value 5.54123402 glob_norm 0.350595206\n",
      "Iteration 200 L -4.29894638 loss -4.28954792 loss_ordinary 1.25222206 entropy_value 5.54177 glob_norm 0.297051668\n",
      "Iteration 250 L -4.28156328 loss -4.27420855 loss_ordinary 1.26512456 entropy_value 5.53933334 glob_norm 0.437569261\n",
      "Iteration 300 L -4.32655764 loss -4.30117893 loss_ordinary 1.24090862 entropy_value 5.54208708 glob_norm 0.361703098\n",
      "Iteration 350 L -4.32682514 loss -4.33354 loss_ordinary 1.21018803 entropy_value 5.54372787 glob_norm 0.417711407\n",
      "Iteration 400 L -4.31428671 loss -4.303967 loss_ordinary 1.24339962 entropy_value 5.54736662 glob_norm 0.580663621\n",
      "Iteration 450 L -4.31063175 loss -4.33313608 loss_ordinary 1.20974243 entropy_value 5.54287863 glob_norm 0.295414627\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power -0.0182189941 lambd_papr -0.0352153964 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.2903738 loss -4.28718472 loss_ordinary 1.25704324 entropy_value 5.54422808 glob_norm 0.36901179\n",
      "Iteration 50 L -4.27549791 loss -4.27950191 loss_ordinary 1.26012611 entropy_value 5.53962803 glob_norm 0.415206\n",
      "Iteration 100 L -4.30315256 loss -4.29587603 loss_ordinary 1.25123823 entropy_value 5.54711437 glob_norm 0.454513\n",
      "Iteration 150 L -4.3081913 loss -4.31426525 loss_ordinary 1.2235719 entropy_value 5.53783703 glob_norm 0.355063409\n",
      "Iteration 200 L -4.34233427 loss -4.35159969 loss_ordinary 1.18377984 entropy_value 5.53538 glob_norm 0.443650365\n",
      "Iteration 250 L -4.30109835 loss -4.30414248 loss_ordinary 1.23051071 entropy_value 5.53465319 glob_norm 0.255602211\n",
      "Iteration 300 L -4.30431 loss -4.31344795 loss_ordinary 1.22069645 entropy_value 5.5341444 glob_norm 0.349603832\n",
      "Iteration 350 L -4.27955866 loss -4.29575586 loss_ordinary 1.24005222 entropy_value 5.53580761 glob_norm 0.359399766\n",
      "Iteration 400 L -4.29701 loss -4.30572367 loss_ordinary 1.23676336 entropy_value 5.54248667 glob_norm 0.415302724\n",
      "Iteration 450 L -4.30160093 loss -4.30960798 loss_ordinary 1.23097908 entropy_value 5.54058695 glob_norm 0.330424786\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0.151898384 lambd_papr -0.0350172669 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.30189848 loss -4.31200886 loss_ordinary 1.2281791 entropy_value 5.54018784 glob_norm 0.550498903\n",
      "Iteration 50 L -4.31140852 loss -4.30940247 loss_ordinary 1.2351563 entropy_value 5.54455853 glob_norm 0.347279549\n",
      "Iteration 100 L -4.3087306 loss -4.30655098 loss_ordinary 1.23783529 entropy_value 5.54438639 glob_norm 0.386073798\n",
      "Iteration 150 L -4.30197811 loss -4.30797148 loss_ordinary 1.23623419 entropy_value 5.54420519 glob_norm 0.505351603\n",
      "Iteration 200 L -4.2772665 loss -4.29502 loss_ordinary 1.24703789 entropy_value 5.54205799 glob_norm 0.397316337\n",
      "Iteration 250 L -4.32399416 loss -4.32926464 loss_ordinary 1.20593131 entropy_value 5.5351963 glob_norm 0.327599019\n",
      "Iteration 300 L -4.32646418 loss -4.33532333 loss_ordinary 1.20203769 entropy_value 5.53736067 glob_norm 0.376493871\n",
      "Iteration 350 L -4.31504297 loss -4.31275129 loss_ordinary 1.23482716 entropy_value 5.54757833 glob_norm 0.503491044\n",
      "Iteration 400 L -4.29922199 loss -4.30309439 loss_ordinary 1.24104857 entropy_value 5.54414272 glob_norm 0.354047537\n",
      "Iteration 450 L -4.27017 loss -4.27822161 loss_ordinary 1.27082264 entropy_value 5.54904413 glob_norm 0.326851606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.147037029 lambd_papr -0.0366741084 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.29917288 loss -4.29773664 loss_ordinary 1.25409877 entropy_value 5.55183554 glob_norm 0.336790025\n",
      "Iteration 50 L -4.30097771 loss -4.29965782 loss_ordinary 1.24088848 entropy_value 5.54054642 glob_norm 0.375314295\n",
      "Iteration 100 L -4.29704952 loss -4.28456879 loss_ordinary 1.26264501 entropy_value 5.54721403 glob_norm 0.425367147\n",
      "Iteration 150 L -4.29312515 loss -4.28631926 loss_ordinary 1.25792062 entropy_value 5.54424 glob_norm 0.410667717\n",
      "Iteration 200 L -4.30605555 loss -4.29827642 loss_ordinary 1.25136256 entropy_value 5.54963875 glob_norm 0.453869134\n",
      "Iteration 250 L -4.27686 loss -4.26943111 loss_ordinary 1.27467418 entropy_value 5.54410505 glob_norm 0.506484687\n",
      "Iteration 300 L -4.30187464 loss -4.30988407 loss_ordinary 1.24242258 entropy_value 5.55230665 glob_norm 0.321503699\n",
      "Iteration 350 L -4.29658079 loss -4.30926657 loss_ordinary 1.24041748 entropy_value 5.54968405 glob_norm 0.294918418\n",
      "Iteration 400 L -4.30511665 loss -4.29592657 loss_ordinary 1.25367773 entropy_value 5.54960442 glob_norm 0.310943753\n",
      "Iteration 450 L -4.26240206 loss -4.27272224 loss_ordinary 1.27441585 entropy_value 5.54713821 glob_norm 0.374897242\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0.086826086 lambd_papr -0.0382827334 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.27258778 loss -4.26771212 loss_ordinary 1.28221488 entropy_value 5.54992676 glob_norm 0.370362192\n",
      "Iteration 50 L -4.32394409 loss -4.30220509 loss_ordinary 1.24441481 entropy_value 5.54662 glob_norm 0.490709156\n",
      "Iteration 100 L -4.31166124 loss -4.29704857 loss_ordinary 1.25335777 entropy_value 5.55040646 glob_norm 0.352024108\n",
      "Iteration 150 L -4.27918959 loss -4.28782797 loss_ordinary 1.26209795 entropy_value 5.54992628 glob_norm 0.396656394\n",
      "Iteration 200 L -4.29900646 loss -4.28196049 loss_ordinary 1.26758468 entropy_value 5.54954481 glob_norm 0.313237101\n",
      "Iteration 250 L -4.30408335 loss -4.31246901 loss_ordinary 1.23521876 entropy_value 5.54768753 glob_norm 0.257866651\n",
      "Iteration 300 L -4.30000591 loss -4.28576803 loss_ordinary 1.26219857 entropy_value 5.54796648 glob_norm 0.334774226\n",
      "Iteration 350 L -4.28546 loss -4.26256895 loss_ordinary 1.29471803 entropy_value 5.55728722 glob_norm 0.561501205\n",
      "Iteration 400 L -4.28425741 loss -4.26601934 loss_ordinary 1.29552686 entropy_value 5.56154585 glob_norm 0.414328814\n",
      "Iteration 450 L -4.30088329 loss -4.27892637 loss_ordinary 1.27293444 entropy_value 5.55186081 glob_norm 0.384122401\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power -0.639434814 lambd_papr -0.0392354839 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.2726965 loss -4.2618928 loss_ordinary 1.29496849 entropy_value 5.5568614 glob_norm 0.331240833\n",
      "Iteration 50 L -4.31602859 loss -4.32790232 loss_ordinary 1.21957052 entropy_value 5.54747295 glob_norm 0.372244745\n",
      "Iteration 100 L -4.28885698 loss -4.30383635 loss_ordinary 1.23596752 entropy_value 5.53980398 glob_norm 0.380492538\n",
      "Iteration 150 L -4.34179 loss -4.33484125 loss_ordinary 1.21223724 entropy_value 5.54707861 glob_norm 0.29015708\n",
      "Iteration 200 L -4.31434298 loss -4.32187939 loss_ordinary 1.21041334 entropy_value 5.53229284 glob_norm 0.322971404\n",
      "Iteration 250 L -4.31223583 loss -4.32501 loss_ordinary 1.2102139 entropy_value 5.53522396 glob_norm 0.335620791\n",
      "Iteration 300 L -4.3075676 loss -4.3161149 loss_ordinary 1.21693385 entropy_value 5.53304863 glob_norm 0.335636228\n",
      "Iteration 350 L -4.284832 loss -4.28043365 loss_ordinary 1.25995982 entropy_value 5.54039335 glob_norm 0.360750914\n",
      "Iteration 400 L -4.28914356 loss -4.29758787 loss_ordinary 1.23341644 entropy_value 5.53100443 glob_norm 0.429154128\n",
      "Iteration 450 L -4.33425665 loss -4.34076834 loss_ordinary 1.19438255 entropy_value 5.535151 glob_norm 0.386694044\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.0170791149 lambd_papr -0.0321978554 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28663826 loss -4.29200125 loss_ordinary 1.23693585 entropy_value 5.52893686 glob_norm 0.395827\n",
      "Iteration 50 L -4.29542542 loss -4.29841471 loss_ordinary 1.22829306 entropy_value 5.52670765 glob_norm 0.320807874\n",
      "Iteration 100 L -4.29297495 loss -4.29538774 loss_ordinary 1.24293721 entropy_value 5.53832483 glob_norm 0.317263812\n",
      "Iteration 150 L -4.33217 loss -4.33465147 loss_ordinary 1.1960932 entropy_value 5.53074455 glob_norm 0.254387408\n",
      "Iteration 200 L -4.28830433 loss -4.29650402 loss_ordinary 1.23372686 entropy_value 5.53023052 glob_norm 0.486450225\n",
      "Iteration 250 L -4.31616163 loss -4.31720972 loss_ordinary 1.20941675 entropy_value 5.52662659 glob_norm 0.464380413\n",
      "Iteration 300 L -4.31004906 loss -4.3034811 loss_ordinary 1.2287935 entropy_value 5.53227472 glob_norm 0.4339782\n",
      "Iteration 350 L -4.34759808 loss -4.31486559 loss_ordinary 1.22449446 entropy_value 5.53936 glob_norm 0.365103096\n",
      "Iteration 400 L -4.31655455 loss -4.32077456 loss_ordinary 1.21132421 entropy_value 5.53209925 glob_norm 0.322476417\n",
      "Iteration 450 L -4.32311058 loss -4.32412529 loss_ordinary 1.20328748 entropy_value 5.52741289 glob_norm 0.314368725\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0.283103466 lambd_papr -0.0323863924 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28325129 loss -4.292377 loss_ordinary 1.23563516 entropy_value 5.52801228 glob_norm 0.356666476\n",
      "Iteration 50 L -4.32731342 loss -4.33131886 loss_ordinary 1.20055795 entropy_value 5.53187704 glob_norm 0.274776191\n",
      "Iteration 100 L -4.29330826 loss -4.31062126 loss_ordinary 1.22280371 entropy_value 5.53342485 glob_norm 0.332067788\n",
      "Iteration 150 L -4.29971075 loss -4.30005789 loss_ordinary 1.24325621 entropy_value 5.54331446 glob_norm 0.329730809\n",
      "Iteration 200 L -4.27507782 loss -4.27754 loss_ordinary 1.26768315 entropy_value 5.54522324 glob_norm 0.430844188\n",
      "Iteration 250 L -4.3050561 loss -4.31531763 loss_ordinary 1.21785855 entropy_value 5.53317642 glob_norm 0.349069029\n",
      "Iteration 300 L -4.29651499 loss -4.30573797 loss_ordinary 1.24109459 entropy_value 5.54683256 glob_norm 0.461540222\n",
      "Iteration 350 L -4.33578062 loss -4.3468442 loss_ordinary 1.19449091 entropy_value 5.54133511 glob_norm 0.358307242\n",
      "Iteration 400 L -4.30089 loss -4.30282879 loss_ordinary 1.23922884 entropy_value 5.54205751 glob_norm 0.420282245\n",
      "Iteration 450 L -4.27192974 loss -4.2830615 loss_ordinary 1.25745332 entropy_value 5.54051447 glob_norm 0.31339395\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power -0.023389101 lambd_papr -0.0355209559 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31203079 loss -4.3239212 loss_ordinary 1.20764399 entropy_value 5.53156519 glob_norm 0.358206719\n",
      "Iteration 50 L -4.28642273 loss -4.30051422 loss_ordinary 1.23637891 entropy_value 5.53689337 glob_norm 0.428201735\n",
      "Iteration 100 L -4.36185265 loss -4.34987545 loss_ordinary 1.18969178 entropy_value 5.53956747 glob_norm 0.299702942\n",
      "Iteration 150 L -4.33513 loss -4.32855129 loss_ordinary 1.20847309 entropy_value 5.5370245 glob_norm 0.40026626\n",
      "Iteration 200 L -4.25175381 loss -4.26924133 loss_ordinary 1.27472115 entropy_value 5.54396296 glob_norm 0.544573665\n",
      "Iteration 250 L -4.30183697 loss -4.31700325 loss_ordinary 1.22642338 entropy_value 5.54342651 glob_norm 0.424328\n",
      "Iteration 300 L -4.2959404 loss -4.29499 loss_ordinary 1.24678493 entropy_value 5.54177523 glob_norm 0.351088613\n",
      "Iteration 350 L -4.28946495 loss -4.29450178 loss_ordinary 1.24047959 entropy_value 5.53498125 glob_norm 0.300855726\n",
      "Iteration 400 L -4.32353449 loss -4.31976271 loss_ordinary 1.21764922 entropy_value 5.53741217 glob_norm 0.488576382\n",
      "Iteration 450 L -4.30806446 loss -4.30476522 loss_ordinary 1.22392511 entropy_value 5.52869034 glob_norm 0.278849244\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.228910446 lambd_papr -0.0352612101 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34121 loss -4.34987593 loss_ordinary 1.18688977 entropy_value 5.53676558 glob_norm 0.299762\n",
      "Iteration 50 L -4.31970215 loss -4.32639837 loss_ordinary 1.21888852 entropy_value 5.54528666 glob_norm 0.390521199\n",
      "Iteration 100 L -4.28752661 loss -4.28296041 loss_ordinary 1.26673937 entropy_value 5.5497 glob_norm 0.453538984\n",
      "Iteration 150 L -4.31118298 loss -4.31493616 loss_ordinary 1.23407221 entropy_value 5.54900789 glob_norm 0.320708185\n",
      "Iteration 200 L -4.27311897 loss -4.2772789 loss_ordinary 1.26730466 entropy_value 5.5445838 glob_norm 0.548377693\n",
      "Iteration 250 L -4.27196693 loss -4.27861547 loss_ordinary 1.26984024 entropy_value 5.54845524 glob_norm 0.330020577\n",
      "Iteration 300 L -4.30373955 loss -4.31235838 loss_ordinary 1.23392618 entropy_value 5.5462842 glob_norm 0.285913795\n",
      "Iteration 350 L -4.26126862 loss -4.2651186 loss_ordinary 1.28897238 entropy_value 5.55409098 glob_norm 0.301787555\n",
      "Iteration 400 L -4.25122929 loss -4.27074432 loss_ordinary 1.27864313 entropy_value 5.54938745 glob_norm 0.433037609\n",
      "Iteration 450 L -4.29897213 loss -4.29690218 loss_ordinary 1.24696398 entropy_value 5.54386616 glob_norm 0.365713239\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power -0.315900087 lambd_papr -0.0378109701 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.24942303 loss -4.26713943 loss_ordinary 1.28617895 entropy_value 5.5533185 glob_norm 0.292669684\n",
      "Iteration 50 L -4.28890705 loss -4.30025959 loss_ordinary 1.24402285 entropy_value 5.54428291 glob_norm 0.249113545\n",
      "Iteration 100 L -4.31577682 loss -4.31014299 loss_ordinary 1.22936344 entropy_value 5.53950644 glob_norm 0.27043575\n",
      "Iteration 150 L -4.27952576 loss -4.29287195 loss_ordinary 1.25100708 entropy_value 5.54387903 glob_norm 0.439121068\n",
      "Iteration 200 L -4.29679298 loss -4.3058238 loss_ordinary 1.23816502 entropy_value 5.5439887 glob_norm 0.400476843\n",
      "Iteration 250 L -4.3403759 loss -4.33516 loss_ordinary 1.20727277 entropy_value 5.54243231 glob_norm 0.295723259\n",
      "Iteration 300 L -4.31389141 loss -4.31720495 loss_ordinary 1.21788478 entropy_value 5.53508949 glob_norm 0.469828665\n",
      "Iteration 350 L -4.32682371 loss -4.3259182 loss_ordinary 1.21182764 entropy_value 5.53774548 glob_norm 0.358621389\n",
      "Iteration 400 L -4.33827829 loss -4.32721806 loss_ordinary 1.21044791 entropy_value 5.53766632 glob_norm 0.351477265\n",
      "Iteration 450 L -4.29846859 loss -4.29981136 loss_ordinary 1.23294461 entropy_value 5.53275633 glob_norm 0.382130861\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.0222096443 lambd_papr -0.0342817 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.29308 loss -4.27874613 loss_ordinary 1.25505221 entropy_value 5.53379822 glob_norm 0.342935503\n",
      "Iteration 50 L -4.30685425 loss -4.32587624 loss_ordinary 1.21877301 entropy_value 5.5446496 glob_norm 0.339271963\n",
      "Iteration 100 L -4.33066702 loss -4.33829689 loss_ordinary 1.1999166 entropy_value 5.53821325 glob_norm 0.419700682\n",
      "Iteration 150 L -4.3205843 loss -4.32262039 loss_ordinary 1.22342718 entropy_value 5.54604769 glob_norm 0.259500206\n",
      "Iteration 200 L -4.31007767 loss -4.29410934 loss_ordinary 1.24079216 entropy_value 5.53490162 glob_norm 0.456644058\n",
      "Iteration 250 L -4.33697033 loss -4.32662201 loss_ordinary 1.21041667 entropy_value 5.53703833 glob_norm 0.436502904\n",
      "Iteration 300 L -4.26231623 loss -4.26640463 loss_ordinary 1.27499759 entropy_value 5.54140186 glob_norm 0.30586949\n",
      "Iteration 350 L -4.28980255 loss -4.29038048 loss_ordinary 1.24739635 entropy_value 5.53777695 glob_norm 0.397967964\n",
      "Iteration 400 L -4.27302265 loss -4.28841972 loss_ordinary 1.24563265 entropy_value 5.53405237 glob_norm 0.31507346\n",
      "Iteration 450 L -4.28348494 loss -4.27625132 loss_ordinary 1.25909221 entropy_value 5.53534317 glob_norm 0.36879456\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power 0.0349447727 lambd_papr -0.0345305726 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28212595 loss -4.29084396 loss_ordinary 1.25198257 entropy_value 5.54282618 glob_norm 0.384763956\n",
      "Iteration 50 L -4.32056 loss -4.31221294 loss_ordinary 1.22930229 entropy_value 5.54151535 glob_norm 0.42855987\n",
      "Iteration 100 L -4.30167627 loss -4.30487776 loss_ordinary 1.23257422 entropy_value 5.53745174 glob_norm 0.349966526\n",
      "Iteration 150 L -4.27148199 loss -4.26205444 loss_ordinary 1.27947652 entropy_value 5.54153109 glob_norm 0.420145154\n",
      "Iteration 200 L -4.30679226 loss -4.30223417 loss_ordinary 1.23590469 entropy_value 5.53813887 glob_norm 0.460271955\n",
      "Iteration 250 L -4.26883 loss -4.28032827 loss_ordinary 1.25988328 entropy_value 5.54021168 glob_norm 0.458579153\n",
      "Iteration 300 L -4.28780937 loss -4.27674818 loss_ordinary 1.26091433 entropy_value 5.53766251 glob_norm 0.55442816\n",
      "Iteration 350 L -4.31717968 loss -4.3299 loss_ordinary 1.20775938 entropy_value 5.53765917 glob_norm 0.409671932\n",
      "Iteration 400 L -4.32147551 loss -4.32063913 loss_ordinary 1.21756864 entropy_value 5.53820753 glob_norm 0.401358753\n",
      "Iteration 450 L -4.29569578 loss -4.31338406 loss_ordinary 1.21865928 entropy_value 5.53204346 glob_norm 0.318159252\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0.14158082 lambd_papr -0.0349233262 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28774 loss -4.29752588 loss_ordinary 1.24182701 entropy_value 5.53935289 glob_norm 0.424905807\n",
      "Iteration 50 L -4.27087545 loss -4.27799177 loss_ordinary 1.26812088 entropy_value 5.54611254 glob_norm 0.342406601\n",
      "Iteration 100 L -4.31992674 loss -4.33298731 loss_ordinary 1.20493937 entropy_value 5.53792667 glob_norm 0.363316566\n",
      "Iteration 150 L -4.28706884 loss -4.30750751 loss_ordinary 1.23675895 entropy_value 5.5442667 glob_norm 0.292771071\n",
      "Iteration 200 L -4.3228693 loss -4.31707764 loss_ordinary 1.23103368 entropy_value 5.54811144 glob_norm 0.397787482\n",
      "Iteration 250 L -4.26776505 loss -4.26541901 loss_ordinary 1.27879691 entropy_value 5.54421616 glob_norm 0.485976726\n",
      "Iteration 300 L -4.30724716 loss -4.31418037 loss_ordinary 1.2273941 entropy_value 5.54157448 glob_norm 0.417689174\n",
      "Iteration 350 L -4.27360868 loss -4.26508713 loss_ordinary 1.27680695 entropy_value 5.54189396 glob_norm 0.312535584\n",
      "Iteration 400 L -4.26128817 loss -4.27203321 loss_ordinary 1.27128422 entropy_value 5.54331732 glob_norm 0.350846857\n",
      "Iteration 450 L -4.28919363 loss -4.30341291 loss_ordinary 1.23845327 entropy_value 5.54186583 glob_norm 0.43551892\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0.00388717651 lambd_papr -0.0365193598 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32618332 loss -4.31603146 loss_ordinary 1.22896838 entropy_value 5.545 glob_norm 0.416780114\n",
      "Iteration 50 L -4.30454254 loss -4.30839396 loss_ordinary 1.23474443 entropy_value 5.5431385 glob_norm 0.39696303\n",
      "Iteration 100 L -4.31972599 loss -4.31815147 loss_ordinary 1.2190851 entropy_value 5.53723669 glob_norm 0.382708728\n",
      "Iteration 150 L -4.30948496 loss -4.30296 loss_ordinary 1.24347401 entropy_value 5.5464344 glob_norm 0.312544912\n",
      "Iteration 200 L -4.26849842 loss -4.27998161 loss_ordinary 1.26095617 entropy_value 5.54093742 glob_norm 0.39544034\n",
      "Iteration 250 L -4.27966 loss -4.25338221 loss_ordinary 1.29047954 entropy_value 5.54386139 glob_norm 0.379728645\n",
      "Iteration 300 L -4.32634735 loss -4.31435251 loss_ordinary 1.23143923 entropy_value 5.5457921 glob_norm 0.396838218\n",
      "Iteration 350 L -4.29518461 loss -4.30092335 loss_ordinary 1.24393821 entropy_value 5.54486132 glob_norm 0.395207435\n",
      "Iteration 400 L -4.30976915 loss -4.29587221 loss_ordinary 1.24993408 entropy_value 5.54580641 glob_norm 0.411805183\n",
      "Iteration 450 L -4.32764912 loss -4.32873 loss_ordinary 1.21822989 entropy_value 5.54696 glob_norm 0.396704912\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0.150144577 lambd_papr -0.0365633108 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3267045 loss -4.31816864 loss_ordinary 1.21807241 entropy_value 5.53624105 glob_norm 0.331564248\n",
      "Iteration 50 L -4.30265 loss -4.31275892 loss_ordinary 1.23240745 entropy_value 5.54516649 glob_norm 0.343260944\n",
      "Iteration 100 L -4.32948494 loss -4.32305431 loss_ordinary 1.22708774 entropy_value 5.55014229 glob_norm 0.421008617\n",
      "Iteration 150 L -4.28376865 loss -4.29997492 loss_ordinary 1.25290811 entropy_value 5.55288267 glob_norm 0.382395059\n",
      "Iteration 200 L -4.28389597 loss -4.29291344 loss_ordinary 1.24754989 entropy_value 5.54046345 glob_norm 0.439728916\n",
      "Iteration 250 L -4.31147099 loss -4.29360962 loss_ordinary 1.25401545 entropy_value 5.54762506 glob_norm 0.356134832\n",
      "Iteration 300 L -4.31445217 loss -4.29923153 loss_ordinary 1.25152016 entropy_value 5.55075169 glob_norm 0.303998828\n",
      "Iteration 350 L -4.28157091 loss -4.27728367 loss_ordinary 1.27929723 entropy_value 5.55658102 glob_norm 0.390083432\n",
      "Iteration 400 L -4.31424 loss -4.31749773 loss_ordinary 1.23564291 entropy_value 5.55314064 glob_norm 0.40201056\n",
      "Iteration 450 L -4.30495787 loss -4.29689455 loss_ordinary 1.24903202 entropy_value 5.54592657 glob_norm 0.390840232\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.00503659248 lambd_papr -0.0382660553 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.24923325 loss -4.25999546 loss_ordinary 1.28482139 entropy_value 5.54481697 glob_norm 0.311860114\n",
      "Iteration 50 L -4.35852098 loss -4.36608315 loss_ordinary 1.18733978 entropy_value 5.55342293 glob_norm 0.325060189\n",
      "Iteration 100 L -4.31934309 loss -4.32424402 loss_ordinary 1.22574198 entropy_value 5.54998589 glob_norm 0.395874977\n",
      "Iteration 150 L -4.26475191 loss -4.24433088 loss_ordinary 1.31559157 entropy_value 5.5599227 glob_norm 0.38432768\n",
      "Iteration 200 L -4.32333422 loss -4.30325508 loss_ordinary 1.24388587 entropy_value 5.5471406 glob_norm 0.344730675\n",
      "Iteration 250 L -4.32060432 loss -4.30421114 loss_ordinary 1.24400783 entropy_value 5.5482192 glob_norm 0.426526517\n",
      "Iteration 300 L -4.25210857 loss -4.26163864 loss_ordinary 1.29091394 entropy_value 5.5525527 glob_norm 0.452213317\n",
      "Iteration 350 L -4.27805805 loss -4.27576494 loss_ordinary 1.2782222 entropy_value 5.55398703 glob_norm 0.419071943\n",
      "Iteration 400 L -4.29748583 loss -4.29185772 loss_ordinary 1.25505805 entropy_value 5.54691601 glob_norm 0.452366889\n",
      "Iteration 450 L -4.31609583 loss -4.32635403 loss_ordinary 1.21812761 entropy_value 5.54448175 glob_norm 0.337036729\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.115455866 lambd_papr -0.038208764 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32564688 loss -4.33592796 loss_ordinary 1.21504366 entropy_value 5.55097198 glob_norm 0.376877487\n",
      "Iteration 50 L -4.32403 loss -4.31789064 loss_ordinary 1.23569739 entropy_value 5.55358791 glob_norm 0.379871666\n",
      "Iteration 100 L -4.31745052 loss -4.32147646 loss_ordinary 1.22723472 entropy_value 5.5487113 glob_norm 0.302887887\n",
      "Iteration 150 L -4.31617165 loss -4.32539511 loss_ordinary 1.22498572 entropy_value 5.55038071 glob_norm 0.297688246\n",
      "Iteration 200 L -4.30556107 loss -4.29628181 loss_ordinary 1.25673807 entropy_value 5.55302 glob_norm 0.317319304\n",
      "Iteration 250 L -4.29495859 loss -4.27706671 loss_ordinary 1.26808119 entropy_value 5.5451479 glob_norm 0.435992867\n",
      "Iteration 300 L -4.29940081 loss -4.31266689 loss_ordinary 1.24108696 entropy_value 5.55375385 glob_norm 0.3627823\n",
      "Iteration 350 L -4.29822588 loss -4.30200243 loss_ordinary 1.25827873 entropy_value 5.56028128 glob_norm 0.370161533\n",
      "Iteration 400 L -4.30710459 loss -4.31783438 loss_ordinary 1.23426008 entropy_value 5.55209446 glob_norm 0.332030118\n",
      "Iteration 450 L -4.29363346 loss -4.29485035 loss_ordinary 1.26035142 entropy_value 5.55520201 glob_norm 0.457130849\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power 0.0365197659 lambd_papr -0.039525982 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.26808691 loss -4.28897142 loss_ordinary 1.26273048 entropy_value 5.55170155 glob_norm 0.424124897\n",
      "Iteration 50 L -4.25690508 loss -4.27040339 loss_ordinary 1.28873372 entropy_value 5.55913734 glob_norm 0.382039875\n",
      "Iteration 100 L -4.29956293 loss -4.29605 loss_ordinary 1.25421023 entropy_value 5.55026054 glob_norm 0.371780962\n",
      "Iteration 150 L -4.31116295 loss -4.29231787 loss_ordinary 1.2679776 entropy_value 5.5602951 glob_norm 0.46229738\n",
      "Iteration 200 L -4.28667879 loss -4.27311468 loss_ordinary 1.28227937 entropy_value 5.5553937 glob_norm 0.35912621\n",
      "Iteration 250 L -4.31132555 loss -4.31433 loss_ordinary 1.2378664 entropy_value 5.5521965 glob_norm 0.410292417\n",
      "Iteration 300 L -4.26464081 loss -4.26968813 loss_ordinary 1.28603673 entropy_value 5.55572462 glob_norm 0.290886104\n",
      "Iteration 350 L -4.28050184 loss -4.27536678 loss_ordinary 1.28554535 entropy_value 5.56091261 glob_norm 0.408139735\n",
      "Iteration 400 L -4.30301428 loss -4.30514717 loss_ordinary 1.24680984 entropy_value 5.55195713 glob_norm 0.289944172\n",
      "Iteration 450 L -4.29331303 loss -4.26993132 loss_ordinary 1.28462839 entropy_value 5.55456 glob_norm 0.40154022\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power -0.0717241764 lambd_papr -0.0399438813 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28946781 loss -4.27504 loss_ordinary 1.27506924 entropy_value 5.55010939 glob_norm 0.371753722\n",
      "Iteration 50 L -4.32510424 loss -4.31996202 loss_ordinary 1.23605537 entropy_value 5.5560174 glob_norm 0.37585941\n",
      "Iteration 100 L -4.27017546 loss -4.27059889 loss_ordinary 1.29067731 entropy_value 5.56127644 glob_norm 0.434058458\n",
      "Iteration 150 L -4.33964157 loss -4.34859228 loss_ordinary 1.20441353 entropy_value 5.5530057 glob_norm 0.28851524\n",
      "Iteration 200 L -4.32435417 loss -4.31991673 loss_ordinary 1.23016024 entropy_value 5.55007696 glob_norm 0.42134884\n",
      "Iteration 250 L -4.28636837 loss -4.28952408 loss_ordinary 1.26435113 entropy_value 5.55387545 glob_norm 0.379731327\n",
      "Iteration 300 L -4.27281904 loss -4.26601648 loss_ordinary 1.29306209 entropy_value 5.55907869 glob_norm 0.355461746\n",
      "Iteration 350 L -4.31006432 loss -4.31484127 loss_ordinary 1.24110353 entropy_value 5.55594492 glob_norm 0.317657232\n",
      "Iteration 400 L -4.27909327 loss -4.28555 loss_ordinary 1.26342273 entropy_value 5.54897308 glob_norm 0.419286072\n",
      "Iteration 450 L -4.28650475 loss -4.29178762 loss_ordinary 1.25604749 entropy_value 5.54783487 glob_norm 0.29992041\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.130229 lambd_papr -0.0391206741 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.2974081 loss -4.2771616 loss_ordinary 1.28080475 entropy_value 5.55796623 glob_norm 0.435699701\n",
      "Iteration 50 L -4.27996445 loss -4.29573441 loss_ordinary 1.25397146 entropy_value 5.54970598 glob_norm 0.340565741\n",
      "Iteration 100 L -4.31791496 loss -4.31562 loss_ordinary 1.23838603 entropy_value 5.5540061 glob_norm 0.379949212\n",
      "Iteration 150 L -4.28996038 loss -4.28412294 loss_ordinary 1.27094519 entropy_value 5.55506802 glob_norm 0.414535969\n",
      "Iteration 200 L -4.34936523 loss -4.30367661 loss_ordinary 1.25200665 entropy_value 5.55568361 glob_norm 0.363828182\n",
      "Iteration 250 L -4.29595 loss -4.28545427 loss_ordinary 1.27296805 entropy_value 5.55842257 glob_norm 0.362194508\n",
      "Iteration 300 L -4.29502916 loss -4.28934431 loss_ordinary 1.27518189 entropy_value 5.56452608 glob_norm 0.318281293\n",
      "Iteration 350 L -4.29695606 loss -4.31206799 loss_ordinary 1.23815405 entropy_value 5.55022192 glob_norm 0.283132911\n",
      "Iteration 400 L -4.26705 loss -4.26979446 loss_ordinary 1.2811904 entropy_value 5.55098534 glob_norm 0.279676527\n",
      "Iteration 450 L -4.28807163 loss -4.28855371 loss_ordinary 1.2720294 entropy_value 5.56058311 glob_norm 0.33241263\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power -0.0954926 lambd_papr -0.0406198464 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3096385 loss -4.3069973 loss_ordinary 1.25582469 entropy_value 5.56282234 glob_norm 0.322953969\n",
      "Iteration 50 L -4.30124617 loss -4.28011942 loss_ordinary 1.27274799 entropy_value 5.55286741 glob_norm 0.463012129\n",
      "Iteration 100 L -4.30452442 loss -4.30217075 loss_ordinary 1.24872684 entropy_value 5.5508976 glob_norm 0.399608254\n",
      "Iteration 150 L -4.33020782 loss -4.32551575 loss_ordinary 1.22812772 entropy_value 5.55364323 glob_norm 0.420878619\n",
      "Iteration 200 L -4.32206583 loss -4.32683 loss_ordinary 1.23170221 entropy_value 5.55853224 glob_norm 0.329923272\n",
      "Iteration 250 L -4.28729486 loss -4.28504276 loss_ordinary 1.26292789 entropy_value 5.54797077 glob_norm 0.446113378\n",
      "Iteration 300 L -4.28150034 loss -4.29034424 loss_ordinary 1.26468289 entropy_value 5.55502701 glob_norm 0.278305978\n",
      "Iteration 350 L -4.29118156 loss -4.29132843 loss_ordinary 1.25611365 entropy_value 5.54744148 glob_norm 0.360131919\n",
      "Iteration 400 L -4.30165195 loss -4.29914951 loss_ordinary 1.25669456 entropy_value 5.55584383 glob_norm 0.477764338\n",
      "Iteration 450 L -4.28798676 loss -4.30542755 loss_ordinary 1.2501651 entropy_value 5.55559254 glob_norm 0.319190711\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power -0.239471912 lambd_papr -0.0395172536 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_13_papr_7.0\n",
      "\n",
      "===== Running SNR=13 dB | PAPR=8.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0164325982 loss 0.0164325982 loss_ordinary 6.00761604 entropy_value 5.99118328 glob_norm 0.629374862\n",
      "Iteration 50 L -2.92476749 loss -2.92476749 loss_ordinary 3.03503942 entropy_value 5.95980692 glob_norm 0.399358213\n",
      "Iteration 100 L -3.77679 loss -3.77679 loss_ordinary 2.13918638 entropy_value 5.91597605 glob_norm 0.314606\n",
      "Iteration 150 L -3.94307923 loss -3.94307923 loss_ordinary 1.93222082 entropy_value 5.8753 glob_norm 0.328044951\n",
      "Iteration 200 L -4.08023453 loss -4.08023453 loss_ordinary 1.68521154 entropy_value 5.76544619 glob_norm 0.422674388\n",
      "Iteration 250 L -4.19396114 loss -4.19396114 loss_ordinary 1.43921173 entropy_value 5.63317299 glob_norm 0.338652611\n",
      "Iteration 300 L -4.25801611 loss -4.25801611 loss_ordinary 1.28564596 entropy_value 5.54366207 glob_norm 0.512147248\n",
      "Iteration 350 L -4.28520632 loss -4.28520632 loss_ordinary 1.21178007 entropy_value 5.49698639 glob_norm 0.484007418\n",
      "Iteration 400 L -4.31765509 loss -4.31765509 loss_ordinary 1.14392436 entropy_value 5.46157932 glob_norm 0.40321362\n",
      "Iteration 450 L -4.33188629 loss -4.33193588 loss_ordinary 1.11079264 entropy_value 5.44272852 glob_norm 0.452699\n",
      "Iteration 500 L -4.34033394 loss -4.34056091 loss_ordinary 1.09645319 entropy_value 5.4370141 glob_norm 0.561035514\n",
      "Iteration 550 L -4.33355618 loss -4.33484459 loss_ordinary 1.08301091 entropy_value 5.41785574 glob_norm 0.480566859\n",
      "Iteration 600 L -4.3154459 loss -4.31603956 loss_ordinary 1.10518849 entropy_value 5.42122793 glob_norm 0.455154419\n",
      "Iteration 650 L -4.32477903 loss -4.3247838 loss_ordinary 1.09413731 entropy_value 5.41892099 glob_norm 0.335256696\n",
      "Iteration 700 L -4.35916948 loss -4.3592658 loss_ordinary 1.04726839 entropy_value 5.40653419 glob_norm 0.537958\n",
      "Iteration 750 L -4.32234144 loss -4.32330799 loss_ordinary 1.08200669 entropy_value 5.40531445 glob_norm 0.442679822\n",
      "Iteration 800 L -4.33721876 loss -4.33721876 loss_ordinary 1.05045164 entropy_value 5.38767 glob_norm 0.530459583\n",
      "Iteration 850 L -4.33650923 loss -4.33784866 loss_ordinary 1.06061971 entropy_value 5.39846849 glob_norm 0.398392379\n",
      "Iteration 900 L -4.34293413 loss -4.34296846 loss_ordinary 1.05258751 entropy_value 5.39555597 glob_norm 0.370542705\n",
      "Iteration 950 L -4.35773468 loss -4.35866404 loss_ordinary 1.03950644 entropy_value 5.39817095 glob_norm 0.409258515\n",
      "Iteration 1000 L -4.31729 loss -4.31831312 loss_ordinary 1.07093418 entropy_value 5.38924742 glob_norm 0.430984378\n",
      "Iteration 1050 L -4.3508544 loss -4.35104609 loss_ordinary 1.0466162 entropy_value 5.39766216 glob_norm 0.343073934\n",
      "Iteration 1100 L -4.34323883 loss -4.34341955 loss_ordinary 1.05705416 entropy_value 5.40047407 glob_norm 0.484520108\n",
      "Iteration 1150 L -4.33723974 loss -4.33723974 loss_ordinary 1.05393958 entropy_value 5.39117908 glob_norm 0.336442113\n",
      "Iteration 1200 L -4.33941507 loss -4.33941507 loss_ordinary 1.05563807 entropy_value 5.39505291 glob_norm 0.568126202\n",
      "Iteration 1250 L -4.36518955 loss -4.36519623 loss_ordinary 1.0341562 entropy_value 5.39935255 glob_norm 0.382350445\n",
      "Iteration 1300 L -4.37270308 loss -4.37390041 loss_ordinary 1.00599396 entropy_value 5.37989426 glob_norm 0.289451063\n",
      "Iteration 1350 L -4.32543373 loss -4.3254509 loss_ordinary 1.06809139 entropy_value 5.39354229 glob_norm 0.363391608\n",
      "Iteration 1400 L -4.34704256 loss -4.34704494 loss_ordinary 1.04972863 entropy_value 5.39677334 glob_norm 0.457890302\n",
      "Iteration 1450 L -4.32137442 loss -4.32261 loss_ordinary 1.05777287 entropy_value 5.38038301 glob_norm 0.439145\n",
      "Iteration 1500 L -4.34534264 loss -4.34534264 loss_ordinary 1.0510689 entropy_value 5.3964119 glob_norm 0.434381396\n",
      "Iteration 1550 L -4.28540134 loss -4.28542519 loss_ordinary 1.09752989 entropy_value 5.38295507 glob_norm 0.386120617\n",
      "Iteration 1600 L -4.31722879 loss -4.31758404 loss_ordinary 1.06981158 entropy_value 5.38739586 glob_norm 0.369850904\n",
      "Iteration 1650 L -4.34918642 loss -4.349473 loss_ordinary 1.04112601 entropy_value 5.39059877 glob_norm 0.488399953\n",
      "Iteration 1700 L -4.32449245 loss -4.32506657 loss_ordinary 1.06162035 entropy_value 5.38668728 glob_norm 0.578301\n",
      "Iteration 1750 L -4.30920792 loss -4.30990171 loss_ordinary 1.08088565 entropy_value 5.3907876 glob_norm 0.408439696\n",
      "Iteration 1800 L -4.31820107 loss -4.31860161 loss_ordinary 1.05749416 entropy_value 5.37609577 glob_norm 0.458995283\n",
      "Iteration 1850 L -4.35814285 loss -4.35856915 loss_ordinary 1.02390301 entropy_value 5.38247252 glob_norm 0.664895654\n",
      "Iteration 1900 L -4.3564477 loss -4.35675812 loss_ordinary 1.02940989 entropy_value 5.38616753 glob_norm 0.439846426\n",
      "Iteration 1950 L -4.36234045 loss -4.36234045 loss_ordinary 1.02322936 entropy_value 5.38556957 glob_norm 0.403088152\n",
      "Iteration 2000 L -4.31262636 loss -4.31280661 loss_ordinary 1.06659043 entropy_value 5.37939692 glob_norm 0.485010177\n",
      "Iteration 2050 L -4.34025621 loss -4.34096336 loss_ordinary 1.04064655 entropy_value 5.38160944 glob_norm 0.421881229\n",
      "Iteration 2100 L -4.33793259 loss -4.3387 loss_ordinary 1.04813278 entropy_value 5.38683271 glob_norm 0.469715565\n",
      "Iteration 2150 L -4.33539 loss -4.33539057 loss_ordinary 1.06023967 entropy_value 5.39563036 glob_norm 0.465321749\n",
      "Iteration 2200 L -4.37479067 loss -4.37499046 loss_ordinary 1.01301146 entropy_value 5.38800192 glob_norm 0.325803816\n",
      "Iteration 2250 L -4.33563042 loss -4.33646059 loss_ordinary 1.0446806 entropy_value 5.38114119 glob_norm 0.438784629\n",
      "Iteration 2300 L -4.34574747 loss -4.34612417 loss_ordinary 1.03968167 entropy_value 5.38580608 glob_norm 0.337894708\n",
      "Iteration 2350 L -4.3364 loss -4.33690929 loss_ordinary 1.05384088 entropy_value 5.39075041 glob_norm 0.349188685\n",
      "Iteration 2400 L -4.32338095 loss -4.32371235 loss_ordinary 1.06128693 entropy_value 5.38499975 glob_norm 0.422730953\n",
      "Iteration 2450 L -4.31675053 loss -4.31684208 loss_ordinary 1.07709789 entropy_value 5.39394 glob_norm 0.428439528\n",
      "Iteration 2500 L -4.34059048 loss -4.34092855 loss_ordinary 1.04034 entropy_value 5.3812685 glob_norm 0.350829899\n",
      "Iteration 2550 L -4.33806372 loss -4.3383503 loss_ordinary 1.04837334 entropy_value 5.38672352 glob_norm 0.338281631\n",
      "Iteration 2600 L -4.34398556 loss -4.34398556 loss_ordinary 1.03062761 entropy_value 5.37461329 glob_norm 0.290778816\n",
      "Iteration 2650 L -4.38688469 loss -4.38747025 loss_ordinary 0.99211812 entropy_value 5.37958813 glob_norm 0.277087331\n",
      "Iteration 2700 L -4.34791279 loss -4.34791279 loss_ordinary 1.03345656 entropy_value 5.38136959 glob_norm 0.435996622\n",
      "Iteration 2750 L -4.29634666 loss -4.29681921 loss_ordinary 1.08918834 entropy_value 5.38600731 glob_norm 0.416082174\n",
      "Iteration 2800 L -4.34243202 loss -4.34290171 loss_ordinary 1.03736138 entropy_value 5.38026333 glob_norm 0.448507309\n",
      "Iteration 2850 L -4.30308533 loss -4.30353069 loss_ordinary 1.08150673 entropy_value 5.38503742 glob_norm 0.56980896\n",
      "Iteration 2900 L -4.32970572 loss -4.32995749 loss_ordinary 1.0575974 entropy_value 5.38755512 glob_norm 0.367029041\n",
      "Iteration 2950 L -4.31451845 loss -4.31578398 loss_ordinary 1.05981791 entropy_value 5.37560177 glob_norm 0.617375612\n",
      "Iteration 3000 L -4.33143711 loss -4.33159924 loss_ordinary 1.04813921 entropy_value 5.37973881 glob_norm 0.372072875\n",
      "Iteration 3050 L -4.34589958 loss -4.34706736 loss_ordinary 1.0277195 entropy_value 5.37478638 glob_norm 0.349984348\n",
      "Iteration 3100 L -4.30800915 loss -4.30831385 loss_ordinary 1.06719923 entropy_value 5.37551308 glob_norm 0.573145092\n",
      "Iteration 3150 L -4.34112167 loss -4.34150028 loss_ordinary 1.03572881 entropy_value 5.37722921 glob_norm 0.304911435\n",
      "Iteration 3200 L -4.32357168 loss -4.32390738 loss_ordinary 1.05394602 entropy_value 5.37785339 glob_norm 0.32062602\n",
      "Iteration 3250 L -4.33577871 loss -4.33598614 loss_ordinary 1.044559 entropy_value 5.38054514 glob_norm 0.403422713\n",
      "Iteration 3300 L -4.34083796 loss -4.34177 loss_ordinary 1.04041541 entropy_value 5.38218546 glob_norm 0.361183524\n",
      "Iteration 3350 L -4.31748486 loss -4.31765652 loss_ordinary 1.0721997 entropy_value 5.38985586 glob_norm 0.35036692\n",
      "Iteration 3400 L -4.3655076 loss -4.36657047 loss_ordinary 1.00878119 entropy_value 5.37535191 glob_norm 0.29795146\n",
      "Iteration 3450 L -4.35843229 loss -4.35965681 loss_ordinary 1.02320635 entropy_value 5.38286304 glob_norm 0.448362231\n",
      "Iteration 3500 L -4.3428359 loss -4.34314537 loss_ordinary 1.03113508 entropy_value 5.37428045 glob_norm 0.265713245\n",
      "Iteration 3550 L -4.32193375 loss -4.32193375 loss_ordinary 1.05758512 entropy_value 5.37951851 glob_norm 0.338869512\n",
      "Iteration 3600 L -4.33394194 loss -4.33410597 loss_ordinary 1.05700195 entropy_value 5.39110756 glob_norm 0.517772734\n",
      "Iteration 3650 L -4.36440563 loss -4.36532211 loss_ordinary 1.02222013 entropy_value 5.38754225 glob_norm 0.405487299\n",
      "Iteration 3700 L -4.35699797 loss -4.35746861 loss_ordinary 1.02159381 entropy_value 5.37906265 glob_norm 0.627449095\n",
      "Iteration 3750 L -4.32581472 loss -4.32590437 loss_ordinary 1.05280399 entropy_value 5.37870836 glob_norm 0.464162886\n",
      "Iteration 3800 L -4.29957485 loss -4.29961157 loss_ordinary 1.08570981 entropy_value 5.38532114 glob_norm 0.328001201\n",
      "Iteration 3850 L -4.3078 loss -4.30820894 loss_ordinary 1.06855464 entropy_value 5.37676382 glob_norm 0.515654206\n",
      "Iteration 3900 L -4.31313181 loss -4.31365395 loss_ordinary 1.06374514 entropy_value 5.37739897 glob_norm 0.456046224\n",
      "Iteration 3950 L -4.35384035 loss -4.35385036 loss_ordinary 1.03125858 entropy_value 5.38510895 glob_norm 0.441081494\n",
      "Iteration 4000 L -4.35067272 loss -4.3506732 loss_ordinary 1.03705764 entropy_value 5.38773108 glob_norm 0.322548389\n",
      "Iteration 4050 L -4.34815598 loss -4.34817266 loss_ordinary 1.02854967 entropy_value 5.37672186 glob_norm 0.464430064\n",
      "Iteration 4100 L -4.36098862 loss -4.36123896 loss_ordinary 1.02126145 entropy_value 5.3825 glob_norm 0.332495391\n",
      "Iteration 4150 L -4.32459545 loss -4.32460976 loss_ordinary 1.05674958 entropy_value 5.3813591 glob_norm 0.373825401\n",
      "Iteration 4200 L -4.30849934 loss -4.30861855 loss_ordinary 1.0766294 entropy_value 5.38524818 glob_norm 0.443274707\n",
      "Iteration 4250 L -4.32006741 loss -4.32007217 loss_ordinary 1.06348598 entropy_value 5.38355827 glob_norm 0.421874017\n",
      "Iteration 4300 L -4.36154413 loss -4.36171 loss_ordinary 1.01337922 entropy_value 5.37508917 glob_norm 0.348521322\n",
      "Iteration 4350 L -4.29458 loss -4.29471445 loss_ordinary 1.09342253 entropy_value 5.38813686 glob_norm 0.496694684\n",
      "Iteration 4400 L -4.35576963 loss -4.35584736 loss_ordinary 1.02704215 entropy_value 5.38288927 glob_norm 0.316389471\n",
      "Iteration 4450 L -4.30368233 loss -4.30386448 loss_ordinary 1.08018529 entropy_value 5.38404942 glob_norm 0.488986313\n",
      "Iteration 4500 L -4.34071875 loss -4.3407197 loss_ordinary 1.03490686 entropy_value 5.37562656 glob_norm 0.323592365\n",
      "Iteration 4550 L -4.33544779 loss -4.33556938 loss_ordinary 1.05859888 entropy_value 5.39416838 glob_norm 0.416360915\n",
      "Iteration 4600 L -4.3179431 loss -4.31881618 loss_ordinary 1.0580163 entropy_value 5.37683249 glob_norm 0.38559866\n",
      "Iteration 4650 L -4.34974718 loss -4.34984303 loss_ordinary 1.03217983 entropy_value 5.38202286 glob_norm 0.327646017\n",
      "Iteration 4700 L -4.35969877 loss -4.35969877 loss_ordinary 1.01550913 entropy_value 5.37520742 glob_norm 0.372694075\n",
      "Iteration 4750 L -4.31748486 loss -4.31748486 loss_ordinary 1.06885016 entropy_value 5.3863349 glob_norm 0.404174566\n",
      "Iteration 4800 L -4.33111858 loss -4.3316946 loss_ordinary 1.04166222 entropy_value 5.3733573 glob_norm 0.446463\n",
      "Iteration 4850 L -4.3252635 loss -4.3252635 loss_ordinary 1.06187212 entropy_value 5.38713551 glob_norm 0.434826016\n",
      "Iteration 4900 L -4.33961296 loss -4.33961296 loss_ordinary 1.04610062 entropy_value 5.38571358 glob_norm 0.43242687\n",
      "Iteration 4950 L -4.35917568 loss -4.3601613 loss_ordinary 1.01342082 entropy_value 5.37358189 glob_norm 0.618279\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 0.0783946514 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33231878 loss -4.33232594 loss_ordinary 1.05120873 entropy_value 5.38353443 glob_norm 0.469284773\n",
      "Iteration 50 L -4.31503963 loss -4.3151989 loss_ordinary 1.07258832 entropy_value 5.38778734 glob_norm 0.460712969\n",
      "Iteration 100 L -4.37621212 loss -4.37673092 loss_ordinary 1.01017642 entropy_value 5.3869071 glob_norm 0.457436264\n",
      "Iteration 150 L -4.36265278 loss -4.36312199 loss_ordinary 1.02239501 entropy_value 5.38551712 glob_norm 0.293558687\n",
      "Iteration 200 L -4.35814428 loss -4.35836315 loss_ordinary 1.02709258 entropy_value 5.38545561 glob_norm 0.362866461\n",
      "Iteration 250 L -4.34006357 loss -4.34010029 loss_ordinary 1.04910409 entropy_value 5.3892045 glob_norm 0.459662437\n",
      "Iteration 300 L -4.32411385 loss -4.32428217 loss_ordinary 1.06277466 entropy_value 5.38705683 glob_norm 0.370472133\n",
      "Iteration 350 L -4.28363657 loss -4.283916 loss_ordinary 1.10311103 entropy_value 5.38702679 glob_norm 0.341385931\n",
      "Iteration 400 L -4.35647345 loss -4.35715437 loss_ordinary 1.03189921 entropy_value 5.38905382 glob_norm 0.506789625\n",
      "Iteration 450 L -4.33330297 loss -4.33410597 loss_ordinary 1.05007708 entropy_value 5.38418293 glob_norm 0.477660298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power -0.0751287937 lambd_papr -0.000783946482 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31293821 loss -4.3130722 loss_ordinary 1.06853616 entropy_value 5.38160801 glob_norm 0.409126133\n",
      "Iteration 50 L -4.32925606 loss -4.3292675 loss_ordinary 1.04860258 entropy_value 5.37787 glob_norm 0.350118876\n",
      "Iteration 100 L -4.31314516 loss -4.31314516 loss_ordinary 1.06835556 entropy_value 5.38150072 glob_norm 0.447718203\n",
      "Iteration 150 L -4.33330297 loss -4.33483791 loss_ordinary 1.04633474 entropy_value 5.38117266 glob_norm 0.37958765\n",
      "Iteration 200 L -4.34726095 loss -4.34770823 loss_ordinary 1.0408268 entropy_value 5.38853502 glob_norm 0.411126554\n",
      "Iteration 250 L -4.32613373 loss -4.3263936 loss_ordinary 1.06412685 entropy_value 5.39052 glob_norm 0.348731369\n",
      "Iteration 300 L -4.31723118 loss -4.31736374 loss_ordinary 1.07416737 entropy_value 5.39153099 glob_norm 0.315077901\n",
      "Iteration 350 L -4.3359766 loss -4.33644819 loss_ordinary 1.04154217 entropy_value 5.37799072 glob_norm 0.439461052\n",
      "Iteration 400 L -4.3520422 loss -4.35320616 loss_ordinary 1.02939367 entropy_value 5.38260031 glob_norm 0.321544886\n",
      "Iteration 450 L -4.33418798 loss -4.33477259 loss_ordinary 1.05774879 entropy_value 5.39252138 glob_norm 0.445704639\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0.367054 lambd_papr -3.04047135e-05 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28812504 loss -4.28806877 loss_ordinary 1.09531772 entropy_value 5.38338661 glob_norm 0.410888582\n",
      "Iteration 50 L -4.36291122 loss -4.36192036 loss_ordinary 1.02051973 entropy_value 5.38243961 glob_norm 0.341574699\n",
      "Iteration 100 L -4.32910061 loss -4.32810926 loss_ordinary 1.06233275 entropy_value 5.39044237 glob_norm 0.349256814\n",
      "Iteration 150 L -4.35027838 loss -4.35087967 loss_ordinary 1.0413152 entropy_value 5.39219522 glob_norm 0.361566156\n",
      "Iteration 200 L -4.33939743 loss -4.3396039 loss_ordinary 1.05306196 entropy_value 5.39266539 glob_norm 0.330944926\n",
      "Iteration 250 L -4.36862946 loss -4.3677249 loss_ordinary 1.02801859 entropy_value 5.39574385 glob_norm 0.378634095\n",
      "Iteration 300 L -4.33794641 loss -4.33695507 loss_ordinary 1.05417931 entropy_value 5.39113474 glob_norm 0.446518183\n",
      "Iteration 350 L -4.30127 loss -4.30093384 loss_ordinary 1.09990394 entropy_value 5.4008379 glob_norm 0.356296122\n",
      "Iteration 400 L -4.33436394 loss -4.33851767 loss_ordinary 1.04841948 entropy_value 5.38693714 glob_norm 0.363340676\n",
      "Iteration 450 L -4.34772635 loss -4.34711456 loss_ordinary 1.04607475 entropy_value 5.39318943 glob_norm 0.365693837\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0.0193572044 lambd_papr -0.00372300064 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35233307 loss -4.35415745 loss_ordinary 1.03479397 entropy_value 5.3889513 glob_norm 0.422449738\n",
      "Iteration 50 L -4.32996225 loss -4.32888222 loss_ordinary 1.07472849 entropy_value 5.40361071 glob_norm 0.397130907\n",
      "Iteration 100 L -4.31211185 loss -4.31437683 loss_ordinary 1.07971442 entropy_value 5.39409113 glob_norm 0.419648319\n",
      "Iteration 150 L -4.35949469 loss -4.3584 loss_ordinary 1.03166139 entropy_value 5.39006138 glob_norm 0.390479624\n",
      "Iteration 200 L -4.36313 loss -4.36294508 loss_ordinary 1.03205585 entropy_value 5.39500093 glob_norm 0.324697\n",
      "Iteration 250 L -4.33457041 loss -4.33496714 loss_ordinary 1.06668591 entropy_value 5.40165281 glob_norm 0.340476573\n",
      "Iteration 300 L -4.3303957 loss -4.33016253 loss_ordinary 1.06463706 entropy_value 5.39479971 glob_norm 0.303286254\n",
      "Iteration 350 L -4.36036634 loss -4.36224937 loss_ordinary 1.03431916 entropy_value 5.39656878 glob_norm 0.275316179\n",
      "Iteration 400 L -4.34137821 loss -4.34041643 loss_ordinary 1.05553544 entropy_value 5.39595127 glob_norm 0.404245317\n",
      "Iteration 450 L -4.31372643 loss -4.31307697 loss_ordinary 1.08115125 entropy_value 5.39422798 glob_norm 0.282418191\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0.28444767 lambd_papr -0.00391832 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3388052 loss -4.33564758 loss_ordinary 1.06097388 entropy_value 5.3966217 glob_norm 0.41010353\n",
      "Iteration 50 L -4.35366631 loss -4.35117579 loss_ordinary 1.0464679 entropy_value 5.39764357 glob_norm 0.303897262\n",
      "Iteration 100 L -4.32972383 loss -4.32904243 loss_ordinary 1.07065594 entropy_value 5.39969873 glob_norm 0.421601\n",
      "Iteration 150 L -4.33015347 loss -4.32747602 loss_ordinary 1.07495582 entropy_value 5.40243196 glob_norm 0.395870596\n",
      "Iteration 200 L -4.35308 loss -4.35177374 loss_ordinary 1.05475497 entropy_value 5.40652895 glob_norm 0.289878607\n",
      "Iteration 250 L -4.32789803 loss -4.32557249 loss_ordinary 1.07678378 entropy_value 5.40235615 glob_norm 0.344958246\n",
      "Iteration 300 L -4.32133865 loss -4.32003784 loss_ordinary 1.09308219 entropy_value 5.41312027 glob_norm 0.405064315\n",
      "Iteration 350 L -4.32493353 loss -4.32244349 loss_ordinary 1.09140599 entropy_value 5.41384935 glob_norm 0.366687119\n",
      "Iteration 400 L -4.34117508 loss -4.34139156 loss_ordinary 1.06373465 entropy_value 5.40512657 glob_norm 0.246900395\n",
      "Iteration 450 L -4.33721399 loss -4.33580971 loss_ordinary 1.07735455 entropy_value 5.41316462 glob_norm 0.39691928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power -0.162064552 lambd_papr -0.00679708412 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.36347771 loss -4.3632369 loss_ordinary 1.04588377 entropy_value 5.40912056 glob_norm 0.272806436\n",
      "Iteration 50 L -4.33054161 loss -4.32917213 loss_ordinary 1.07900596 entropy_value 5.40817785 glob_norm 0.374189794\n",
      "Iteration 100 L -4.35741568 loss -4.35602903 loss_ordinary 1.04062259 entropy_value 5.39665174 glob_norm 0.326752067\n",
      "Iteration 150 L -4.32385111 loss -4.32437706 loss_ordinary 1.0800904 entropy_value 5.40446758 glob_norm 0.308312595\n",
      "Iteration 200 L -4.34097576 loss -4.34356976 loss_ordinary 1.06550288 entropy_value 5.4090724 glob_norm 0.310955763\n",
      "Iteration 250 L -4.32174253 loss -4.32292891 loss_ordinary 1.07603407 entropy_value 5.39896297 glob_norm 0.360506296\n",
      "Iteration 300 L -4.33213377 loss -4.33155727 loss_ordinary 1.07776523 entropy_value 5.40932226 glob_norm 0.381259948\n",
      "Iteration 350 L -4.34505844 loss -4.34367752 loss_ordinary 1.06431675 entropy_value 5.40799427 glob_norm 0.318530023\n",
      "Iteration 400 L -4.30915308 loss -4.30957127 loss_ordinary 1.09646416 entropy_value 5.40603542 glob_norm 0.363203317\n",
      "Iteration 450 L -4.36671114 loss -4.36511 loss_ordinary 1.03813744 entropy_value 5.40324736 glob_norm 0.393582165\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power -0.1753335 lambd_papr -0.00515198242 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34329 loss -4.34252453 loss_ordinary 1.06581259 entropy_value 5.40833712 glob_norm 0.421685725\n",
      "Iteration 50 L -4.30607 loss -4.30746365 loss_ordinary 1.09238029 entropy_value 5.39984369 glob_norm 0.475267649\n",
      "Iteration 100 L -4.35021162 loss -4.34941101 loss_ordinary 1.0532707 entropy_value 5.40268183 glob_norm 0.461793184\n",
      "Iteration 150 L -4.32578611 loss -4.32549524 loss_ordinary 1.0727452 entropy_value 5.39824 glob_norm 0.498605371\n",
      "Iteration 200 L -4.3072257 loss -4.30831194 loss_ordinary 1.08994246 entropy_value 5.39825439 glob_norm 0.313388497\n",
      "Iteration 250 L -4.30300379 loss -4.30239344 loss_ordinary 1.10012877 entropy_value 5.40252256 glob_norm 0.41277492\n",
      "Iteration 300 L -4.32294846 loss -4.32246256 loss_ordinary 1.07536018 entropy_value 5.39782286 glob_norm 0.26735729\n",
      "Iteration 350 L -4.34847832 loss -4.34866714 loss_ordinary 1.04576182 entropy_value 5.39442921 glob_norm 0.447541296\n",
      "Iteration 400 L -4.32462692 loss -4.32427549 loss_ordinary 1.07137907 entropy_value 5.3956542 glob_norm 0.43326661\n",
      "Iteration 450 L -4.32069921 loss -4.3207984 loss_ordinary 1.07382333 entropy_value 5.39462185 glob_norm 0.292176813\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power -0.160172701 lambd_papr -0.00336684962 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32632494 loss -4.32784367 loss_ordinary 1.07383454 entropy_value 5.40167809 glob_norm 0.282579452\n",
      "Iteration 50 L -4.29971886 loss -4.29958057 loss_ordinary 1.09168029 entropy_value 5.39126062 glob_norm 0.514023066\n",
      "Iteration 100 L -4.32810926 loss -4.32797098 loss_ordinary 1.0639137 entropy_value 5.39188433 glob_norm 0.500500321\n",
      "Iteration 150 L -4.35995913 loss -4.36089659 loss_ordinary 1.0313251 entropy_value 5.39222145 glob_norm 0.307822\n",
      "Iteration 200 L -4.33161831 loss -4.33163738 loss_ordinary 1.06440198 entropy_value 5.39603949 glob_norm 0.330744326\n",
      "Iteration 250 L -4.33786726 loss -4.33809948 loss_ordinary 1.05924976 entropy_value 5.39734936 glob_norm 0.379977196\n",
      "Iteration 300 L -4.33140707 loss -4.33315229 loss_ordinary 1.05930531 entropy_value 5.39245749 glob_norm 0.374691904\n",
      "Iteration 350 L -4.32275343 loss -4.32429028 loss_ordinary 1.06934381 entropy_value 5.39363432 glob_norm 0.325419277\n",
      "Iteration 400 L -4.36696529 loss -4.36705303 loss_ordinary 1.02633297 entropy_value 5.39338589 glob_norm 0.367587507\n",
      "Iteration 450 L -4.33456898 loss -4.334764 loss_ordinary 1.05890477 entropy_value 5.39366865 glob_norm 0.368576705\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.176028967 lambd_papr -0.00173118187 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3490386 loss -4.34832811 loss_ordinary 1.03339958 entropy_value 5.3817277 glob_norm 0.401295662\n",
      "Iteration 50 L -4.30177259 loss -4.30263519 loss_ordinary 1.08168578 entropy_value 5.38432074 glob_norm 0.356228858\n",
      "Iteration 100 L -4.29763603 loss -4.29846573 loss_ordinary 1.09999549 entropy_value 5.39846134 glob_norm 0.374587774\n",
      "Iteration 150 L -4.34659338 loss -4.34762239 loss_ordinary 1.0455327 entropy_value 5.3931551 glob_norm 0.257980585\n",
      "Iteration 200 L -4.32814455 loss -4.32767296 loss_ordinary 1.07688117 entropy_value 5.40455389 glob_norm 0.441176593\n",
      "Iteration 250 L -4.34674311 loss -4.34703779 loss_ordinary 1.05044079 entropy_value 5.39747858 glob_norm 0.324989825\n",
      "Iteration 300 L -4.34491539 loss -4.34584761 loss_ordinary 1.04691982 entropy_value 5.39276695 glob_norm 0.319663584\n",
      "Iteration 350 L -4.32510519 loss -4.3250947 loss_ordinary 1.05766428 entropy_value 5.38275909 glob_norm 0.557004929\n",
      "Iteration 400 L -4.3478179 loss -4.34860516 loss_ordinary 1.03785908 entropy_value 5.3864646 glob_norm 0.29483977\n",
      "Iteration 450 L -4.38139296 loss -4.38075352 loss_ordinary 1.01639664 entropy_value 5.39715052 glob_norm 0.322846174\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power -0.291974783 lambd_papr -0.00353416498 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33632278 loss -4.33631086 loss_ordinary 1.06184876 entropy_value 5.3981595 glob_norm 0.342533737\n",
      "Iteration 50 L -4.3536272 loss -4.35459518 loss_ordinary 1.04127645 entropy_value 5.39587164 glob_norm 0.380676925\n",
      "Iteration 100 L -4.35182762 loss -4.35191441 loss_ordinary 1.03956425 entropy_value 5.39147854 glob_norm 0.382424235\n",
      "Iteration 150 L -4.30573559 loss -4.30672073 loss_ordinary 1.08178937 entropy_value 5.38851 glob_norm 0.361627281\n",
      "Iteration 200 L -4.34325171 loss -4.34354496 loss_ordinary 1.04341483 entropy_value 5.38695955 glob_norm 0.428390801\n",
      "Iteration 250 L -4.33377409 loss -4.33375406 loss_ordinary 1.05741131 entropy_value 5.39116526 glob_norm 0.364790827\n",
      "Iteration 300 L -4.33671379 loss -4.33708858 loss_ordinary 1.04720199 entropy_value 5.38429 glob_norm 0.363001853\n",
      "Iteration 350 L -4.31160164 loss -4.31188536 loss_ordinary 1.08121812 entropy_value 5.3931036 glob_norm 0.355896\n",
      "Iteration 400 L -4.30360699 loss -4.30400562 loss_ordinary 1.0914638 entropy_value 5.39546919 glob_norm 0.337947071\n",
      "Iteration 450 L -4.34329414 loss -4.34508228 loss_ordinary 1.04259205 entropy_value 5.38767481 glob_norm 0.356473327\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.319003582 lambd_papr -0.000534630846 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33377695 loss -4.33324957 loss_ordinary 1.04806602 entropy_value 5.38131571 glob_norm 0.504741728\n",
      "Iteration 50 L -4.34865046 loss -4.3483572 loss_ordinary 1.04250526 entropy_value 5.39086199 glob_norm 0.33282423\n",
      "Iteration 100 L -4.3429904 loss -4.34237909 loss_ordinary 1.05718875 entropy_value 5.39956808 glob_norm 0.31713143\n",
      "Iteration 150 L -4.35676956 loss -4.35575 loss_ordinary 1.03881359 entropy_value 5.39456415 glob_norm 0.426605463\n",
      "Iteration 200 L -4.33290148 loss -4.33383322 loss_ordinary 1.05900371 entropy_value 5.39283705 glob_norm 0.452043414\n",
      "Iteration 250 L -4.35443163 loss -4.35598803 loss_ordinary 1.03874516 entropy_value 5.39473343 glob_norm 0.268779397\n",
      "Iteration 300 L -4.3253541 loss -4.32478714 loss_ordinary 1.07149768 entropy_value 5.39628458 glob_norm 0.269877017\n",
      "Iteration 350 L -4.33033895 loss -4.33007193 loss_ordinary 1.06322324 entropy_value 5.39329481 glob_norm 0.69698745\n",
      "Iteration 400 L -4.33002853 loss -4.33077192 loss_ordinary 1.07411218 entropy_value 5.40488386 glob_norm 0.352309912\n",
      "Iteration 450 L -4.35131359 loss -4.35075903 loss_ordinary 1.04335928 entropy_value 5.39411831 glob_norm 0.289745778\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power -0.162690878 lambd_papr -0.00382167078 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3273468 loss -4.32702875 loss_ordinary 1.07186115 entropy_value 5.39889 glob_norm 0.273448884\n",
      "Iteration 50 L -4.37645674 loss -4.37744665 loss_ordinary 1.02128696 entropy_value 5.39873362 glob_norm 0.340386659\n",
      "Iteration 100 L -4.35311174 loss -4.35378456 loss_ordinary 1.04379249 entropy_value 5.39757729 glob_norm 0.299688101\n",
      "Iteration 150 L -4.344522 loss -4.34422922 loss_ordinary 1.05089498 entropy_value 5.39512444 glob_norm 0.530624688\n",
      "Iteration 200 L -4.35142183 loss -4.35110331 loss_ordinary 1.04507935 entropy_value 5.39618254 glob_norm 0.347538233\n",
      "Iteration 250 L -4.35812235 loss -4.35795593 loss_ordinary 1.03631783 entropy_value 5.39427376 glob_norm 0.399785727\n",
      "Iteration 300 L -4.30175 loss -4.30170202 loss_ordinary 1.09438336 entropy_value 5.39608574 glob_norm 0.442700058\n",
      "Iteration 350 L -4.35264969 loss -4.35233116 loss_ordinary 1.04520988 entropy_value 5.39754105 glob_norm 0.268461317\n",
      "Iteration 400 L -4.33885241 loss -4.33990335 loss_ordinary 1.05584872 entropy_value 5.39575195 glob_norm 0.406812549\n",
      "Iteration 450 L -4.35877657 loss -4.35872841 loss_ordinary 1.04013038 entropy_value 5.39885902 glob_norm 0.364287317\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power -0.206469268 lambd_papr -0.002140261 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35068035 loss -4.35071516 loss_ordinary 1.05045676 entropy_value 5.40117216 glob_norm 0.303315729\n",
      "Iteration 50 L -4.33499527 loss -4.33499527 loss_ordinary 1.05877113 entropy_value 5.3937664 glob_norm 0.301856399\n",
      "Iteration 100 L -4.31796598 loss -4.31889868 loss_ordinary 1.07321846 entropy_value 5.39211702 glob_norm 0.304033369\n",
      "Iteration 150 L -4.32163525 loss -4.32249165 loss_ordinary 1.0669508 entropy_value 5.38944244 glob_norm 0.325905174\n",
      "Iteration 200 L -4.33495235 loss -4.33541632 loss_ordinary 1.05296183 entropy_value 5.38837814 glob_norm 0.326955497\n",
      "Iteration 250 L -4.375422 loss -4.37563276 loss_ordinary 1.00834429 entropy_value 5.38397694 glob_norm 0.333710581\n",
      "Iteration 300 L -4.37047958 loss -4.37047958 loss_ordinary 1.01697195 entropy_value 5.38745165 glob_norm 0.432106316\n",
      "Iteration 350 L -4.32662201 loss -4.32778502 loss_ordinary 1.0563134 entropy_value 5.38409853 glob_norm 0.603413761\n",
      "Iteration 400 L -4.35490894 loss -4.35523653 loss_ordinary 1.0279156 entropy_value 5.38315201 glob_norm 0.320682406\n",
      "Iteration 450 L -4.3536787 loss -4.35379791 loss_ordinary 1.02731979 entropy_value 5.38111782 glob_norm 0.369161606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.280275106 lambd_papr 0 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32758617 loss -4.3275609 loss_ordinary 1.06105125 entropy_value 5.38861179 glob_norm 0.4080185\n",
      "Iteration 50 L -4.3421154 loss -4.34285212 loss_ordinary 1.04675102 entropy_value 5.38960314 glob_norm 0.326405\n",
      "Iteration 100 L -4.3084383 loss -4.30866146 loss_ordinary 1.08142138 entropy_value 5.39008284 glob_norm 0.38971439\n",
      "Iteration 150 L -4.31920624 loss -4.32014894 loss_ordinary 1.07645845 entropy_value 5.3966074 glob_norm 0.39968434\n",
      "Iteration 200 L -4.33958054 loss -4.33917952 loss_ordinary 1.0554862 entropy_value 5.39466572 glob_norm 0.368570626\n",
      "Iteration 250 L -4.34031391 loss -4.34007072 loss_ordinary 1.04664874 entropy_value 5.3867197 glob_norm 0.341192633\n",
      "Iteration 300 L -4.33097219 loss -4.33106565 loss_ordinary 1.07166243 entropy_value 5.40272808 glob_norm 0.390204608\n",
      "Iteration 350 L -4.33587217 loss -4.33562708 loss_ordinary 1.05387533 entropy_value 5.38950253 glob_norm 0.307478219\n",
      "Iteration 400 L -4.34132671 loss -4.34104967 loss_ordinary 1.05327129 entropy_value 5.39432096 glob_norm 0.274075806\n",
      "Iteration 450 L -4.31042767 loss -4.31084776 loss_ordinary 1.08511734 entropy_value 5.3959651 glob_norm 0.373336673\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power -0.254523039 lambd_papr -0.0029140485 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34183073 loss -4.34311581 loss_ordinary 1.05260241 entropy_value 5.3957181 glob_norm 0.414720476\n",
      "Iteration 50 L -4.34311676 loss -4.34311199 loss_ordinary 1.0542978 entropy_value 5.39741039 glob_norm 0.238683417\n",
      "Iteration 100 L -4.30351973 loss -4.30363464 loss_ordinary 1.08466172 entropy_value 5.38829613 glob_norm 0.379949778\n",
      "Iteration 150 L -4.32639313 loss -4.3269763 loss_ordinary 1.06443298 entropy_value 5.3914094 glob_norm 0.269369811\n",
      "Iteration 200 L -4.33015585 loss -4.33075762 loss_ordinary 1.0554148 entropy_value 5.38617277 glob_norm 0.364194065\n",
      "Iteration 250 L -4.34740925 loss -4.34740496 loss_ordinary 1.04426217 entropy_value 5.39166689 glob_norm 0.335642725\n",
      "Iteration 300 L -4.3324666 loss -4.33246231 loss_ordinary 1.05494177 entropy_value 5.38740396 glob_norm 0.287885547\n",
      "Iteration 350 L -4.36493683 loss -4.36536074 loss_ordinary 1.02506089 entropy_value 5.39042187 glob_norm 0.286148727\n",
      "Iteration 400 L -4.3322978 loss -4.33427286 loss_ordinary 1.05280983 entropy_value 5.38708258 glob_norm 0.37733537\n",
      "Iteration 450 L -4.34138727 loss -4.3413825 loss_ordinary 1.05537748 entropy_value 5.39676 glob_norm 0.466138035\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power -0.0248392243 lambd_papr -0.000259807799 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33641577 loss -4.3364625 loss_ordinary 1.04744923 entropy_value 5.38391209 glob_norm 0.324526876\n",
      "Iteration 50 L -4.34427643 loss -4.34438848 loss_ordinary 1.04470062 entropy_value 5.38908958 glob_norm 0.389533192\n",
      "Iteration 100 L -4.34198284 loss -4.3419919 loss_ordinary 1.04060686 entropy_value 5.38259888 glob_norm 0.409082621\n",
      "Iteration 150 L -4.31140137 loss -4.31144047 loss_ordinary 1.07927024 entropy_value 5.39071035 glob_norm 0.337367147\n",
      "Iteration 200 L -4.32641077 loss -4.32647943 loss_ordinary 1.06213832 entropy_value 5.38861799 glob_norm 0.370413512\n",
      "Iteration 250 L -4.34108353 loss -4.34114885 loss_ordinary 1.04283249 entropy_value 5.38398123 glob_norm 0.34111\n",
      "Iteration 300 L -4.36428213 loss -4.3643012 loss_ordinary 1.02027178 entropy_value 5.38457298 glob_norm 0.367165893\n",
      "Iteration 350 L -4.34854221 loss -4.34864521 loss_ordinary 1.042135 entropy_value 5.39078045 glob_norm 0.333181739\n",
      "Iteration 400 L -4.33762789 loss -4.33762789 loss_ordinary 1.04951465 entropy_value 5.38714266 glob_norm 0.303519934\n",
      "Iteration 450 L -4.30524492 loss -4.30592489 loss_ordinary 1.08081949 entropy_value 5.38674402 glob_norm 0.326693505\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0.0207102299 lambd_papr 0 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33731651 loss -4.33769274 loss_ordinary 1.03767467 entropy_value 5.37536716 glob_norm 0.471026331\n",
      "Iteration 50 L -4.32246208 loss -4.32308435 loss_ordinary 1.06234193 entropy_value 5.38542604 glob_norm 0.405974537\n",
      "Iteration 100 L -4.33075857 loss -4.33127689 loss_ordinary 1.05278254 entropy_value 5.38405943 glob_norm 0.295721799\n",
      "Iteration 150 L -4.32369041 loss -4.32531118 loss_ordinary 1.06264913 entropy_value 5.38796 glob_norm 0.32946\n",
      "Iteration 200 L -4.37773371 loss -4.37777853 loss_ordinary 1.00356686 entropy_value 5.38134575 glob_norm 0.408317447\n",
      "Iteration 250 L -4.33116722 loss -4.33126211 loss_ordinary 1.04384565 entropy_value 5.37510729 glob_norm 0.357764632\n",
      "Iteration 300 L -4.35818768 loss -4.35818434 loss_ordinary 1.02958953 entropy_value 5.38777399 glob_norm 0.329665542\n",
      "Iteration 350 L -4.33141565 loss -4.33232594 loss_ordinary 1.05591869 entropy_value 5.38824463 glob_norm 0.333228886\n",
      "Iteration 400 L -4.3360033 loss -4.33640146 loss_ordinary 1.05155 entropy_value 5.38795137 glob_norm 0.356505334\n",
      "Iteration 450 L -4.35590124 loss -4.35695 loss_ordinary 1.02982914 entropy_value 5.38677931 glob_norm 0.321240693\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power -0.0206482839 lambd_papr -0.000217270121 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3426404 loss -4.34337854 loss_ordinary 1.0381366 entropy_value 5.38151503 glob_norm 0.353200197\n",
      "Iteration 50 L -4.355721 loss -4.35640287 loss_ordinary 1.03276753 entropy_value 5.38917065 glob_norm 0.300058693\n",
      "Iteration 100 L -4.30092955 loss -4.3018117 loss_ordinary 1.08876371 entropy_value 5.39057541 glob_norm 0.601297319\n",
      "Iteration 150 L -4.35636806 loss -4.35717678 loss_ordinary 1.02285731 entropy_value 5.38003397 glob_norm 0.309160411\n",
      "Iteration 200 L -4.32823563 loss -4.32845736 loss_ordinary 1.0571841 entropy_value 5.38564157 glob_norm 0.34651497\n",
      "Iteration 250 L -4.32875 loss -4.3287673 loss_ordinary 1.06068099 entropy_value 5.38944864 glob_norm 0.327985\n",
      "Iteration 300 L -4.36422634 loss -4.36485958 loss_ordinary 1.01724267 entropy_value 5.38210249 glob_norm 0.371300817\n",
      "Iteration 350 L -4.30299139 loss -4.30299139 loss_ordinary 1.09202576 entropy_value 5.39501715 glob_norm 0.419185847\n",
      "Iteration 400 L -4.32678127 loss -4.32844543 loss_ordinary 1.04941249 entropy_value 5.37785816 glob_norm 0.321393251\n",
      "Iteration 450 L -4.34315109 loss -4.34376383 loss_ordinary 1.0372951 entropy_value 5.38105917 glob_norm 0.279943675\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0.0311493874 lambd_papr 0 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3277 loss -4.32769251 loss_ordinary 1.05399227 entropy_value 5.38168478 glob_norm 0.350215316\n",
      "Iteration 50 L -4.31574106 loss -4.31611347 loss_ordinary 1.07324958 entropy_value 5.38936329 glob_norm 0.377041847\n",
      "Iteration 100 L -4.35757446 loss -4.35782814 loss_ordinary 1.02456594 entropy_value 5.38239431 glob_norm 0.332421631\n",
      "Iteration 150 L -4.34720659 loss -4.34719944 loss_ordinary 1.03180492 entropy_value 5.379004 glob_norm 0.350358039\n",
      "Iteration 200 L -4.34810066 loss -4.34809542 loss_ordinary 1.0347 entropy_value 5.38279533 glob_norm 0.305083603\n",
      "Iteration 250 L -4.34453821 loss -4.34468746 loss_ordinary 1.03487957 entropy_value 5.37956715 glob_norm 0.463541269\n",
      "Iteration 300 L -4.34727621 loss -4.34737539 loss_ordinary 1.03304386 entropy_value 5.38041925 glob_norm 0.464265376\n",
      "Iteration 350 L -4.35697556 loss -4.35706139 loss_ordinary 1.0342927 entropy_value 5.39135408 glob_norm 0.377646029\n",
      "Iteration 400 L -4.35348225 loss -4.35353947 loss_ordinary 1.03794527 entropy_value 5.39148474 glob_norm 0.482025534\n",
      "Iteration 450 L -4.34808683 loss -4.34807968 loss_ordinary 1.03540826 entropy_value 5.38348818 glob_norm 0.348090291\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0.154851198 lambd_papr -0.000328750553 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34881401 loss -4.34909201 loss_ordinary 1.04183948 entropy_value 5.39093161 glob_norm 0.399867505\n",
      "Iteration 50 L -4.3046875 loss -4.30510139 loss_ordinary 1.08053315 entropy_value 5.38563442 glob_norm 0.354865968\n",
      "Iteration 100 L -4.30869246 loss -4.3093195 loss_ordinary 1.07712066 entropy_value 5.38644028 glob_norm 0.413954586\n",
      "Iteration 150 L -4.33891249 loss -4.3402071 loss_ordinary 1.04347396 entropy_value 5.38368082 glob_norm 0.38293004\n",
      "Iteration 200 L -4.34618092 loss -4.34696674 loss_ordinary 1.03977132 entropy_value 5.38673782 glob_norm 0.420145422\n",
      "Iteration 250 L -4.34610558 loss -4.34685946 loss_ordinary 1.04415548 entropy_value 5.39101505 glob_norm 0.395596474\n",
      "Iteration 300 L -4.32783413 loss -4.32854652 loss_ordinary 1.05991149 entropy_value 5.38845778 glob_norm 0.504679739\n",
      "Iteration 350 L -4.30007124 loss -4.30124331 loss_ordinary 1.09767044 entropy_value 5.39891386 glob_norm 0.557478607\n",
      "Iteration 400 L -4.36974144 loss -4.3695941 loss_ordinary 1.02010942 entropy_value 5.38970375 glob_norm 0.236739457\n",
      "Iteration 450 L -4.33150148 loss -4.33123827 loss_ordinary 1.05474448 entropy_value 5.38598251 glob_norm 0.468328953\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power -0.061447382 lambd_papr -0.00196795259 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33440065 loss -4.33446836 loss_ordinary 1.05080068 entropy_value 5.38526917 glob_norm 0.441278905\n",
      "Iteration 50 L -4.3531661 loss -4.3530488 loss_ordinary 1.04393291 entropy_value 5.39698219 glob_norm 0.307228506\n",
      "Iteration 100 L -4.33081722 loss -4.33090639 loss_ordinary 1.05846322 entropy_value 5.38936949 glob_norm 0.350814164\n",
      "Iteration 150 L -4.33813286 loss -4.33801556 loss_ordinary 1.06201112 entropy_value 5.4000268 glob_norm 0.397236466\n",
      "Iteration 200 L -4.33216429 loss -4.3321681 loss_ordinary 1.04699206 entropy_value 5.37916 glob_norm 0.322452784\n",
      "Iteration 250 L -4.32466698 loss -4.32573 loss_ordinary 1.0650295 entropy_value 5.39075947 glob_norm 0.381227672\n",
      "Iteration 300 L -4.3470912 loss -4.34789705 loss_ordinary 1.03614116 entropy_value 5.38403845 glob_norm 0.359919041\n",
      "Iteration 350 L -4.33160639 loss -4.33209419 loss_ordinary 1.05770564 entropy_value 5.3898 glob_norm 0.414558083\n",
      "Iteration 400 L -4.35972261 loss -4.35984278 loss_ordinary 1.03770256 entropy_value 5.39754534 glob_norm 0.295119017\n",
      "Iteration 450 L -4.35225773 loss -4.35221481 loss_ordinary 1.03558052 entropy_value 5.38779545 glob_norm 0.309192628\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -0.0919177532 lambd_papr -0.00131554017 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34794 loss -4.34840918 loss_ordinary 1.03321278 entropy_value 5.38162231 glob_norm 0.431239933\n",
      "Iteration 50 L -4.33603048 loss -4.33602285 loss_ordinary 1.05627 entropy_value 5.3922925 glob_norm 0.443417877\n",
      "Iteration 100 L -4.35040951 loss -4.35277081 loss_ordinary 1.0312047 entropy_value 5.38397551 glob_norm 0.267350733\n",
      "Iteration 150 L -4.34182453 loss -4.342134 loss_ordinary 1.04775178 entropy_value 5.3898859 glob_norm 0.343632281\n",
      "Iteration 200 L -4.34368086 loss -4.34375906 loss_ordinary 1.03675866 entropy_value 5.38051796 glob_norm 0.321645528\n",
      "Iteration 250 L -4.35306168 loss -4.35400677 loss_ordinary 1.03511071 entropy_value 5.38911772 glob_norm 0.337141126\n",
      "Iteration 300 L -4.32170248 loss -4.32170916 loss_ordinary 1.07484627 entropy_value 5.39655542 glob_norm 0.405237377\n",
      "Iteration 350 L -4.33927822 loss -4.33927059 loss_ordinary 1.04583478 entropy_value 5.38510513 glob_norm 0.43624711\n",
      "Iteration 400 L -4.30689526 loss -4.30728 loss_ordinary 1.07936728 entropy_value 5.38664722 glob_norm 0.290928632\n",
      "Iteration 450 L -4.32697821 loss -4.32816744 loss_ordinary 1.06351769 entropy_value 5.39168501 glob_norm 0.483550102\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power -0.031521067 lambd_papr -0.000336683355 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33026266 loss -4.3308 loss_ordinary 1.05638623 entropy_value 5.38718605 glob_norm 0.33285591\n",
      "Iteration 50 L -4.34532499 loss -4.34554386 loss_ordinary 1.04400504 entropy_value 5.38954926 glob_norm 0.261725754\n",
      "Iteration 100 L -4.33968258 loss -4.33970499 loss_ordinary 1.04393625 entropy_value 5.38364124 glob_norm 0.259467781\n",
      "Iteration 150 L -4.329144 loss -4.32953024 loss_ordinary 1.0551 entropy_value 5.38463 glob_norm 0.348467648\n",
      "Iteration 200 L -4.33524895 loss -4.33528471 loss_ordinary 1.04024923 entropy_value 5.37553453 glob_norm 0.444793463\n",
      "Iteration 250 L -4.34994411 loss -4.34994411 loss_ordinary 1.03245914 entropy_value 5.38240337 glob_norm 0.413626879\n",
      "Iteration 300 L -4.32506561 loss -4.32517433 loss_ordinary 1.06259012 entropy_value 5.38776445 glob_norm 0.402994633\n",
      "Iteration 350 L -4.33122253 loss -4.33231878 loss_ordinary 1.04828024 entropy_value 5.38059902 glob_norm 0.291523218\n",
      "Iteration 400 L -4.34743786 loss -4.34744358 loss_ordinary 1.03634071 entropy_value 5.38378429 glob_norm 0.339816123\n",
      "Iteration 450 L -4.35634136 loss -4.3570323 loss_ordinary 1.02221906 entropy_value 5.37925148 glob_norm 0.436838955\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0 lambd_papr 0 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3366394 loss -4.3366394 loss_ordinary 1.04534698 entropy_value 5.38198662 glob_norm 0.359304\n",
      "Iteration 50 L -4.3319726 loss -4.33197832 loss_ordinary 1.04920661 entropy_value 5.38118505 glob_norm 0.352769285\n",
      "Iteration 100 L -4.31650352 loss -4.31670427 loss_ordinary 1.0663296 entropy_value 5.38303375 glob_norm 0.3755005\n",
      "Iteration 150 L -4.34703875 loss -4.34708452 loss_ordinary 1.02594399 entropy_value 5.37302828 glob_norm 0.491046339\n",
      "Iteration 200 L -4.31235075 loss -4.31250048 loss_ordinary 1.07470512 entropy_value 5.3872056 glob_norm 0.414864957\n",
      "Iteration 250 L -4.32215738 loss -4.32215738 loss_ordinary 1.06894779 entropy_value 5.39110518 glob_norm 0.445581794\n",
      "Iteration 300 L -4.32627869 loss -4.32627869 loss_ordinary 1.05653727 entropy_value 5.38281631 glob_norm 0.437406808\n",
      "Iteration 350 L -4.36436224 loss -4.36486959 loss_ordinary 1.01290417 entropy_value 5.37777376 glob_norm 0.426083654\n",
      "Iteration 400 L -4.34964466 loss -4.34964561 loss_ordinary 1.03549361 entropy_value 5.38513947 glob_norm 0.308503479\n",
      "Iteration 450 L -4.34460688 loss -4.34460688 loss_ordinary 1.04238737 entropy_value 5.38699484 glob_norm 0.488500714\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.161422968 lambd_papr 0 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3308177 loss -4.33172512 loss_ordinary 1.05256069 entropy_value 5.38428593 glob_norm 0.553365827\n",
      "Iteration 50 L -4.3138485 loss -4.31571722 loss_ordinary 1.06991076 entropy_value 5.38562822 glob_norm 0.455463856\n",
      "Iteration 100 L -4.33159161 loss -4.33182573 loss_ordinary 1.0611881 entropy_value 5.39301348 glob_norm 0.27445063\n",
      "Iteration 150 L -4.35010767 loss -4.35016489 loss_ordinary 1.03740382 entropy_value 5.38756847 glob_norm 0.418360025\n",
      "Iteration 200 L -4.34847879 loss -4.34827709 loss_ordinary 1.03937221 entropy_value 5.38764906 glob_norm 0.291383415\n",
      "Iteration 250 L -4.322752 loss -4.32361841 loss_ordinary 1.06065297 entropy_value 5.38427162 glob_norm 0.420810729\n",
      "Iteration 300 L -4.3493309 loss -4.35079956 loss_ordinary 1.04301918 entropy_value 5.39381838 glob_norm 0.510207057\n",
      "Iteration 350 L -4.3476944 loss -4.34831858 loss_ordinary 1.03788006 entropy_value 5.38619852 glob_norm 0.318609089\n",
      "Iteration 400 L -4.33089113 loss -4.33096886 loss_ordinary 1.06401622 entropy_value 5.39498472 glob_norm 0.254295349\n",
      "Iteration 450 L -4.32510471 loss -4.32590151 loss_ordinary 1.06704724 entropy_value 5.3929491 glob_norm 0.345004797\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power 0.268943787 lambd_papr -0.00173455442 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32264042 loss -4.32337523 loss_ordinary 1.05963743 entropy_value 5.38301229 glob_norm 0.334740371\n",
      "Iteration 50 L -4.3251276 loss -4.32375383 loss_ordinary 1.06720138 entropy_value 5.39095497 glob_norm 0.446483552\n",
      "Iteration 100 L -4.32913589 loss -4.32811928 loss_ordinary 1.07085872 entropy_value 5.39897823 glob_norm 0.370500237\n",
      "Iteration 150 L -4.34218645 loss -4.34089851 loss_ordinary 1.05215204 entropy_value 5.39305067 glob_norm 0.353598297\n",
      "Iteration 200 L -4.3433423 loss -4.34212494 loss_ordinary 1.0633837 entropy_value 5.405509 glob_norm 0.444065839\n",
      "Iteration 250 L -4.36330175 loss -4.36357403 loss_ordinary 1.03443646 entropy_value 5.39801025 glob_norm 0.471422195\n",
      "Iteration 300 L -4.34879 loss -4.34735727 loss_ordinary 1.0471983 entropy_value 5.39455557 glob_norm 0.353910595\n",
      "Iteration 350 L -4.31886864 loss -4.31906843 loss_ordinary 1.07955754 entropy_value 5.39862585 glob_norm 0.242244661\n",
      "Iteration 400 L -4.35112047 loss -4.35060787 loss_ordinary 1.04659355 entropy_value 5.39720154 glob_norm 0.330272108\n",
      "Iteration 450 L -4.31921721 loss -4.31937313 loss_ordinary 1.07668722 entropy_value 5.39606 glob_norm 0.350864828\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.00723719597 lambd_papr -0.00463313283 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35695 loss -4.35625124 loss_ordinary 1.0499512 entropy_value 5.40620184 glob_norm 0.354489326\n",
      "Iteration 50 L -4.34833097 loss -4.34702492 loss_ordinary 1.05452228 entropy_value 5.40154696 glob_norm 0.267895132\n",
      "Iteration 100 L -4.32953453 loss -4.32820129 loss_ordinary 1.06820798 entropy_value 5.39640951 glob_norm 0.309543073\n",
      "Iteration 150 L -4.34206772 loss -4.34351301 loss_ordinary 1.05147099 entropy_value 5.39498377 glob_norm 0.247716889\n",
      "Iteration 200 L -4.32571125 loss -4.32641602 loss_ordinary 1.0792197 entropy_value 5.40563583 glob_norm 0.519189596\n",
      "Iteration 250 L -4.33577251 loss -4.33636761 loss_ordinary 1.07044613 entropy_value 5.4068141 glob_norm 0.359022856\n",
      "Iteration 300 L -4.33502245 loss -4.33358 loss_ordinary 1.06940424 entropy_value 5.40298414 glob_norm 0.385393023\n",
      "Iteration 350 L -4.32426214 loss -4.32278538 loss_ordinary 1.08178532 entropy_value 5.40457058 glob_norm 0.321318924\n",
      "Iteration 400 L -4.34574413 loss -4.34465265 loss_ordinary 1.06169808 entropy_value 5.40635109 glob_norm 0.281054378\n",
      "Iteration 450 L -4.35246944 loss -4.35099268 loss_ordinary 1.04649258 entropy_value 5.39748526 glob_norm 0.326850057\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power -0.108774662 lambd_papr -0.00471136672 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.36878729 loss -4.36802483 loss_ordinary 1.02706659 entropy_value 5.39509153 glob_norm 0.316890031\n",
      "Iteration 50 L -4.34520102 loss -4.34446383 loss_ordinary 1.04962802 entropy_value 5.39409208 glob_norm 0.361349106\n",
      "Iteration 100 L -4.32432842 loss -4.3256793 loss_ordinary 1.06591988 entropy_value 5.39159918 glob_norm 0.41790545\n",
      "Iteration 150 L -4.38732767 loss -4.38659334 loss_ordinary 1.01255047 entropy_value 5.39914417 glob_norm 0.376864761\n",
      "Iteration 200 L -4.36138487 loss -4.36180067 loss_ordinary 1.03960633 entropy_value 5.40140676 glob_norm 0.41656062\n",
      "Iteration 250 L -4.31527805 loss -4.31738758 loss_ordinary 1.08756566 entropy_value 5.404953 glob_norm 0.413579494\n",
      "Iteration 300 L -4.33403206 loss -4.33430338 loss_ordinary 1.06342673 entropy_value 5.39773035 glob_norm 0.34287858\n",
      "Iteration 350 L -4.31674194 loss -4.31592798 loss_ordinary 1.08377135 entropy_value 5.39969921 glob_norm 0.409346223\n",
      "Iteration 400 L -4.32392597 loss -4.32387924 loss_ordinary 1.07284236 entropy_value 5.39672184 glob_norm 0.341520965\n",
      "Iteration 450 L -4.34217167 loss -4.34247637 loss_ordinary 1.05399203 entropy_value 5.39646864 glob_norm 0.429195464\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0.0489838123 lambd_papr -0.00353198824 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.3474474 loss -4.34988642 loss_ordinary 1.04489422 entropy_value 5.39478 glob_norm 0.351067\n",
      "Iteration 50 L -4.33857441 loss -4.33825588 loss_ordinary 1.05776703 entropy_value 5.3960228 glob_norm 0.308138251\n",
      "Iteration 100 L -4.34460735 loss -4.34437418 loss_ordinary 1.04854953 entropy_value 5.39292383 glob_norm 0.365261614\n",
      "Iteration 150 L -4.33121777 loss -4.33183336 loss_ordinary 1.07071 entropy_value 5.40254354 glob_norm 0.29939726\n",
      "Iteration 200 L -4.32304096 loss -4.32194853 loss_ordinary 1.07267714 entropy_value 5.39462566 glob_norm 0.401483834\n",
      "Iteration 250 L -4.34652328 loss -4.34546185 loss_ordinary 1.05859685 entropy_value 5.40405893 glob_norm 0.249973506\n",
      "Iteration 300 L -4.35952091 loss -4.35890818 loss_ordinary 1.04580116 entropy_value 5.40470934 glob_norm 0.363628805\n",
      "Iteration 350 L -4.32656908 loss -4.32651424 loss_ordinary 1.07542908 entropy_value 5.40194321 glob_norm 0.386179\n",
      "Iteration 400 L -4.33283138 loss -4.33608723 loss_ordinary 1.06507051 entropy_value 5.40115786 glob_norm 0.341683328\n",
      "Iteration 450 L -4.34484816 loss -4.34531069 loss_ordinary 1.05052054 entropy_value 5.39583111 glob_norm 0.315364182\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0.296065569 lambd_papr -0.0040646838 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32351637 loss -4.3231926 loss_ordinary 1.07703066 entropy_value 5.40022326 glob_norm 0.319708288\n",
      "Iteration 50 L -4.29084682 loss -4.28751707 loss_ordinary 1.11517096 entropy_value 5.40268803 glob_norm 0.265689403\n",
      "Iteration 100 L -4.3360467 loss -4.33255148 loss_ordinary 1.07478666 entropy_value 5.40733814 glob_norm 0.352857858\n",
      "Iteration 150 L -4.34283304 loss -4.34381247 loss_ordinary 1.0653646 entropy_value 5.40917683 glob_norm 0.422661602\n",
      "Iteration 200 L -4.34266376 loss -4.34099627 loss_ordinary 1.06091487 entropy_value 5.40191078 glob_norm 0.516563118\n",
      "Iteration 250 L -4.3014636 loss -4.29931259 loss_ordinary 1.10270154 entropy_value 5.40201426 glob_norm 0.38490358\n",
      "Iteration 300 L -4.3616004 loss -4.36023283 loss_ordinary 1.04633641 entropy_value 5.406569 glob_norm 0.300928831\n",
      "Iteration 350 L -4.34675264 loss -4.34521675 loss_ordinary 1.0623244 entropy_value 5.40754128 glob_norm 0.383919448\n",
      "Iteration 400 L -4.35134506 loss -4.34908152 loss_ordinary 1.06397629 entropy_value 5.41305733 glob_norm 0.451704621\n",
      "Iteration 450 L -4.36245871 loss -4.35983562 loss_ordinary 1.04853415 entropy_value 5.40837 glob_norm 0.382589\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power -0.294100523 lambd_papr -0.00729403459 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34605169 loss -4.34616327 loss_ordinary 1.06368804 entropy_value 5.40985107 glob_norm 0.404335022\n",
      "Iteration 50 L -4.32850313 loss -4.3274107 loss_ordinary 1.07546735 entropy_value 5.40287781 glob_norm 0.332885444\n",
      "Iteration 100 L -4.35237265 loss -4.35191774 loss_ordinary 1.05253077 entropy_value 5.40444851 glob_norm 0.277224123\n",
      "Iteration 150 L -4.36384439 loss -4.36346054 loss_ordinary 1.03502238 entropy_value 5.39848328 glob_norm 0.326302439\n",
      "Iteration 200 L -4.36021852 loss -4.35946894 loss_ordinary 1.03514838 entropy_value 5.39461756 glob_norm 0.367532194\n",
      "Iteration 250 L -4.33041811 loss -4.33086634 loss_ordinary 1.07674754 entropy_value 5.40761375 glob_norm 0.296339899\n",
      "Iteration 300 L -4.35616541 loss -4.35655546 loss_ordinary 1.03984928 entropy_value 5.39640474 glob_norm 0.26490438\n",
      "Iteration 350 L -4.33470631 loss -4.3348155 loss_ordinary 1.06763482 entropy_value 5.40245056 glob_norm 0.385807067\n",
      "Iteration 400 L -4.34161377 loss -4.3434267 loss_ordinary 1.05363154 entropy_value 5.39705801 glob_norm 0.516016245\n",
      "Iteration 450 L -4.34894609 loss -4.3478756 loss_ordinary 1.05323756 entropy_value 5.40111351 glob_norm 0.269653022\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0.137031317 lambd_papr -0.0040764939 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.31029844 loss -4.30903816 loss_ordinary 1.08988571 entropy_value 5.39892387 glob_norm 0.363812298\n",
      "Iteration 50 L -4.31597233 loss -4.31393147 loss_ordinary 1.08683074 entropy_value 5.40076208 glob_norm 0.34758535\n",
      "Iteration 100 L -4.33285475 loss -4.33081388 loss_ordinary 1.08015013 entropy_value 5.41096401 glob_norm 0.349164605\n",
      "Iteration 150 L -4.3582015 loss -4.35743856 loss_ordinary 1.04711056 entropy_value 5.40454912 glob_norm 0.354058415\n",
      "Iteration 200 L -4.3438406 loss -4.34261084 loss_ordinary 1.05859494 entropy_value 5.40120602 glob_norm 0.256079197\n",
      "Iteration 250 L -4.32475185 loss -4.32273531 loss_ordinary 1.08313751 entropy_value 5.40587282 glob_norm 0.435671151\n",
      "Iteration 300 L -4.38075352 loss -4.37891674 loss_ordinary 1.03283453 entropy_value 5.41175127 glob_norm 0.390939623\n",
      "Iteration 350 L -4.33010674 loss -4.3287344 loss_ordinary 1.06974089 entropy_value 5.39847565 glob_norm 0.389545292\n",
      "Iteration 400 L -4.33430958 loss -4.33407545 loss_ordinary 1.07197857 entropy_value 5.40605402 glob_norm 0.277931243\n",
      "Iteration 450 L -4.32093382 loss -4.31974602 loss_ordinary 1.08426404 entropy_value 5.40401 glob_norm 0.589386582\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power -0.249999523 lambd_papr -0.00558015192 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.37671709 loss -4.3778429 loss_ordinary 1.02808702 entropy_value 5.40593 glob_norm 0.291341573\n",
      "Iteration 50 L -4.33722639 loss -4.33673286 loss_ordinary 1.06782532 entropy_value 5.40455818 glob_norm 0.449252039\n",
      "Iteration 100 L -4.31434536 loss -4.31400108 loss_ordinary 1.08784962 entropy_value 5.4018507 glob_norm 0.379481256\n",
      "Iteration 150 L -4.33520222 loss -4.33473253 loss_ordinary 1.0588975 entropy_value 5.39363 glob_norm 0.391231388\n",
      "Iteration 200 L -4.32185411 loss -4.32229471 loss_ordinary 1.06986022 entropy_value 5.39215469 glob_norm 0.33389917\n",
      "Iteration 250 L -4.34694624 loss -4.34642649 loss_ordinary 1.05427659 entropy_value 5.40070295 glob_norm 0.26126954\n",
      "Iteration 300 L -4.33033943 loss -4.33015251 loss_ordinary 1.05901468 entropy_value 5.38916731 glob_norm 0.440839112\n",
      "Iteration 350 L -4.34301853 loss -4.34270096 loss_ordinary 1.04885876 entropy_value 5.39156 glob_norm 0.296521\n",
      "Iteration 400 L -4.36749268 loss -4.36993599 loss_ordinary 1.02806485 entropy_value 5.39800072 glob_norm 0.263065636\n",
      "Iteration 450 L -4.35534382 loss -4.35600805 loss_ordinary 1.04085386 entropy_value 5.39686203 glob_norm 0.332906663\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.300854921 lambd_papr -0.0028286532 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.28122234 loss -4.28251743 loss_ordinary 1.10881805 entropy_value 5.39133501 glob_norm 0.283504903\n",
      "Iteration 50 L -4.31524897 loss -4.31519127 loss_ordinary 1.07685649 entropy_value 5.39204741 glob_norm 0.390010417\n",
      "Iteration 100 L -4.34202719 loss -4.3425169 loss_ordinary 1.05628264 entropy_value 5.39879942 glob_norm 0.37028116\n",
      "Iteration 150 L -4.3678813 loss -4.3659935 loss_ordinary 1.03247035 entropy_value 5.39846373 glob_norm 0.357753813\n",
      "Iteration 200 L -4.37485933 loss -4.37239504 loss_ordinary 1.02656758 entropy_value 5.3989625 glob_norm 0.368523449\n",
      "Iteration 250 L -4.3234868 loss -4.32181263 loss_ordinary 1.0832293 entropy_value 5.40504169 glob_norm 0.288736373\n",
      "Iteration 300 L -4.33538532 loss -4.3342185 loss_ordinary 1.06657779 entropy_value 5.40079641 glob_norm 0.263679057\n",
      "Iteration 350 L -4.34220076 loss -4.34154081 loss_ordinary 1.06646347 entropy_value 5.40800428 glob_norm 0.382990509\n",
      "Iteration 400 L -4.35620165 loss -4.35443 loss_ordinary 1.04615068 entropy_value 5.40058041 glob_norm 0.384015411\n",
      "Iteration 450 L -4.34124565 loss -4.34361839 loss_ordinary 1.06252575 entropy_value 5.40614367 glob_norm 0.288284719\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power -0.235169411 lambd_papr -0.00614980096 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.353477 loss -4.35266 loss_ordinary 1.05910921 entropy_value 5.41176939 glob_norm 0.291635185\n",
      "Iteration 50 L -4.35611916 loss -4.35530233 loss_ordinary 1.05399561 entropy_value 5.40929794 glob_norm 0.268131763\n",
      "Iteration 100 L -4.33392 loss -4.33324814 loss_ordinary 1.07105827 entropy_value 5.40430641 glob_norm 0.348979175\n",
      "Iteration 150 L -4.34994888 loss -4.34982491 loss_ordinary 1.05458796 entropy_value 5.40441322 glob_norm 0.413909703\n",
      "Iteration 200 L -4.31042337 loss -4.30966377 loss_ordinary 1.0882107 entropy_value 5.39787436 glob_norm 0.287001878\n",
      "Iteration 250 L -4.33566141 loss -4.33484459 loss_ordinary 1.06139851 entropy_value 5.3962431 glob_norm 0.451729357\n",
      "Iteration 300 L -4.31485462 loss -4.31448174 loss_ordinary 1.08293343 entropy_value 5.39741516 glob_norm 0.30618456\n",
      "Iteration 350 L -4.31123 loss -4.31085825 loss_ordinary 1.0842663 entropy_value 5.39512444 glob_norm 0.418272555\n",
      "Iteration 400 L -4.31259584 loss -4.31215715 loss_ordinary 1.08699119 entropy_value 5.39914846 glob_norm 0.328795493\n",
      "Iteration 450 L -4.32702208 loss -4.32653522 loss_ordinary 1.07624483 entropy_value 5.40278 glob_norm 0.346932977\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power -0.0597214699 lambd_papr -0.00354596972 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33038712 loss -4.33012962 loss_ordinary 1.06664574 entropy_value 5.39677525 glob_norm 0.359470248\n",
      "Iteration 50 L -4.32296085 loss -4.32402277 loss_ordinary 1.07044816 entropy_value 5.39447117 glob_norm 0.342815369\n",
      "Iteration 100 L -4.3302846 loss -4.33065796 loss_ordinary 1.06330633 entropy_value 5.39396381 glob_norm 0.478507072\n",
      "Iteration 150 L -4.33025026 loss -4.33045149 loss_ordinary 1.06355166 entropy_value 5.39400339 glob_norm 0.4173989\n",
      "Iteration 200 L -4.31633425 loss -4.3161068 loss_ordinary 1.07504964 entropy_value 5.39115667 glob_norm 0.299946636\n",
      "Iteration 250 L -4.31348562 loss -4.31347227 loss_ordinary 1.08171892 entropy_value 5.39519119 glob_norm 0.46894145\n",
      "Iteration 300 L -4.31329346 loss -4.31495142 loss_ordinary 1.08566606 entropy_value 5.40061712 glob_norm 0.343238801\n",
      "Iteration 350 L -4.33969641 loss -4.33915854 loss_ordinary 1.05912864 entropy_value 5.39828682 glob_norm 0.256518245\n",
      "Iteration 400 L -4.32129526 loss -4.32087708 loss_ordinary 1.07819259 entropy_value 5.39906931 glob_norm 0.358464807\n",
      "Iteration 450 L -4.35214758 loss -4.35160971 loss_ordinary 1.0462358 entropy_value 5.39784527 glob_norm 0.309946299\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.0113675594 lambd_papr -0.00288274093 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34584379 loss -4.34611273 loss_ordinary 1.04878712 entropy_value 5.3949 glob_norm 0.313326687\n",
      "Iteration 50 L -4.35886955 loss -4.35900736 loss_ordinary 1.03692162 entropy_value 5.39592934 glob_norm 0.400228053\n",
      "Iteration 100 L -4.36920547 loss -4.36873579 loss_ordinary 1.02708077 entropy_value 5.39581633 glob_norm 0.298154503\n",
      "Iteration 150 L -4.33765602 loss -4.33731651 loss_ordinary 1.06365728 entropy_value 5.40097427 glob_norm 0.308839798\n",
      "Iteration 200 L -4.36860371 loss -4.36822367 loss_ordinary 1.02035236 entropy_value 5.38857603 glob_norm 0.340432793\n",
      "Iteration 250 L -4.34814882 loss -4.34806442 loss_ordinary 1.04377925 entropy_value 5.3918438 glob_norm 0.360549361\n",
      "Iteration 300 L -4.29877138 loss -4.2984519 loss_ordinary 1.0977999 entropy_value 5.39625216 glob_norm 0.271002382\n",
      "Iteration 350 L -4.32013512 loss -4.32254648 loss_ordinary 1.07371104 entropy_value 5.3962574 glob_norm 0.378491163\n",
      "Iteration 400 L -4.33621502 loss -4.33643055 loss_ordinary 1.05406749 entropy_value 5.39049816 glob_norm 0.403415293\n",
      "Iteration 450 L -4.3352294 loss -4.33563185 loss_ordinary 1.05897522 entropy_value 5.39460707 glob_norm 0.407990724\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power -0.0828018188 lambd_papr -0.00300936052 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.37485218 loss -4.37479 loss_ordinary 1.02576184 entropy_value 5.40055227 glob_norm 0.353460848\n",
      "Iteration 50 L -4.32415581 loss -4.32460499 loss_ordinary 1.05847847 entropy_value 5.38308382 glob_norm 0.382189423\n",
      "Iteration 100 L -4.32100296 loss -4.32079029 loss_ordinary 1.07261145 entropy_value 5.39340162 glob_norm 0.296677291\n",
      "Iteration 150 L -4.37406588 loss -4.374156 loss_ordinary 1.01759315 entropy_value 5.39174891 glob_norm 0.260268033\n",
      "Iteration 200 L -4.3505106 loss -4.35192442 loss_ordinary 1.03469014 entropy_value 5.38661432 glob_norm 0.238683835\n",
      "Iteration 250 L -4.32761717 loss -4.32767916 loss_ordinary 1.06657672 entropy_value 5.39425564 glob_norm 0.329524\n",
      "Iteration 300 L -4.35815954 loss -4.35887671 loss_ordinary 1.03851795 entropy_value 5.39739466 glob_norm 0.400438964\n",
      "Iteration 350 L -4.31052923 loss -4.31024933 loss_ordinary 1.09048247 entropy_value 5.40073204 glob_norm 0.319942534\n",
      "Iteration 400 L -4.32087088 loss -4.32164478 loss_ordinary 1.06925 entropy_value 5.39089441 glob_norm 0.449488878\n",
      "Iteration 450 L -4.35692883 loss -4.35751486 loss_ordinary 1.04457295 entropy_value 5.40208769 glob_norm 0.357389957\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.326195478 lambd_papr -0.00208429038 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32154226 loss -4.32059431 loss_ordinary 1.07115388 entropy_value 5.39174795 glob_norm 0.351983279\n",
      "Iteration 50 L -4.33088112 loss -4.32935905 loss_ordinary 1.05946124 entropy_value 5.38882 glob_norm 0.259911686\n",
      "Iteration 100 L -4.32426548 loss -4.32225895 loss_ordinary 1.07700908 entropy_value 5.39926815 glob_norm 0.394470096\n",
      "Iteration 150 L -4.35899782 loss -4.35864592 loss_ordinary 1.04236817 entropy_value 5.40101385 glob_norm 0.268137068\n",
      "Iteration 200 L -4.33180666 loss -4.33077955 loss_ordinary 1.06685221 entropy_value 5.39763212 glob_norm 0.40174976\n",
      "Iteration 250 L -4.36588192 loss -4.36759567 loss_ordinary 1.0352236 entropy_value 5.40281916 glob_norm 0.313193351\n",
      "Iteration 300 L -4.32971144 loss -4.32759714 loss_ordinary 1.0796628 entropy_value 5.40726 glob_norm 0.336106032\n",
      "Iteration 350 L -4.34607792 loss -4.34402037 loss_ordinary 1.06305814 entropy_value 5.40707827 glob_norm 0.346063018\n",
      "Iteration 400 L -4.3136735 loss -4.31381655 loss_ordinary 1.09046495 entropy_value 5.40428114 glob_norm 0.40100193\n",
      "Iteration 450 L -4.32959509 loss -4.32751465 loss_ordinary 1.06920969 entropy_value 5.39672422 glob_norm 0.310370207\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.110518456 lambd_papr -0.00573951192 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34964085 loss -4.35046434 loss_ordinary 1.0537827 entropy_value 5.40424728 glob_norm 0.244576663\n",
      "Iteration 50 L -4.31918907 loss -4.31790161 loss_ordinary 1.08687019 entropy_value 5.4047718 glob_norm 0.382925212\n",
      "Iteration 100 L -4.33839417 loss -4.33730936 loss_ordinary 1.06829309 entropy_value 5.40560246 glob_norm 0.301424772\n",
      "Iteration 150 L -4.3388443 loss -4.33776569 loss_ordinary 1.06297851 entropy_value 5.40074444 glob_norm 0.43955189\n",
      "Iteration 200 L -4.33095121 loss -4.33264256 loss_ordinary 1.06861389 entropy_value 5.40125656 glob_norm 0.328469187\n",
      "Iteration 250 L -4.35331821 loss -4.35466099 loss_ordinary 1.04464364 entropy_value 5.39930487 glob_norm 0.398731977\n",
      "Iteration 300 L -4.34309912 loss -4.34254074 loss_ordinary 1.05454218 entropy_value 5.39708281 glob_norm 0.300242186\n",
      "Iteration 350 L -4.33041048 loss -4.32911587 loss_ordinary 1.07500958 entropy_value 5.40412569 glob_norm 0.39370352\n",
      "Iteration 400 L -4.34970951 loss -4.3484149 loss_ordinary 1.04961896 entropy_value 5.3980341 glob_norm 0.437994629\n",
      "Iteration 450 L -4.34656572 loss -4.34527111 loss_ordinary 1.05006659 entropy_value 5.39533806 glob_norm 0.386185586\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power -0.102761269 lambd_papr -0.00449736929 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32486629 loss -4.32415485 loss_ordinary 1.07062292 entropy_value 5.39477777 glob_norm 0.345746934\n",
      "Iteration 50 L -4.36624908 loss -4.36554 loss_ordinary 1.0342443 entropy_value 5.39978456 glob_norm 0.344602823\n",
      "Iteration 100 L -4.3586278 loss -4.35826492 loss_ordinary 1.03646612 entropy_value 5.39473104 glob_norm 0.30998227\n",
      "Iteration 150 L -4.3152976 loss -4.31458616 loss_ordinary 1.08875895 entropy_value 5.40334511 glob_norm 0.35069567\n",
      "Iteration 200 L -4.3466897 loss -4.34735537 loss_ordinary 1.04858458 entropy_value 5.3959403 glob_norm 0.310978174\n",
      "Iteration 250 L -4.3411355 loss -4.34049177 loss_ordinary 1.05898058 entropy_value 5.39947224 glob_norm 0.295561939\n",
      "Iteration 300 L -4.34693527 loss -4.34623289 loss_ordinary 1.05585313 entropy_value 5.40208578 glob_norm 0.30168286\n",
      "Iteration 350 L -4.31205416 loss -4.31198406 loss_ordinary 1.08704031 entropy_value 5.39902449 glob_norm 0.300022691\n",
      "Iteration 400 L -4.34379244 loss -4.34338379 loss_ordinary 1.05595469 entropy_value 5.39933872 glob_norm 0.410879582\n",
      "Iteration 450 L -4.35698 loss -4.35713482 loss_ordinary 1.03135538 entropy_value 5.38849 glob_norm 0.355134249\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0.0987007618 lambd_papr -0.0033389465 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35053349 loss -4.34927797 loss_ordinary 1.04563081 entropy_value 5.39490843 glob_norm 0.286905378\n",
      "Iteration 50 L -4.37137365 loss -4.37052679 loss_ordinary 1.03370881 entropy_value 5.40423584 glob_norm 0.428568333\n",
      "Iteration 100 L -4.34055138 loss -4.33982372 loss_ordinary 1.06660748 entropy_value 5.4064312 glob_norm 0.332763761\n",
      "Iteration 150 L -4.34815264 loss -4.34762383 loss_ordinary 1.04902875 entropy_value 5.3966527 glob_norm 0.294006079\n",
      "Iteration 200 L -4.32659912 loss -4.32609653 loss_ordinary 1.06512463 entropy_value 5.39122105 glob_norm 0.347963452\n",
      "Iteration 250 L -4.32642937 loss -4.32557869 loss_ordinary 1.07195961 entropy_value 5.39753819 glob_norm 0.394964069\n",
      "Iteration 300 L -4.34704685 loss -4.34842491 loss_ordinary 1.05120385 entropy_value 5.39962912 glob_norm 0.299032688\n",
      "Iteration 350 L -4.32598305 loss -4.32472086 loss_ordinary 1.0705744 entropy_value 5.39529514 glob_norm 0.337814391\n",
      "Iteration 400 L -4.33496904 loss -4.33533907 loss_ordinary 1.06170356 entropy_value 5.39704275 glob_norm 0.343814701\n",
      "Iteration 450 L -4.3611722 loss -4.36068249 loss_ordinary 1.04059207 entropy_value 5.40127468 glob_norm 0.345577598\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0.10430336 lambd_papr -0.00445493311 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34218311 loss -4.34154177 loss_ordinary 1.0617609 entropy_value 5.40330267 glob_norm 0.36656484\n",
      "Iteration 50 L -4.33809805 loss -4.33743572 loss_ordinary 1.06137145 entropy_value 5.39880705 glob_norm 0.334864676\n",
      "Iteration 100 L -4.31195354 loss -4.31321621 loss_ordinary 1.09284353 entropy_value 5.40605974 glob_norm 0.304284871\n",
      "Iteration 150 L -4.36510515 loss -4.36308956 loss_ordinary 1.04150641 entropy_value 5.40459633 glob_norm 0.286884874\n",
      "Iteration 200 L -4.36467028 loss -4.36720753 loss_ordinary 1.02664185 entropy_value 5.39384937 glob_norm 0.287086248\n",
      "Iteration 250 L -4.35920715 loss -4.35998726 loss_ordinary 1.04148018 entropy_value 5.40146732 glob_norm 0.340214789\n",
      "Iteration 300 L -4.35516214 loss -4.35327291 loss_ordinary 1.05117369 entropy_value 5.4044466 glob_norm 0.274789274\n",
      "Iteration 350 L -4.33154488 loss -4.32959223 loss_ordinary 1.07463408 entropy_value 5.40422678 glob_norm 0.309011757\n",
      "Iteration 400 L -4.34886837 loss -4.34787416 loss_ordinary 1.05519 entropy_value 5.40306377 glob_norm 0.300252616\n",
      "Iteration 450 L -4.30174923 loss -4.29986525 loss_ordinary 1.09823871 entropy_value 5.39810419 glob_norm 0.362309337\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.0957202911 lambd_papr -0.00563780498 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.32005453 loss -4.31874609 loss_ordinary 1.08491981 entropy_value 5.40366602 glob_norm 0.275317073\n",
      "Iteration 50 L -4.34705877 loss -4.34691668 loss_ordinary 1.05481458 entropy_value 5.40173101 glob_norm 0.332824528\n",
      "Iteration 100 L -4.33374453 loss -4.33259392 loss_ordinary 1.07438815 entropy_value 5.40698195 glob_norm 0.383472294\n",
      "Iteration 150 L -4.32292271 loss -4.32283735 loss_ordinary 1.09037948 entropy_value 5.41321659 glob_norm 0.320413291\n",
      "Iteration 200 L -4.32723427 loss -4.32750797 loss_ordinary 1.06721735 entropy_value 5.39472532 glob_norm 0.34593752\n",
      "Iteration 250 L -4.35253811 loss -4.35214043 loss_ordinary 1.04882312 entropy_value 5.40096331 glob_norm 0.301661402\n",
      "Iteration 300 L -4.33956194 loss -4.33943319 loss_ordinary 1.05610704 entropy_value 5.39554 glob_norm 0.34747836\n",
      "Iteration 350 L -4.31956625 loss -4.32113361 loss_ordinary 1.07731497 entropy_value 5.39844847 glob_norm 0.337933689\n",
      "Iteration 400 L -4.34338665 loss -4.34222078 loss_ordinary 1.0555383 entropy_value 5.39775896 glob_norm 0.295623541\n",
      "Iteration 450 L -4.3403759 loss -4.3410058 loss_ordinary 1.05563033 entropy_value 5.39663649 glob_norm 0.300938249\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power -0.272828341 lambd_papr -0.00454901438 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.35126448 loss -4.3511343 loss_ordinary 1.04819083 entropy_value 5.39932537 glob_norm 0.359077811\n",
      "Iteration 50 L -4.33542919 loss -4.33766603 loss_ordinary 1.06032515 entropy_value 5.39799118 glob_norm 0.324705929\n",
      "Iteration 100 L -4.33274 loss -4.33308506 loss_ordinary 1.0654434 entropy_value 5.39852858 glob_norm 0.416736841\n",
      "Iteration 150 L -4.35265398 loss -4.35255432 loss_ordinary 1.03525472 entropy_value 5.38780928 glob_norm 0.341192871\n",
      "Iteration 200 L -4.32122803 loss -4.32262 loss_ordinary 1.07320321 entropy_value 5.395823 glob_norm 0.403877527\n",
      "Iteration 250 L -4.31850958 loss -4.31858301 loss_ordinary 1.07248342 entropy_value 5.39106655 glob_norm 0.284933656\n",
      "Iteration 300 L -4.31124163 loss -4.31143618 loss_ordinary 1.07718635 entropy_value 5.38862276 glob_norm 0.357184559\n",
      "Iteration 350 L -4.35615969 loss -4.35847473 loss_ordinary 1.03057 entropy_value 5.38904476 glob_norm 0.321983427\n",
      "Iteration 400 L -4.3235054 loss -4.32340145 loss_ordinary 1.07316566 entropy_value 5.39656734 glob_norm 0.454838395\n",
      "Iteration 450 L -4.33277607 loss -4.33264637 loss_ordinary 1.05956197 entropy_value 5.39220858 glob_norm 0.286114126\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power 0.187143326 lambd_papr -0.00143636018 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.36786079 loss -4.36946869 loss_ordinary 1.01999295 entropy_value 5.38946152 glob_norm 0.419648796\n",
      "Iteration 50 L -4.33186913 loss -4.3316164 loss_ordinary 1.05526745 entropy_value 5.38688374 glob_norm 0.38038668\n",
      "Iteration 100 L -4.34115314 loss -4.34151173 loss_ordinary 1.05408645 entropy_value 5.39559841 glob_norm 0.315280378\n",
      "Iteration 150 L -4.3207736 loss -4.31996918 loss_ordinary 1.0712775 entropy_value 5.3912468 glob_norm 0.375469983\n",
      "Iteration 200 L -4.31153917 loss -4.31247 loss_ordinary 1.08126056 entropy_value 5.39373064 glob_norm 0.3183451\n",
      "Iteration 250 L -4.34960461 loss -4.3488 loss_ordinary 1.04510379 entropy_value 5.39390373 glob_norm 0.285740823\n",
      "Iteration 300 L -4.31122684 loss -4.31205 loss_ordinary 1.08087552 entropy_value 5.39292574 glob_norm 0.389992535\n",
      "Iteration 350 L -4.33005524 loss -4.33140469 loss_ordinary 1.06123924 entropy_value 5.39264393 glob_norm 0.281179696\n",
      "Iteration 400 L -4.37228823 loss -4.3728261 loss_ordinary 1.02026892 entropy_value 5.39309502 glob_norm 0.224573866\n",
      "Iteration 450 L -4.36227942 loss -4.36151648 loss_ordinary 1.03421271 entropy_value 5.39572906 glob_norm 0.283319145\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power -0.00488758087 lambd_papr -0.00357785332 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.33048201 loss -4.33009291 loss_ordinary 1.06033671 entropy_value 5.3904295 glob_norm 0.430298477\n",
      "Iteration 50 L -4.33287287 loss -4.33708858 loss_ordinary 1.05858481 entropy_value 5.39567375 glob_norm 0.250979125\n",
      "Iteration 100 L -4.33385801 loss -4.33308029 loss_ordinary 1.05984569 entropy_value 5.39292622 glob_norm 0.264424205\n",
      "Iteration 150 L -4.33461428 loss -4.33435631 loss_ordinary 1.06008887 entropy_value 5.39444542 glob_norm 0.411499351\n",
      "Iteration 200 L -4.31822586 loss -4.31876564 loss_ordinary 1.07540834 entropy_value 5.39417362 glob_norm 0.408342719\n",
      "Iteration 250 L -4.33128691 loss -4.33074 loss_ordinary 1.0637182 entropy_value 5.39445782 glob_norm 0.255266637\n",
      "Iteration 300 L -4.32764149 loss -4.32875633 loss_ordinary 1.06487381 entropy_value 5.3936305 glob_norm 0.26005286\n",
      "Iteration 350 L -4.33787727 loss -4.33734703 loss_ordinary 1.05586314 entropy_value 5.39321 glob_norm 0.309561819\n",
      "Iteration 400 L -4.33041525 loss -4.33192396 loss_ordinary 1.06710696 entropy_value 5.39903116 glob_norm 0.339800775\n",
      "Iteration 450 L -4.31598568 loss -4.31660414 loss_ordinary 1.08556807 entropy_value 5.40217209 glob_norm 0.371121079\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.28366971 lambd_papr -0.00352175673 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.319695 loss -4.31782341 loss_ordinary 1.07617462 entropy_value 5.39399767 glob_norm 0.355096549\n",
      "Iteration 50 L -4.354527 loss -4.35164928 loss_ordinary 1.04832399 entropy_value 5.39997292 glob_norm 0.394424587\n",
      "Iteration 100 L -4.35624027 loss -4.3548193 loss_ordinary 1.05570471 entropy_value 5.41052389 glob_norm 0.289563328\n",
      "Iteration 150 L -4.32454824 loss -4.32477665 loss_ordinary 1.08294392 entropy_value 5.40772057 glob_norm 0.349410743\n",
      "Iteration 200 L -4.3278265 loss -4.32496738 loss_ordinary 1.07471752 entropy_value 5.39968491 glob_norm 0.258303612\n",
      "Iteration 250 L -4.32618618 loss -4.32493 loss_ordinary 1.08646095 entropy_value 5.41139126 glob_norm 0.290304184\n",
      "Iteration 300 L -4.38028765 loss -4.37980318 loss_ordinary 1.02881932 entropy_value 5.40862226 glob_norm 0.420577884\n",
      "Iteration 350 L -4.32784414 loss -4.32881498 loss_ordinary 1.07966316 entropy_value 5.40847826 glob_norm 0.293817669\n",
      "Iteration 400 L -4.34502792 loss -4.34415388 loss_ordinary 1.05725265 entropy_value 5.40140676 glob_norm 0.416452944\n",
      "Iteration 450 L -4.35605335 loss -4.35318136 loss_ordinary 1.0558157 entropy_value 5.40899706 glob_norm 0.419614673\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power -0.095764637 lambd_papr -0.00678731315 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.34599447 loss -4.34485531 loss_ordinary 1.06628573 entropy_value 5.4111414 glob_norm 0.374953479\n",
      "Iteration 50 L -4.32587 loss -4.32385969 loss_ordinary 1.08042681 entropy_value 5.40428638 glob_norm 0.395289\n",
      "Iteration 100 L -4.30581617 loss -4.30475521 loss_ordinary 1.09680295 entropy_value 5.4015584 glob_norm 0.432082593\n",
      "Iteration 150 L -4.34434175 loss -4.34293175 loss_ordinary 1.05253053 entropy_value 5.39546251 glob_norm 0.32921055\n",
      "Iteration 200 L -4.31720972 loss -4.31639862 loss_ordinary 1.08687222 entropy_value 5.40327072 glob_norm 0.317672968\n",
      "Iteration 250 L -4.31048393 loss -4.30912828 loss_ordinary 1.09656692 entropy_value 5.40569496 glob_norm 0.362163246\n",
      "Iteration 300 L -4.34109116 loss -4.33908081 loss_ordinary 1.06711626 entropy_value 5.40619659 glob_norm 0.239638209\n",
      "Iteration 350 L -4.34168816 loss -4.34139776 loss_ordinary 1.06229198 entropy_value 5.40369 glob_norm 0.238863528\n",
      "Iteration 400 L -4.32196856 loss -4.32274675 loss_ordinary 1.08964562 entropy_value 5.41239214 glob_norm 0.331849664\n",
      "Iteration 450 L -4.36219311 loss -4.36034441 loss_ordinary 1.0521996 entropy_value 5.41254377 glob_norm 0.29487282\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.152333021 lambd_papr -0.00568158 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_13_papr_8.0\n",
      "\n",
      "===== Running SNR=15 dB | PAPR=6.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0195493735 loss 0.0186676849 loss_ordinary 6.00985098 entropy_value 5.99118328 glob_norm 0.634858668\n",
      "Iteration 50 L -3.23115 loss -3.23291 loss_ordinary 2.73674464 entropy_value 5.96965456 glob_norm 0.394652545\n",
      "Iteration 100 L -4.00631571 loss -4.00891256 loss_ordinary 1.95015669 entropy_value 5.95906925 glob_norm 0.299507529\n",
      "Iteration 150 L -4.27809334 loss -4.28056955 loss_ordinary 1.64584672 entropy_value 5.92641592 glob_norm 0.423589677\n",
      "Iteration 200 L -4.52852774 loss -4.53836393 loss_ordinary 1.29365921 entropy_value 5.83202314 glob_norm 0.379964352\n",
      "Iteration 250 L -4.72525215 loss -4.74065208 loss_ordinary 0.999145329 entropy_value 5.73979759 glob_norm 0.290173411\n",
      "Iteration 300 L -4.76267719 loss -4.77772808 loss_ordinary 0.923618913 entropy_value 5.70134687 glob_norm 0.471103519\n",
      "Iteration 350 L -4.85293484 loss -4.86821842 loss_ordinary 0.813869715 entropy_value 5.68208838 glob_norm 0.494919866\n",
      "Iteration 400 L -4.84740305 loss -4.86262083 loss_ordinary 0.810705543 entropy_value 5.67332649 glob_norm 0.459247857\n",
      "Iteration 450 L -4.88096285 loss -4.89677477 loss_ordinary 0.765092611 entropy_value 5.66186762 glob_norm 0.37546128\n",
      "Iteration 500 L -4.8799243 loss -4.89736843 loss_ordinary 0.757108033 entropy_value 5.65447617 glob_norm 0.398968518\n",
      "Iteration 550 L -4.82975721 loss -4.84737158 loss_ordinary 0.80476445 entropy_value 5.65213585 glob_norm 0.445571065\n",
      "Iteration 600 L -4.86041546 loss -4.87652969 loss_ordinary 0.778220534 entropy_value 5.65475 glob_norm 0.413679898\n",
      "Iteration 650 L -4.87057734 loss -4.88630819 loss_ordinary 0.757413626 entropy_value 5.64372206 glob_norm 0.422310859\n",
      "Iteration 700 L -4.87867546 loss -4.89590597 loss_ordinary 0.749586701 entropy_value 5.64549255 glob_norm 0.346523702\n",
      "Iteration 750 L -4.85346842 loss -4.86996508 loss_ordinary 0.77093184 entropy_value 5.6408968 glob_norm 0.383716881\n",
      "Iteration 800 L -4.83296633 loss -4.8491087 loss_ordinary 0.794639289 entropy_value 5.64374828 glob_norm 0.48126176\n",
      "Iteration 850 L -4.90170097 loss -4.91818857 loss_ordinary 0.726796031 entropy_value 5.64498425 glob_norm 0.490825355\n",
      "Iteration 900 L -4.84606457 loss -4.86318 loss_ordinary 0.780634761 entropy_value 5.64381504 glob_norm 0.305733711\n",
      "Iteration 950 L -4.89685774 loss -4.91330338 loss_ordinary 0.726835668 entropy_value 5.6401391 glob_norm 0.576171279\n",
      "Iteration 1000 L -4.87050056 loss -4.88740683 loss_ordinary 0.751825929 entropy_value 5.63923264 glob_norm 0.365641713\n",
      "Iteration 1050 L -4.85445118 loss -4.87030792 loss_ordinary 0.767654121 entropy_value 5.63796186 glob_norm 0.306116641\n",
      "Iteration 1100 L -4.88420296 loss -4.90138435 loss_ordinary 0.737541378 entropy_value 5.63892603 glob_norm 0.417539835\n",
      "Iteration 1150 L -4.87789345 loss -4.89308739 loss_ordinary 0.750686884 entropy_value 5.64377403 glob_norm 0.485798836\n",
      "Iteration 1200 L -4.87259674 loss -4.89121342 loss_ordinary 0.745239854 entropy_value 5.63645315 glob_norm 0.396417767\n",
      "Iteration 1250 L -4.88042641 loss -4.89667225 loss_ordinary 0.742266953 entropy_value 5.6389389 glob_norm 0.398673892\n",
      "Iteration 1300 L -4.88765717 loss -4.90429211 loss_ordinary 0.728018284 entropy_value 5.63231039 glob_norm 0.485783935\n",
      "Iteration 1350 L -4.89032793 loss -4.90686607 loss_ordinary 0.72991997 entropy_value 5.63678598 glob_norm 0.312676698\n",
      "Iteration 1400 L -4.88227654 loss -4.89866257 loss_ordinary 0.738535106 entropy_value 5.63719749 glob_norm 0.592161238\n",
      "Iteration 1450 L -4.87590313 loss -4.89245081 loss_ordinary 0.740494668 entropy_value 5.63294554 glob_norm 0.30486232\n",
      "Iteration 1500 L -4.86919355 loss -4.88443708 loss_ordinary 0.753725648 entropy_value 5.63816261 glob_norm 0.279580295\n",
      "Iteration 1550 L -4.86598396 loss -4.88222694 loss_ordinary 0.762292624 entropy_value 5.64451933 glob_norm 0.357075274\n",
      "Iteration 1600 L -4.88442612 loss -4.90128374 loss_ordinary 0.736060262 entropy_value 5.63734436 glob_norm 0.424514443\n",
      "Iteration 1650 L -4.87033367 loss -4.88806915 loss_ordinary 0.754531622 entropy_value 5.64260054 glob_norm 0.542751372\n",
      "Iteration 1700 L -4.88136816 loss -4.89811182 loss_ordinary 0.736211717 entropy_value 5.6343236 glob_norm 0.411526889\n",
      "Iteration 1750 L -4.88050604 loss -4.89758778 loss_ordinary 0.73411566 entropy_value 5.63170338 glob_norm 0.342422545\n",
      "Iteration 1800 L -4.87551 loss -4.89284325 loss_ordinary 0.745331168 entropy_value 5.63817453 glob_norm 0.585124373\n",
      "Iteration 1850 L -4.85112906 loss -4.86862183 loss_ordinary 0.765907884 entropy_value 5.63453 glob_norm 0.321125507\n",
      "Iteration 1900 L -4.87661743 loss -4.8940444 loss_ordinary 0.73382467 entropy_value 5.62786865 glob_norm 0.519807756\n",
      "Iteration 1950 L -4.88580275 loss -4.90257645 loss_ordinary 0.736301601 entropy_value 5.63887835 glob_norm 0.327593058\n",
      "Iteration 2000 L -4.90655088 loss -4.92365217 loss_ordinary 0.709635139 entropy_value 5.63328695 glob_norm 0.461099565\n",
      "Iteration 2050 L -4.86225128 loss -4.87916183 loss_ordinary 0.759561956 entropy_value 5.63872385 glob_norm 0.517351329\n",
      "Iteration 2100 L -4.88511133 loss -4.90170383 loss_ordinary 0.736154079 entropy_value 5.63785791 glob_norm 0.488831699\n",
      "Iteration 2150 L -4.86357069 loss -4.87994051 loss_ordinary 0.752078056 entropy_value 5.63201857 glob_norm 0.423089117\n",
      "Iteration 2200 L -4.90070677 loss -4.91529226 loss_ordinary 0.720536411 entropy_value 5.63582897 glob_norm 0.329539686\n",
      "Iteration 2250 L -4.90751028 loss -4.92394638 loss_ordinary 0.711037159 entropy_value 5.63498354 glob_norm 0.413517803\n",
      "Iteration 2300 L -4.88602 loss -4.90307522 loss_ordinary 0.73156929 entropy_value 5.63464499 glob_norm 0.473916262\n",
      "Iteration 2350 L -4.8859539 loss -4.90221739 loss_ordinary 0.728923202 entropy_value 5.63114071 glob_norm 0.36040175\n",
      "Iteration 2400 L -4.87899399 loss -4.89679956 loss_ordinary 0.733594239 entropy_value 5.63039398 glob_norm 0.614774466\n",
      "Iteration 2450 L -4.85252714 loss -4.87014055 loss_ordinary 0.762749732 entropy_value 5.6328907 glob_norm 0.314354599\n",
      "Iteration 2500 L -4.85558176 loss -4.87214041 loss_ordinary 0.756753087 entropy_value 5.62889338 glob_norm 0.393205345\n",
      "Iteration 2550 L -4.8877387 loss -4.90453911 loss_ordinary 0.731059968 entropy_value 5.63559914 glob_norm 0.377316743\n",
      "Iteration 2600 L -4.85376692 loss -4.87184381 loss_ordinary 0.767629743 entropy_value 5.63947392 glob_norm 0.374657035\n",
      "Iteration 2650 L -4.8685441 loss -4.88616276 loss_ordinary 0.74422878 entropy_value 5.63039112 glob_norm 0.36289233\n",
      "Iteration 2700 L -4.90670729 loss -4.92249441 loss_ordinary 0.713288605 entropy_value 5.6357832 glob_norm 0.453112245\n",
      "Iteration 2750 L -4.87712193 loss -4.89461517 loss_ordinary 0.74149096 entropy_value 5.63610601 glob_norm 0.438823581\n",
      "Iteration 2800 L -4.91912937 loss -4.93507195 loss_ordinary 0.703934371 entropy_value 5.63900614 glob_norm 0.352778584\n",
      "Iteration 2850 L -4.88933277 loss -4.9056015 loss_ordinary 0.732650697 entropy_value 5.63825226 glob_norm 0.47863552\n",
      "Iteration 2900 L -4.87213278 loss -4.88891888 loss_ordinary 0.749225 entropy_value 5.63814449 glob_norm 0.437313\n",
      "Iteration 2950 L -4.88560247 loss -4.90142822 loss_ordinary 0.728906512 entropy_value 5.63033438 glob_norm 0.500098825\n",
      "Iteration 3000 L -4.86545134 loss -4.88216257 loss_ordinary 0.751317561 entropy_value 5.63348 glob_norm 0.481983036\n",
      "Iteration 3050 L -4.9000082 loss -4.91717911 loss_ordinary 0.711934 entropy_value 5.62911272 glob_norm 0.345750779\n",
      "Iteration 3100 L -4.87561417 loss -4.89298058 loss_ordinary 0.738831937 entropy_value 5.63181257 glob_norm 0.376760721\n",
      "Iteration 3150 L -4.88998556 loss -4.90590858 loss_ordinary 0.734100699 entropy_value 5.6400094 glob_norm 0.331136853\n",
      "Iteration 3200 L -4.89391947 loss -4.90968895 loss_ordinary 0.724876761 entropy_value 5.63456583 glob_norm 0.387971342\n",
      "Iteration 3250 L -4.85861588 loss -4.87498903 loss_ordinary 0.761331439 entropy_value 5.63632059 glob_norm 0.422905147\n",
      "Iteration 3300 L -4.8824544 loss -4.89788723 loss_ordinary 0.735891402 entropy_value 5.63377857 glob_norm 0.344377458\n",
      "Iteration 3350 L -4.87192822 loss -4.88867474 loss_ordinary 0.74639523 entropy_value 5.63507 glob_norm 0.343164176\n",
      "Iteration 3400 L -4.88637733 loss -4.90158939 loss_ordinary 0.73076725 entropy_value 5.63235664 glob_norm 0.392259151\n",
      "Iteration 3450 L -4.87131929 loss -4.88902807 loss_ordinary 0.741534472 entropy_value 5.63056278 glob_norm 0.444838643\n",
      "Iteration 3500 L -4.8950491 loss -4.91242647 loss_ordinary 0.726959705 entropy_value 5.63938618 glob_norm 0.288500249\n",
      "Iteration 3550 L -4.87033939 loss -4.88627338 loss_ordinary 0.744827628 entropy_value 5.63110113 glob_norm 0.34633854\n",
      "Iteration 3600 L -4.87898 loss -4.89561081 loss_ordinary 0.738422811 entropy_value 5.6340332 glob_norm 0.547119439\n",
      "Iteration 3650 L -4.88087 loss -4.90009546 loss_ordinary 0.727314472 entropy_value 5.62741 glob_norm 0.372713864\n",
      "Iteration 3700 L -4.87064695 loss -4.88781166 loss_ordinary 0.742346227 entropy_value 5.63015795 glob_norm 0.31790483\n",
      "Iteration 3750 L -4.84368372 loss -4.86132336 loss_ordinary 0.77499181 entropy_value 5.63631535 glob_norm 0.478706777\n",
      "Iteration 3800 L -4.85745811 loss -4.87428904 loss_ordinary 0.754986525 entropy_value 5.62927532 glob_norm 0.493808568\n",
      "Iteration 3850 L -4.91998243 loss -4.9366765 loss_ordinary 0.698632538 entropy_value 5.63530874 glob_norm 0.392958015\n",
      "Iteration 3900 L -4.84727 loss -4.86289072 loss_ordinary 0.770884335 entropy_value 5.63377476 glob_norm 0.443372488\n",
      "Iteration 3950 L -4.8682375 loss -4.88552856 loss_ordinary 0.749995351 entropy_value 5.6355238 glob_norm 0.404065669\n",
      "Iteration 4000 L -4.83926964 loss -4.85579777 loss_ordinary 0.783363402 entropy_value 5.63916111 glob_norm 0.525980234\n",
      "Iteration 4050 L -4.88601112 loss -4.9028697 loss_ordinary 0.727041185 entropy_value 5.62991095 glob_norm 0.356122911\n",
      "Iteration 4100 L -4.89207125 loss -4.90897322 loss_ordinary 0.723165035 entropy_value 5.63213825 glob_norm 0.397600055\n",
      "Iteration 4150 L -4.88876963 loss -4.90408707 loss_ordinary 0.729606271 entropy_value 5.63369322 glob_norm 0.392955869\n",
      "Iteration 4200 L -4.88069582 loss -4.89780569 loss_ordinary 0.737881422 entropy_value 5.63568687 glob_norm 0.362896502\n",
      "Iteration 4250 L -4.85507822 loss -4.87233734 loss_ordinary 0.76627934 entropy_value 5.63861704 glob_norm 0.333840549\n",
      "Iteration 4300 L -4.86520195 loss -4.88117123 loss_ordinary 0.759547949 entropy_value 5.64071941 glob_norm 0.356921\n",
      "Iteration 4350 L -4.83646345 loss -4.85267 loss_ordinary 0.7859779 entropy_value 5.63864803 glob_norm 0.339920908\n",
      "Iteration 4400 L -4.90685463 loss -4.92547321 loss_ordinary 0.710773766 entropy_value 5.63624716 glob_norm 0.437454432\n",
      "Iteration 4450 L -4.88618374 loss -4.90266275 loss_ordinary 0.73657918 entropy_value 5.6392417 glob_norm 0.410164\n",
      "Iteration 4500 L -4.87182903 loss -4.88775682 loss_ordinary 0.750123322 entropy_value 5.63788033 glob_norm 0.384880722\n",
      "Iteration 4550 L -4.88240767 loss -4.90004 loss_ordinary 0.734797776 entropy_value 5.6348381 glob_norm 0.410860747\n",
      "Iteration 4600 L -4.8867631 loss -4.90169764 loss_ordinary 0.726011395 entropy_value 5.62770891 glob_norm 0.459468633\n",
      "Iteration 4650 L -4.85567856 loss -4.87343931 loss_ordinary 0.754456818 entropy_value 5.62789631 glob_norm 0.362272918\n",
      "Iteration 4700 L -4.86186361 loss -4.87888479 loss_ordinary 0.758872807 entropy_value 5.63775778 glob_norm 0.315592676\n",
      "Iteration 4750 L -4.89855909 loss -4.9133811 loss_ordinary 0.72397995 entropy_value 5.63736057 glob_norm 0.549536\n",
      "Iteration 4800 L -4.86569405 loss -4.88144684 loss_ordinary 0.75932318 entropy_value 5.64077 glob_norm 0.502061486\n",
      "Iteration 4850 L -4.88051939 loss -4.89835215 loss_ordinary 0.741419 entropy_value 5.63977098 glob_norm 0.497428179\n",
      "Iteration 4900 L -4.87283278 loss -4.88896179 loss_ordinary 0.746545136 entropy_value 5.63550663 glob_norm 0.564041853\n",
      "Iteration 4950 L -4.84900761 loss -4.86487341 loss_ordinary 0.767230332 entropy_value 5.63210344 glob_norm 0.569095254\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 1.52024472 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85048532 loss -4.90070486 loss_ordinary 0.736793101 entropy_value 5.63749743 glob_norm 0.337396324\n",
      "Iteration 50 L -4.83984661 loss -4.88689041 loss_ordinary 0.754421294 entropy_value 5.64131165 glob_norm 0.39809081\n",
      "Iteration 100 L -4.85733461 loss -4.90101147 loss_ordinary 0.743988514 entropy_value 5.64500046 glob_norm 0.634093583\n",
      "Iteration 150 L -4.84629393 loss -4.89282608 loss_ordinary 0.753455043 entropy_value 5.64628077 glob_norm 0.474136204\n",
      "Iteration 200 L -4.86214876 loss -4.90568495 loss_ordinary 0.735855639 entropy_value 5.64154053 glob_norm 0.371798694\n",
      "Iteration 250 L -4.84159613 loss -4.89162683 loss_ordinary 0.744429827 entropy_value 5.63605642 glob_norm 0.515400231\n",
      "Iteration 300 L -4.82983112 loss -4.87616158 loss_ordinary 0.767428637 entropy_value 5.64359 glob_norm 0.404560924\n",
      "Iteration 350 L -4.81857395 loss -4.86355591 loss_ordinary 0.791690648 entropy_value 5.65524626 glob_norm 0.44103384\n",
      "Iteration 400 L -4.83706617 loss -4.88245249 loss_ordinary 0.771392405 entropy_value 5.65384483 glob_norm 0.606371164\n",
      "Iteration 450 L -4.88364887 loss -4.927701 loss_ordinary 0.726173937 entropy_value 5.65387487 glob_norm 0.38862738\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 1.49121356 lambd_papr -0.0152024468 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8390069 loss -4.91291189 loss_ordinary 0.731874228 entropy_value 5.64478636 glob_norm 0.438871592\n",
      "Iteration 50 L -4.81646776 loss -4.89111 loss_ordinary 0.759755254 entropy_value 5.65086555 glob_norm 0.34572351\n",
      "Iteration 100 L -4.78620577 loss -4.85492897 loss_ordinary 0.809016943 entropy_value 5.66394615 glob_norm 0.547290742\n",
      "Iteration 150 L -4.84867573 loss -4.91884756 loss_ordinary 0.737511635 entropy_value 5.6563592 glob_norm 0.358239055\n",
      "Iteration 200 L -4.80012321 loss -4.86910582 loss_ordinary 0.790129542 entropy_value 5.659235 glob_norm 0.393991262\n",
      "Iteration 250 L -4.81476545 loss -4.87991667 loss_ordinary 0.774070919 entropy_value 5.65398788 glob_norm 0.572079062\n",
      "Iteration 300 L -4.82181025 loss -4.89048529 loss_ordinary 0.778947 entropy_value 5.66943216 glob_norm 0.393432826\n",
      "Iteration 350 L -4.81955957 loss -4.88703775 loss_ordinary 0.7783 entropy_value 5.66533804 glob_norm 0.536491334\n",
      "Iteration 400 L -4.82960224 loss -4.89861345 loss_ordinary 0.770916164 entropy_value 5.66952944 glob_norm 0.378425628\n",
      "Iteration 450 L -4.79766846 loss -4.86703205 loss_ordinary 0.800283432 entropy_value 5.66731548 glob_norm 0.479022861\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 1.30529857 lambd_papr -0.030159317 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.78063631 loss -4.87501478 loss_ordinary 0.787570715 entropy_value 5.66258574 glob_norm 0.561074734\n",
      "Iteration 50 L -4.78800058 loss -4.86870718 loss_ordinary 0.797808349 entropy_value 5.66651535 glob_norm 0.337059885\n",
      "Iteration 100 L -4.78220654 loss -4.87387276 loss_ordinary 0.795876682 entropy_value 5.66974926 glob_norm 0.521469831\n",
      "Iteration 150 L -4.77898407 loss -4.85846519 loss_ordinary 0.816049218 entropy_value 5.67451429 glob_norm 0.3346394\n",
      "Iteration 200 L -4.79108095 loss -4.8672719 loss_ordinary 0.813778698 entropy_value 5.68105078 glob_norm 0.41117388\n",
      "Iteration 250 L -4.78155184 loss -4.86165762 loss_ordinary 0.813344836 entropy_value 5.6750021 glob_norm 0.552346468\n",
      "Iteration 300 L -4.78405905 loss -4.86699057 loss_ordinary 0.815796256 entropy_value 5.68278694 glob_norm 0.372119486\n",
      "Iteration 350 L -4.8025341 loss -4.88538122 loss_ordinary 0.79990232 entropy_value 5.68528318 glob_norm 0.430250555\n",
      "Iteration 400 L -4.79175615 loss -4.8722353 loss_ordinary 0.810186803 entropy_value 5.68242216 glob_norm 0.550408721\n",
      "Iteration 450 L -4.75905371 loss -4.84857464 loss_ordinary 0.829247475 entropy_value 5.67782211 glob_norm 0.388431668\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 1.1778121 lambd_papr -0.043290738 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72269917 loss -4.82119226 loss_ordinary 0.85538882 entropy_value 5.67658091 glob_norm 0.646780431\n",
      "Iteration 50 L -4.75649881 loss -4.8479352 loss_ordinary 0.841224849 entropy_value 5.68916035 glob_norm 0.348241955\n",
      "Iteration 100 L -4.79286385 loss -4.87732553 loss_ordinary 0.817184389 entropy_value 5.69451046 glob_norm 0.462439239\n",
      "Iteration 150 L -4.79495239 loss -4.88085508 loss_ordinary 0.806112111 entropy_value 5.6869669 glob_norm 0.351244301\n",
      "Iteration 200 L -4.79051399 loss -4.8684864 loss_ordinary 0.821186543 entropy_value 5.68967295 glob_norm 0.373904228\n",
      "Iteration 250 L -4.78213692 loss -4.86884689 loss_ordinary 0.828819454 entropy_value 5.69766617 glob_norm 0.463161707\n",
      "Iteration 300 L -4.74990416 loss -4.83434725 loss_ordinary 0.864960253 entropy_value 5.69930744 glob_norm 0.257733136\n",
      "Iteration 350 L -4.77612162 loss -4.85655 loss_ordinary 0.839409053 entropy_value 5.69595957 glob_norm 0.47719866\n",
      "Iteration 400 L -4.78612804 loss -4.86152411 loss_ordinary 0.834123909 entropy_value 5.69564867 glob_norm 0.322008938\n",
      "Iteration 450 L -4.79271936 loss -4.86987734 loss_ordinary 0.825052202 entropy_value 5.6949296 glob_norm 0.683831871\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0.853437662 lambd_papr -0.0551751815 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.80021858 loss -4.88508844 loss_ordinary 0.810615897 entropy_value 5.69570398 glob_norm 0.481529087\n",
      "Iteration 50 L -4.76856852 loss -4.85975838 loss_ordinary 0.836846054 entropy_value 5.69660473 glob_norm 0.355392545\n",
      "Iteration 100 L -4.8108077 loss -4.88963699 loss_ordinary 0.813135624 entropy_value 5.70277262 glob_norm 0.359020948\n",
      "Iteration 150 L -4.73635149 loss -4.84484768 loss_ordinary 0.856927633 entropy_value 5.70177507 glob_norm 0.340711534\n",
      "Iteration 200 L -4.76392221 loss -4.86571121 loss_ordinary 0.833860517 entropy_value 5.69957209 glob_norm 0.412362605\n",
      "Iteration 250 L -4.78673744 loss -4.87922049 loss_ordinary 0.827769 entropy_value 5.70698929 glob_norm 0.485067189\n",
      "Iteration 300 L -4.74490929 loss -4.8309679 loss_ordinary 0.878200352 entropy_value 5.70916843 glob_norm 0.747868717\n",
      "Iteration 350 L -4.77137518 loss -4.86971521 loss_ordinary 0.830314755 entropy_value 5.70003 glob_norm 0.440371573\n",
      "Iteration 400 L -4.7811 loss -4.86568689 loss_ordinary 0.840130568 entropy_value 5.7058177 glob_norm 0.607010841\n",
      "Iteration 450 L -4.75660372 loss -4.85326147 loss_ordinary 0.853607595 entropy_value 5.70686913 glob_norm 0.399133295\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.832633495 lambd_papr -0.0638124347 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74579763 loss -4.84627104 loss_ordinary 0.858854115 entropy_value 5.70512486 glob_norm 0.362755775\n",
      "Iteration 50 L -4.76368284 loss -4.86736536 loss_ordinary 0.838310421 entropy_value 5.70567608 glob_norm 0.54042244\n",
      "Iteration 100 L -4.75859785 loss -4.84606838 loss_ordinary 0.860536 entropy_value 5.70660448 glob_norm 0.402358264\n",
      "Iteration 150 L -4.75068283 loss -4.83960533 loss_ordinary 0.871863782 entropy_value 5.71146965 glob_norm 0.307589859\n",
      "Iteration 200 L -4.74354506 loss -4.82926083 loss_ordinary 0.886864305 entropy_value 5.71612501 glob_norm 0.457771957\n",
      "Iteration 250 L -4.75728 loss -4.84734249 loss_ordinary 0.863431 entropy_value 5.71077347 glob_norm 0.524157763\n",
      "Iteration 300 L -4.76623058 loss -4.83598375 loss_ordinary 0.875913501 entropy_value 5.7118969 glob_norm 0.590870857\n",
      "Iteration 350 L -4.77020741 loss -4.85891962 loss_ordinary 0.856973469 entropy_value 5.71589279 glob_norm 0.516401947\n",
      "Iteration 400 L -4.72744846 loss -4.81526423 loss_ordinary 0.898174405 entropy_value 5.71343899 glob_norm 0.689921618\n",
      "Iteration 450 L -4.76651525 loss -4.85119486 loss_ordinary 0.864114523 entropy_value 5.71530962 glob_norm 0.483314097\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0.926833391 lambd_papr -0.072264418 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.73484039 loss -4.84136248 loss_ordinary 0.869077682 entropy_value 5.71044 glob_norm 0.412445068\n",
      "Iteration 50 L -4.71239042 loss -4.81435108 loss_ordinary 0.901400447 entropy_value 5.71575165 glob_norm 0.572924137\n",
      "Iteration 100 L -4.73986483 loss -4.82620716 loss_ordinary 0.892253101 entropy_value 5.71846 glob_norm 0.423356324\n",
      "Iteration 150 L -4.71028519 loss -4.81696892 loss_ordinary 0.903830409 entropy_value 5.72079897 glob_norm 0.509913385\n",
      "Iteration 200 L -4.77936077 loss -4.86617136 loss_ordinary 0.856139243 entropy_value 5.72231054 glob_norm 0.403044343\n",
      "Iteration 250 L -4.75675297 loss -4.84708738 loss_ordinary 0.869157135 entropy_value 5.7162447 glob_norm 0.51047\n",
      "Iteration 300 L -4.76279163 loss -4.8680172 loss_ordinary 0.849618077 entropy_value 5.71763515 glob_norm 0.451730698\n",
      "Iteration 350 L -4.7623 loss -4.82476425 loss_ordinary 0.895024 entropy_value 5.71978807 glob_norm 0.415402889\n",
      "Iteration 400 L -4.74825573 loss -4.84895897 loss_ordinary 0.871212959 entropy_value 5.72017193 glob_norm 0.439060956\n",
      "Iteration 450 L -4.79411602 loss -4.88627 loss_ordinary 0.836228907 entropy_value 5.72249889 glob_norm 0.434780866\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0.800075769 lambd_papr -0.0817008391 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7776618 loss -4.86177731 loss_ordinary 0.861026466 entropy_value 5.72280407 glob_norm 0.31252867\n",
      "Iteration 50 L -4.73243046 loss -4.82850218 loss_ordinary 0.888277471 entropy_value 5.71677971 glob_norm 0.429112285\n",
      "Iteration 100 L -4.75265026 loss -4.82640362 loss_ordinary 0.901972055 entropy_value 5.72837543 glob_norm 0.433696479\n",
      "Iteration 150 L -4.73862886 loss -4.82141256 loss_ordinary 0.905247629 entropy_value 5.72666 glob_norm 0.482707351\n",
      "Iteration 200 L -4.73293543 loss -4.8173914 loss_ordinary 0.905275881 entropy_value 5.72266769 glob_norm 0.555915833\n",
      "Iteration 250 L -4.75341082 loss -4.83704519 loss_ordinary 0.893886328 entropy_value 5.73093176 glob_norm 0.462714851\n",
      "Iteration 300 L -4.70630217 loss -4.80863762 loss_ordinary 0.919452429 entropy_value 5.72809029 glob_norm 0.515547276\n",
      "Iteration 350 L -4.73936605 loss -4.82262468 loss_ordinary 0.906166077 entropy_value 5.72879076 glob_norm 0.539936602\n",
      "Iteration 400 L -4.7264123 loss -4.81868744 loss_ordinary 0.908156931 entropy_value 5.72684479 glob_norm 0.382905722\n",
      "Iteration 450 L -4.7503581 loss -4.8397603 loss_ordinary 0.888359 entropy_value 5.72811937 glob_norm 0.389639378\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.823547363 lambd_papr -0.0898711309 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.7292819 loss -4.83060408 loss_ordinary 0.895920575 entropy_value 5.72652435 glob_norm 0.408030301\n",
      "Iteration 50 L -4.72758341 loss -4.81697655 loss_ordinary 0.910481 entropy_value 5.72745752 glob_norm 0.441861898\n",
      "Iteration 100 L -4.70640564 loss -4.80850744 loss_ordinary 0.923487246 entropy_value 5.73199463 glob_norm 0.427123934\n",
      "Iteration 150 L -4.73674488 loss -4.8224473 loss_ordinary 0.914740622 entropy_value 5.73718786 glob_norm 0.745150089\n",
      "Iteration 200 L -4.73212194 loss -4.80852222 loss_ordinary 0.926248729 entropy_value 5.73477125 glob_norm 0.497419834\n",
      "Iteration 250 L -4.71634197 loss -4.82479525 loss_ordinary 0.905342817 entropy_value 5.7301383 glob_norm 0.598784685\n",
      "Iteration 300 L -4.75383806 loss -4.81724691 loss_ordinary 0.914153278 entropy_value 5.73140049 glob_norm 0.51487112\n",
      "Iteration 350 L -4.72184 loss -4.81674051 loss_ordinary 0.922383 entropy_value 5.73912382 glob_norm 0.310729802\n",
      "Iteration 400 L -4.68997335 loss -4.78616953 loss_ordinary 0.949193895 entropy_value 5.73536348 glob_norm 0.729928851\n",
      "Iteration 450 L -4.71745872 loss -4.79865 loss_ordinary 0.934854686 entropy_value 5.73350477 glob_norm 0.367564559\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0.538516283 lambd_papr -0.098306343 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.75523281 loss -4.85625362 loss_ordinary 0.876253486 entropy_value 5.73250675 glob_norm 0.318839967\n",
      "Iteration 50 L -4.70488167 loss -4.80607557 loss_ordinary 0.92819792 entropy_value 5.73427343 glob_norm 0.445534647\n",
      "Iteration 100 L -4.71602726 loss -4.83166409 loss_ordinary 0.902646124 entropy_value 5.73431 glob_norm 0.391371906\n",
      "Iteration 150 L -4.75895596 loss -4.82025337 loss_ordinary 0.919424057 entropy_value 5.73967743 glob_norm 0.471999228\n",
      "Iteration 200 L -4.70872784 loss -4.81158066 loss_ordinary 0.92766 entropy_value 5.73924065 glob_norm 0.496161968\n",
      "Iteration 250 L -4.69247389 loss -4.78704 loss_ordinary 0.949878395 entropy_value 5.73691893 glob_norm 0.591672\n",
      "Iteration 300 L -4.68202066 loss -4.80608177 loss_ordinary 0.930321634 entropy_value 5.73640347 glob_norm 0.351643592\n",
      "Iteration 350 L -4.72289896 loss -4.82742071 loss_ordinary 0.914885461 entropy_value 5.74230576 glob_norm 0.581153929\n",
      "Iteration 400 L -4.72735453 loss -4.83532953 loss_ordinary 0.902627289 entropy_value 5.737957 glob_norm 0.314624637\n",
      "Iteration 450 L -4.69934654 loss -4.79679489 loss_ordinary 0.949417 entropy_value 5.74621201 glob_norm 0.581674814\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.64100647 lambd_papr -0.10383866 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72336769 loss -4.815063 loss_ordinary 0.9265818 entropy_value 5.74164486 glob_norm 0.542617619\n",
      "Iteration 50 L -4.77581596 loss -4.84156656 loss_ordinary 0.903895557 entropy_value 5.74546194 glob_norm 0.375534296\n",
      "Iteration 100 L -4.75155449 loss -4.83437777 loss_ordinary 0.907648861 entropy_value 5.74202681 glob_norm 0.42636326\n",
      "Iteration 150 L -4.75117159 loss -4.8096056 loss_ordinary 0.933496356 entropy_value 5.74310207 glob_norm 0.407207251\n",
      "Iteration 200 L -4.73621464 loss -4.83044481 loss_ordinary 0.921196401 entropy_value 5.75164127 glob_norm 0.576119542\n",
      "Iteration 250 L -4.73483038 loss -4.81817102 loss_ordinary 0.924273193 entropy_value 5.74244404 glob_norm 0.586493373\n",
      "Iteration 300 L -4.73490715 loss -4.80935907 loss_ordinary 0.93570894 entropy_value 5.74506807 glob_norm 0.401117504\n",
      "Iteration 350 L -4.72648478 loss -4.81249142 loss_ordinary 0.936605752 entropy_value 5.74909735 glob_norm 0.534773409\n",
      "Iteration 400 L -4.71112 loss -4.7989049 loss_ordinary 0.947788954 entropy_value 5.74669361 glob_norm 0.57373786\n",
      "Iteration 450 L -4.71497536 loss -4.80016518 loss_ordinary 0.946127295 entropy_value 5.74629211 glob_norm 0.604234815\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0.52417016 lambd_papr -0.110443644 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72099257 loss -4.79928827 loss_ordinary 0.950848699 entropy_value 5.75013685 glob_norm 0.376829326\n",
      "Iteration 50 L -4.71967793 loss -4.8224864 loss_ordinary 0.927467167 entropy_value 5.74995375 glob_norm 0.358715802\n",
      "Iteration 100 L -4.69904852 loss -4.78351212 loss_ordinary 0.968404353 entropy_value 5.75191641 glob_norm 0.44615674\n",
      "Iteration 150 L -4.73307657 loss -4.79619932 loss_ordinary 0.952308953 entropy_value 5.74850845 glob_norm 0.49219209\n",
      "Iteration 200 L -4.69872713 loss -4.79759645 loss_ordinary 0.955202639 entropy_value 5.75279903 glob_norm 0.494323552\n",
      "Iteration 250 L -4.71499252 loss -4.80007887 loss_ordinary 0.955887616 entropy_value 5.75596666 glob_norm 0.564371943\n",
      "Iteration 300 L -4.75816393 loss -4.81628609 loss_ordinary 0.936153054 entropy_value 5.75243902 glob_norm 0.451419473\n",
      "Iteration 350 L -4.69863939 loss -4.77799702 loss_ordinary 0.976007521 entropy_value 5.75400448 glob_norm 0.615299702\n",
      "Iteration 400 L -4.72956467 loss -4.82090569 loss_ordinary 0.934003532 entropy_value 5.75490904 glob_norm 0.592026055\n",
      "Iteration 450 L -4.704772 loss -4.78680468 loss_ordinary 0.964574635 entropy_value 5.75137949 glob_norm 0.566883624\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.571103573 lambd_papr -0.115860939 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67604446 loss -4.7681365 loss_ordinary 0.982000351 entropy_value 5.75013685 glob_norm 0.57434988\n",
      "Iteration 50 L -4.7324791 loss -4.79554129 loss_ordinary 0.954842687 entropy_value 5.75038385 glob_norm 0.573435783\n",
      "Iteration 100 L -4.70371103 loss -4.79585791 loss_ordinary 0.958422482 entropy_value 5.75428057 glob_norm 0.458581775\n",
      "Iteration 150 L -4.74898243 loss -4.80038643 loss_ordinary 0.956654847 entropy_value 5.75704145 glob_norm 0.442362577\n",
      "Iteration 200 L -4.72504902 loss -4.80531025 loss_ordinary 0.949083149 entropy_value 5.75439358 glob_norm 0.771137536\n",
      "Iteration 250 L -4.70388031 loss -4.77357435 loss_ordinary 0.978102446 entropy_value 5.75167656 glob_norm 0.453712523\n",
      "Iteration 300 L -4.74897289 loss -4.82652235 loss_ordinary 0.931044757 entropy_value 5.75756741 glob_norm 0.488005131\n",
      "Iteration 350 L -4.71121836 loss -4.78222036 loss_ordinary 0.97424835 entropy_value 5.75646877 glob_norm 0.427987486\n",
      "Iteration 400 L -4.78659201 loss -4.81686544 loss_ordinary 0.945366085 entropy_value 5.76223135 glob_norm 0.519052088\n",
      "Iteration 450 L -4.67723513 loss -4.79656792 loss_ordinary 0.96234405 entropy_value 5.75891209 glob_norm 0.467019588\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.576465368 lambd_papr -0.121781 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70915699 loss -4.80049133 loss_ordinary 0.953504682 entropy_value 5.75399542 glob_norm 0.589907527\n",
      "Iteration 50 L -4.72714949 loss -4.77188444 loss_ordinary 0.985564113 entropy_value 5.7574482 glob_norm 0.397675931\n",
      "Iteration 100 L -4.75701094 loss -4.81165075 loss_ordinary 0.953621745 entropy_value 5.76527262 glob_norm 0.455442548\n",
      "Iteration 150 L -4.7288537 loss -4.7943635 loss_ordinary 0.968398273 entropy_value 5.76276207 glob_norm 0.473466128\n",
      "Iteration 200 L -4.75338316 loss -4.80859137 loss_ordinary 0.959807396 entropy_value 5.76839876 glob_norm 0.524076\n",
      "Iteration 250 L -4.70077515 loss -4.79752493 loss_ordinary 0.961886764 entropy_value 5.75941181 glob_norm 0.586634815\n",
      "Iteration 300 L -4.7154789 loss -4.80207062 loss_ordinary 0.961072087 entropy_value 5.76314259 glob_norm 0.497480899\n",
      "Iteration 350 L -4.69974804 loss -4.79397106 loss_ordinary 0.970754683 entropy_value 5.76472569 glob_norm 0.461981326\n",
      "Iteration 400 L -4.66681767 loss -4.76704073 loss_ordinary 0.997321 entropy_value 5.76436186 glob_norm 0.455950201\n",
      "Iteration 450 L -4.72158909 loss -4.77084541 loss_ordinary 0.994920373 entropy_value 5.76576567 glob_norm 0.629852295\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.281378508 lambd_papr -0.127774566 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68551636 loss -4.7745862 loss_ordinary 0.986477673 entropy_value 5.76106358 glob_norm 0.709464192\n",
      "Iteration 50 L -4.68985462 loss -4.79992723 loss_ordinary 0.970354557 entropy_value 5.77028179 glob_norm 0.380386084\n",
      "Iteration 100 L -4.68162107 loss -4.75191498 loss_ordinary 1.01157939 entropy_value 5.76349401 glob_norm 0.51212281\n",
      "Iteration 150 L -4.75257492 loss -4.77393818 loss_ordinary 0.990716219 entropy_value 5.76465464 glob_norm 0.495327592\n",
      "Iteration 200 L -4.6715703 loss -4.76155424 loss_ordinary 1.00497866 entropy_value 5.7665329 glob_norm 0.50715524\n",
      "Iteration 250 L -4.74525738 loss -4.80185509 loss_ordinary 0.969699383 entropy_value 5.77155447 glob_norm 0.478567541\n",
      "Iteration 300 L -4.71004248 loss -4.75608397 loss_ordinary 1.01652169 entropy_value 5.7726059 glob_norm 0.453441143\n",
      "Iteration 350 L -4.72559071 loss -4.77025509 loss_ordinary 1.00002623 entropy_value 5.77028131 glob_norm 0.457191408\n",
      "Iteration 400 L -4.69862127 loss -4.77287292 loss_ordinary 0.995994329 entropy_value 5.76886749 glob_norm 0.592439771\n",
      "Iteration 450 L -4.69504547 loss -4.76016378 loss_ordinary 1.0090059 entropy_value 5.76917 glob_norm 0.505484879\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.348924398 lambd_papr -0.130708858 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71619606 loss -4.78283358 loss_ordinary 0.982282758 entropy_value 5.76511621 glob_norm 0.533272684\n",
      "Iteration 50 L -4.74031115 loss -4.76621771 loss_ordinary 1.00619256 entropy_value 5.77241039 glob_norm 0.513978541\n",
      "Iteration 100 L -4.67675 loss -4.74577808 loss_ordinary 1.02846444 entropy_value 5.7742424 glob_norm 0.518850207\n",
      "Iteration 150 L -4.78892 loss -4.78757334 loss_ordinary 0.986534953 entropy_value 5.77410841 glob_norm 0.669302583\n",
      "Iteration 200 L -4.73125 loss -4.74838448 loss_ordinary 1.02895641 entropy_value 5.77734089 glob_norm 0.625285506\n",
      "Iteration 250 L -4.72303057 loss -4.79783154 loss_ordinary 0.981321096 entropy_value 5.77915287 glob_norm 0.501399398\n",
      "Iteration 300 L -4.73796225 loss -4.75944805 loss_ordinary 1.01349807 entropy_value 5.77294588 glob_norm 0.511555552\n",
      "Iteration 350 L -4.71566296 loss -4.79647112 loss_ordinary 0.97668153 entropy_value 5.77315283 glob_norm 0.36553964\n",
      "Iteration 400 L -4.74828529 loss -4.78381729 loss_ordinary 0.988291264 entropy_value 5.77210855 glob_norm 0.655724227\n",
      "Iteration 450 L -4.69457245 loss -4.76480055 loss_ordinary 1.00637424 entropy_value 5.77117491 glob_norm 0.598679304\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0.302259684 lambd_papr -0.134358466 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70815182 loss -4.77984762 loss_ordinary 0.991349459 entropy_value 5.77119684 glob_norm 0.580790222\n",
      "Iteration 50 L -4.7493763 loss -4.7811408 loss_ordinary 0.991919041 entropy_value 5.77306 glob_norm 0.644904196\n",
      "Iteration 100 L -4.6971817 loss -4.75488806 loss_ordinary 1.02270103 entropy_value 5.77758932 glob_norm 0.460566133\n",
      "Iteration 150 L -4.73480797 loss -4.78346539 loss_ordinary 0.99039 entropy_value 5.77385521 glob_norm 0.42017439\n",
      "Iteration 200 L -4.72584772 loss -4.77149916 loss_ordinary 1.00711668 entropy_value 5.77861547 glob_norm 0.454678565\n",
      "Iteration 250 L -4.72759724 loss -4.75940323 loss_ordinary 1.01784062 entropy_value 5.77724409 glob_norm 0.472587675\n",
      "Iteration 300 L -4.67019081 loss -4.72799301 loss_ordinary 1.05506063 entropy_value 5.7830534 glob_norm 0.538022459\n",
      "Iteration 350 L -4.7468853 loss -4.76991749 loss_ordinary 1.01106119 entropy_value 5.78097868 glob_norm 0.557546496\n",
      "Iteration 400 L -4.73302412 loss -4.77019835 loss_ordinary 1.01292622 entropy_value 5.78312445 glob_norm 0.675501168\n",
      "Iteration 450 L -4.71584845 loss -4.74647427 loss_ordinary 1.02703035 entropy_value 5.77350426 glob_norm 0.477420062\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0.196593523 lambd_papr -0.137529463 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68145037 loss -4.73311472 loss_ordinary 1.05190706 entropy_value 5.78502178 glob_norm 0.500249147\n",
      "Iteration 50 L -4.7123251 loss -4.74206495 loss_ordinary 1.03824806 entropy_value 5.78031349 glob_norm 0.639495254\n",
      "Iteration 100 L -4.73756075 loss -4.78850269 loss_ordinary 0.990434825 entropy_value 5.77893734 glob_norm 0.741411507\n",
      "Iteration 150 L -4.72619486 loss -4.7729497 loss_ordinary 1.008178 entropy_value 5.78112793 glob_norm 0.4279567\n",
      "Iteration 200 L -4.68004894 loss -4.7204442 loss_ordinary 1.06593347 entropy_value 5.78637743 glob_norm 0.608973145\n",
      "Iteration 250 L -4.70830965 loss -4.73524237 loss_ordinary 1.05089366 entropy_value 5.78613615 glob_norm 0.535099268\n",
      "Iteration 300 L -4.76790476 loss -4.76718044 loss_ordinary 1.02238548 entropy_value 5.78956604 glob_norm 0.47817564\n",
      "Iteration 350 L -4.69748974 loss -4.71725273 loss_ordinary 1.06942642 entropy_value 5.78667974 glob_norm 0.619632304\n",
      "Iteration 400 L -4.77617931 loss -4.75072432 loss_ordinary 1.0338304 entropy_value 5.78455448 glob_norm 0.462181807\n",
      "Iteration 450 L -4.71565437 loss -4.76442 loss_ordinary 1.02423966 entropy_value 5.78865957 glob_norm 0.542283833\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0.331163406 lambd_papr -0.139598101 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72415304 loss -4.72849941 loss_ordinary 1.05810153 entropy_value 5.78660107 glob_norm 0.515652895\n",
      "Iteration 50 L -4.72039175 loss -4.74005938 loss_ordinary 1.05036497 entropy_value 5.79042482 glob_norm 0.676544845\n",
      "Iteration 100 L -4.657444 loss -4.71904707 loss_ordinary 1.06713152 entropy_value 5.78617859 glob_norm 0.607687294\n",
      "Iteration 150 L -4.69886923 loss -4.7284255 loss_ordinary 1.05877 entropy_value 5.78719568 glob_norm 0.673242271\n",
      "Iteration 200 L -4.74144554 loss -4.74463749 loss_ordinary 1.04179156 entropy_value 5.78642893 glob_norm 0.49884668\n",
      "Iteration 250 L -4.7268095 loss -4.74973679 loss_ordinary 1.03921235 entropy_value 5.78894901 glob_norm 0.844225824\n",
      "Iteration 300 L -4.73166704 loss -4.73577309 loss_ordinary 1.05392933 entropy_value 5.78970242 glob_norm 0.670495689\n",
      "Iteration 350 L -4.73634624 loss -4.73915768 loss_ordinary 1.05452371 entropy_value 5.79368114 glob_norm 0.492284745\n",
      "Iteration 400 L -4.73647594 loss -4.74300718 loss_ordinary 1.04602921 entropy_value 5.78903627 glob_norm 0.53365469\n",
      "Iteration 450 L -4.72904682 loss -4.74733257 loss_ordinary 1.04539192 entropy_value 5.79272461 glob_norm 0.508343577\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0.0555963516 lambd_papr -0.143093199 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.73703861 loss -4.73977423 loss_ordinary 1.04874861 entropy_value 5.7885232 glob_norm 0.508416772\n",
      "Iteration 50 L -4.70449448 loss -4.73070955 loss_ordinary 1.06208515 entropy_value 5.7927947 glob_norm 0.522039294\n",
      "Iteration 100 L -4.71183872 loss -4.6957078 loss_ordinary 1.09707093 entropy_value 5.79277897 glob_norm 0.807698786\n",
      "Iteration 150 L -4.69207144 loss -4.68615532 loss_ordinary 1.11024809 entropy_value 5.79640341 glob_norm 0.592538178\n",
      "Iteration 200 L -4.69809818 loss -4.7319026 loss_ordinary 1.0664444 entropy_value 5.798347 glob_norm 0.500693262\n",
      "Iteration 250 L -4.70057 loss -4.71911764 loss_ordinary 1.07624638 entropy_value 5.7953639 glob_norm 0.509569764\n",
      "Iteration 300 L -4.72738695 loss -4.72237539 loss_ordinary 1.07405353 entropy_value 5.79642868 glob_norm 0.525258303\n",
      "Iteration 350 L -4.73762846 loss -4.76393223 loss_ordinary 1.02869487 entropy_value 5.79262733 glob_norm 0.535184443\n",
      "Iteration 400 L -4.71586037 loss -4.72086859 loss_ordinary 1.07056093 entropy_value 5.79142952 glob_norm 0.809745193\n",
      "Iteration 450 L -4.73768902 loss -4.75281763 loss_ordinary 1.04159594 entropy_value 5.79441309 glob_norm 0.593077183\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.0636866093 lambd_papr -0.14368172 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68303061 loss -4.72343206 loss_ordinary 1.07847834 entropy_value 5.8019104 glob_norm 0.535153747\n",
      "Iteration 50 L -4.79319859 loss -4.71997452 loss_ordinary 1.07976162 entropy_value 5.7997365 glob_norm 0.682894468\n",
      "Iteration 100 L -4.7043004 loss -4.72251 loss_ordinary 1.07482827 entropy_value 5.79733849 glob_norm 0.515027463\n",
      "Iteration 150 L -4.70689726 loss -4.69828367 loss_ordinary 1.09764481 entropy_value 5.79592896 glob_norm 0.581056118\n",
      "Iteration 200 L -4.69808531 loss -4.72624302 loss_ordinary 1.06867576 entropy_value 5.79491901 glob_norm 0.435800582\n",
      "Iteration 250 L -4.66988897 loss -4.70618296 loss_ordinary 1.09412539 entropy_value 5.80030823 glob_norm 0.630108\n",
      "Iteration 300 L -4.73158312 loss -4.73497534 loss_ordinary 1.06404424 entropy_value 5.79902 glob_norm 0.596937478\n",
      "Iteration 350 L -4.70183277 loss -4.73245907 loss_ordinary 1.06414044 entropy_value 5.79659939 glob_norm 0.428376883\n",
      "Iteration 400 L -4.72487736 loss -4.72194242 loss_ordinary 1.08013165 entropy_value 5.80207396 glob_norm 0.580934644\n",
      "Iteration 450 L -4.76788282 loss -4.71982145 loss_ordinary 1.08108866 entropy_value 5.80091 glob_norm 0.518747211\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -0.0484242439 lambd_papr -0.144357905 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.75904 loss -4.7312851 loss_ordinary 1.06605 entropy_value 5.79733467 glob_norm 0.661504269\n",
      "Iteration 50 L -4.74828815 loss -4.75104904 loss_ordinary 1.05282 entropy_value 5.80386877 glob_norm 0.519040048\n",
      "Iteration 100 L -4.63536453 loss -4.70113087 loss_ordinary 1.09303057 entropy_value 5.79416132 glob_norm 0.631451607\n",
      "Iteration 150 L -4.78208876 loss -4.74414825 loss_ordinary 1.05580926 entropy_value 5.79995728 glob_norm 0.857433736\n",
      "Iteration 200 L -4.72316551 loss -4.71808958 loss_ordinary 1.07920551 entropy_value 5.79729509 glob_norm 0.577812314\n",
      "Iteration 250 L -4.90763664 loss -4.73539686 loss_ordinary 1.06709564 entropy_value 5.80249214 glob_norm 0.906930923\n",
      "Iteration 300 L -4.64447069 loss -4.66302156 loss_ordinary 1.13919067 entropy_value 5.80221224 glob_norm 0.595181406\n",
      "Iteration 350 L -4.73139143 loss -4.69691229 loss_ordinary 1.10338938 entropy_value 5.80030203 glob_norm 0.611934125\n",
      "Iteration 400 L -4.72970295 loss -4.72442055 loss_ordinary 1.0758568 entropy_value 5.80027723 glob_norm 0.457419872\n",
      "Iteration 450 L -4.73837709 loss -4.72278357 loss_ordinary 1.07641697 entropy_value 5.79920053 glob_norm 0.581622303\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power 0.0472352505 lambd_papr -0.14384222 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74452543 loss -4.72962046 loss_ordinary 1.06764758 entropy_value 5.79726839 glob_norm 0.472063273\n",
      "Iteration 50 L -4.73890781 loss -4.70630217 loss_ordinary 1.10161662 entropy_value 5.80791855 glob_norm 0.591569483\n",
      "Iteration 100 L -4.77266312 loss -4.73891115 loss_ordinary 1.06766713 entropy_value 5.80657864 glob_norm 0.540702283\n",
      "Iteration 150 L -4.71464 loss -4.73132515 loss_ordinary 1.07263446 entropy_value 5.80396 glob_norm 0.449574858\n",
      "Iteration 200 L -4.73115873 loss -4.7157197 loss_ordinary 1.08540094 entropy_value 5.80112076 glob_norm 0.634293079\n",
      "Iteration 250 L -4.72790813 loss -4.72981167 loss_ordinary 1.06881094 entropy_value 5.79862261 glob_norm 0.594195604\n",
      "Iteration 300 L -4.68183517 loss -4.71732807 loss_ordinary 1.08096576 entropy_value 5.79829407 glob_norm 0.437404871\n",
      "Iteration 350 L -4.67170906 loss -4.68299675 loss_ordinary 1.11639774 entropy_value 5.79939461 glob_norm 0.55990088\n",
      "Iteration 400 L -4.70710611 loss -4.68462038 loss_ordinary 1.11271966 entropy_value 5.79734 glob_norm 0.560629725\n",
      "Iteration 450 L -4.71411037 loss -4.73316717 loss_ordinary 1.06670773 entropy_value 5.79987478 glob_norm 0.674532\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power -0.136696815 lambd_papr -0.144346744 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71044493 loss -4.70684671 loss_ordinary 1.09612095 entropy_value 5.80296755 glob_norm 0.551164389\n",
      "Iteration 50 L -4.81188822 loss -4.72703 loss_ordinary 1.07666636 entropy_value 5.80369616 glob_norm 0.859800279\n",
      "Iteration 100 L -4.73398304 loss -4.70456839 loss_ordinary 1.09558916 entropy_value 5.80015755 glob_norm 0.499715835\n",
      "Iteration 150 L -4.67178 loss -4.70022392 loss_ordinary 1.10334015 entropy_value 5.80356407 glob_norm 0.553596795\n",
      "Iteration 200 L -4.70666456 loss -4.70079327 loss_ordinary 1.09966886 entropy_value 5.80046225 glob_norm 0.586373508\n",
      "Iteration 250 L -4.71058702 loss -4.71376371 loss_ordinary 1.08493805 entropy_value 5.79870176 glob_norm 0.660938084\n",
      "Iteration 300 L -4.80220461 loss -4.74579 loss_ordinary 1.05167627 entropy_value 5.79746628 glob_norm 0.779586136\n",
      "Iteration 350 L -4.67804193 loss -4.68027878 loss_ordinary 1.12182403 entropy_value 5.80210304 glob_norm 0.608606\n",
      "Iteration 400 L -4.69756746 loss -4.69700527 loss_ordinary 1.10666263 entropy_value 5.80366802 glob_norm 0.619143903\n",
      "Iteration 450 L -4.6883688 loss -4.71318436 loss_ordinary 1.08475387 entropy_value 5.79793835 glob_norm 0.593279779\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power -0.0285270214 lambd_papr -0.142882273 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72908068 loss -4.72470808 loss_ordinary 1.07878458 entropy_value 5.80349255 glob_norm 0.632692039\n",
      "Iteration 50 L -4.70534134 loss -4.74393034 loss_ordinary 1.05855513 entropy_value 5.80248547 glob_norm 0.585432053\n",
      "Iteration 100 L -4.72402287 loss -4.73746061 loss_ordinary 1.06022251 entropy_value 5.79768276 glob_norm 0.639154434\n",
      "Iteration 150 L -4.70063162 loss -4.70195675 loss_ordinary 1.09924483 entropy_value 5.80120182 glob_norm 0.532318294\n",
      "Iteration 200 L -4.67394161 loss -4.7222333 loss_ordinary 1.07696843 entropy_value 5.79920197 glob_norm 0.470724761\n",
      "Iteration 250 L -4.72651577 loss -4.73269653 loss_ordinary 1.06999934 entropy_value 5.80269575 glob_norm 0.462654859\n",
      "Iteration 300 L -4.83747578 loss -4.75462341 loss_ordinary 1.04647517 entropy_value 5.80109835 glob_norm 0.563320577\n",
      "Iteration 350 L -4.76428556 loss -4.75934649 loss_ordinary 1.03936195 entropy_value 5.79870892 glob_norm 0.543212473\n",
      "Iteration 400 L -4.67401314 loss -4.67920208 loss_ordinary 1.12977874 entropy_value 5.80898094 glob_norm 0.519923925\n",
      "Iteration 450 L -4.75013876 loss -4.69851208 loss_ordinary 1.10768437 entropy_value 5.80619669 glob_norm 0.68163383\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power -0.254865885 lambd_papr -0.142575741 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.69921875 loss -4.69487095 loss_ordinary 1.11238086 entropy_value 5.80725193 glob_norm 0.849081397\n",
      "Iteration 50 L -4.70266676 loss -4.72202253 loss_ordinary 1.08395934 entropy_value 5.80598164 glob_norm 0.657048\n",
      "Iteration 100 L -4.69756746 loss -4.72229528 loss_ordinary 1.07361591 entropy_value 5.79591179 glob_norm 0.633365452\n",
      "Iteration 150 L -4.72241688 loss -4.7215023 loss_ordinary 1.08407354 entropy_value 5.80557585 glob_norm 0.456000149\n",
      "Iteration 200 L -4.72164297 loss -4.74173498 loss_ordinary 1.05928588 entropy_value 5.80102062 glob_norm 0.504892\n",
      "Iteration 250 L -4.71754313 loss -4.7059803 loss_ordinary 1.09919798 entropy_value 5.80517817 glob_norm 0.54535228\n",
      "Iteration 300 L -4.77335453 loss -4.75127792 loss_ordinary 1.05093932 entropy_value 5.80221701 glob_norm 0.580795765\n",
      "Iteration 350 L -4.70206118 loss -4.69151402 loss_ordinary 1.10747278 entropy_value 5.79898643 glob_norm 0.584588408\n",
      "Iteration 400 L -4.73955917 loss -4.75852394 loss_ordinary 1.04060042 entropy_value 5.79912424 glob_norm 0.510293722\n",
      "Iteration 450 L -4.71155119 loss -4.73180485 loss_ordinary 1.06811011 entropy_value 5.79991484 glob_norm 0.551997721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power -0.457108736 lambd_papr -0.139828891 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74644661 loss -4.70554209 loss_ordinary 1.09566343 entropy_value 5.80120611 glob_norm 0.517212808\n",
      "Iteration 50 L -4.72201633 loss -4.74635363 loss_ordinary 1.05048931 entropy_value 5.79684305 glob_norm 0.520194173\n",
      "Iteration 100 L -4.70695496 loss -4.73925495 loss_ordinary 1.05467737 entropy_value 5.79393244 glob_norm 0.737206936\n",
      "Iteration 150 L -4.71050882 loss -4.72115707 loss_ordinary 1.06787109 entropy_value 5.78902817 glob_norm 0.647244811\n",
      "Iteration 200 L -4.70263195 loss -4.72549438 loss_ordinary 1.07327926 entropy_value 5.79877329 glob_norm 0.662492454\n",
      "Iteration 250 L -4.74414825 loss -4.73255539 loss_ordinary 1.05736971 entropy_value 5.7899251 glob_norm 0.648824811\n",
      "Iteration 300 L -4.74691868 loss -4.75133038 loss_ordinary 1.03605235 entropy_value 5.7873826 glob_norm 0.62093848\n",
      "Iteration 350 L -4.76558638 loss -4.75388956 loss_ordinary 1.03356802 entropy_value 5.78745747 glob_norm 0.496732563\n",
      "Iteration 400 L -4.80103922 loss -4.74913836 loss_ordinary 1.04354012 entropy_value 5.79267836 glob_norm 0.623927832\n",
      "Iteration 450 L -4.71580887 loss -4.74723244 loss_ordinary 1.04799402 entropy_value 5.79522657 glob_norm 0.735444129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power -0.184490442 lambd_papr -0.134887561 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72042942 loss -4.73252106 loss_ordinary 1.05802298 entropy_value 5.79054356 glob_norm 0.557709336\n",
      "Iteration 50 L -4.7107954 loss -4.7371726 loss_ordinary 1.05463755 entropy_value 5.79181 glob_norm 0.386433154\n",
      "Iteration 100 L -4.69028378 loss -4.71373558 loss_ordinary 1.07293355 entropy_value 5.78666925 glob_norm 0.603771329\n",
      "Iteration 150 L -4.68307352 loss -4.71216822 loss_ordinary 1.08219028 entropy_value 5.79435873 glob_norm 0.434452146\n",
      "Iteration 200 L -4.76486588 loss -4.7502203 loss_ordinary 1.04224 entropy_value 5.79246044 glob_norm 0.691852093\n",
      "Iteration 250 L -4.80559826 loss -4.7679944 loss_ordinary 1.02703536 entropy_value 5.79502964 glob_norm 0.559848905\n",
      "Iteration 300 L -4.69536638 loss -4.73968029 loss_ordinary 1.05181634 entropy_value 5.79149628 glob_norm 0.766155124\n",
      "Iteration 350 L -4.73665619 loss -4.75991154 loss_ordinary 1.03698671 entropy_value 5.79689789 glob_norm 0.439226896\n",
      "Iteration 400 L -4.707551 loss -4.72719431 loss_ordinary 1.06245017 entropy_value 5.78964472 glob_norm 0.539192855\n",
      "Iteration 450 L -4.68495083 loss -4.7458992 loss_ordinary 1.04382122 entropy_value 5.78972 glob_norm 0.57153\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0.0744667053 lambd_papr -0.132887244 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.77017641 loss -4.7417407 loss_ordinary 1.04450941 entropy_value 5.78625 glob_norm 0.643183589\n",
      "Iteration 50 L -4.76265812 loss -4.78046036 loss_ordinary 1.00220573 entropy_value 5.78266621 glob_norm 0.428269416\n",
      "Iteration 100 L -4.75691891 loss -4.79255676 loss_ordinary 0.998978734 entropy_value 5.79153585 glob_norm 0.628488362\n",
      "Iteration 150 L -4.77382851 loss -4.73043823 loss_ordinary 1.04757762 entropy_value 5.77801561 glob_norm 0.914453328\n",
      "Iteration 200 L -4.63749075 loss -4.71494579 loss_ordinary 1.06643927 entropy_value 5.78138542 glob_norm 0.621519148\n",
      "Iteration 250 L -4.69455 loss -4.75450659 loss_ordinary 1.02542877 entropy_value 5.77993488 glob_norm 0.553506315\n",
      "Iteration 300 L -4.74739504 loss -4.7383914 loss_ordinary 1.04842174 entropy_value 5.78681278 glob_norm 0.588935852\n",
      "Iteration 350 L -4.69740534 loss -4.7219758 loss_ordinary 1.06637394 entropy_value 5.78834963 glob_norm 0.636952817\n",
      "Iteration 400 L -4.71638346 loss -4.73581743 loss_ordinary 1.04732621 entropy_value 5.78314352 glob_norm 0.475138038\n",
      "Iteration 450 L -4.72304535 loss -4.75960112 loss_ordinary 1.0291332 entropy_value 5.78873444 glob_norm 0.505684614\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0.0926392078 lambd_papr -0.133697063 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71521473 loss -4.73467684 loss_ordinary 1.05371773 entropy_value 5.78839445 glob_norm 0.530347109\n",
      "Iteration 50 L -4.73620176 loss -4.72496319 loss_ordinary 1.05888617 entropy_value 5.78384924 glob_norm 0.575459242\n",
      "Iteration 100 L -4.67348862 loss -4.73946857 loss_ordinary 1.04636955 entropy_value 5.78583813 glob_norm 0.587971\n",
      "Iteration 150 L -4.68793774 loss -4.76621675 loss_ordinary 1.01894939 entropy_value 5.78516626 glob_norm 0.511060536\n",
      "Iteration 200 L -4.72082233 loss -4.73574638 loss_ordinary 1.05376768 entropy_value 5.78951359 glob_norm 0.582718074\n",
      "Iteration 250 L -4.77004766 loss -4.7640729 loss_ordinary 1.02215064 entropy_value 5.78622341 glob_norm 0.635694444\n",
      "Iteration 300 L -4.71379423 loss -4.72812271 loss_ordinary 1.06293452 entropy_value 5.79105759 glob_norm 0.741845548\n",
      "Iteration 350 L -4.74363899 loss -4.75690889 loss_ordinary 1.03609824 entropy_value 5.7930069 glob_norm 0.472645879\n",
      "Iteration 400 L -4.67113256 loss -4.7494874 loss_ordinary 1.03616548 entropy_value 5.78565311 glob_norm 0.438959301\n",
      "Iteration 450 L -4.7522254 loss -4.76190376 loss_ordinary 1.02646387 entropy_value 5.78836775 glob_norm 0.507739902\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.19550252 lambd_papr -0.134707525 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.70766544 loss -4.74299717 loss_ordinary 1.0482254 entropy_value 5.79122257 glob_norm 0.577654481\n",
      "Iteration 50 L -4.66609573 loss -4.71687508 loss_ordinary 1.07920849 entropy_value 5.79608345 glob_norm 0.439964116\n",
      "Iteration 100 L -4.76480389 loss -4.74509478 loss_ordinary 1.04897153 entropy_value 5.79406643 glob_norm 0.454927176\n",
      "Iteration 150 L -4.7423892 loss -4.76472282 loss_ordinary 1.03041673 entropy_value 5.79514 glob_norm 0.478522331\n",
      "Iteration 200 L -4.74544859 loss -4.73884773 loss_ordinary 1.04935408 entropy_value 5.78820181 glob_norm 0.645980895\n",
      "Iteration 250 L -4.69200182 loss -4.73219919 loss_ordinary 1.05719638 entropy_value 5.78939533 glob_norm 0.522155702\n",
      "Iteration 300 L -4.713449 loss -4.73729372 loss_ordinary 1.05192924 entropy_value 5.78922272 glob_norm 0.558626175\n",
      "Iteration 350 L -4.74970627 loss -4.75967503 loss_ordinary 1.03162897 entropy_value 5.79130363 glob_norm 0.723859251\n",
      "Iteration 400 L -4.64164162 loss -4.72709894 loss_ordinary 1.0637157 entropy_value 5.79081488 glob_norm 0.671028\n",
      "Iteration 450 L -4.74282122 loss -4.752244 loss_ordinary 1.03432965 entropy_value 5.78657341 glob_norm 0.452177048\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0.00923800468 lambd_papr -0.136846378 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.68023634 loss -4.69578314 loss_ordinary 1.0898453 entropy_value 5.78562832 glob_norm 0.743730724\n",
      "Iteration 50 L -4.6818 loss -4.74288225 loss_ordinary 1.04504085 entropy_value 5.78792334 glob_norm 0.645646513\n",
      "Iteration 100 L -4.68531322 loss -4.75747776 loss_ordinary 1.0355159 entropy_value 5.79299355 glob_norm 0.565759659\n",
      "Iteration 150 L -4.69938421 loss -4.72384167 loss_ordinary 1.06684589 entropy_value 5.79068756 glob_norm 0.508478\n",
      "Iteration 200 L -4.69184542 loss -4.7598033 loss_ordinary 1.03128242 entropy_value 5.79108572 glob_norm 0.506269038\n",
      "Iteration 250 L -4.71478033 loss -4.74396229 loss_ordinary 1.04682386 entropy_value 5.79078627 glob_norm 0.591646552\n",
      "Iteration 300 L -4.71200132 loss -4.74083519 loss_ordinary 1.05202 entropy_value 5.79285526 glob_norm 0.532484651\n",
      "Iteration 350 L -4.72761202 loss -4.75589323 loss_ordinary 1.03244555 entropy_value 5.78833866 glob_norm 0.728017509\n",
      "Iteration 400 L -4.69539547 loss -4.72998953 loss_ordinary 1.06257987 entropy_value 5.79256964 glob_norm 0.576464355\n",
      "Iteration 450 L -4.74076 loss -4.73582029 loss_ordinary 1.06575811 entropy_value 5.80157804 glob_norm 0.568813\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power -0.274688482 lambd_papr -0.136947751 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71546316 loss -4.69732094 loss_ordinary 1.09594083 entropy_value 5.79326153 glob_norm 0.553940177\n",
      "Iteration 50 L -4.74656916 loss -4.7725668 loss_ordinary 1.01496315 entropy_value 5.78753 glob_norm 0.586889505\n",
      "Iteration 100 L -4.7555 loss -4.77701569 loss_ordinary 1.01789284 entropy_value 5.79490852 glob_norm 0.496342391\n",
      "Iteration 150 L -4.72885132 loss -4.74468422 loss_ordinary 1.04232824 entropy_value 5.78701258 glob_norm 0.464390457\n",
      "Iteration 200 L -4.72416925 loss -4.74069357 loss_ordinary 1.04851151 entropy_value 5.78920507 glob_norm 0.533310354\n",
      "Iteration 250 L -4.75101566 loss -4.74766636 loss_ordinary 1.04626191 entropy_value 5.79392815 glob_norm 0.536744952\n",
      "Iteration 300 L -4.67718 loss -4.72093153 loss_ordinary 1.07109177 entropy_value 5.79202318 glob_norm 0.562940478\n",
      "Iteration 350 L -4.77005816 loss -4.74314737 loss_ordinary 1.04995215 entropy_value 5.7930994 glob_norm 0.628401\n",
      "Iteration 400 L -4.73153353 loss -4.73998451 loss_ordinary 1.05007815 entropy_value 5.7900629 glob_norm 0.559384644\n",
      "Iteration 450 L -4.75640726 loss -4.77095938 loss_ordinary 1.01813078 entropy_value 5.78909 glob_norm 0.57978934\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.276334763 lambd_papr -0.133924529 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71583796 loss -4.72763634 loss_ordinary 1.0637486 entropy_value 5.79138517 glob_norm 0.718794048\n",
      "Iteration 50 L -4.77787971 loss -4.76732731 loss_ordinary 1.02370143 entropy_value 5.7910285 glob_norm 0.605828881\n",
      "Iteration 100 L -4.71416378 loss -4.75975 loss_ordinary 1.03054976 entropy_value 5.79029942 glob_norm 0.503595829\n",
      "Iteration 150 L -4.72269 loss -4.7086482 loss_ordinary 1.08286345 entropy_value 5.79151154 glob_norm 0.766166508\n",
      "Iteration 200 L -4.75129843 loss -4.76955223 loss_ordinary 1.02114093 entropy_value 5.79069281 glob_norm 0.594090044\n",
      "Iteration 250 L -4.80348635 loss -4.75746727 loss_ordinary 1.03225148 entropy_value 5.78971863 glob_norm 0.66463846\n",
      "Iteration 300 L -4.75688505 loss -4.74118423 loss_ordinary 1.05330062 entropy_value 5.79448462 glob_norm 0.686499\n",
      "Iteration 350 L -4.7241354 loss -4.74730873 loss_ordinary 1.04466951 entropy_value 5.79197788 glob_norm 0.800707459\n",
      "Iteration 400 L -4.68534136 loss -4.71334314 loss_ordinary 1.08063269 entropy_value 5.79397583 glob_norm 0.661313057\n",
      "Iteration 450 L -4.74627 loss -4.73870373 loss_ordinary 1.05708098 entropy_value 5.79578495 glob_norm 0.439386547\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0.241982937 lambd_papr -0.13697499 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.69314241 loss -4.71070862 loss_ordinary 1.08142006 entropy_value 5.79212856 glob_norm 0.791098118\n",
      "Iteration 50 L -4.70213032 loss -4.7346158 loss_ordinary 1.06091607 entropy_value 5.79553175 glob_norm 0.440844655\n",
      "Iteration 100 L -4.70395184 loss -4.72598219 loss_ordinary 1.07335305 entropy_value 5.79933548 glob_norm 0.644271195\n",
      "Iteration 150 L -4.72101498 loss -4.72825146 loss_ordinary 1.06758165 entropy_value 5.79583311 glob_norm 0.691769\n",
      "Iteration 200 L -4.76471138 loss -4.76526403 loss_ordinary 1.03288972 entropy_value 5.79815435 glob_norm 0.407150447\n",
      "Iteration 250 L -4.72674131 loss -4.70641518 loss_ordinary 1.08967161 entropy_value 5.79608679 glob_norm 0.873445153\n",
      "Iteration 300 L -4.72836781 loss -4.69257259 loss_ordinary 1.10407853 entropy_value 5.79665089 glob_norm 0.682598829\n",
      "Iteration 350 L -4.75764036 loss -4.70558548 loss_ordinary 1.09095073 entropy_value 5.79653645 glob_norm 0.584769607\n",
      "Iteration 400 L -4.64841 loss -4.67320395 loss_ordinary 1.1320852 entropy_value 5.80528927 glob_norm 0.570644\n",
      "Iteration 450 L -4.74605 loss -4.73688078 loss_ordinary 1.07193899 entropy_value 5.80882 glob_norm 0.466850072\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power -0.350928068 lambd_papr -0.139654264 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.84567833 loss -4.74917793 loss_ordinary 1.05874705 entropy_value 5.80792475 glob_norm 0.886642933\n",
      "Iteration 50 L -4.71906281 loss -4.71012497 loss_ordinary 1.09499526 entropy_value 5.80512 glob_norm 0.762568951\n",
      "Iteration 100 L -4.82282543 loss -4.72789431 loss_ordinary 1.06936347 entropy_value 5.7972579 glob_norm 0.721421957\n",
      "Iteration 150 L -4.73708153 loss -4.72858667 loss_ordinary 1.07143474 entropy_value 5.80002117 glob_norm 0.673034668\n",
      "Iteration 200 L -4.69042873 loss -4.68139744 loss_ordinary 1.12105143 entropy_value 5.80244875 glob_norm 0.5398736\n",
      "Iteration 250 L -4.66687059 loss -4.69002819 loss_ordinary 1.10911179 entropy_value 5.79914 glob_norm 0.52036947\n",
      "Iteration 300 L -4.71229315 loss -4.69748878 loss_ordinary 1.1013397 entropy_value 5.7988286 glob_norm 0.596345067\n",
      "Iteration 350 L -4.74577951 loss -4.7432313 loss_ordinary 1.05453515 entropy_value 5.79776621 glob_norm 0.547044754\n",
      "Iteration 400 L -4.72507906 loss -4.72185326 loss_ordinary 1.08122945 entropy_value 5.80308247 glob_norm 0.436343044\n",
      "Iteration 450 L -4.64671707 loss -4.66475105 loss_ordinary 1.13939774 entropy_value 5.80414867 glob_norm 0.59535867\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power -0.0747067928 lambd_papr -0.135757074 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.76241302 loss -4.72029209 loss_ordinary 1.07547212 entropy_value 5.79576445 glob_norm 0.531295836\n",
      "Iteration 50 L -4.78286219 loss -4.73278618 loss_ordinary 1.06970727 entropy_value 5.80249357 glob_norm 0.594065\n",
      "Iteration 100 L -4.80317545 loss -4.75772 loss_ordinary 1.03985965 entropy_value 5.79758 glob_norm 0.562463939\n",
      "Iteration 150 L -4.71767473 loss -4.72178316 loss_ordinary 1.07410133 entropy_value 5.79588413 glob_norm 0.510355711\n",
      "Iteration 200 L -4.7509675 loss -4.72256327 loss_ordinary 1.07543159 entropy_value 5.79799461 glob_norm 0.573775\n",
      "Iteration 250 L -4.70060873 loss -4.73470926 loss_ordinary 1.05952561 entropy_value 5.79423523 glob_norm 0.623772621\n",
      "Iteration 300 L -4.67348385 loss -4.72509336 loss_ordinary 1.07452774 entropy_value 5.79962111 glob_norm 0.645173132\n",
      "Iteration 350 L -4.79066849 loss -4.75747 loss_ordinary 1.03413224 entropy_value 5.79160213 glob_norm 1.02405643\n",
      "Iteration 400 L -4.8420105 loss -4.74198103 loss_ordinary 1.05628657 entropy_value 5.79826784 glob_norm 0.916856468\n",
      "Iteration 450 L -4.7628808 loss -4.72172 loss_ordinary 1.07006061 entropy_value 5.79178047 glob_norm 0.604993224\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power -0.0648241043 lambd_papr -0.134924933 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67698717 loss -4.71654415 loss_ordinary 1.07688749 entropy_value 5.79343176 glob_norm 0.581377208\n",
      "Iteration 50 L -4.70989847 loss -4.76459551 loss_ordinary 1.0289042 entropy_value 5.79349947 glob_norm 0.622134805\n",
      "Iteration 100 L -4.71709824 loss -4.73346663 loss_ordinary 1.05990291 entropy_value 5.79337 glob_norm 0.636516273\n",
      "Iteration 150 L -4.7400074 loss -4.73481655 loss_ordinary 1.06668365 entropy_value 5.80150032 glob_norm 0.51501894\n",
      "Iteration 200 L -4.68676 loss -4.71324348 loss_ordinary 1.07642603 entropy_value 5.78966951 glob_norm 0.499663144\n",
      "Iteration 250 L -4.69337797 loss -4.70768881 loss_ordinary 1.08478022 entropy_value 5.79246902 glob_norm 0.5383811\n",
      "Iteration 300 L -4.74032164 loss -4.74317598 loss_ordinary 1.0506506 entropy_value 5.79382658 glob_norm 0.721170068\n",
      "Iteration 350 L -4.72051239 loss -4.73067427 loss_ordinary 1.0653168 entropy_value 5.79599142 glob_norm 0.607231259\n",
      "Iteration 400 L -4.70716524 loss -4.72483444 loss_ordinary 1.06806815 entropy_value 5.79290247 glob_norm 0.449867725\n",
      "Iteration 450 L -4.6989646 loss -4.73214674 loss_ordinary 1.06281662 entropy_value 5.79496384 glob_norm 0.510542274\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power -0.161155939 lambd_papr -0.134200707 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.71905375 loss -4.72149515 loss_ordinary 1.0684948 entropy_value 5.78999 glob_norm 0.609863102\n",
      "Iteration 50 L -4.73406172 loss -4.73520374 loss_ordinary 1.05893242 entropy_value 5.79413605 glob_norm 0.651745617\n",
      "Iteration 100 L -4.7079587 loss -4.71474123 loss_ordinary 1.07597089 entropy_value 5.79071236 glob_norm 0.520255387\n",
      "Iteration 150 L -4.68865 loss -4.72839451 loss_ordinary 1.06309807 entropy_value 5.79149246 glob_norm 0.556347728\n",
      "Iteration 200 L -4.69492388 loss -4.72829819 loss_ordinary 1.06298292 entropy_value 5.79128122 glob_norm 0.547521472\n",
      "Iteration 250 L -4.72532034 loss -4.76007128 loss_ordinary 1.03162301 entropy_value 5.79169464 glob_norm 0.571516097\n",
      "Iteration 300 L -4.67922354 loss -4.72835493 loss_ordinary 1.05788291 entropy_value 5.78623772 glob_norm 0.507204413\n",
      "Iteration 350 L -4.70942307 loss -4.725317 loss_ordinary 1.06974411 entropy_value 5.79506111 glob_norm 0.562690675\n",
      "Iteration 400 L -4.73216677 loss -4.77036142 loss_ordinary 1.01843834 entropy_value 5.7888 glob_norm 0.557866514\n",
      "Iteration 450 L -4.67715263 loss -4.72696161 loss_ordinary 1.06835008 entropy_value 5.79531193 glob_norm 0.546353161\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.222457886 lambd_papr -0.13239485 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67481089 loss -4.72654343 loss_ordinary 1.06566179 entropy_value 5.79220486 glob_norm 0.730976701\n",
      "Iteration 50 L -4.70323515 loss -4.71746349 loss_ordinary 1.07232296 entropy_value 5.78978634 glob_norm 0.560482323\n",
      "Iteration 100 L -4.72315264 loss -4.73591042 loss_ordinary 1.051512 entropy_value 5.78742266 glob_norm 0.623131931\n",
      "Iteration 150 L -4.68216419 loss -4.71982431 loss_ordinary 1.06745923 entropy_value 5.78728342 glob_norm 0.601677358\n",
      "Iteration 200 L -4.69568443 loss -4.75400114 loss_ordinary 1.03358364 entropy_value 5.78758478 glob_norm 0.573642194\n",
      "Iteration 250 L -4.70578098 loss -4.74746609 loss_ordinary 1.03649044 entropy_value 5.78395653 glob_norm 0.48360765\n",
      "Iteration 300 L -4.76805782 loss -4.76821089 loss_ordinary 1.01508033 entropy_value 5.78329086 glob_norm 0.476755\n",
      "Iteration 350 L -4.70334625 loss -4.75183249 loss_ordinary 1.03482425 entropy_value 5.78665686 glob_norm 0.454676926\n",
      "Iteration 400 L -4.74349165 loss -4.75242662 loss_ordinary 1.03551257 entropy_value 5.78793907 glob_norm 0.46832487\n",
      "Iteration 450 L -4.76508141 loss -4.78280592 loss_ordinary 1.00162303 entropy_value 5.7844286 glob_norm 0.467271566\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power -0.107530832 lambd_papr -0.129894599 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.75460529 loss -4.78148556 loss_ordinary 1.00081956 entropy_value 5.78230476 glob_norm 0.380090058\n",
      "Iteration 50 L -4.71372843 loss -4.74657249 loss_ordinary 1.038661 entropy_value 5.7852335 glob_norm 0.638097346\n",
      "Iteration 100 L -4.71083975 loss -4.75677061 loss_ordinary 1.0276202 entropy_value 5.78439093 glob_norm 0.413239419\n",
      "Iteration 150 L -4.78228521 loss -4.75777483 loss_ordinary 1.02776301 entropy_value 5.78553772 glob_norm 0.801642537\n",
      "Iteration 200 L -4.70203924 loss -4.76542616 loss_ordinary 1.01781881 entropy_value 5.78324461 glob_norm 0.535736263\n",
      "Iteration 250 L -4.72192574 loss -4.74892855 loss_ordinary 1.03852224 entropy_value 5.78745079 glob_norm 0.473890215\n",
      "Iteration 300 L -4.74667358 loss -4.78133154 loss_ordinary 1.00004661 entropy_value 5.78137827 glob_norm 0.457352221\n",
      "Iteration 350 L -4.7017293 loss -4.74086666 loss_ordinary 1.04245162 entropy_value 5.78331852 glob_norm 0.47883448\n",
      "Iteration 400 L -4.74316502 loss -4.73634 loss_ordinary 1.0493784 entropy_value 5.78571844 glob_norm 0.766333103\n",
      "Iteration 450 L -4.7309866 loss -4.76462364 loss_ordinary 1.01682901 entropy_value 5.78145266 glob_norm 0.486599445\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0.10525012 lambd_papr -0.128682405 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72128296 loss -4.76182175 loss_ordinary 1.03057337 entropy_value 5.79239464 glob_norm 0.567393601\n",
      "Iteration 50 L -4.69648409 loss -4.7412262 loss_ordinary 1.04046023 entropy_value 5.78168631 glob_norm 0.532010794\n",
      "Iteration 100 L -4.72295189 loss -4.72949266 loss_ordinary 1.0542239 entropy_value 5.78371668 glob_norm 0.582630277\n",
      "Iteration 150 L -4.74106121 loss -4.7461772 loss_ordinary 1.03885245 entropy_value 5.78503 glob_norm 0.566337764\n",
      "Iteration 200 L -4.72984076 loss -4.73678827 loss_ordinary 1.04481292 entropy_value 5.78160143 glob_norm 0.494106\n",
      "Iteration 250 L -4.71024275 loss -4.74469137 loss_ordinary 1.03562689 entropy_value 5.78031826 glob_norm 0.574138284\n",
      "Iteration 300 L -4.68394136 loss -4.74908543 loss_ordinary 1.03316927 entropy_value 5.7822547 glob_norm 0.607933581\n",
      "Iteration 350 L -4.72566509 loss -4.75468349 loss_ordinary 1.02825022 entropy_value 5.78293371 glob_norm 0.661743522\n",
      "Iteration 400 L -4.7373414 loss -4.74135399 loss_ordinary 1.03923416 entropy_value 5.78058815 glob_norm 0.682643056\n",
      "Iteration 450 L -4.78142595 loss -4.77252197 loss_ordinary 1.0146414 entropy_value 5.78716326 glob_norm 0.648453474\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0.0775918961 lambd_papr -0.129872441 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.77107 loss -4.76996708 loss_ordinary 1.01836324 entropy_value 5.78833055 glob_norm 0.705931962\n",
      "Iteration 50 L -4.71325302 loss -4.77467585 loss_ordinary 1.00960147 entropy_value 5.78427744 glob_norm 0.487270802\n",
      "Iteration 100 L -4.7568903 loss -4.77838659 loss_ordinary 1.00725818 entropy_value 5.78564501 glob_norm 0.461740851\n",
      "Iteration 150 L -4.75701523 loss -4.75572062 loss_ordinary 1.02470958 entropy_value 5.78043032 glob_norm 0.555190206\n",
      "Iteration 200 L -4.70953274 loss -4.73083067 loss_ordinary 1.05016923 entropy_value 5.781 glob_norm 0.518847048\n",
      "Iteration 250 L -4.7218461 loss -4.73458195 loss_ordinary 1.04706669 entropy_value 5.78164864 glob_norm 0.709522605\n",
      "Iteration 300 L -4.69161701 loss -4.74387836 loss_ordinary 1.03802848 entropy_value 5.7819066 glob_norm 0.413839221\n",
      "Iteration 350 L -4.75654697 loss -4.72062111 loss_ordinary 1.07315028 entropy_value 5.79377127 glob_norm 0.601382613\n",
      "Iteration 400 L -4.74801636 loss -4.72007513 loss_ordinary 1.06325138 entropy_value 5.78332663 glob_norm 0.602475643\n",
      "Iteration 450 L -4.69749 loss -4.75167 loss_ordinary 1.02898395 entropy_value 5.78065395 glob_norm 0.57826215\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power 0.0778579712 lambd_papr -0.130752385 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.72477055 loss -4.74454594 loss_ordinary 1.03371978 entropy_value 5.77826548 glob_norm 0.56358695\n",
      "Iteration 50 L -4.69255829 loss -4.71987343 loss_ordinary 1.06518435 entropy_value 5.78505754 glob_norm 0.482863665\n",
      "Iteration 100 L -4.77696 loss -4.74508572 loss_ordinary 1.04355145 entropy_value 5.78863716 glob_norm 0.53980732\n",
      "Iteration 150 L -4.6898489 loss -4.72377443 loss_ordinary 1.06596482 entropy_value 5.78973961 glob_norm 0.529677093\n",
      "Iteration 200 L -4.71122169 loss -4.75074148 loss_ordinary 1.03114307 entropy_value 5.78188467 glob_norm 0.600195706\n",
      "Iteration 250 L -4.70385599 loss -4.74666643 loss_ordinary 1.039361 entropy_value 5.78602743 glob_norm 0.433246076\n",
      "Iteration 300 L -4.71076965 loss -4.73636723 loss_ordinary 1.0491389 entropy_value 5.78550577 glob_norm 0.43446517\n",
      "Iteration 350 L -4.70893049 loss -4.75508404 loss_ordinary 1.03258669 entropy_value 5.78767061 glob_norm 0.448216528\n",
      "Iteration 400 L -4.68684149 loss -4.73834848 loss_ordinary 1.0543437 entropy_value 5.79269218 glob_norm 0.469213\n",
      "Iteration 450 L -4.70764923 loss -4.73157406 loss_ordinary 1.05791056 entropy_value 5.78948498 glob_norm 0.462016821\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.342511177 lambd_papr -0.13163799 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.67848635 loss -4.71347952 loss_ordinary 1.07700014 entropy_value 5.79047966 glob_norm 0.548947692\n",
      "Iteration 50 L -4.67891026 loss -4.71579266 loss_ordinary 1.07305515 entropy_value 5.78884792 glob_norm 0.478337318\n",
      "Iteration 100 L -4.74464 loss -4.76342678 loss_ordinary 1.02326834 entropy_value 5.78669548 glob_norm 0.470158607\n",
      "Iteration 150 L -4.72589827 loss -4.72452974 loss_ordinary 1.0676918 entropy_value 5.79222155 glob_norm 0.452305526\n",
      "Iteration 200 L -4.78802156 loss -4.74306583 loss_ordinary 1.04704988 entropy_value 5.79011583 glob_norm 0.595864892\n",
      "Iteration 250 L -4.75284958 loss -4.71894884 loss_ordinary 1.07571042 entropy_value 5.79465961 glob_norm 0.736410677\n",
      "Iteration 300 L -4.72666359 loss -4.74904823 loss_ordinary 1.04153728 entropy_value 5.79058552 glob_norm 0.536336482\n",
      "Iteration 350 L -4.69598818 loss -4.7094388 loss_ordinary 1.08590448 entropy_value 5.7953434 glob_norm 0.537834227\n",
      "Iteration 400 L -4.75789452 loss -4.77769804 loss_ordinary 1.01429152 entropy_value 5.79199 glob_norm 0.435082346\n",
      "Iteration 450 L -4.79107475 loss -4.75438881 loss_ordinary 1.03739941 entropy_value 5.7917881 glob_norm 0.546643138\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power 0.130149126 lambd_papr -0.135545641 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.74483252 loss -4.75983572 loss_ordinary 1.03736413 entropy_value 5.7972 glob_norm 0.4391734\n",
      "Iteration 50 L -4.75127697 loss -4.78520584 loss_ordinary 1.00356162 entropy_value 5.78876734 glob_norm 0.81652391\n",
      "Iteration 100 L -4.81115341 loss -4.77563 loss_ordinary 1.0167799 entropy_value 5.79241 glob_norm 0.690374672\n",
      "Iteration 150 L -4.72141743 loss -4.71337128 loss_ordinary 1.08079994 entropy_value 5.79417133 glob_norm 0.592859089\n",
      "Iteration 200 L -4.7473712 loss -4.72610331 loss_ordinary 1.0699259 entropy_value 5.79602909 glob_norm 0.672662377\n",
      "Iteration 250 L -4.73938036 loss -4.73941231 loss_ordinary 1.05749345 entropy_value 5.79690552 glob_norm 0.509714365\n",
      "Iteration 300 L -4.7831049 loss -4.74328089 loss_ordinary 1.05350447 entropy_value 5.79678535 glob_norm 0.642269969\n",
      "Iteration 350 L -4.69529295 loss -4.72035408 loss_ordinary 1.07535541 entropy_value 5.79570913 glob_norm 0.489198655\n",
      "Iteration 400 L -4.76562643 loss -4.71845245 loss_ordinary 1.08119535 entropy_value 5.79964781 glob_norm 0.522512734\n",
      "Iteration 450 L -4.69608831 loss -4.69184923 loss_ordinary 1.10776031 entropy_value 5.79960918 glob_norm 0.624948\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power -0.037555933 lambd_papr -0.137034953 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.73218489 loss -4.73036098 loss_ordinary 1.06931746 entropy_value 5.7996788 glob_norm 0.399520874\n",
      "Iteration 50 L -4.73914766 loss -4.70918 loss_ordinary 1.092049 entropy_value 5.80122948 glob_norm 0.706633508\n",
      "Iteration 100 L -4.78331661 loss -4.71767139 loss_ordinary 1.0841043 entropy_value 5.80177546 glob_norm 0.614659429\n",
      "Iteration 150 L -4.80452299 loss -4.73141479 loss_ordinary 1.06807089 entropy_value 5.79948521 glob_norm 0.567361712\n",
      "Iteration 200 L -4.72525024 loss -4.74288368 loss_ordinary 1.0556612 entropy_value 5.79854488 glob_norm 0.575320482\n",
      "Iteration 250 L -4.71240044 loss -4.7259922 loss_ordinary 1.07975519 entropy_value 5.80574751 glob_norm 0.619435668\n",
      "Iteration 300 L -4.69482 loss -4.69794416 loss_ordinary 1.1019038 entropy_value 5.79984808 glob_norm 0.433452606\n",
      "Iteration 350 L -4.66448879 loss -4.71115303 loss_ordinary 1.08980465 entropy_value 5.80095768 glob_norm 0.682204068\n",
      "Iteration 400 L -4.68720436 loss -4.70778131 loss_ordinary 1.09101427 entropy_value 5.79879522 glob_norm 0.635365844\n",
      "Iteration 450 L -4.72757912 loss -4.70855474 loss_ordinary 1.09548748 entropy_value 5.80404234 glob_norm 0.552162588\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.0312526226 lambd_papr -0.136603907 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.73522186 loss -4.7378931 loss_ordinary 1.06063485 entropy_value 5.79852772 glob_norm 0.5387609\n",
      "Iteration 50 L -4.74229383 loss -4.70970774 loss_ordinary 1.08413756 entropy_value 5.79384518 glob_norm 0.451635212\n",
      "Iteration 100 L -4.73849773 loss -4.71125555 loss_ordinary 1.08634377 entropy_value 5.79759884 glob_norm 0.580227911\n",
      "Iteration 150 L -4.69110441 loss -4.71933556 loss_ordinary 1.0818944 entropy_value 5.80123 glob_norm 0.552284479\n",
      "Iteration 200 L -4.79806423 loss -4.77071428 loss_ordinary 1.02628708 entropy_value 5.79700136 glob_norm 0.501632\n",
      "Iteration 250 L -4.74713707 loss -4.71910572 loss_ordinary 1.0809195 entropy_value 5.80002546 glob_norm 0.611409724\n",
      "Iteration 300 L -4.67909384 loss -4.72147036 loss_ordinary 1.07456374 entropy_value 5.79603386 glob_norm 0.438640147\n",
      "Iteration 350 L -4.76599836 loss -4.75793505 loss_ordinary 1.0380702 entropy_value 5.79600525 glob_norm 0.686719596\n",
      "Iteration 400 L -4.74083805 loss -4.72545671 loss_ordinary 1.07262909 entropy_value 5.79808521 glob_norm 0.675378859\n",
      "Iteration 450 L -4.69974566 loss -4.70641 loss_ordinary 1.09017158 entropy_value 5.79658175 glob_norm 0.429750323\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power -0.258398533 lambd_papr -0.13696368 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.75786638 loss -4.71633291 loss_ordinary 1.0857383 entropy_value 5.80207109 glob_norm 0.559507191\n",
      "Iteration 50 L -4.73961163 loss -4.72207069 loss_ordinary 1.07845747 entropy_value 5.80052805 glob_norm 0.748172343\n",
      "Iteration 100 L -4.75156116 loss -4.75012207 loss_ordinary 1.04679453 entropy_value 5.79691648 glob_norm 0.420909852\n",
      "Iteration 150 L -4.70608616 loss -4.7121129 loss_ordinary 1.08576047 entropy_value 5.7978735 glob_norm 0.489596367\n",
      "Iteration 200 L -4.69261456 loss -4.69924212 loss_ordinary 1.09461677 entropy_value 5.793859 glob_norm 0.655985236\n",
      "Iteration 250 L -4.66886711 loss -4.7112155 loss_ordinary 1.08115029 entropy_value 5.79236603 glob_norm 0.540967762\n",
      "Iteration 300 L -4.70943546 loss -4.73009729 loss_ordinary 1.06743491 entropy_value 5.79753256 glob_norm 0.513870478\n",
      "Iteration 350 L -4.7058444 loss -4.70621252 loss_ordinary 1.09000707 entropy_value 5.79622 glob_norm 0.821255863\n",
      "Iteration 400 L -4.69733572 loss -4.73405886 loss_ordinary 1.05841565 entropy_value 5.79247475 glob_norm 0.50604558\n",
      "Iteration 450 L -4.6470542 loss -4.70557547 loss_ordinary 1.08136308 entropy_value 5.78693819 glob_norm 0.583572924\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.13765645 lambd_papr -0.13398011 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_15_papr_6.0\n",
      "\n",
      "===== Running SNR=15 dB | PAPR=7.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0220825728 loss 0.0220825728 loss_ordinary 6.01326609 entropy_value 5.99118328 glob_norm 0.642090321\n",
      "Iteration 50 L -3.14933205 loss -3.14933205 loss_ordinary 2.82094288 entropy_value 5.97027493 glob_norm 0.379324287\n",
      "Iteration 100 L -4.02868128 loss -4.02868128 loss_ordinary 1.92806292 entropy_value 5.95674419 glob_norm 0.389825374\n",
      "Iteration 150 L -4.36317778 loss -4.36346769 loss_ordinary 1.52831113 entropy_value 5.89177895 glob_norm 0.594411731\n",
      "Iteration 200 L -4.63161039 loss -4.63457775 loss_ordinary 1.13827312 entropy_value 5.77285099 glob_norm 0.562835217\n",
      "Iteration 250 L -4.76747274 loss -4.77237415 loss_ordinary 0.928778708 entropy_value 5.7011528 glob_norm 0.614387333\n",
      "Iteration 300 L -4.81154633 loss -4.81516075 loss_ordinary 0.86875236 entropy_value 5.68391323 glob_norm 0.50719595\n",
      "Iteration 350 L -4.84190607 loss -4.84517145 loss_ordinary 0.829234481 entropy_value 5.67440605 glob_norm 0.400045812\n",
      "Iteration 400 L -4.85106707 loss -4.85400867 loss_ordinary 0.812711656 entropy_value 5.66672039 glob_norm 0.468102157\n",
      "Iteration 450 L -4.8685379 loss -4.87069 loss_ordinary 0.784439087 entropy_value 5.65512896 glob_norm 0.415048629\n",
      "Iteration 500 L -4.86249399 loss -4.86457157 loss_ordinary 0.781826854 entropy_value 5.64639854 glob_norm 0.304307371\n",
      "Iteration 550 L -4.87081909 loss -4.87450552 loss_ordinary 0.778272212 entropy_value 5.65277815 glob_norm 0.400848478\n",
      "Iteration 600 L -4.84829903 loss -4.85315847 loss_ordinary 0.793778837 entropy_value 5.64693689 glob_norm 0.58771646\n",
      "Iteration 650 L -4.87881899 loss -4.88315058 loss_ordinary 0.768502474 entropy_value 5.65165329 glob_norm 0.357626379\n",
      "Iteration 700 L -4.89498 loss -4.89831257 loss_ordinary 0.737502158 entropy_value 5.63581514 glob_norm 0.397534221\n",
      "Iteration 750 L -4.8624568 loss -4.8647 loss_ordinary 0.785395384 entropy_value 5.65009499 glob_norm 0.482282877\n",
      "Iteration 800 L -4.91508055 loss -4.91741562 loss_ordinary 0.726131737 entropy_value 5.64354753 glob_norm 0.27634716\n",
      "Iteration 850 L -4.8736825 loss -4.87697649 loss_ordinary 0.757641435 entropy_value 5.63461781 glob_norm 0.374895751\n",
      "Iteration 900 L -4.85932 loss -4.86186171 loss_ordinary 0.776092231 entropy_value 5.63795424 glob_norm 0.364224017\n",
      "Iteration 950 L -4.8617754 loss -4.86541796 loss_ordinary 0.773260653 entropy_value 5.63867903 glob_norm 0.320709944\n",
      "Iteration 1000 L -4.84907484 loss -4.85396099 loss_ordinary 0.781473517 entropy_value 5.6354351 glob_norm 0.415878952\n",
      "Iteration 1050 L -4.89966345 loss -4.9023366 loss_ordinary 0.733761728 entropy_value 5.63609838 glob_norm 0.443415225\n",
      "Iteration 1100 L -4.88409519 loss -4.88781834 loss_ordinary 0.751496732 entropy_value 5.63931513 glob_norm 0.568936944\n",
      "Iteration 1150 L -4.8863368 loss -4.88966084 loss_ordinary 0.741263032 entropy_value 5.63092375 glob_norm 0.526903\n",
      "Iteration 1200 L -4.88215446 loss -4.88359308 loss_ordinary 0.747738421 entropy_value 5.63133144 glob_norm 0.626550436\n",
      "Iteration 1250 L -4.87887239 loss -4.88317347 loss_ordinary 0.749533594 entropy_value 5.63270712 glob_norm 0.368791699\n",
      "Iteration 1300 L -4.89991283 loss -4.90409565 loss_ordinary 0.730394244 entropy_value 5.63449 glob_norm 0.277830929\n",
      "Iteration 1350 L -4.89304781 loss -4.89695501 loss_ordinary 0.738338768 entropy_value 5.63529348 glob_norm 0.398529\n",
      "Iteration 1400 L -4.87591362 loss -4.87777519 loss_ordinary 0.759773135 entropy_value 5.63754845 glob_norm 0.372128874\n",
      "Iteration 1450 L -4.90072393 loss -4.90351963 loss_ordinary 0.73195684 entropy_value 5.63547659 glob_norm 0.459240794\n",
      "Iteration 1500 L -4.90356207 loss -4.90614462 loss_ordinary 0.733407736 entropy_value 5.63955212 glob_norm 0.535737\n",
      "Iteration 1550 L -4.87922192 loss -4.88204336 loss_ordinary 0.754290164 entropy_value 5.63633347 glob_norm 0.400367081\n",
      "Iteration 1600 L -4.92433167 loss -4.9280014 loss_ordinary 0.710264504 entropy_value 5.63826609 glob_norm 0.375520617\n",
      "Iteration 1650 L -4.87771893 loss -4.88093138 loss_ordinary 0.752031386 entropy_value 5.6329627 glob_norm 0.398280412\n",
      "Iteration 1700 L -4.87702799 loss -4.88029194 loss_ordinary 0.749119 entropy_value 5.62941122 glob_norm 0.481992751\n",
      "Iteration 1750 L -4.87100887 loss -4.87606287 loss_ordinary 0.759337544 entropy_value 5.6354003 glob_norm 0.605918765\n",
      "Iteration 1800 L -4.84258366 loss -4.84488869 loss_ordinary 0.799456 entropy_value 5.64434481 glob_norm 0.435502708\n",
      "Iteration 1850 L -4.88349962 loss -4.8861475 loss_ordinary 0.745931387 entropy_value 5.63207865 glob_norm 0.350070834\n",
      "Iteration 1900 L -4.85852289 loss -4.86144114 loss_ordinary 0.772798598 entropy_value 5.63423967 glob_norm 0.389238209\n",
      "Iteration 1950 L -4.88543558 loss -4.88976717 loss_ordinary 0.741587222 entropy_value 5.63135433 glob_norm 0.533372164\n",
      "Iteration 2000 L -4.88818169 loss -4.89072514 loss_ordinary 0.743259907 entropy_value 5.63398504 glob_norm 0.428357154\n",
      "Iteration 2050 L -4.9036479 loss -4.90817165 loss_ordinary 0.723914 entropy_value 5.6320858 glob_norm 0.411985546\n",
      "Iteration 2100 L -4.86148214 loss -4.86441898 loss_ordinary 0.762434423 entropy_value 5.62685347 glob_norm 0.395641923\n",
      "Iteration 2150 L -4.86813068 loss -4.87047 loss_ordinary 0.764062822 entropy_value 5.63453293 glob_norm 0.328407913\n",
      "Iteration 2200 L -4.89901924 loss -4.90178585 loss_ordinary 0.734683275 entropy_value 5.63646936 glob_norm 0.415365368\n",
      "Iteration 2250 L -4.88249826 loss -4.88726711 loss_ordinary 0.744343638 entropy_value 5.63161087 glob_norm 0.422454566\n",
      "Iteration 2300 L -4.88055754 loss -4.88424397 loss_ordinary 0.748298645 entropy_value 5.63254261 glob_norm 0.314486921\n",
      "Iteration 2350 L -4.89442492 loss -4.89646435 loss_ordinary 0.7361601 entropy_value 5.63262415 glob_norm 0.349258\n",
      "Iteration 2400 L -4.91102219 loss -4.91360426 loss_ordinary 0.723613441 entropy_value 5.63721752 glob_norm 0.337240398\n",
      "Iteration 2450 L -4.88420725 loss -4.88873196 loss_ordinary 0.744445622 entropy_value 5.63317728 glob_norm 0.457395166\n",
      "Iteration 2500 L -4.86346245 loss -4.86599255 loss_ordinary 0.766153276 entropy_value 5.63214588 glob_norm 0.431249112\n",
      "Iteration 2550 L -4.91632128 loss -4.92008495 loss_ordinary 0.712750852 entropy_value 5.63283539 glob_norm 0.393309385\n",
      "Iteration 2600 L -4.90864468 loss -4.91163874 loss_ordinary 0.708727956 entropy_value 5.62036705 glob_norm 0.39725256\n",
      "Iteration 2650 L -4.86237335 loss -4.8659091 loss_ordinary 0.761876106 entropy_value 5.62778521 glob_norm 0.320276976\n",
      "Iteration 2700 L -4.89771128 loss -4.90072489 loss_ordinary 0.730182707 entropy_value 5.63090754 glob_norm 0.474935949\n",
      "Iteration 2750 L -4.86907101 loss -4.87163877 loss_ordinary 0.765469253 entropy_value 5.63710833 glob_norm 0.33502388\n",
      "Iteration 2800 L -4.89344215 loss -4.89719534 loss_ordinary 0.72937113 entropy_value 5.62656641 glob_norm 0.6172418\n",
      "Iteration 2850 L -4.90790129 loss -4.91110849 loss_ordinary 0.718531787 entropy_value 5.62964058 glob_norm 0.323229253\n",
      "Iteration 2900 L -4.89722824 loss -4.89912224 loss_ordinary 0.732007325 entropy_value 5.63112926 glob_norm 0.32837081\n",
      "Iteration 2950 L -4.87073898 loss -4.8746767 loss_ordinary 0.752856255 entropy_value 5.62753344 glob_norm 0.361989379\n",
      "Iteration 3000 L -4.90548515 loss -4.90881443 loss_ordinary 0.724084079 entropy_value 5.63289833 glob_norm 0.500653684\n",
      "Iteration 3050 L -4.89036465 loss -4.89384651 loss_ordinary 0.743507802 entropy_value 5.63735437 glob_norm 0.327882409\n",
      "Iteration 3100 L -4.87660599 loss -4.87997103 loss_ordinary 0.751661539 entropy_value 5.63163233 glob_norm 0.34935239\n",
      "Iteration 3150 L -4.89546394 loss -4.89758158 loss_ordinary 0.735937 entropy_value 5.6335187 glob_norm 0.515839756\n",
      "Iteration 3200 L -4.88535166 loss -4.88766384 loss_ordinary 0.747589231 entropy_value 5.63525295 glob_norm 0.36064139\n",
      "Iteration 3250 L -4.91498137 loss -4.91880465 loss_ordinary 0.716944695 entropy_value 5.63575 glob_norm 0.353753746\n",
      "Iteration 3300 L -4.9059453 loss -4.90896177 loss_ordinary 0.723743558 entropy_value 5.63270569 glob_norm 0.359169334\n",
      "Iteration 3350 L -4.90047598 loss -4.9040885 loss_ordinary 0.727351069 entropy_value 5.63143969 glob_norm 0.430789679\n",
      "Iteration 3400 L -4.91971827 loss -4.92451715 loss_ordinary 0.705846727 entropy_value 5.63036394 glob_norm 0.381251246\n",
      "Iteration 3450 L -4.87819815 loss -4.88112068 loss_ordinary 0.74931 entropy_value 5.6304307 glob_norm 0.33141309\n",
      "Iteration 3500 L -4.92105913 loss -4.92318964 loss_ordinary 0.705851257 entropy_value 5.62904072 glob_norm 0.34008953\n",
      "Iteration 3550 L -4.88387918 loss -4.88788795 loss_ordinary 0.744848609 entropy_value 5.63273668 glob_norm 0.31672138\n",
      "Iteration 3600 L -4.90922976 loss -4.91072655 loss_ordinary 0.721618474 entropy_value 5.6323452 glob_norm 0.487269908\n",
      "Iteration 3650 L -4.89425659 loss -4.89906073 loss_ordinary 0.726731241 entropy_value 5.62579203 glob_norm 0.357603163\n",
      "Iteration 3700 L -4.90917397 loss -4.91307783 loss_ordinary 0.723508477 entropy_value 5.63658619 glob_norm 0.421994328\n",
      "Iteration 3750 L -4.87744 loss -4.88127518 loss_ordinary 0.75572443 entropy_value 5.63699961 glob_norm 0.314933926\n",
      "Iteration 3800 L -4.90039492 loss -4.90394 loss_ordinary 0.731797159 entropy_value 5.63573742 glob_norm 0.323245704\n",
      "Iteration 3850 L -4.91238451 loss -4.91525412 loss_ordinary 0.717039943 entropy_value 5.63229418 glob_norm 0.37217921\n",
      "Iteration 3900 L -4.89759207 loss -4.90153885 loss_ordinary 0.729896069 entropy_value 5.63143492 glob_norm 0.392715782\n",
      "Iteration 3950 L -4.89476633 loss -4.89863634 loss_ordinary 0.736439 entropy_value 5.63507557 glob_norm 0.328900576\n",
      "Iteration 4000 L -4.89735603 loss -4.90035248 loss_ordinary 0.725423515 entropy_value 5.62577581 glob_norm 0.447871089\n",
      "Iteration 4050 L -4.90235186 loss -4.90475655 loss_ordinary 0.72577244 entropy_value 5.63052893 glob_norm 0.365241557\n",
      "Iteration 4100 L -4.88312864 loss -4.88832664 loss_ordinary 0.740173936 entropy_value 5.62850046 glob_norm 0.351782084\n",
      "Iteration 4150 L -4.87174797 loss -4.87382936 loss_ordinary 0.762453437 entropy_value 5.63628292 glob_norm 0.512371302\n",
      "Iteration 4200 L -4.897192 loss -4.90002489 loss_ordinary 0.727467239 entropy_value 5.62749243 glob_norm 0.366505742\n",
      "Iteration 4250 L -4.89302969 loss -4.89536285 loss_ordinary 0.735641837 entropy_value 5.63100481 glob_norm 0.435720265\n",
      "Iteration 4300 L -4.89871645 loss -4.90111113 loss_ordinary 0.733505368 entropy_value 5.63461637 glob_norm 0.300733805\n",
      "Iteration 4350 L -4.8918 loss -4.89335537 loss_ordinary 0.738588333 entropy_value 5.63194418 glob_norm 0.343690813\n",
      "Iteration 4400 L -4.83365917 loss -4.83718681 loss_ordinary 0.790668905 entropy_value 5.62785578 glob_norm 0.427876055\n",
      "Iteration 4450 L -4.88607693 loss -4.88705158 loss_ordinary 0.74865526 entropy_value 5.63570642 glob_norm 0.527053177\n",
      "Iteration 4500 L -4.9019928 loss -4.90507603 loss_ordinary 0.72800976 entropy_value 5.63308573 glob_norm 0.337788552\n",
      "Iteration 4550 L -4.88166761 loss -4.88440609 loss_ordinary 0.749209 entropy_value 5.63361549 glob_norm 0.346181303\n",
      "Iteration 4600 L -4.93476963 loss -4.93640423 loss_ordinary 0.693936408 entropy_value 5.63034058 glob_norm 0.361895204\n",
      "Iteration 4650 L -4.91666842 loss -4.91964769 loss_ordinary 0.713491142 entropy_value 5.63313913 glob_norm 0.367229164\n",
      "Iteration 4700 L -4.86406326 loss -4.86624908 loss_ordinary 0.76970154 entropy_value 5.63595057 glob_norm 0.347821325\n",
      "Iteration 4750 L -4.90433121 loss -4.90657568 loss_ordinary 0.725157201 entropy_value 5.63173294 glob_norm 0.361506641\n",
      "Iteration 4800 L -4.90091419 loss -4.9026947 loss_ordinary 0.727044284 entropy_value 5.62973881 glob_norm 0.446456611\n",
      "Iteration 4850 L -4.87548 loss -4.87839842 loss_ordinary 0.752842426 entropy_value 5.63124084 glob_norm 0.431424409\n",
      "Iteration 4900 L -4.8867836 loss -4.88904858 loss_ordinary 0.737747848 entropy_value 5.62679625 glob_norm 0.276688814\n",
      "Iteration 4950 L -4.90098286 loss -4.90333414 loss_ordinary 0.726266801 entropy_value 5.62960148 glob_norm 0.367389649\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 0.73067379 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85396481 loss -4.8623023 loss_ordinary 0.771503747 entropy_value 5.63380623 glob_norm 0.394823\n",
      "Iteration 50 L -4.84999037 loss -4.85773945 loss_ordinary 0.777419209 entropy_value 5.63515854 glob_norm 0.421179\n",
      "Iteration 100 L -4.87139559 loss -4.87513447 loss_ordinary 0.76646775 entropy_value 5.64160204 glob_norm 0.380086899\n",
      "Iteration 150 L -4.88182 loss -4.88910627 loss_ordinary 0.746128738 entropy_value 5.63523483 glob_norm 0.334199399\n",
      "Iteration 200 L -4.88495302 loss -4.89182329 loss_ordinary 0.745690167 entropy_value 5.63751364 glob_norm 0.360237718\n",
      "Iteration 250 L -4.89416409 loss -4.9002161 loss_ordinary 0.748404622 entropy_value 5.64862061 glob_norm 0.314432323\n",
      "Iteration 300 L -4.88736963 loss -4.88934755 loss_ordinary 0.755283117 entropy_value 5.64463043 glob_norm 0.303325206\n",
      "Iteration 350 L -4.85477972 loss -4.86129713 loss_ordinary 0.768901408 entropy_value 5.63019848 glob_norm 0.565127671\n",
      "Iteration 400 L -4.88872766 loss -4.89468861 loss_ordinary 0.746702135 entropy_value 5.6413908 glob_norm 0.411718369\n",
      "Iteration 450 L -4.88836432 loss -4.89760637 loss_ordinary 0.745288193 entropy_value 5.64289427 glob_norm 0.357157469\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 0.576586723 lambd_papr -0.00730673783 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90402412 loss -4.90564871 loss_ordinary 0.740089118 entropy_value 5.64573812 glob_norm 0.384444654\n",
      "Iteration 50 L -4.87727 loss -4.88559341 loss_ordinary 0.761816204 entropy_value 5.64741 glob_norm 0.466590106\n",
      "Iteration 100 L -4.89111376 loss -4.89937544 loss_ordinary 0.75203371 entropy_value 5.65140915 glob_norm 0.266018927\n",
      "Iteration 150 L -4.88922167 loss -4.8939333 loss_ordinary 0.75944066 entropy_value 5.65337372 glob_norm 0.31499216\n",
      "Iteration 200 L -4.86728048 loss -4.87216806 loss_ordinary 0.78076303 entropy_value 5.65293121 glob_norm 0.285496265\n",
      "Iteration 250 L -4.90536118 loss -4.90580034 loss_ordinary 0.748085201 entropy_value 5.65388536 glob_norm 0.363071918\n",
      "Iteration 300 L -4.89074612 loss -4.90005112 loss_ordinary 0.759941041 entropy_value 5.65999222 glob_norm 0.434316546\n",
      "Iteration 350 L -4.89035606 loss -4.89346457 loss_ordinary 0.751651525 entropy_value 5.64511633 glob_norm 0.349703163\n",
      "Iteration 400 L -4.90906763 loss -4.9083252 loss_ordinary 0.74878943 entropy_value 5.65711451 glob_norm 0.379439592\n",
      "Iteration 450 L -4.85693741 loss -4.868361 loss_ordinary 0.778119683 entropy_value 5.64648056 glob_norm 0.335400343\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power -0.0392751694 lambd_papr -0.0130899027 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91128969 loss -4.9132905 loss_ordinary 0.735846162 entropy_value 5.64913654 glob_norm 0.395416468\n",
      "Iteration 50 L -4.90155697 loss -4.90885878 loss_ordinary 0.741861761 entropy_value 5.6507206 glob_norm 0.420882434\n",
      "Iteration 100 L -4.87035131 loss -4.87504292 loss_ordinary 0.783989787 entropy_value 5.65903282 glob_norm 0.556465\n",
      "Iteration 150 L -4.87595749 loss -4.87950611 loss_ordinary 0.774485528 entropy_value 5.6539917 glob_norm 0.316697806\n",
      "Iteration 200 L -4.9015851 loss -4.90446424 loss_ordinary 0.747934461 entropy_value 5.65239906 glob_norm 0.337700337\n",
      "Iteration 250 L -4.87494135 loss -4.87855053 loss_ordinary 0.778358579 entropy_value 5.65690947 glob_norm 0.378311068\n",
      "Iteration 300 L -4.88680696 loss -4.89634 loss_ordinary 0.759753644 entropy_value 5.6560936 glob_norm 0.432380408\n",
      "Iteration 350 L -4.88471222 loss -4.88672113 loss_ordinary 0.772517323 entropy_value 5.65923834 glob_norm 0.450926632\n",
      "Iteration 400 L -4.91362143 loss -4.91959715 loss_ordinary 0.727565348 entropy_value 5.64716291 glob_norm 0.460024476\n",
      "Iteration 450 L -4.90042496 loss -4.90504885 loss_ordinary 0.74710536 entropy_value 5.65215445 glob_norm 0.420112461\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0.119575739 lambd_papr -0.012694791 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89531612 loss -4.90083694 loss_ordinary 0.745809615 entropy_value 5.64664698 glob_norm 0.374584049\n",
      "Iteration 50 L -4.89353323 loss -4.89726448 loss_ordinary 0.753371179 entropy_value 5.65063572 glob_norm 0.480655432\n",
      "Iteration 100 L -4.88602448 loss -4.89522314 loss_ordinary 0.767476261 entropy_value 5.6626997 glob_norm 0.362832606\n",
      "Iteration 150 L -4.88379383 loss -4.89138174 loss_ordinary 0.767742038 entropy_value 5.6591239 glob_norm 0.407114893\n",
      "Iteration 200 L -4.86391926 loss -4.8614521 loss_ordinary 0.791966617 entropy_value 5.65341902 glob_norm 0.392772853\n",
      "Iteration 250 L -4.86511803 loss -4.87387705 loss_ordinary 0.782111883 entropy_value 5.65598869 glob_norm 0.374530941\n",
      "Iteration 300 L -4.87719393 loss -4.87738609 loss_ordinary 0.778299749 entropy_value 5.6556859 glob_norm 0.512882292\n",
      "Iteration 350 L -4.87055206 loss -4.87982035 loss_ordinary 0.774651647 entropy_value 5.65447235 glob_norm 0.44934985\n",
      "Iteration 400 L -4.9019146 loss -4.90443182 loss_ordinary 0.747635841 entropy_value 5.65206718 glob_norm 0.5621261\n",
      "Iteration 450 L -4.85015821 loss -4.85240221 loss_ordinary 0.80349642 entropy_value 5.65589857 glob_norm 0.440844119\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0.112570763 lambd_papr -0.0139013426 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87288666 loss -4.88062048 loss_ordinary 0.78054142 entropy_value 5.6611619 glob_norm 0.303844213\n",
      "Iteration 50 L -4.87005329 loss -4.87507439 loss_ordinary 0.783604205 entropy_value 5.65867853 glob_norm 0.366960049\n",
      "Iteration 100 L -4.86623526 loss -4.87452221 loss_ordinary 0.775410771 entropy_value 5.64993286 glob_norm 0.445635587\n",
      "Iteration 150 L -4.84862757 loss -4.85251093 loss_ordinary 0.804272056 entropy_value 5.6567831 glob_norm 0.39119032\n",
      "Iteration 200 L -4.85883188 loss -4.86156511 loss_ordinary 0.796185732 entropy_value 5.65775061 glob_norm 0.378369242\n",
      "Iteration 250 L -4.89285374 loss -4.90096045 loss_ordinary 0.749830484 entropy_value 5.65079117 glob_norm 0.357363939\n",
      "Iteration 300 L -4.90389204 loss -4.90850878 loss_ordinary 0.755224288 entropy_value 5.66373301 glob_norm 0.572906375\n",
      "Iteration 350 L -4.87799215 loss -4.87880087 loss_ordinary 0.780909717 entropy_value 5.65971088 glob_norm 0.475257128\n",
      "Iteration 400 L -4.87398815 loss -4.87619972 loss_ordinary 0.778480232 entropy_value 5.65468025 glob_norm 0.319223344\n",
      "Iteration 450 L -4.87766075 loss -4.87881756 loss_ordinary 0.77192992 entropy_value 5.65074778 glob_norm 0.438942105\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.292322159 lambd_papr -0.0150406193 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90939045 loss -4.91299057 loss_ordinary 0.744031 entropy_value 5.65702152 glob_norm 0.420462787\n",
      "Iteration 50 L -4.88181686 loss -4.88585186 loss_ordinary 0.772482395 entropy_value 5.65833426 glob_norm 0.419396251\n",
      "Iteration 100 L -4.88890791 loss -4.90043211 loss_ordinary 0.763463557 entropy_value 5.66389561 glob_norm 0.313909292\n",
      "Iteration 150 L -4.86206 loss -4.86628628 loss_ordinary 0.789687 entropy_value 5.65597296 glob_norm 0.418968379\n",
      "Iteration 200 L -4.90056038 loss -4.90017176 loss_ordinary 0.766893327 entropy_value 5.66706514 glob_norm 0.675815523\n",
      "Iteration 250 L -4.88337946 loss -4.88792753 loss_ordinary 0.770888507 entropy_value 5.65881586 glob_norm 0.322139919\n",
      "Iteration 300 L -4.87407923 loss -4.87327147 loss_ordinary 0.78606993 entropy_value 5.65934134 glob_norm 0.553086758\n",
      "Iteration 350 L -4.87487841 loss -4.87654257 loss_ordinary 0.785349667 entropy_value 5.66189241 glob_norm 0.330411941\n",
      "Iteration 400 L -4.87125111 loss -4.87208414 loss_ordinary 0.786532223 entropy_value 5.65861607 glob_norm 0.460551\n",
      "Iteration 450 L -4.86824942 loss -4.87034512 loss_ordinary 0.787027 entropy_value 5.657372 glob_norm 0.33384\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power -0.100190401 lambd_papr -0.0180079527 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85787153 loss -4.86660242 loss_ordinary 0.797063589 entropy_value 5.66366577 glob_norm 0.325627416\n",
      "Iteration 50 L -4.87167025 loss -4.87842 loss_ordinary 0.7883811 entropy_value 5.66680098 glob_norm 0.313517392\n",
      "Iteration 100 L -4.8961935 loss -4.89531612 loss_ordinary 0.764625251 entropy_value 5.6599412 glob_norm 0.330907971\n",
      "Iteration 150 L -4.91195536 loss -4.9191165 loss_ordinary 0.738337874 entropy_value 5.65745449 glob_norm 0.482670158\n",
      "Iteration 200 L -4.89403725 loss -4.89938927 loss_ordinary 0.756595671 entropy_value 5.65598488 glob_norm 0.319386035\n",
      "Iteration 250 L -4.90348101 loss -4.91258335 loss_ordinary 0.746400237 entropy_value 5.65898371 glob_norm 0.45103994\n",
      "Iteration 300 L -4.85223293 loss -4.85802221 loss_ordinary 0.80210495 entropy_value 5.66012764 glob_norm 0.51730442\n",
      "Iteration 350 L -4.88672447 loss -4.89222097 loss_ordinary 0.766697109 entropy_value 5.6589179 glob_norm 0.357717454\n",
      "Iteration 400 L -4.88054085 loss -4.87918 loss_ordinary 0.77425617 entropy_value 5.65343618 glob_norm 0.357186228\n",
      "Iteration 450 L -4.87392473 loss -4.87401152 loss_ordinary 0.780933678 entropy_value 5.6549449 glob_norm 0.477943867\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0.0231642723 lambd_papr -0.0169878788 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90856361 loss -4.91239071 loss_ordinary 0.75460887 entropy_value 5.66699934 glob_norm 0.28693217\n",
      "Iteration 50 L -4.86056328 loss -4.85617924 loss_ordinary 0.806153357 entropy_value 5.66233253 glob_norm 0.37051931\n",
      "Iteration 100 L -4.87386465 loss -4.86990595 loss_ordinary 0.792022586 entropy_value 5.66192865 glob_norm 0.511998\n",
      "Iteration 150 L -4.8978734 loss -4.89347267 loss_ordinary 0.76128912 entropy_value 5.65476179 glob_norm 0.296866268\n",
      "Iteration 200 L -4.89489079 loss -4.88812637 loss_ordinary 0.771922767 entropy_value 5.66004896 glob_norm 0.331960499\n",
      "Iteration 250 L -4.86530399 loss -4.8613205 loss_ordinary 0.796902418 entropy_value 5.65822315 glob_norm 0.371132255\n",
      "Iteration 300 L -4.8688693 loss -4.87598228 loss_ordinary 0.7862252 entropy_value 5.6622076 glob_norm 0.281992555\n",
      "Iteration 350 L -4.87425375 loss -4.87993574 loss_ordinary 0.778321564 entropy_value 5.65825748 glob_norm 0.520437062\n",
      "Iteration 400 L -4.8648963 loss -4.86979246 loss_ordinary 0.782487 entropy_value 5.65227938 glob_norm 0.371539235\n",
      "Iteration 450 L -4.84495592 loss -4.8481884 loss_ordinary 0.817072272 entropy_value 5.66526079 glob_norm 0.384289205\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.332596064 lambd_papr -0.0172244292 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87493372 loss -4.87582302 loss_ordinary 0.78794384 entropy_value 5.66376686 glob_norm 0.364015251\n",
      "Iteration 50 L -4.89285 loss -4.88887215 loss_ordinary 0.782869637 entropy_value 5.67174196 glob_norm 0.395402074\n",
      "Iteration 100 L -4.86737061 loss -4.87781334 loss_ordinary 0.780614197 entropy_value 5.65842724 glob_norm 0.38961643\n",
      "Iteration 150 L -4.87624502 loss -4.88994217 loss_ordinary 0.769043744 entropy_value 5.65898609 glob_norm 0.321748197\n",
      "Iteration 200 L -4.88418055 loss -4.88500881 loss_ordinary 0.781813 entropy_value 5.66682196 glob_norm 0.245008588\n",
      "Iteration 250 L -4.84356117 loss -4.84715366 loss_ordinary 0.814994156 entropy_value 5.66214752 glob_norm 0.461045861\n",
      "Iteration 300 L -4.87625885 loss -4.87862301 loss_ordinary 0.782346547 entropy_value 5.66096973 glob_norm 0.500440538\n",
      "Iteration 350 L -4.84045 loss -4.8396287 loss_ordinary 0.825362444 entropy_value 5.66499138 glob_norm 0.478515476\n",
      "Iteration 400 L -4.87729 loss -4.88323832 loss_ordinary 0.781457 entropy_value 5.66469479 glob_norm 0.419448107\n",
      "Iteration 450 L -4.85357475 loss -4.85959673 loss_ordinary 0.810438454 entropy_value 5.67003536 glob_norm 0.458657771\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0.136110544 lambd_papr -0.0206310563 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89303255 loss -4.88333464 loss_ordinary 0.787774265 entropy_value 5.67110872 glob_norm 0.396365404\n",
      "Iteration 50 L -4.91695356 loss -4.89529 loss_ordinary 0.775443435 entropy_value 5.67073345 glob_norm 0.388922423\n",
      "Iteration 100 L -4.86229086 loss -4.85919094 loss_ordinary 0.804789543 entropy_value 5.66398 glob_norm 0.435615808\n",
      "Iteration 150 L -4.89089537 loss -4.87372255 loss_ordinary 0.785779357 entropy_value 5.65950203 glob_norm 0.476111084\n",
      "Iteration 200 L -4.86540031 loss -4.87002659 loss_ordinary 0.789204359 entropy_value 5.65923071 glob_norm 0.339358538\n",
      "Iteration 250 L -4.89312553 loss -4.89698 loss_ordinary 0.773248196 entropy_value 5.670228 glob_norm 0.367672175\n",
      "Iteration 300 L -4.87704229 loss -4.87967682 loss_ordinary 0.785899401 entropy_value 5.66557646 glob_norm 0.42466554\n",
      "Iteration 350 L -4.91309166 loss -4.90300179 loss_ordinary 0.760157824 entropy_value 5.66315937 glob_norm 0.38411063\n",
      "Iteration 400 L -4.86132908 loss -4.86681509 loss_ordinary 0.795088232 entropy_value 5.66190338 glob_norm 0.301926941\n",
      "Iteration 450 L -4.87996721 loss -4.88056612 loss_ordinary 0.78655 entropy_value 5.66711617 glob_norm 0.399845\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.168454409 lambd_papr -0.0220293552 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88737822 loss -4.88285685 loss_ordinary 0.782623231 entropy_value 5.66548 glob_norm 0.317821354\n",
      "Iteration 50 L -4.88716698 loss -4.89336824 loss_ordinary 0.776058555 entropy_value 5.66942692 glob_norm 0.530628443\n",
      "Iteration 100 L -4.89298153 loss -4.88517618 loss_ordinary 0.783473313 entropy_value 5.6686492 glob_norm 0.34599486\n",
      "Iteration 150 L -4.8874855 loss -4.89703512 loss_ordinary 0.769375 entropy_value 5.66641 glob_norm 0.312644929\n",
      "Iteration 200 L -4.89293575 loss -4.88563347 loss_ordinary 0.783991 entropy_value 5.66962481 glob_norm 0.346059084\n",
      "Iteration 250 L -4.85527563 loss -4.85557508 loss_ordinary 0.814674258 entropy_value 5.67024946 glob_norm 0.384078056\n",
      "Iteration 300 L -4.87106609 loss -4.8671174 loss_ordinary 0.80607909 entropy_value 5.67319632 glob_norm 0.388717\n",
      "Iteration 350 L -4.88398409 loss -4.87861204 loss_ordinary 0.792940855 entropy_value 5.67155266 glob_norm 0.425116748\n",
      "Iteration 400 L -4.84017801 loss -4.83836508 loss_ordinary 0.829289317 entropy_value 5.66765451 glob_norm 0.431058913\n",
      "Iteration 450 L -4.82921314 loss -4.83566 loss_ordinary 0.836230874 entropy_value 5.67189074 glob_norm 0.374552935\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power -0.0856986046 lambd_papr -0.0237651244 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88472033 loss -4.8778162 loss_ordinary 0.788577914 entropy_value 5.66639423 glob_norm 0.318801075\n",
      "Iteration 50 L -4.87748241 loss -4.87699747 loss_ordinary 0.793645918 entropy_value 5.67064333 glob_norm 0.35299626\n",
      "Iteration 100 L -4.88784647 loss -4.88791609 loss_ordinary 0.781118214 entropy_value 5.66903448 glob_norm 0.37396422\n",
      "Iteration 150 L -4.89945316 loss -4.89844131 loss_ordinary 0.777625 entropy_value 5.6760664 glob_norm 0.464515507\n",
      "Iteration 200 L -4.89472 loss -4.88881588 loss_ordinary 0.786063 entropy_value 5.67487907 glob_norm 0.508056641\n",
      "Iteration 250 L -4.86684847 loss -4.86977291 loss_ordinary 0.800321 entropy_value 5.67009401 glob_norm 0.457772017\n",
      "Iteration 300 L -4.91050911 loss -4.90284538 loss_ordinary 0.756869495 entropy_value 5.6597147 glob_norm 0.585872\n",
      "Iteration 350 L -4.90983295 loss -4.89202881 loss_ordinary 0.777616441 entropy_value 5.66964531 glob_norm 0.457220763\n",
      "Iteration 400 L -4.89003038 loss -4.89948606 loss_ordinary 0.772763 entropy_value 5.67224932 glob_norm 0.314319164\n",
      "Iteration 450 L -4.90014267 loss -4.88087702 loss_ordinary 0.783234119 entropy_value 5.66411114 glob_norm 0.503025174\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.126274824 lambd_papr -0.0228794292 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87118 loss -4.86177492 loss_ordinary 0.802974284 entropy_value 5.66474915 glob_norm 0.357963741\n",
      "Iteration 50 L -4.89041948 loss -4.88666201 loss_ordinary 0.780880153 entropy_value 5.66754246 glob_norm 0.298048049\n",
      "Iteration 100 L -4.88814116 loss -4.88779211 loss_ordinary 0.783178568 entropy_value 5.67097092 glob_norm 0.371395051\n",
      "Iteration 150 L -4.86684084 loss -4.86624336 loss_ordinary 0.806936145 entropy_value 5.67317963 glob_norm 0.338412613\n",
      "Iteration 200 L -4.88080597 loss -4.8907733 loss_ordinary 0.780091107 entropy_value 5.67086458 glob_norm 0.304932594\n",
      "Iteration 250 L -4.90234327 loss -4.89326143 loss_ordinary 0.777285218 entropy_value 5.67054701 glob_norm 0.542950273\n",
      "Iteration 300 L -4.88053465 loss -4.88412476 loss_ordinary 0.786135793 entropy_value 5.67026091 glob_norm 0.382713646\n",
      "Iteration 350 L -4.88361502 loss -4.89318752 loss_ordinary 0.780475676 entropy_value 5.67366314 glob_norm 0.479806513\n",
      "Iteration 400 L -4.8902688 loss -4.88717794 loss_ordinary 0.787874937 entropy_value 5.67505264 glob_norm 0.362802386\n",
      "Iteration 450 L -4.85497284 loss -4.86144352 loss_ordinary 0.81147784 entropy_value 5.67292118 glob_norm 0.31963253\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power -0.0563607216 lambd_papr -0.0241883937 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89248371 loss -4.90127659 loss_ordinary 0.761603296 entropy_value 5.66288 glob_norm 0.381699979\n",
      "Iteration 50 L -4.88349295 loss -4.87143087 loss_ordinary 0.800163746 entropy_value 5.67159462 glob_norm 0.402267605\n",
      "Iteration 100 L -4.87916756 loss -4.87419748 loss_ordinary 0.790117204 entropy_value 5.66431475 glob_norm 0.429869741\n",
      "Iteration 150 L -4.88178396 loss -4.88839436 loss_ordinary 0.78468 entropy_value 5.67307472 glob_norm 0.402152598\n",
      "Iteration 200 L -4.90407419 loss -4.90112352 loss_ordinary 0.771768034 entropy_value 5.67289162 glob_norm 0.280286372\n",
      "Iteration 250 L -4.87060261 loss -4.86806679 loss_ordinary 0.802480161 entropy_value 5.67054653 glob_norm 0.390513301\n",
      "Iteration 300 L -4.85505867 loss -4.8565383 loss_ordinary 0.817144454 entropy_value 5.67368269 glob_norm 0.611604333\n",
      "Iteration 350 L -4.8684907 loss -4.86698437 loss_ordinary 0.802944958 entropy_value 5.6699295 glob_norm 0.524715245\n",
      "Iteration 400 L -4.9087882 loss -4.90429211 loss_ordinary 0.764357686 entropy_value 5.66864967 glob_norm 0.365707099\n",
      "Iteration 450 L -4.86130571 loss -4.85784245 loss_ordinary 0.810069382 entropy_value 5.66791153 glob_norm 0.630406678\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.100225687 lambd_papr -0.0236024056 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87327862 loss -4.86694241 loss_ordinary 0.796120048 entropy_value 5.66306257 glob_norm 0.423538476\n",
      "Iteration 50 L -4.85836792 loss -4.85708857 loss_ordinary 0.810224712 entropy_value 5.6673131 glob_norm 0.517551601\n",
      "Iteration 100 L -4.8907795 loss -4.88241673 loss_ordinary 0.792661667 entropy_value 5.67507839 glob_norm 0.446018875\n",
      "Iteration 150 L -4.9371357 loss -4.92960548 loss_ordinary 0.741431653 entropy_value 5.6710372 glob_norm 0.498200864\n",
      "Iteration 200 L -4.86190748 loss -4.86158133 loss_ordinary 0.809089541 entropy_value 5.67067099 glob_norm 0.361294419\n",
      "Iteration 250 L -4.86205626 loss -4.86151457 loss_ordinary 0.801879704 entropy_value 5.66339397 glob_norm 0.469437391\n",
      "Iteration 300 L -4.88714457 loss -4.87634516 loss_ordinary 0.791995049 entropy_value 5.66834 glob_norm 0.361723065\n",
      "Iteration 350 L -4.90563345 loss -4.88869572 loss_ordinary 0.780780733 entropy_value 5.66947603 glob_norm 0.305618137\n",
      "Iteration 400 L -4.89461422 loss -4.890553 loss_ordinary 0.782678604 entropy_value 5.6732316 glob_norm 0.414435893\n",
      "Iteration 450 L -4.86952209 loss -4.87338781 loss_ordinary 0.801034 entropy_value 5.67442179 glob_norm 0.390150726\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.182507992 lambd_papr -0.0246475879 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88248444 loss -4.88444662 loss_ordinary 0.783928871 entropy_value 5.66837549 glob_norm 0.366407722\n",
      "Iteration 50 L -4.89894342 loss -4.89231348 loss_ordinary 0.77606076 entropy_value 5.66837406 glob_norm 0.461498141\n",
      "Iteration 100 L -4.87244129 loss -4.87371397 loss_ordinary 0.79446888 entropy_value 5.66818285 glob_norm 0.361831069\n",
      "Iteration 150 L -4.89408875 loss -4.89124823 loss_ordinary 0.783725858 entropy_value 5.67497396 glob_norm 0.293513775\n",
      "Iteration 200 L -4.86303091 loss -4.85281229 loss_ordinary 0.81953311 entropy_value 5.67234564 glob_norm 0.58378458\n",
      "Iteration 250 L -4.88576221 loss -4.86885691 loss_ordinary 0.80098027 entropy_value 5.66983747 glob_norm 0.321182847\n",
      "Iteration 300 L -4.88455868 loss -4.88000536 loss_ordinary 0.80006808 entropy_value 5.68007326 glob_norm 0.383837193\n",
      "Iteration 350 L -4.90198898 loss -4.88463402 loss_ordinary 0.787249207 entropy_value 5.67188311 glob_norm 0.360107124\n",
      "Iteration 400 L -4.90560293 loss -4.89960718 loss_ordinary 0.772284329 entropy_value 5.67189121 glob_norm 0.34755078\n",
      "Iteration 450 L -4.88265371 loss -4.88174963 loss_ordinary 0.79622 entropy_value 5.67796946 glob_norm 0.426219344\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power -0.0241541862 lambd_papr -0.026556544 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87150288 loss -4.85707569 loss_ordinary 0.815547764 entropy_value 5.67262363 glob_norm 0.349712819\n",
      "Iteration 50 L -4.86702347 loss -4.87527514 loss_ordinary 0.795869291 entropy_value 5.67114449 glob_norm 0.488879263\n",
      "Iteration 100 L -4.84797 loss -4.85807228 loss_ordinary 0.816494524 entropy_value 5.67456675 glob_norm 0.42056185\n",
      "Iteration 150 L -4.86480427 loss -4.85857201 loss_ordinary 0.816613853 entropy_value 5.67518616 glob_norm 0.356746674\n",
      "Iteration 200 L -4.90636969 loss -4.90606356 loss_ordinary 0.767643511 entropy_value 5.67370701 glob_norm 0.354504943\n",
      "Iteration 250 L -4.86258364 loss -4.87237692 loss_ordinary 0.79680109 entropy_value 5.66917801 glob_norm 0.433600277\n",
      "Iteration 300 L -4.85196 loss -4.85738611 loss_ordinary 0.815747082 entropy_value 5.67313337 glob_norm 0.477454305\n",
      "Iteration 350 L -4.85859823 loss -4.86066532 loss_ordinary 0.809892178 entropy_value 5.67055702 glob_norm 0.41581741\n",
      "Iteration 400 L -4.84210253 loss -4.83499098 loss_ordinary 0.84168452 entropy_value 5.6766758 glob_norm 0.378147274\n",
      "Iteration 450 L -4.85218143 loss -4.84834099 loss_ordinary 0.824328661 entropy_value 5.67266941 glob_norm 0.389263362\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power -0.0245761871 lambd_papr -0.0263031442 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87079716 loss -4.85748053 loss_ordinary 0.821018338 entropy_value 5.67849922 glob_norm 0.376287729\n",
      "Iteration 50 L -4.89502335 loss -4.89633369 loss_ordinary 0.778747082 entropy_value 5.67508078 glob_norm 0.31994\n",
      "Iteration 100 L -4.9147 loss -4.90329933 loss_ordinary 0.770217776 entropy_value 5.67351723 glob_norm 0.316025198\n",
      "Iteration 150 L -4.85159969 loss -4.84824 loss_ordinary 0.824406207 entropy_value 5.67264605 glob_norm 0.387830228\n",
      "Iteration 200 L -4.87027311 loss -4.86634445 loss_ordinary 0.801369131 entropy_value 5.66771364 glob_norm 0.408161461\n",
      "Iteration 250 L -4.86799145 loss -4.86868095 loss_ordinary 0.804208934 entropy_value 5.67288971 glob_norm 0.56394726\n",
      "Iteration 300 L -4.89036703 loss -4.89277077 loss_ordinary 0.781256 entropy_value 5.67402697 glob_norm 0.287531286\n",
      "Iteration 350 L -4.85949 loss -4.87213516 loss_ordinary 0.800019443 entropy_value 5.67215443 glob_norm 0.379125029\n",
      "Iteration 400 L -4.90469456 loss -4.8946557 loss_ordinary 0.768639326 entropy_value 5.66329527 glob_norm 0.507131\n",
      "Iteration 450 L -4.85334396 loss -4.84926176 loss_ordinary 0.822494 entropy_value 5.67175579 glob_norm 0.457601935\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power -0.0876658 lambd_papr -0.0260445438 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85701323 loss -4.85072565 loss_ordinary 0.82246989 entropy_value 5.67319584 glob_norm 0.52432394\n",
      "Iteration 50 L -4.87328291 loss -4.87657118 loss_ordinary 0.800313234 entropy_value 5.67688465 glob_norm 0.329665929\n",
      "Iteration 100 L -4.88512707 loss -4.879004 loss_ordinary 0.79496932 entropy_value 5.67397308 glob_norm 0.563872635\n",
      "Iteration 150 L -4.91323328 loss -4.90397644 loss_ordinary 0.766950607 entropy_value 5.67092705 glob_norm 0.298245043\n",
      "Iteration 200 L -4.84597111 loss -4.84526539 loss_ordinary 0.827915072 entropy_value 5.67318058 glob_norm 0.30223763\n",
      "Iteration 250 L -4.89894772 loss -4.89365435 loss_ordinary 0.78269285 entropy_value 5.67634678 glob_norm 0.456867844\n",
      "Iteration 300 L -4.86966467 loss -4.87251806 loss_ordinary 0.796891928 entropy_value 5.66941 glob_norm 0.358950585\n",
      "Iteration 350 L -4.87983751 loss -4.87244272 loss_ordinary 0.801536143 entropy_value 5.67397881 glob_norm 0.444301039\n",
      "Iteration 400 L -4.84809351 loss -4.84677 loss_ordinary 0.825148165 entropy_value 5.67191744 glob_norm 0.363121\n",
      "Iteration 450 L -4.87302637 loss -4.86541224 loss_ordinary 0.806554258 entropy_value 5.67196655 glob_norm 0.318471342\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power -0.178985834 lambd_papr -0.0251193196 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91623306 loss -4.91350412 loss_ordinary 0.758876562 entropy_value 5.67238045 glob_norm 0.452083945\n",
      "Iteration 50 L -4.88318491 loss -4.88551664 loss_ordinary 0.786486447 entropy_value 5.67200279 glob_norm 0.391942382\n",
      "Iteration 100 L -4.89917374 loss -4.900033 loss_ordinary 0.765504718 entropy_value 5.66553783 glob_norm 0.305640697\n",
      "Iteration 150 L -4.90111113 loss -4.88887835 loss_ordinary 0.778872788 entropy_value 5.66775131 glob_norm 0.40124765\n",
      "Iteration 200 L -4.87250805 loss -4.86937189 loss_ordinary 0.801059484 entropy_value 5.67043114 glob_norm 0.339772224\n",
      "Iteration 250 L -4.8871007 loss -4.891819 loss_ordinary 0.779181778 entropy_value 5.67100096 glob_norm 0.287595123\n",
      "Iteration 300 L -4.88406658 loss -4.88115311 loss_ordinary 0.785172164 entropy_value 5.66632557 glob_norm 0.306178689\n",
      "Iteration 350 L -4.87510252 loss -4.86933661 loss_ordinary 0.804139435 entropy_value 5.67347574 glob_norm 0.443956673\n",
      "Iteration 400 L -4.88705444 loss -4.87011576 loss_ordinary 0.805070698 entropy_value 5.67518616 glob_norm 0.305481642\n",
      "Iteration 450 L -4.87178946 loss -4.86501837 loss_ordinary 0.801757038 entropy_value 5.66677523 glob_norm 0.344729424\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power -0.193089962 lambd_papr -0.0232246369 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88098431 loss -4.86992168 loss_ordinary 0.799962 entropy_value 5.6698842 glob_norm 0.28644371\n",
      "Iteration 50 L -4.87374067 loss -4.88128948 loss_ordinary 0.786039472 entropy_value 5.66732931 glob_norm 0.338795185\n",
      "Iteration 100 L -4.89892 loss -4.89039612 loss_ordinary 0.770111799 entropy_value 5.66050768 glob_norm 0.297779471\n",
      "Iteration 150 L -4.87569952 loss -4.87941742 loss_ordinary 0.784359694 entropy_value 5.66377687 glob_norm 0.313250899\n",
      "Iteration 200 L -4.89183044 loss -4.89379215 loss_ordinary 0.773963511 entropy_value 5.6677556 glob_norm 0.428035259\n",
      "Iteration 250 L -4.86939096 loss -4.87195063 loss_ordinary 0.79789567 entropy_value 5.66984606 glob_norm 0.370915145\n",
      "Iteration 300 L -4.88802862 loss -4.88544512 loss_ordinary 0.77818656 entropy_value 5.66363144 glob_norm 0.305271059\n",
      "Iteration 350 L -4.84487104 loss -4.85052109 loss_ordinary 0.813798189 entropy_value 5.66431952 glob_norm 0.31690973\n",
      "Iteration 400 L -4.87410879 loss -4.88221121 loss_ordinary 0.787461877 entropy_value 5.66967297 glob_norm 0.33783716\n",
      "Iteration 450 L -4.90511465 loss -4.90728426 loss_ordinary 0.760295212 entropy_value 5.66757965 glob_norm 0.341951549\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -0.292608976 lambd_papr -0.0211745203 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8689518 loss -4.87664127 loss_ordinary 0.785121799 entropy_value 5.66176319 glob_norm 0.423362404\n",
      "Iteration 50 L -4.89711714 loss -4.89272976 loss_ordinary 0.772522 entropy_value 5.66525173 glob_norm 0.42475909\n",
      "Iteration 100 L -4.87918472 loss -4.87937975 loss_ordinary 0.784419894 entropy_value 5.6638 glob_norm 0.344738573\n",
      "Iteration 150 L -4.87993765 loss -4.88336611 loss_ordinary 0.779722 entropy_value 5.66308784 glob_norm 0.429663837\n",
      "Iteration 200 L -4.88565445 loss -4.90126371 loss_ordinary 0.761404574 entropy_value 5.66266823 glob_norm 0.531139\n",
      "Iteration 250 L -4.90361547 loss -4.90896845 loss_ordinary 0.751505 entropy_value 5.66047335 glob_norm 0.395492017\n",
      "Iteration 300 L -4.87784147 loss -4.87442636 loss_ordinary 0.796633184 entropy_value 5.67105961 glob_norm 0.439808\n",
      "Iteration 350 L -4.86358738 loss -4.86598492 loss_ordinary 0.793718 entropy_value 5.65970278 glob_norm 0.301274776\n",
      "Iteration 400 L -4.8449626 loss -4.85135 loss_ordinary 0.815989375 entropy_value 5.66733885 glob_norm 0.335371315\n",
      "Iteration 450 L -4.89909887 loss -4.90215397 loss_ordinary 0.763918281 entropy_value 5.66607237 glob_norm 0.282102942\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power -0.0261015892 lambd_papr -0.018058449 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86929035 loss -4.87358427 loss_ordinary 0.789175034 entropy_value 5.6627593 glob_norm 0.355705559\n",
      "Iteration 50 L -4.86949205 loss -4.86731339 loss_ordinary 0.801803052 entropy_value 5.6691165 glob_norm 0.410808474\n",
      "Iteration 100 L -4.87961054 loss -4.88416433 loss_ordinary 0.778072476 entropy_value 5.66223669 glob_norm 0.533767879\n",
      "Iteration 150 L -4.89976549 loss -4.90551949 loss_ordinary 0.764148 entropy_value 5.66966724 glob_norm 0.455747813\n",
      "Iteration 200 L -4.86919212 loss -4.87647057 loss_ordinary 0.78339982 entropy_value 5.65987062 glob_norm 0.457796752\n",
      "Iteration 250 L -4.8760705 loss -4.88427305 loss_ordinary 0.779138505 entropy_value 5.66341114 glob_norm 0.383059174\n",
      "Iteration 300 L -4.88384485 loss -4.87724543 loss_ordinary 0.783174157 entropy_value 5.66041946 glob_norm 0.32932958\n",
      "Iteration 350 L -4.89087439 loss -4.88757467 loss_ordinary 0.776370347 entropy_value 5.6639452 glob_norm 0.473769635\n",
      "Iteration 400 L -4.89306927 loss -4.8939805 loss_ordinary 0.7653898 entropy_value 5.65937042 glob_norm 0.380886853\n",
      "Iteration 450 L -4.87403917 loss -4.87031555 loss_ordinary 0.793075442 entropy_value 5.66339064 glob_norm 0.432105\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power -0.0359478 lambd_papr -0.017779652 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88838291 loss -4.89168549 loss_ordinary 0.778138578 entropy_value 5.66982365 glob_norm 0.335649192\n",
      "Iteration 50 L -4.86590624 loss -4.86048651 loss_ordinary 0.799078524 entropy_value 5.65956497 glob_norm 0.293477148\n",
      "Iteration 100 L -4.88030052 loss -4.89503098 loss_ordinary 0.763844073 entropy_value 5.65887499 glob_norm 0.433177948\n",
      "Iteration 150 L -4.87021303 loss -4.86552477 loss_ordinary 0.794021547 entropy_value 5.65954638 glob_norm 0.425985485\n",
      "Iteration 200 L -4.85353518 loss -4.8567524 loss_ordinary 0.802149832 entropy_value 5.65890217 glob_norm 0.340419501\n",
      "Iteration 250 L -4.84740639 loss -4.84669256 loss_ordinary 0.815491498 entropy_value 5.66218424 glob_norm 0.430456191\n",
      "Iteration 300 L -4.86698484 loss -4.86329031 loss_ordinary 0.80095613 entropy_value 5.66424656 glob_norm 0.355964869\n",
      "Iteration 350 L -4.85985184 loss -4.86797428 loss_ordinary 0.792778075 entropy_value 5.6607523 glob_norm 0.300766081\n",
      "Iteration 400 L -4.88380766 loss -4.8833189 loss_ordinary 0.776644766 entropy_value 5.65996361 glob_norm 0.358366787\n",
      "Iteration 450 L -4.8908987 loss -4.8954711 loss_ordinary 0.764166832 entropy_value 5.65963745 glob_norm 0.383388\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.148616791 lambd_papr -0.0173945334 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88721514 loss -4.8897047 loss_ordinary 0.770946443 entropy_value 5.66065121 glob_norm 0.335388601\n",
      "Iteration 50 L -4.88901329 loss -4.89288759 loss_ordinary 0.770406783 entropy_value 5.66329432 glob_norm 0.350615919\n",
      "Iteration 100 L -4.87305 loss -4.87423372 loss_ordinary 0.792604744 entropy_value 5.66683817 glob_norm 0.337458074\n",
      "Iteration 150 L -4.86730719 loss -4.87434196 loss_ordinary 0.789705634 entropy_value 5.66404724 glob_norm 0.3644346\n",
      "Iteration 200 L -4.88726568 loss -4.888978 loss_ordinary 0.772437036 entropy_value 5.6614151 glob_norm 0.450363725\n",
      "Iteration 250 L -4.881742 loss -4.88467741 loss_ordinary 0.778202891 entropy_value 5.66288042 glob_norm 0.463037461\n",
      "Iteration 300 L -4.85845518 loss -4.86692095 loss_ordinary 0.796480477 entropy_value 5.66340113 glob_norm 0.384809345\n",
      "Iteration 350 L -4.8995347 loss -4.89138937 loss_ordinary 0.774048269 entropy_value 5.6654377 glob_norm 0.302982897\n",
      "Iteration 400 L -4.87961435 loss -4.88317728 loss_ordinary 0.777291059 entropy_value 5.66046858 glob_norm 0.386639506\n",
      "Iteration 450 L -4.86139297 loss -4.85451412 loss_ordinary 0.799174309 entropy_value 5.65368891 glob_norm 0.420429915\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power 0.160669565 lambd_papr -0.0189914797 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89704514 loss -4.9041419 loss_ordinary 0.757946134 entropy_value 5.66208792 glob_norm 0.399799943\n",
      "Iteration 50 L -4.90045929 loss -4.89306641 loss_ordinary 0.767377555 entropy_value 5.66044378 glob_norm 0.375896841\n",
      "Iteration 100 L -4.88619471 loss -4.88252497 loss_ordinary 0.78672725 entropy_value 5.66925192 glob_norm 0.333770096\n",
      "Iteration 150 L -4.90319729 loss -4.90096283 loss_ordinary 0.756003 entropy_value 5.65696573 glob_norm 0.291274935\n",
      "Iteration 200 L -4.82452154 loss -4.83226538 loss_ordinary 0.830005825 entropy_value 5.6622715 glob_norm 0.399647534\n",
      "Iteration 250 L -4.87845755 loss -4.8813138 loss_ordinary 0.785951853 entropy_value 5.66726542 glob_norm 0.388364434\n",
      "Iteration 300 L -4.89024305 loss -4.89279032 loss_ordinary 0.769630671 entropy_value 5.66242075 glob_norm 0.440395921\n",
      "Iteration 350 L -4.86655426 loss -4.8708663 loss_ordinary 0.798863 entropy_value 5.66972971 glob_norm 0.346257418\n",
      "Iteration 400 L -4.87146616 loss -4.87225199 loss_ordinary 0.78928864 entropy_value 5.66154051 glob_norm 0.37894541\n",
      "Iteration 450 L -4.87097263 loss -4.87331581 loss_ordinary 0.792325437 entropy_value 5.66564131 glob_norm 0.358270317\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.0314631462 lambd_papr -0.0207231175 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89626074 loss -4.89475203 loss_ordinary 0.770708442 entropy_value 5.66546 glob_norm 0.322376192\n",
      "Iteration 50 L -4.87342787 loss -4.87341 loss_ordinary 0.788963854 entropy_value 5.66237402 glob_norm 0.300862163\n",
      "Iteration 100 L -4.88691759 loss -4.90226793 loss_ordinary 0.763475716 entropy_value 5.66574335 glob_norm 0.2908099\n",
      "Iteration 150 L -4.87978029 loss -4.88855124 loss_ordinary 0.77761507 entropy_value 5.66616631 glob_norm 0.345830172\n",
      "Iteration 200 L -4.89504766 loss -4.90219784 loss_ordinary 0.762376726 entropy_value 5.66457462 glob_norm 0.346235663\n",
      "Iteration 250 L -4.91437626 loss -4.90273142 loss_ordinary 0.760351777 entropy_value 5.66308308 glob_norm 0.450471282\n",
      "Iteration 300 L -4.87259 loss -4.87542057 loss_ordinary 0.790415049 entropy_value 5.66583538 glob_norm 0.374554694\n",
      "Iteration 350 L -4.88319206 loss -4.8866477 loss_ordinary 0.789443374 entropy_value 5.67609072 glob_norm 0.354098856\n",
      "Iteration 400 L -4.86774445 loss -4.87495565 loss_ordinary 0.793744743 entropy_value 5.6687 glob_norm 0.404074639\n",
      "Iteration 450 L -4.86948967 loss -4.87940836 loss_ordinary 0.786832631 entropy_value 5.66624069 glob_norm 0.336026549\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power -0.351993799 lambd_papr -0.0210632328 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90904236 loss -4.90764 loss_ordinary 0.757970631 entropy_value 5.66561079 glob_norm 0.375540823\n",
      "Iteration 50 L -4.89389801 loss -4.89652205 loss_ordinary 0.764481246 entropy_value 5.66100359 glob_norm 0.369150668\n",
      "Iteration 100 L -4.87473392 loss -4.87602472 loss_ordinary 0.781998754 entropy_value 5.65802336 glob_norm 0.552398264\n",
      "Iteration 150 L -4.85718918 loss -4.86317444 loss_ordinary 0.801147819 entropy_value 5.66432238 glob_norm 0.344170153\n",
      "Iteration 200 L -4.88645077 loss -4.89652491 loss_ordinary 0.765093207 entropy_value 5.66161776 glob_norm 0.354828656\n",
      "Iteration 250 L -4.86423731 loss -4.86750126 loss_ordinary 0.796741843 entropy_value 5.66424322 glob_norm 0.33794117\n",
      "Iteration 300 L -4.89284611 loss -4.89252 loss_ordinary 0.765566 entropy_value 5.65808582 glob_norm 0.366122067\n",
      "Iteration 350 L -4.86901093 loss -4.86948299 loss_ordinary 0.789109 entropy_value 5.65859222 glob_norm 0.424838603\n",
      "Iteration 400 L -4.892735 loss -4.88903761 loss_ordinary 0.775322795 entropy_value 5.66436052 glob_norm 0.610905468\n",
      "Iteration 450 L -4.8903327 loss -4.89689302 loss_ordinary 0.765286267 entropy_value 5.66217947 glob_norm 0.292487651\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power -0.0927109718 lambd_papr -0.0172467753 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85432339 loss -4.85726547 loss_ordinary 0.80957669 entropy_value 5.66684198 glob_norm 0.373291552\n",
      "Iteration 50 L -4.90909767 loss -4.9143548 loss_ordinary 0.745193422 entropy_value 5.65954828 glob_norm 0.312999606\n",
      "Iteration 100 L -4.87525463 loss -4.87926245 loss_ordinary 0.777653098 entropy_value 5.65691566 glob_norm 0.470271021\n",
      "Iteration 150 L -4.89439392 loss -4.89548826 loss_ordinary 0.758072495 entropy_value 5.65356064 glob_norm 0.49999246\n",
      "Iteration 200 L -4.88501 loss -4.89112711 loss_ordinary 0.763673186 entropy_value 5.6548 glob_norm 0.320765644\n",
      "Iteration 250 L -4.87252903 loss -4.8786 loss_ordinary 0.778591752 entropy_value 5.65719175 glob_norm 0.266688\n",
      "Iteration 300 L -4.8800416 loss -4.88044262 loss_ordinary 0.785007834 entropy_value 5.66545057 glob_norm 0.442663908\n",
      "Iteration 350 L -4.90223789 loss -4.90483093 loss_ordinary 0.763302147 entropy_value 5.66813326 glob_norm 0.391524404\n",
      "Iteration 400 L -4.88065243 loss -4.87683725 loss_ordinary 0.782960534 entropy_value 5.65979815 glob_norm 0.370445311\n",
      "Iteration 450 L -4.85538912 loss -4.85878563 loss_ordinary 0.803557217 entropy_value 5.66234303 glob_norm 0.375707448\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power -0.236711025 lambd_papr -0.0162385497 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85591936 loss -4.86342144 loss_ordinary 0.793765604 entropy_value 5.65718699 glob_norm 0.393189639\n",
      "Iteration 50 L -4.87648582 loss -4.88111877 loss_ordinary 0.776602209 entropy_value 5.65772057 glob_norm 0.339172333\n",
      "Iteration 100 L -4.89214945 loss -4.89233398 loss_ordinary 0.76353538 entropy_value 5.65586948 glob_norm 0.390945494\n",
      "Iteration 150 L -4.87330389 loss -4.87986469 loss_ordinary 0.77585721 entropy_value 5.65572166 glob_norm 0.353250325\n",
      "Iteration 200 L -4.87943316 loss -4.88279057 loss_ordinary 0.77165 entropy_value 5.65444088 glob_norm 0.336350113\n",
      "Iteration 250 L -4.9096446 loss -4.91228104 loss_ordinary 0.744848 entropy_value 5.65712929 glob_norm 0.361627787\n",
      "Iteration 300 L -4.89162874 loss -4.89654827 loss_ordinary 0.76085794 entropy_value 5.65740633 glob_norm 0.478528976\n",
      "Iteration 350 L -4.87049913 loss -4.87592554 loss_ordinary 0.787947953 entropy_value 5.6638732 glob_norm 0.304954052\n",
      "Iteration 400 L -4.88160181 loss -4.88638973 loss_ordinary 0.764705539 entropy_value 5.65109539 glob_norm 0.369429588\n",
      "Iteration 450 L -4.88976336 loss -4.89181709 loss_ordinary 0.762188256 entropy_value 5.65400505 glob_norm 0.391949922\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.0752024651 lambd_papr -0.0136566116 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.9060216 loss -4.90773058 loss_ordinary 0.747281492 entropy_value 5.65501213 glob_norm 0.329261601\n",
      "Iteration 50 L -4.92585039 loss -4.92649412 loss_ordinary 0.732667089 entropy_value 5.65916109 glob_norm 0.485882699\n",
      "Iteration 100 L -4.88035917 loss -4.88004684 loss_ordinary 0.776764214 entropy_value 5.65681076 glob_norm 0.365520567\n",
      "Iteration 150 L -4.87758636 loss -4.88091087 loss_ordinary 0.779290199 entropy_value 5.66020107 glob_norm 0.3108899\n",
      "Iteration 200 L -4.91287374 loss -4.91309214 loss_ordinary 0.741927207 entropy_value 5.65501928 glob_norm 0.342262268\n",
      "Iteration 250 L -4.8857832 loss -4.88222122 loss_ordinary 0.774505794 entropy_value 5.65672731 glob_norm 0.380812913\n",
      "Iteration 300 L -4.86494398 loss -4.87015629 loss_ordinary 0.790816784 entropy_value 5.66097307 glob_norm 0.454523683\n",
      "Iteration 350 L -4.91353464 loss -4.91792536 loss_ordinary 0.739288 entropy_value 5.65721321 glob_norm 0.448186189\n",
      "Iteration 400 L -4.86752224 loss -4.866467 loss_ordinary 0.791427672 entropy_value 5.65789461 glob_norm 0.508114636\n",
      "Iteration 450 L -4.87080097 loss -4.87761307 loss_ordinary 0.779204607 entropy_value 5.65681744 glob_norm 0.370434523\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0.304824114 lambd_papr -0.0144793475 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87567234 loss -4.87871456 loss_ordinary 0.784431 entropy_value 5.66314554 glob_norm 0.478979558\n",
      "Iteration 50 L -4.89263487 loss -4.89612579 loss_ordinary 0.765730917 entropy_value 5.66185713 glob_norm 0.383839607\n",
      "Iteration 100 L -4.9117775 loss -4.91821814 loss_ordinary 0.742005408 entropy_value 5.66022348 glob_norm 0.355329335\n",
      "Iteration 150 L -4.86576 loss -4.86985731 loss_ordinary 0.786977649 entropy_value 5.65683508 glob_norm 0.459626794\n",
      "Iteration 200 L -4.8568964 loss -4.86674309 loss_ordinary 0.799827218 entropy_value 5.66657 glob_norm 0.460409284\n",
      "Iteration 250 L -4.86516953 loss -4.86493731 loss_ordinary 0.794944763 entropy_value 5.65988207 glob_norm 0.463189065\n",
      "Iteration 300 L -4.89420605 loss -4.89248085 loss_ordinary 0.770147502 entropy_value 5.66262865 glob_norm 0.491699666\n",
      "Iteration 350 L -4.91862345 loss -4.91361189 loss_ordinary 0.746555328 entropy_value 5.66016722 glob_norm 0.375031769\n",
      "Iteration 400 L -4.89405298 loss -4.89768887 loss_ordinary 0.762508273 entropy_value 5.66019678 glob_norm 0.347790748\n",
      "Iteration 450 L -4.88450956 loss -4.8902235 loss_ordinary 0.773859203 entropy_value 5.66408253 glob_norm 0.459641635\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0.0329723358 lambd_papr -0.0178242121 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87118816 loss -4.87706 loss_ordinary 0.780679286 entropy_value 5.65773916 glob_norm 0.38687405\n",
      "Iteration 50 L -4.88308048 loss -4.88638783 loss_ordinary 0.77385211 entropy_value 5.66024 glob_norm 0.364990026\n",
      "Iteration 100 L -4.86486244 loss -4.85920858 loss_ordinary 0.805265784 entropy_value 5.66447401 glob_norm 0.395465314\n",
      "Iteration 150 L -4.87137508 loss -4.86678076 loss_ordinary 0.796032548 entropy_value 5.66281366 glob_norm 0.415381104\n",
      "Iteration 200 L -4.88728857 loss -4.89655399 loss_ordinary 0.760482907 entropy_value 5.65703678 glob_norm 0.336630255\n",
      "Iteration 250 L -4.88553286 loss -4.88851643 loss_ordinary 0.77457726 entropy_value 5.66309357 glob_norm 0.31924212\n",
      "Iteration 300 L -4.89720106 loss -4.88950872 loss_ordinary 0.77003479 entropy_value 5.65954351 glob_norm 0.353978217\n",
      "Iteration 350 L -4.87353468 loss -4.88134193 loss_ordinary 0.780054033 entropy_value 5.66139603 glob_norm 0.378355652\n",
      "Iteration 400 L -4.83086824 loss -4.83535671 loss_ordinary 0.826022923 entropy_value 5.66137934 glob_norm 0.404779524\n",
      "Iteration 450 L -4.86828566 loss -4.86799 loss_ordinary 0.794518411 entropy_value 5.66250896 glob_norm 0.309083611\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power -0.149737835 lambd_papr -0.0181871057 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87533712 loss -4.88599873 loss_ordinary 0.779101193 entropy_value 5.66509962 glob_norm 0.363454759\n",
      "Iteration 50 L -4.86070347 loss -4.86731 loss_ordinary 0.794095159 entropy_value 5.66140509 glob_norm 0.377637208\n",
      "Iteration 100 L -4.88511467 loss -4.89243507 loss_ordinary 0.76748991 entropy_value 5.65992498 glob_norm 0.411714077\n",
      "Iteration 150 L -4.84896421 loss -4.85348701 loss_ordinary 0.808633626 entropy_value 5.66212082 glob_norm 0.436684787\n",
      "Iteration 200 L -4.89784813 loss -4.90011358 loss_ordinary 0.762379646 entropy_value 5.66249371 glob_norm 0.472002953\n",
      "Iteration 250 L -4.87524462 loss -4.87988234 loss_ordinary 0.786352634 entropy_value 5.66623545 glob_norm 0.348433048\n",
      "Iteration 300 L -4.91510153 loss -4.91757536 loss_ordinary 0.740227222 entropy_value 5.65780258 glob_norm 0.266549051\n",
      "Iteration 350 L -4.87940931 loss -4.87421608 loss_ordinary 0.78118217 entropy_value 5.65539837 glob_norm 0.367708772\n",
      "Iteration 400 L -4.88245 loss -4.87862062 loss_ordinary 0.782112241 entropy_value 5.66073275 glob_norm 0.326418\n",
      "Iteration 450 L -4.85244894 loss -4.86020279 loss_ordinary 0.7997697 entropy_value 5.65997219 glob_norm 0.339764267\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0.31616354 lambd_papr -0.0165341441 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89971876 loss -4.9023838 loss_ordinary 0.75613451 entropy_value 5.65851784 glob_norm 0.447126418\n",
      "Iteration 50 L -4.88854742 loss -4.88437033 loss_ordinary 0.781514287 entropy_value 5.66588449 glob_norm 0.484247208\n",
      "Iteration 100 L -4.86993933 loss -4.87258959 loss_ordinary 0.797359049 entropy_value 5.66994858 glob_norm 0.371144474\n",
      "Iteration 150 L -4.89663219 loss -4.89588118 loss_ordinary 0.770640671 entropy_value 5.66652203 glob_norm 0.371000469\n",
      "Iteration 200 L -4.88130283 loss -4.88532591 loss_ordinary 0.77994442 entropy_value 5.66527033 glob_norm 0.335174084\n",
      "Iteration 250 L -4.8883543 loss -4.88289547 loss_ordinary 0.786864102 entropy_value 5.66975975 glob_norm 0.402276665\n",
      "Iteration 300 L -4.88617516 loss -4.88338614 loss_ordinary 0.778079927 entropy_value 5.66146612 glob_norm 0.340183467\n",
      "Iteration 350 L -4.86539888 loss -4.87018204 loss_ordinary 0.797122478 entropy_value 5.66730452 glob_norm 0.544194579\n",
      "Iteration 400 L -4.88359642 loss -4.88195848 loss_ordinary 0.784927964 entropy_value 5.66688681 glob_norm 0.314921379\n",
      "Iteration 450 L -4.87789822 loss -4.88169622 loss_ordinary 0.778059483 entropy_value 5.65975571 glob_norm 0.417061418\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0.0127539635 lambd_papr -0.0200347546 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.85570049 loss -4.85749149 loss_ordinary 0.802850187 entropy_value 5.66034174 glob_norm 0.369353503\n",
      "Iteration 50 L -4.88856268 loss -4.89429808 loss_ordinary 0.769301713 entropy_value 5.6636 glob_norm 0.444958121\n",
      "Iteration 100 L -4.88159657 loss -4.86460161 loss_ordinary 0.797139049 entropy_value 5.6617403 glob_norm 0.505231559\n",
      "Iteration 150 L -4.87806 loss -4.88418388 loss_ordinary 0.78125906 entropy_value 5.66544294 glob_norm 0.375938535\n",
      "Iteration 200 L -4.88272333 loss -4.88313103 loss_ordinary 0.779185593 entropy_value 5.6623168 glob_norm 0.439006716\n",
      "Iteration 250 L -4.85955048 loss -4.86725 loss_ordinary 0.793082178 entropy_value 5.6603322 glob_norm 0.394146293\n",
      "Iteration 300 L -4.90483284 loss -4.90195179 loss_ordinary 0.763480484 entropy_value 5.66543245 glob_norm 0.348255038\n",
      "Iteration 350 L -4.88930702 loss -4.88352156 loss_ordinary 0.782548547 entropy_value 5.66607 glob_norm 0.485531241\n",
      "Iteration 400 L -4.87599564 loss -4.87259674 loss_ordinary 0.793586731 entropy_value 5.66618347 glob_norm 0.418445408\n",
      "Iteration 450 L -4.8994565 loss -4.90258598 loss_ordinary 0.764723837 entropy_value 5.66730976 glob_norm 0.330736756\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.14980197 lambd_papr -0.020176392 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88889551 loss -4.89627218 loss_ordinary 0.763906956 entropy_value 5.66017914 glob_norm 0.577885568\n",
      "Iteration 50 L -4.88135195 loss -4.88503933 loss_ordinary 0.780298948 entropy_value 5.66533852 glob_norm 0.303964227\n",
      "Iteration 100 L -4.86854553 loss -4.86780643 loss_ordinary 0.802087843 entropy_value 5.66989422 glob_norm 0.388925225\n",
      "Iteration 150 L -4.86101389 loss -4.85989141 loss_ordinary 0.807779729 entropy_value 5.6676712 glob_norm 0.404819757\n",
      "Iteration 200 L -4.84368038 loss -4.85049343 loss_ordinary 0.812704682 entropy_value 5.66319799 glob_norm 0.584981501\n",
      "Iteration 250 L -4.87381506 loss -4.86907 loss_ordinary 0.797241211 entropy_value 5.66631174 glob_norm 0.361890554\n",
      "Iteration 300 L -4.87057972 loss -4.87295246 loss_ordinary 0.790672183 entropy_value 5.66362476 glob_norm 0.371151507\n",
      "Iteration 350 L -4.93862295 loss -4.92621851 loss_ordinary 0.743018687 entropy_value 5.66923714 glob_norm 0.290456027\n",
      "Iteration 400 L -4.87702227 loss -4.87098932 loss_ordinary 0.798189759 entropy_value 5.66917896 glob_norm 0.353540301\n",
      "Iteration 450 L -4.9000349 loss -4.90241575 loss_ordinary 0.764018834 entropy_value 5.66643476 glob_norm 0.276653498\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power 0.141029119 lambd_papr -0.0218449887 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89594 loss -4.89322472 loss_ordinary 0.770581901 entropy_value 5.66380692 glob_norm 0.469446242\n",
      "Iteration 50 L -4.8848691 loss -4.89159966 loss_ordinary 0.775639 entropy_value 5.66723871 glob_norm 0.468393\n",
      "Iteration 100 L -4.85073137 loss -4.85533094 loss_ordinary 0.805301964 entropy_value 5.66063261 glob_norm 0.366220623\n",
      "Iteration 150 L -4.87833071 loss -4.88547754 loss_ordinary 0.777448237 entropy_value 5.66292572 glob_norm 0.31705603\n",
      "Iteration 200 L -4.88782644 loss -4.89213085 loss_ordinary 0.777481616 entropy_value 5.66961241 glob_norm 0.337787569\n",
      "Iteration 250 L -4.85308218 loss -4.85444546 loss_ordinary 0.813976 entropy_value 5.66842175 glob_norm 0.267353922\n",
      "Iteration 300 L -4.88635826 loss -4.88261795 loss_ordinary 0.79315269 entropy_value 5.67577076 glob_norm 0.506584048\n",
      "Iteration 350 L -4.87605286 loss -4.87812662 loss_ordinary 0.789169192 entropy_value 5.66729593 glob_norm 0.300111204\n",
      "Iteration 400 L -4.87903404 loss -4.8796854 loss_ordinary 0.787985384 entropy_value 5.66767073 glob_norm 0.33778584\n",
      "Iteration 450 L -4.86869049 loss -4.86662245 loss_ordinary 0.801414549 entropy_value 5.66803694 glob_norm 0.311224878\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.235502481 lambd_papr -0.0234205797 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86941 loss -4.85614681 loss_ordinary 0.8122226 entropy_value 5.66836929 glob_norm 0.485218734\n",
      "Iteration 50 L -4.90401173 loss -4.89452457 loss_ordinary 0.779850304 entropy_value 5.67437458 glob_norm 0.357193828\n",
      "Iteration 100 L -4.88487911 loss -4.87683868 loss_ordinary 0.794998407 entropy_value 5.67183733 glob_norm 0.414912164\n",
      "Iteration 150 L -4.85736132 loss -4.8568573 loss_ordinary 0.812528253 entropy_value 5.66938543 glob_norm 0.351099968\n",
      "Iteration 200 L -4.8946681 loss -4.89202595 loss_ordinary 0.778086841 entropy_value 5.67011261 glob_norm 0.311285\n",
      "Iteration 250 L -4.8560853 loss -4.86098146 loss_ordinary 0.813707292 entropy_value 5.67468882 glob_norm 0.304087877\n",
      "Iteration 300 L -4.88639545 loss -4.87739182 loss_ordinary 0.792823911 entropy_value 5.67021561 glob_norm 0.348187804\n",
      "Iteration 350 L -4.86870813 loss -4.86633158 loss_ordinary 0.806909 entropy_value 5.67324066 glob_norm 0.325386196\n",
      "Iteration 400 L -4.87526655 loss -4.87547302 loss_ordinary 0.795533597 entropy_value 5.67100668 glob_norm 0.381458\n",
      "Iteration 450 L -4.84877634 loss -4.84593201 loss_ordinary 0.82817477 entropy_value 5.67410707 glob_norm 0.42291379\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.105236769 lambd_papr -0.0260595307 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87651443 loss -4.8702817 loss_ordinary 0.800076962 entropy_value 5.67035866 glob_norm 0.400404125\n",
      "Iteration 50 L -4.89492702 loss -4.88367081 loss_ordinary 0.785641789 entropy_value 5.66931295 glob_norm 0.444512635\n",
      "Iteration 100 L -4.85582209 loss -4.85824776 loss_ordinary 0.809845805 entropy_value 5.6680932 glob_norm 0.353742331\n",
      "Iteration 150 L -4.86855412 loss -4.8648138 loss_ordinary 0.809924245 entropy_value 5.67473793 glob_norm 0.33170408\n",
      "Iteration 200 L -4.9106369 loss -4.8869772 loss_ordinary 0.789015114 entropy_value 5.67599249 glob_norm 0.508926928\n",
      "Iteration 250 L -4.87822914 loss -4.87377 loss_ordinary 0.796205878 entropy_value 5.66997623 glob_norm 0.362180322\n",
      "Iteration 300 L -4.89646387 loss -4.89359283 loss_ordinary 0.773857057 entropy_value 5.66745 glob_norm 0.491955131\n",
      "Iteration 350 L -4.87744284 loss -4.87796879 loss_ordinary 0.794656515 entropy_value 5.67262506 glob_norm 0.357052892\n",
      "Iteration 400 L -4.86501074 loss -4.86861897 loss_ordinary 0.805248141 entropy_value 5.67386723 glob_norm 0.414856702\n",
      "Iteration 450 L -4.89206314 loss -4.89541721 loss_ordinary 0.772242665 entropy_value 5.66765976 glob_norm 0.327496022\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power -0.0358822346 lambd_papr -0.024876751 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8764348 loss -4.88407326 loss_ordinary 0.788962841 entropy_value 5.6730361 glob_norm 0.483823925\n",
      "Iteration 50 L -4.86122417 loss -4.86046171 loss_ordinary 0.815346181 entropy_value 5.67580795 glob_norm 0.310194254\n",
      "Iteration 100 L -4.91217232 loss -4.90244818 loss_ordinary 0.77028507 entropy_value 5.67273331 glob_norm 0.327435046\n",
      "Iteration 150 L -4.91324663 loss -4.91510725 loss_ordinary 0.752519 entropy_value 5.66762638 glob_norm 0.366042674\n",
      "Iteration 200 L -4.88853884 loss -4.89342403 loss_ordinary 0.773393154 entropy_value 5.66681719 glob_norm 0.488555163\n",
      "Iteration 250 L -4.87488174 loss -4.86848879 loss_ordinary 0.805500269 entropy_value 5.6739893 glob_norm 0.377366364\n",
      "Iteration 300 L -4.87213755 loss -4.86683846 loss_ordinary 0.800417662 entropy_value 5.66725588 glob_norm 0.472998619\n",
      "Iteration 350 L -4.91128302 loss -4.89152718 loss_ordinary 0.777562857 entropy_value 5.66909027 glob_norm 0.43639338\n",
      "Iteration 400 L -4.89494848 loss -4.8911109 loss_ordinary 0.782333612 entropy_value 5.67344427 glob_norm 0.488206595\n",
      "Iteration 450 L -4.86094284 loss -4.85820723 loss_ordinary 0.811376929 entropy_value 5.66958427 glob_norm 0.35577935\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power -0.293261766 lambd_papr -0.0244722515 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86327744 loss -4.85816145 loss_ordinary 0.809300184 entropy_value 5.6674614 glob_norm 0.329765916\n",
      "Iteration 50 L -4.85301161 loss -4.85310698 loss_ordinary 0.815971 entropy_value 5.66907787 glob_norm 0.347762823\n",
      "Iteration 100 L -4.88146114 loss -4.8767972 loss_ordinary 0.792516351 entropy_value 5.66931391 glob_norm 0.350426555\n",
      "Iteration 150 L -4.88053417 loss -4.87951 loss_ordinary 0.796487689 entropy_value 5.67599773 glob_norm 0.333446711\n",
      "Iteration 200 L -4.88947248 loss -4.88496 loss_ordinary 0.786491156 entropy_value 5.67145109 glob_norm 0.409867823\n",
      "Iteration 250 L -4.90606165 loss -4.90017509 loss_ordinary 0.767559946 entropy_value 5.6677351 glob_norm 0.357182562\n",
      "Iteration 300 L -4.90995598 loss -4.91151524 loss_ordinary 0.756441236 entropy_value 5.66795635 glob_norm 0.666509867\n",
      "Iteration 350 L -4.87707424 loss -4.87767363 loss_ordinary 0.789677501 entropy_value 5.66735125 glob_norm 0.381594926\n",
      "Iteration 400 L -4.90039968 loss -4.8937993 loss_ordinary 0.776812077 entropy_value 5.67061138 glob_norm 0.383094937\n",
      "Iteration 450 L -4.86889219 loss -4.85290384 loss_ordinary 0.815467238 entropy_value 5.6683712 glob_norm 0.358670056\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0.0486397743 lambd_papr -0.0211564079 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86854935 loss -4.8680172 loss_ordinary 0.800661445 entropy_value 5.66867828 glob_norm 0.278545767\n",
      "Iteration 50 L -4.90869093 loss -4.90804338 loss_ordinary 0.761519372 entropy_value 5.66956282 glob_norm 0.383074641\n",
      "Iteration 100 L -4.88268328 loss -4.88765907 loss_ordinary 0.779225588 entropy_value 5.6668849 glob_norm 0.467404604\n",
      "Iteration 150 L -4.86695 loss -4.8694582 loss_ordinary 0.788960934 entropy_value 5.65841913 glob_norm 0.471785486\n",
      "Iteration 200 L -4.87322617 loss -4.87139273 loss_ordinary 0.794011354 entropy_value 5.66540432 glob_norm 0.409872234\n",
      "Iteration 250 L -4.88360643 loss -4.89090824 loss_ordinary 0.773702204 entropy_value 5.66461039 glob_norm 0.410985976\n",
      "Iteration 300 L -4.88501024 loss -4.88612604 loss_ordinary 0.786421 entropy_value 5.67254686 glob_norm 0.332258552\n",
      "Iteration 350 L -4.89721489 loss -4.89479589 loss_ordinary 0.772534549 entropy_value 5.66733027 glob_norm 0.315243453\n",
      "Iteration 400 L -4.90478849 loss -4.90141439 loss_ordinary 0.76710695 entropy_value 5.6685214 glob_norm 0.46197629\n",
      "Iteration 450 L -4.89238739 loss -4.89393282 loss_ordinary 0.772631884 entropy_value 5.66656494 glob_norm 0.335021\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.0250537395 lambd_papr -0.0217080172 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87213564 loss -4.87979698 loss_ordinary 0.783308744 entropy_value 5.66310596 glob_norm 0.284349203\n",
      "Iteration 50 L -4.86699677 loss -4.87648821 loss_ordinary 0.794658065 entropy_value 5.67114639 glob_norm 0.31488362\n",
      "Iteration 100 L -4.87955141 loss -4.88136148 loss_ordinary 0.7843045 entropy_value 5.6656661 glob_norm 0.412155747\n",
      "Iteration 150 L -4.87721443 loss -4.87195969 loss_ordinary 0.79703486 entropy_value 5.66899443 glob_norm 0.439833224\n",
      "Iteration 200 L -4.88198233 loss -4.87589312 loss_ordinary 0.786153913 entropy_value 5.66204739 glob_norm 0.396089822\n",
      "Iteration 250 L -4.86020374 loss -4.86154795 loss_ordinary 0.805090606 entropy_value 5.66663837 glob_norm 0.295458972\n",
      "Iteration 300 L -4.89985037 loss -4.89786768 loss_ordinary 0.764798403 entropy_value 5.66266632 glob_norm 0.291275144\n",
      "Iteration 350 L -4.85270262 loss -4.84933376 loss_ordinary 0.818830132 entropy_value 5.66816378 glob_norm 0.389060974\n",
      "Iteration 400 L -4.91231155 loss -4.91195583 loss_ordinary 0.754265666 entropy_value 5.66622162 glob_norm 0.315582812\n",
      "Iteration 450 L -4.84832859 loss -4.8519454 loss_ordinary 0.802283764 entropy_value 5.65422964 glob_norm 0.475817949\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.212409735 lambd_papr -0.0214230381 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88141537 loss -4.88103628 loss_ordinary 0.786973357 entropy_value 5.66800928 glob_norm 0.313607484\n",
      "Iteration 50 L -4.85988 loss -4.86207199 loss_ordinary 0.804066181 entropy_value 5.6661377 glob_norm 0.342497975\n",
      "Iteration 100 L -4.86436605 loss -4.85806274 loss_ordinary 0.813664556 entropy_value 5.67172718 glob_norm 0.343277216\n",
      "Iteration 150 L -4.86384439 loss -4.86790657 loss_ordinary 0.802099228 entropy_value 5.6700058 glob_norm 0.424932957\n",
      "Iteration 200 L -4.88745546 loss -4.88583517 loss_ordinary 0.779480636 entropy_value 5.66531563 glob_norm 0.461649269\n",
      "Iteration 250 L -4.88344145 loss -4.88761 loss_ordinary 0.780930877 entropy_value 5.66854095 glob_norm 0.376129955\n",
      "Iteration 300 L -4.91479349 loss -4.90349913 loss_ordinary 0.766556144 entropy_value 5.67005539 glob_norm 0.352096051\n",
      "Iteration 350 L -4.84754229 loss -4.84149456 loss_ordinary 0.832708359 entropy_value 5.67420292 glob_norm 0.408340275\n",
      "Iteration 400 L -4.90607262 loss -4.89253473 loss_ordinary 0.775349736 entropy_value 5.66788435 glob_norm 0.300451458\n",
      "Iteration 450 L -4.88699341 loss -4.8930645 loss_ordinary 0.774038851 entropy_value 5.66710329 glob_norm 0.406470239\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power -0.295594692 lambd_papr -0.023846386 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8657136 loss -4.86714315 loss_ordinary 0.809363484 entropy_value 5.676507 glob_norm 0.326202214\n",
      "Iteration 50 L -4.90965414 loss -4.90017128 loss_ordinary 0.771322489 entropy_value 5.67149401 glob_norm 0.292367131\n",
      "Iteration 100 L -4.87263155 loss -4.86983681 loss_ordinary 0.788979888 entropy_value 5.65881681 glob_norm 0.425596356\n",
      "Iteration 150 L -4.8890295 loss -4.88443899 loss_ordinary 0.778639078 entropy_value 5.66307783 glob_norm 0.323714137\n",
      "Iteration 200 L -4.8902483 loss -4.88951635 loss_ordinary 0.771853328 entropy_value 5.66136932 glob_norm 0.310619324\n",
      "Iteration 250 L -4.90543079 loss -4.89519024 loss_ordinary 0.764680922 entropy_value 5.6598711 glob_norm 0.382990241\n",
      "Iteration 300 L -4.89022303 loss -4.89337397 loss_ordinary 0.766711056 entropy_value 5.66008472 glob_norm 0.346069872\n",
      "Iteration 350 L -4.8941493 loss -4.89103127 loss_ordinary 0.77109915 entropy_value 5.66213036 glob_norm 0.504481852\n",
      "Iteration 400 L -4.89177656 loss -4.88931894 loss_ordinary 0.776821375 entropy_value 5.66614056 glob_norm 0.364924669\n",
      "Iteration 450 L -4.88384151 loss -4.88035583 loss_ordinary 0.787455916 entropy_value 5.66781187 glob_norm 0.371276736\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power -0.0551154613 lambd_papr -0.0204638764 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90499258 loss -4.89860296 loss_ordinary 0.762699902 entropy_value 5.66130304 glob_norm 0.312532097\n",
      "Iteration 50 L -4.85709906 loss -4.85253668 loss_ordinary 0.80985409 entropy_value 5.66239 glob_norm 0.427504033\n",
      "Iteration 100 L -4.89617586 loss -4.90216875 loss_ordinary 0.758791745 entropy_value 5.66096 glob_norm 0.399390906\n",
      "Iteration 150 L -4.87950802 loss -4.88728857 loss_ordinary 0.775611639 entropy_value 5.6629 glob_norm 0.277745932\n",
      "Iteration 200 L -4.88071394 loss -4.88444471 loss_ordinary 0.7743572 entropy_value 5.65880203 glob_norm 0.287652373\n",
      "Iteration 250 L -4.82802057 loss -4.83716917 loss_ordinary 0.833041191 entropy_value 5.67021036 glob_norm 0.407483578\n",
      "Iteration 300 L -4.86998415 loss -4.87127638 loss_ordinary 0.789531589 entropy_value 5.66080809 glob_norm 0.326350629\n",
      "Iteration 350 L -4.8801 loss -4.87093306 loss_ordinary 0.79525274 entropy_value 5.66618586 glob_norm 0.31621626\n",
      "Iteration 400 L -4.89682674 loss -4.8833127 loss_ordinary 0.777855158 entropy_value 5.6611681 glob_norm 0.428321958\n",
      "Iteration 450 L -4.90635872 loss -4.90737295 loss_ordinary 0.755928397 entropy_value 5.66330147 glob_norm 0.349785\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.122676611 lambd_papr -0.0198312942 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87268162 loss -4.8792057 loss_ordinary 0.787535548 entropy_value 5.66674137 glob_norm 0.424386889\n",
      "Iteration 50 L -4.86019611 loss -4.85729265 loss_ordinary 0.804990947 entropy_value 5.66228342 glob_norm 0.361231238\n",
      "Iteration 100 L -4.88146782 loss -4.87205267 loss_ordinary 0.792425275 entropy_value 5.66447783 glob_norm 0.451384693\n",
      "Iteration 150 L -4.8748126 loss -4.87397814 loss_ordinary 0.794086814 entropy_value 5.66806459 glob_norm 0.331714183\n",
      "Iteration 200 L -4.84330463 loss -4.85235405 loss_ordinary 0.815737963 entropy_value 5.66809225 glob_norm 0.431951612\n",
      "Iteration 250 L -4.87595463 loss -4.88424587 loss_ordinary 0.789028764 entropy_value 5.67327499 glob_norm 0.411064267\n",
      "Iteration 300 L -4.89958239 loss -4.9003706 loss_ordinary 0.764404237 entropy_value 5.66477489 glob_norm 0.280520737\n",
      "Iteration 350 L -4.88360357 loss -4.88260508 loss_ordinary 0.779574811 entropy_value 5.66218042 glob_norm 0.486238867\n",
      "Iteration 400 L -4.86329174 loss -4.85068 loss_ordinary 0.812835932 entropy_value 5.66351604 glob_norm 0.400978774\n",
      "Iteration 450 L -4.90709209 loss -4.91418886 loss_ordinary 0.74875778 entropy_value 5.6629467 glob_norm 0.460715294\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0.150523901 lambd_papr -0.0212435257 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86436129 loss -4.86240578 loss_ordinary 0.804524362 entropy_value 5.66693 glob_norm 0.34649837\n",
      "Iteration 50 L -4.86450768 loss -4.86776257 loss_ordinary 0.794416249 entropy_value 5.66217852 glob_norm 0.367587358\n",
      "Iteration 100 L -4.90597677 loss -4.88091135 loss_ordinary 0.783518195 entropy_value 5.66442966 glob_norm 0.30618608\n",
      "Iteration 150 L -4.89532042 loss -4.90175295 loss_ordinary 0.760128677 entropy_value 5.66188145 glob_norm 0.355874509\n",
      "Iteration 200 L -4.8696022 loss -4.85859919 loss_ordinary 0.805734038 entropy_value 5.66433334 glob_norm 0.339846939\n",
      "Iteration 250 L -4.91112 loss -4.91052437 loss_ordinary 0.755715489 entropy_value 5.66623974 glob_norm 0.347473532\n",
      "Iteration 300 L -4.84050894 loss -4.84766245 loss_ordinary 0.824545503 entropy_value 5.67220783 glob_norm 0.344165295\n",
      "Iteration 350 L -4.87297106 loss -4.87740755 loss_ordinary 0.788750589 entropy_value 5.6661582 glob_norm 0.349028528\n",
      "Iteration 400 L -4.89769125 loss -4.89582253 loss_ordinary 0.773372114 entropy_value 5.6691947 glob_norm 0.411164403\n",
      "Iteration 450 L -4.86735 loss -4.86019659 loss_ordinary 0.80887568 entropy_value 5.66907215 glob_norm 0.378095806\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.0822041 lambd_papr -0.0229815282 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_15_papr_7.0\n",
      "\n",
      "===== Running SNR=15 dB | PAPR=8.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0150388507 loss 0.0150388507 loss_ordinary 6.00622225 entropy_value 5.99118328 glob_norm 0.638605893\n",
      "Iteration 50 L -3.11649275 loss -3.11649275 loss_ordinary 2.84935832 entropy_value 5.96585083 glob_norm 0.430078924\n",
      "Iteration 100 L -4.00618887 loss -4.00618887 loss_ordinary 1.94972777 entropy_value 5.95591688 glob_norm 0.399299264\n",
      "Iteration 150 L -4.31853342 loss -4.31853342 loss_ordinary 1.60053277 entropy_value 5.91906643 glob_norm 0.308856398\n",
      "Iteration 200 L -4.58760881 loss -4.58760881 loss_ordinary 1.21658826 entropy_value 5.80419683 glob_norm 0.349347919\n",
      "Iteration 250 L -4.74787283 loss -4.74787283 loss_ordinary 0.9847188 entropy_value 5.73259163 glob_norm 0.58736378\n",
      "Iteration 300 L -4.82398033 loss -4.82398033 loss_ordinary 0.863361061 entropy_value 5.68734121 glob_norm 0.270985335\n",
      "Iteration 350 L -4.84952545 loss -4.84952545 loss_ordinary 0.813197911 entropy_value 5.66272354 glob_norm 0.352582812\n",
      "Iteration 400 L -4.88072252 loss -4.88073397 loss_ordinary 0.773353159 entropy_value 5.65408754 glob_norm 0.295876771\n",
      "Iteration 450 L -4.89674282 loss -4.89674282 loss_ordinary 0.744494081 entropy_value 5.64123678 glob_norm 0.362661958\n",
      "Iteration 500 L -4.84424496 loss -4.84424496 loss_ordinary 0.803541601 entropy_value 5.64778662 glob_norm 0.438659132\n",
      "Iteration 550 L -4.88451099 loss -4.88451099 loss_ordinary 0.749624789 entropy_value 5.63413572 glob_norm 0.285419971\n",
      "Iteration 600 L -4.91184425 loss -4.91184425 loss_ordinary 0.722349 entropy_value 5.63419342 glob_norm 0.37343207\n",
      "Iteration 650 L -4.89551926 loss -4.89551926 loss_ordinary 0.735148966 entropy_value 5.63066816 glob_norm 0.309659302\n",
      "Iteration 700 L -4.90476418 loss -4.90476418 loss_ordinary 0.720497608 entropy_value 5.62526178 glob_norm 0.397213042\n",
      "Iteration 750 L -4.86132 loss -4.86132 loss_ordinary 0.768395066 entropy_value 5.62971497 glob_norm 0.430164337\n",
      "Iteration 800 L -4.88860178 loss -4.88863039 loss_ordinary 0.733322144 entropy_value 5.62195253 glob_norm 0.386961967\n",
      "Iteration 850 L -4.90460062 loss -4.90460062 loss_ordinary 0.723781347 entropy_value 5.62838173 glob_norm 0.35060975\n",
      "Iteration 900 L -4.8588376 loss -4.8588376 loss_ordinary 0.762162805 entropy_value 5.62100029 glob_norm 0.451299161\n",
      "Iteration 950 L -4.89073515 loss -4.89073515 loss_ordinary 0.726425827 entropy_value 5.61716127 glob_norm 0.411977738\n",
      "Iteration 1000 L -4.9061017 loss -4.9061017 loss_ordinary 0.71085012 entropy_value 5.61695147 glob_norm 0.418818265\n",
      "Iteration 1050 L -4.88627243 loss -4.88627243 loss_ordinary 0.741041183 entropy_value 5.62731361 glob_norm 0.345234632\n",
      "Iteration 1100 L -4.88061666 loss -4.88061666 loss_ordinary 0.738880455 entropy_value 5.6194973 glob_norm 0.432810366\n",
      "Iteration 1150 L -4.93895 loss -4.93895 loss_ordinary 0.677413583 entropy_value 5.61636353 glob_norm 0.417002469\n",
      "Iteration 1200 L -4.89956 loss -4.89956 loss_ordinary 0.715399742 entropy_value 5.61495972 glob_norm 0.390176177\n",
      "Iteration 1250 L -4.9278965 loss -4.9278965 loss_ordinary 0.694081903 entropy_value 5.62197876 glob_norm 0.354024678\n",
      "Iteration 1300 L -4.87009573 loss -4.87009573 loss_ordinary 0.747344434 entropy_value 5.61744 glob_norm 0.253495216\n",
      "Iteration 1350 L -4.89803505 loss -4.89803505 loss_ordinary 0.72751689 entropy_value 5.6255517 glob_norm 0.317162\n",
      "Iteration 1400 L -4.88729954 loss -4.88729954 loss_ordinary 0.734306037 entropy_value 5.62160587 glob_norm 0.35012\n",
      "Iteration 1450 L -4.89672661 loss -4.89672661 loss_ordinary 0.721282959 entropy_value 5.61800909 glob_norm 0.482825249\n",
      "Iteration 1500 L -4.89430237 loss -4.89447546 loss_ordinary 0.724539697 entropy_value 5.61901522 glob_norm 0.314858139\n",
      "Iteration 1550 L -4.88380909 loss -4.88380909 loss_ordinary 0.730660558 entropy_value 5.61446953 glob_norm 0.388742208\n",
      "Iteration 1600 L -4.89119768 loss -4.89119768 loss_ordinary 0.721054316 entropy_value 5.61225176 glob_norm 0.375330657\n",
      "Iteration 1650 L -4.89486599 loss -4.89486599 loss_ordinary 0.7125808 entropy_value 5.60744667 glob_norm 0.436627179\n",
      "Iteration 1700 L -4.8769722 loss -4.8769722 loss_ordinary 0.739804924 entropy_value 5.61677742 glob_norm 0.345301747\n",
      "Iteration 1750 L -4.92553616 loss -4.92553616 loss_ordinary 0.698476076 entropy_value 5.62401199 glob_norm 0.337316036\n",
      "Iteration 1800 L -4.86913824 loss -4.86913824 loss_ordinary 0.743085444 entropy_value 5.61222363 glob_norm 0.292108417\n",
      "Iteration 1850 L -4.89284372 loss -4.89284372 loss_ordinary 0.721815467 entropy_value 5.61465883 glob_norm 0.374111027\n",
      "Iteration 1900 L -4.88383198 loss -4.88383198 loss_ordinary 0.733586848 entropy_value 5.61741877 glob_norm 0.36905849\n",
      "Iteration 1950 L -4.90388346 loss -4.90388346 loss_ordinary 0.706657588 entropy_value 5.61054087 glob_norm 0.404877722\n",
      "Iteration 2000 L -4.91415 loss -4.91415 loss_ordinary 0.700269043 entropy_value 5.61441946 glob_norm 0.466131508\n",
      "Iteration 2050 L -4.9073329 loss -4.9073329 loss_ordinary 0.708697319 entropy_value 5.61603 glob_norm 0.430730462\n",
      "Iteration 2100 L -4.87852573 loss -4.87852669 loss_ordinary 0.734956324 entropy_value 5.61348248 glob_norm 0.281552345\n",
      "Iteration 2150 L -4.90074635 loss -4.90074635 loss_ordinary 0.717428088 entropy_value 5.61817455 glob_norm 0.317252725\n",
      "Iteration 2200 L -4.87501478 loss -4.87501478 loss_ordinary 0.738221765 entropy_value 5.61323643 glob_norm 0.390711755\n",
      "Iteration 2250 L -4.90234 loss -4.90234 loss_ordinary 0.716259539 entropy_value 5.61859941 glob_norm 0.42459479\n",
      "Iteration 2300 L -4.90224886 loss -4.90225124 loss_ordinary 0.707204282 entropy_value 5.60945559 glob_norm 0.414113432\n",
      "Iteration 2350 L -4.90928459 loss -4.90928459 loss_ordinary 0.706653953 entropy_value 5.61593866 glob_norm 0.319323421\n",
      "Iteration 2400 L -4.90944195 loss -4.90944195 loss_ordinary 0.706735969 entropy_value 5.61617756 glob_norm 0.266475439\n",
      "Iteration 2450 L -4.89381 loss -4.89381 loss_ordinary 0.718301713 entropy_value 5.61211157 glob_norm 0.34561038\n",
      "Iteration 2500 L -4.91878653 loss -4.91878653 loss_ordinary 0.693525255 entropy_value 5.61231184 glob_norm 0.384276152\n",
      "Iteration 2550 L -4.8953824 loss -4.8953824 loss_ordinary 0.721536517 entropy_value 5.61691904 glob_norm 0.439305365\n",
      "Iteration 2600 L -4.88920355 loss -4.88920355 loss_ordinary 0.73173964 entropy_value 5.62094307 glob_norm 0.33838138\n",
      "Iteration 2650 L -4.90078545 loss -4.9010334 loss_ordinary 0.716821969 entropy_value 5.61785507 glob_norm 0.377644807\n",
      "Iteration 2700 L -4.88010788 loss -4.88020468 loss_ordinary 0.726220548 entropy_value 5.60642529 glob_norm 0.47139743\n",
      "Iteration 2750 L -4.91178036 loss -4.91178036 loss_ordinary 0.703828514 entropy_value 5.61560869 glob_norm 0.359511167\n",
      "Iteration 2800 L -4.9007 loss -4.9007 loss_ordinary 0.710328162 entropy_value 5.61102819 glob_norm 0.333299607\n",
      "Iteration 2850 L -4.86608601 loss -4.86608601 loss_ordinary 0.74711436 entropy_value 5.6132 glob_norm 0.484789371\n",
      "Iteration 2900 L -4.89676428 loss -4.89676428 loss_ordinary 0.718251288 entropy_value 5.61501551 glob_norm 0.277888298\n",
      "Iteration 2950 L -4.87652397 loss -4.87652397 loss_ordinary 0.736756742 entropy_value 5.61328077 glob_norm 0.313997149\n",
      "Iteration 3000 L -4.85735846 loss -4.85735846 loss_ordinary 0.758109689 entropy_value 5.61546803 glob_norm 0.317573\n",
      "Iteration 3050 L -4.89600372 loss -4.89600372 loss_ordinary 0.722271502 entropy_value 5.61827517 glob_norm 0.397939861\n",
      "Iteration 3100 L -4.907897 loss -4.907897 loss_ordinary 0.708982825 entropy_value 5.61687946 glob_norm 0.359509259\n",
      "Iteration 3150 L -4.91249323 loss -4.91249323 loss_ordinary 0.697558582 entropy_value 5.61005211 glob_norm 0.393040299\n",
      "Iteration 3200 L -4.92484856 loss -4.92484856 loss_ordinary 0.693277895 entropy_value 5.61812639 glob_norm 0.474340588\n",
      "Iteration 3250 L -4.90315819 loss -4.90315819 loss_ordinary 0.710949719 entropy_value 5.61410809 glob_norm 0.363744229\n",
      "Iteration 3300 L -4.89815235 loss -4.89815235 loss_ordinary 0.713314474 entropy_value 5.61146688 glob_norm 0.359815\n",
      "Iteration 3350 L -4.88666868 loss -4.88666868 loss_ordinary 0.728103518 entropy_value 5.6147728 glob_norm 0.406064153\n",
      "Iteration 3400 L -4.88481426 loss -4.88481426 loss_ordinary 0.729895055 entropy_value 5.61470938 glob_norm 0.375462741\n",
      "Iteration 3450 L -4.88467598 loss -4.88467598 loss_ordinary 0.733436 entropy_value 5.61811209 glob_norm 0.510748565\n",
      "Iteration 3500 L -4.90020132 loss -4.90020132 loss_ordinary 0.706241429 entropy_value 5.60644293 glob_norm 0.342811227\n",
      "Iteration 3550 L -4.90821648 loss -4.90821648 loss_ordinary 0.713502288 entropy_value 5.62171841 glob_norm 0.2974433\n",
      "Iteration 3600 L -4.88936 loss -4.88936 loss_ordinary 0.726751745 entropy_value 5.61611176 glob_norm 0.329286039\n",
      "Iteration 3650 L -4.88241911 loss -4.88241911 loss_ordinary 0.73185873 entropy_value 5.61427784 glob_norm 0.467577189\n",
      "Iteration 3700 L -4.88660717 loss -4.88660717 loss_ordinary 0.721992 entropy_value 5.60859919 glob_norm 0.301224947\n",
      "Iteration 3750 L -4.86493778 loss -4.86493778 loss_ordinary 0.74788779 entropy_value 5.61282587 glob_norm 0.311931282\n",
      "Iteration 3800 L -4.88242245 loss -4.88261271 loss_ordinary 0.731603444 entropy_value 5.61421633 glob_norm 0.38417694\n",
      "Iteration 3850 L -4.88255644 loss -4.88255644 loss_ordinary 0.729334712 entropy_value 5.61189127 glob_norm 0.291641951\n",
      "Iteration 3900 L -4.89267778 loss -4.89267778 loss_ordinary 0.719841957 entropy_value 5.61251974 glob_norm 0.440767169\n",
      "Iteration 3950 L -4.91500902 loss -4.91500902 loss_ordinary 0.696594656 entropy_value 5.61160374 glob_norm 0.328766137\n",
      "Iteration 4000 L -4.88468885 loss -4.88468885 loss_ordinary 0.727861881 entropy_value 5.61255074 glob_norm 0.30753094\n",
      "Iteration 4050 L -4.90245533 loss -4.90245533 loss_ordinary 0.705885768 entropy_value 5.60834122 glob_norm 0.380660087\n",
      "Iteration 4100 L -4.925704 loss -4.925704 loss_ordinary 0.685548663 entropy_value 5.61125278 glob_norm 0.487110496\n",
      "Iteration 4150 L -4.87554455 loss -4.87554455 loss_ordinary 0.738121748 entropy_value 5.61366606 glob_norm 0.32671845\n",
      "Iteration 4200 L -4.90138721 loss -4.90138721 loss_ordinary 0.70739764 entropy_value 5.60878468 glob_norm 0.386441559\n",
      "Iteration 4250 L -4.8983593 loss -4.8983593 loss_ordinary 0.713939667 entropy_value 5.61229897 glob_norm 0.344441742\n",
      "Iteration 4300 L -4.887362 loss -4.887362 loss_ordinary 0.72867012 entropy_value 5.61603212 glob_norm 0.425326765\n",
      "Iteration 4350 L -4.88123131 loss -4.88123512 loss_ordinary 0.7288692 entropy_value 5.61010408 glob_norm 0.371807128\n",
      "Iteration 4400 L -4.88059664 loss -4.88059664 loss_ordinary 0.736581 entropy_value 5.61717749 glob_norm 0.482500046\n",
      "Iteration 4450 L -4.92193556 loss -4.92194128 loss_ordinary 0.690894425 entropy_value 5.61283588 glob_norm 0.33321166\n",
      "Iteration 4500 L -4.91390228 loss -4.9139204 loss_ordinary 0.698887706 entropy_value 5.61280775 glob_norm 0.336799085\n",
      "Iteration 4550 L -4.90224028 loss -4.90234804 loss_ordinary 0.712499738 entropy_value 5.61484766 glob_norm 0.316375822\n",
      "Iteration 4600 L -4.90061045 loss -4.90061045 loss_ordinary 0.714845717 entropy_value 5.61545658 glob_norm 0.391282052\n",
      "Iteration 4650 L -4.93015909 loss -4.93015909 loss_ordinary 0.690327585 entropy_value 5.62048674 glob_norm 0.295748353\n",
      "Iteration 4700 L -4.89245176 loss -4.89245176 loss_ordinary 0.721290588 entropy_value 5.61374187 glob_norm 0.297348142\n",
      "Iteration 4750 L -4.9000473 loss -4.9000473 loss_ordinary 0.708775818 entropy_value 5.6088233 glob_norm 0.404376328\n",
      "Iteration 4800 L -4.89128399 loss -4.89128399 loss_ordinary 0.724876881 entropy_value 5.61616087 glob_norm 0.443148494\n",
      "Iteration 4850 L -4.90799522 loss -4.90799522 loss_ordinary 0.701274037 entropy_value 5.60926962 glob_norm 0.308404893\n",
      "Iteration 4900 L -4.8887887 loss -4.88891554 loss_ordinary 0.721396 entropy_value 5.61031151 glob_norm 0.394932389\n",
      "Iteration 4950 L -4.89610052 loss -4.89610052 loss_ordinary 0.720836878 entropy_value 5.61693764 glob_norm 0.42752558\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 0 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91106939 loss -4.91106939 loss_ordinary 0.700367928 entropy_value 5.61143732 glob_norm 0.441402\n",
      "Iteration 50 L -4.88262177 loss -4.88262177 loss_ordinary 0.73098278 entropy_value 5.61360455 glob_norm 0.35838896\n",
      "Iteration 100 L -4.90233421 loss -4.90233421 loss_ordinary 0.714205742 entropy_value 5.61654 glob_norm 0.413026869\n",
      "Iteration 150 L -4.88676262 loss -4.88676453 loss_ordinary 0.723747075 entropy_value 5.6105113 glob_norm 0.364611953\n",
      "Iteration 200 L -4.90330696 loss -4.90330696 loss_ordinary 0.715472341 entropy_value 5.61877918 glob_norm 0.337097049\n",
      "Iteration 250 L -4.89152479 loss -4.89152479 loss_ordinary 0.71935761 entropy_value 5.61088228 glob_norm 0.349325448\n",
      "Iteration 300 L -4.91766357 loss -4.91766357 loss_ordinary 0.705699205 entropy_value 5.62336254 glob_norm 0.513051569\n",
      "Iteration 350 L -4.88008118 loss -4.88008118 loss_ordinary 0.736346304 entropy_value 5.6164279 glob_norm 0.441429377\n",
      "Iteration 400 L -4.91718 loss -4.91718 loss_ordinary 0.695947587 entropy_value 5.61312771 glob_norm 0.328885823\n",
      "Iteration 450 L -4.89194822 loss -4.89210796 loss_ordinary 0.722479939 entropy_value 5.61458778 glob_norm 0.260322869\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 0 lambd_papr 0 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88795662 loss -4.88795662 loss_ordinary 0.728647768 entropy_value 5.61660433 glob_norm 0.377664536\n",
      "Iteration 50 L -4.92081356 loss -4.92084551 loss_ordinary 0.695049 entropy_value 5.61589479 glob_norm 0.321841419\n",
      "Iteration 100 L -4.9002285 loss -4.9002285 loss_ordinary 0.718895793 entropy_value 5.61912441 glob_norm 0.386563361\n",
      "Iteration 150 L -4.87601852 loss -4.87601852 loss_ordinary 0.73796612 entropy_value 5.61398458 glob_norm 0.258716494\n",
      "Iteration 200 L -4.91204834 loss -4.91204834 loss_ordinary 0.705736578 entropy_value 5.61778498 glob_norm 0.354854852\n",
      "Iteration 250 L -4.90932703 loss -4.90932703 loss_ordinary 0.707603455 entropy_value 5.61693048 glob_norm 0.412911922\n",
      "Iteration 300 L -4.87290096 loss -4.87290096 loss_ordinary 0.740254939 entropy_value 5.61315584 glob_norm 0.360634953\n",
      "Iteration 350 L -4.91172457 loss -4.91184187 loss_ordinary 0.702914596 entropy_value 5.61475611 glob_norm 0.380571872\n",
      "Iteration 400 L -4.88273096 loss -4.88276339 loss_ordinary 0.72913444 entropy_value 5.61189747 glob_norm 0.445371509\n",
      "Iteration 450 L -4.89268112 loss -4.89268112 loss_ordinary 0.72347796 entropy_value 5.61615896 glob_norm 0.353152692\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0 lambd_papr 0 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90558815 loss -4.90558815 loss_ordinary 0.713389099 entropy_value 5.61897755 glob_norm 0.373850048\n",
      "Iteration 50 L -4.89301062 loss -4.89301062 loss_ordinary 0.723311305 entropy_value 5.61632156 glob_norm 0.382469\n",
      "Iteration 100 L -4.88815975 loss -4.88815975 loss_ordinary 0.72203207 entropy_value 5.61019182 glob_norm 0.320838511\n",
      "Iteration 150 L -4.89526367 loss -4.89526367 loss_ordinary 0.721081793 entropy_value 5.61634541 glob_norm 0.445803225\n",
      "Iteration 200 L -4.90333939 loss -4.90333939 loss_ordinary 0.708339274 entropy_value 5.61167908 glob_norm 0.329876602\n",
      "Iteration 250 L -4.88463783 loss -4.88463783 loss_ordinary 0.727103055 entropy_value 5.61174107 glob_norm 0.358917564\n",
      "Iteration 300 L -4.88978434 loss -4.88978434 loss_ordinary 0.722272694 entropy_value 5.61205721 glob_norm 0.411173701\n",
      "Iteration 350 L -4.89077187 loss -4.89077187 loss_ordinary 0.729686499 entropy_value 5.6204586 glob_norm 0.343779892\n",
      "Iteration 400 L -4.89367867 loss -4.89367867 loss_ordinary 0.72161442 entropy_value 5.6152935 glob_norm 0.26259011\n",
      "Iteration 450 L -4.85722876 loss -4.85722876 loss_ordinary 0.759778738 entropy_value 5.61700726 glob_norm 0.382322907\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0 lambd_papr 0 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.92785168 loss -4.92785168 loss_ordinary 0.686877608 entropy_value 5.6147294 glob_norm 0.346175432\n",
      "Iteration 50 L -4.91448307 loss -4.91448307 loss_ordinary 0.702787161 entropy_value 5.61727047 glob_norm 0.351937801\n",
      "Iteration 100 L -4.88140297 loss -4.88140297 loss_ordinary 0.729769766 entropy_value 5.61117268 glob_norm 0.333058715\n",
      "Iteration 150 L -4.85836411 loss -4.85836411 loss_ordinary 0.763964295 entropy_value 5.62232828 glob_norm 0.53407526\n",
      "Iteration 200 L -4.88544178 loss -4.88544178 loss_ordinary 0.73520261 entropy_value 5.62064457 glob_norm 0.426472515\n",
      "Iteration 250 L -4.90346527 loss -4.90346527 loss_ordinary 0.705524266 entropy_value 5.60898972 glob_norm 0.36834681\n",
      "Iteration 300 L -4.93033123 loss -4.93033123 loss_ordinary 0.691307724 entropy_value 5.62163877 glob_norm 0.279489696\n",
      "Iteration 350 L -4.85736513 loss -4.85736513 loss_ordinary 0.760479569 entropy_value 5.61784506 glob_norm 0.34112516\n",
      "Iteration 400 L -4.90192175 loss -4.90192175 loss_ordinary 0.706407785 entropy_value 5.6083293 glob_norm 0.442952424\n",
      "Iteration 450 L -4.89261484 loss -4.89261484 loss_ordinary 0.724322736 entropy_value 5.61693764 glob_norm 0.313076317\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0 lambd_papr 0 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91848898 loss -4.91848898 loss_ordinary 0.698490739 entropy_value 5.6169796 glob_norm 0.389722914\n",
      "Iteration 50 L -4.9000864 loss -4.9000864 loss_ordinary 0.708527207 entropy_value 5.60861349 glob_norm 0.38553077\n",
      "Iteration 100 L -4.8999238 loss -4.9002347 loss_ordinary 0.706243753 entropy_value 5.60647821 glob_norm 0.308658808\n",
      "Iteration 150 L -4.92004061 loss -4.92004061 loss_ordinary 0.692743719 entropy_value 5.61278439 glob_norm 0.312770128\n",
      "Iteration 200 L -4.89831638 loss -4.89831638 loss_ordinary 0.714275718 entropy_value 5.61259174 glob_norm 0.310518026\n",
      "Iteration 250 L -4.88984 loss -4.88984 loss_ordinary 0.729649305 entropy_value 5.61948967 glob_norm 0.511885226\n",
      "Iteration 300 L -4.87766457 loss -4.87766457 loss_ordinary 0.733653545 entropy_value 5.61131811 glob_norm 0.321117848\n",
      "Iteration 350 L -4.91105938 loss -4.91105938 loss_ordinary 0.703961611 entropy_value 5.61502075 glob_norm 0.347474396\n",
      "Iteration 400 L -4.87722158 loss -4.87722158 loss_ordinary 0.741010725 entropy_value 5.61823225 glob_norm 0.375189871\n",
      "Iteration 450 L -4.84627104 loss -4.84627104 loss_ordinary 0.76813978 entropy_value 5.61441088 glob_norm 0.346942246\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0 lambd_papr 0 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90130615 loss -4.90130615 loss_ordinary 0.708062708 entropy_value 5.6093688 glob_norm 0.387241542\n",
      "Iteration 50 L -4.87472153 loss -4.87472153 loss_ordinary 0.734693646 entropy_value 5.60941553 glob_norm 0.428983092\n",
      "Iteration 100 L -4.86488199 loss -4.86488199 loss_ordinary 0.750093579 entropy_value 5.61497545 glob_norm 0.350705862\n",
      "Iteration 150 L -4.91761541 loss -4.91766405 loss_ordinary 0.69609946 entropy_value 5.61376381 glob_norm 0.28079775\n",
      "Iteration 200 L -4.89602041 loss -4.89602041 loss_ordinary 0.717135847 entropy_value 5.61315632 glob_norm 0.31285879\n",
      "Iteration 250 L -4.89292812 loss -4.89292812 loss_ordinary 0.722094357 entropy_value 5.61502218 glob_norm 0.493806064\n",
      "Iteration 300 L -4.85576963 loss -4.85576963 loss_ordinary 0.757799923 entropy_value 5.61356974 glob_norm 0.453029\n",
      "Iteration 350 L -4.8692975 loss -4.86929846 loss_ordinary 0.744104445 entropy_value 5.61340284 glob_norm 0.301915944\n",
      "Iteration 400 L -4.87308121 loss -4.87308121 loss_ordinary 0.745104253 entropy_value 5.61818552 glob_norm 0.378572583\n",
      "Iteration 450 L -4.88551235 loss -4.88551235 loss_ordinary 0.726771653 entropy_value 5.61228418 glob_norm 0.482401758\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0 lambd_papr 0 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87051392 loss -4.87051392 loss_ordinary 0.736318886 entropy_value 5.60683298 glob_norm 0.531202197\n",
      "Iteration 50 L -4.8811388 loss -4.8811388 loss_ordinary 0.73116219 entropy_value 5.61230135 glob_norm 0.343743861\n",
      "Iteration 100 L -4.9086175 loss -4.9086175 loss_ordinary 0.703633606 entropy_value 5.61225128 glob_norm 0.325181454\n",
      "Iteration 150 L -4.89328957 loss -4.89336777 loss_ordinary 0.727098465 entropy_value 5.62046671 glob_norm 0.56862396\n",
      "Iteration 200 L -4.90908718 loss -4.90908718 loss_ordinary 0.705187142 entropy_value 5.61427402 glob_norm 0.354945153\n",
      "Iteration 250 L -4.88555574 loss -4.88555574 loss_ordinary 0.725166 entropy_value 5.61072206 glob_norm 0.278726608\n",
      "Iteration 300 L -4.92771816 loss -4.92771816 loss_ordinary 0.681625247 entropy_value 5.60934353 glob_norm 0.355572224\n",
      "Iteration 350 L -4.89654398 loss -4.89654398 loss_ordinary 0.727754235 entropy_value 5.62429857 glob_norm 0.436865747\n",
      "Iteration 400 L -4.88019609 loss -4.88019609 loss_ordinary 0.733626187 entropy_value 5.61382246 glob_norm 0.399240881\n",
      "Iteration 450 L -4.91252232 loss -4.91252232 loss_ordinary 0.707829654 entropy_value 5.62035179 glob_norm 0.473185718\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0 lambd_papr 0 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89414787 loss -4.89414787 loss_ordinary 0.721919537 entropy_value 5.61606741 glob_norm 0.490159482\n",
      "Iteration 50 L -4.92303896 loss -4.92303896 loss_ordinary 0.694648564 entropy_value 5.61768723 glob_norm 0.322404116\n",
      "Iteration 100 L -4.90339708 loss -4.90339708 loss_ordinary 0.716240883 entropy_value 5.61963844 glob_norm 0.4166722\n",
      "Iteration 150 L -4.90655708 loss -4.90691376 loss_ordinary 0.712898135 entropy_value 5.61981153 glob_norm 0.343063116\n",
      "Iteration 200 L -4.8844223 loss -4.8844223 loss_ordinary 0.723967731 entropy_value 5.60839 glob_norm 0.486282229\n",
      "Iteration 250 L -4.87031746 loss -4.87069225 loss_ordinary 0.741358042 entropy_value 5.61205053 glob_norm 0.485383\n",
      "Iteration 300 L -4.87698507 loss -4.87698507 loss_ordinary 0.73871845 entropy_value 5.61570311 glob_norm 0.400767565\n",
      "Iteration 350 L -4.8978281 loss -4.8980484 loss_ordinary 0.721068621 entropy_value 5.61911678 glob_norm 0.297977\n",
      "Iteration 400 L -4.88961029 loss -4.88973379 loss_ordinary 0.722607553 entropy_value 5.61234093 glob_norm 0.44252938\n",
      "Iteration 450 L -4.87124252 loss -4.87124252 loss_ordinary 0.74393183 entropy_value 5.61517429 glob_norm 0.439805061\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0 lambd_papr 0 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90950632 loss -4.90950632 loss_ordinary 0.702733934 entropy_value 5.61224031 glob_norm 0.364740968\n",
      "Iteration 50 L -4.90802193 loss -4.90802193 loss_ordinary 0.704748 entropy_value 5.61277 glob_norm 0.349874973\n",
      "Iteration 100 L -4.90042114 loss -4.90042114 loss_ordinary 0.714774311 entropy_value 5.61519575 glob_norm 0.389848053\n",
      "Iteration 150 L -4.87957287 loss -4.87957287 loss_ordinary 0.730357826 entropy_value 5.60993099 glob_norm 0.357926279\n",
      "Iteration 200 L -4.8967452 loss -4.8967452 loss_ordinary 0.721402884 entropy_value 5.61814785 glob_norm 0.336795837\n",
      "Iteration 250 L -4.91333532 loss -4.91333532 loss_ordinary 0.698712051 entropy_value 5.6120472 glob_norm 0.338580489\n",
      "Iteration 300 L -4.87152863 loss -4.87152863 loss_ordinary 0.737918 entropy_value 5.60944653 glob_norm 0.396352619\n",
      "Iteration 350 L -4.85757399 loss -4.85757399 loss_ordinary 0.751616359 entropy_value 5.60919046 glob_norm 0.422079474\n",
      "Iteration 400 L -4.8795619 loss -4.8795619 loss_ordinary 0.738985777 entropy_value 5.61854744 glob_norm 0.414109945\n",
      "Iteration 450 L -4.90431 loss -4.90431213 loss_ordinary 0.709849179 entropy_value 5.61416149 glob_norm 0.36906743\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0 lambd_papr 0 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88621473 loss -4.88632107 loss_ordinary 0.725163043 entropy_value 5.61148405 glob_norm 0.475819051\n",
      "Iteration 50 L -4.90040493 loss -4.90040493 loss_ordinary 0.712635577 entropy_value 5.61304045 glob_norm 0.319839418\n",
      "Iteration 100 L -4.89801025 loss -4.89801025 loss_ordinary 0.716376662 entropy_value 5.61438656 glob_norm 0.389079452\n",
      "Iteration 150 L -4.84718323 loss -4.84718323 loss_ordinary 0.767800868 entropy_value 5.61498404 glob_norm 0.372229934\n",
      "Iteration 200 L -4.89730406 loss -4.89730406 loss_ordinary 0.720000744 entropy_value 5.6173048 glob_norm 0.39920187\n",
      "Iteration 250 L -4.86959743 loss -4.86959743 loss_ordinary 0.737047791 entropy_value 5.60664558 glob_norm 0.30054298\n",
      "Iteration 300 L -4.88079834 loss -4.88079834 loss_ordinary 0.728400171 entropy_value 5.60919857 glob_norm 0.411877304\n",
      "Iteration 350 L -4.87444735 loss -4.87444735 loss_ordinary 0.739376426 entropy_value 5.61382389 glob_norm 0.52316469\n",
      "Iteration 400 L -4.88789082 loss -4.88857841 loss_ordinary 0.728677869 entropy_value 5.61725616 glob_norm 0.431602269\n",
      "Iteration 450 L -4.89659214 loss -4.89659214 loss_ordinary 0.71833092 entropy_value 5.614923 glob_norm 0.456420779\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.248112202 lambd_papr 0 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.9057579 loss -4.90530205 loss_ordinary 0.704225242 entropy_value 5.60952759 glob_norm 0.355559766\n",
      "Iteration 50 L -4.87911415 loss -4.87865782 loss_ordinary 0.73993969 entropy_value 5.61859751 glob_norm 0.314526975\n",
      "Iteration 100 L -4.86707163 loss -4.8670125 loss_ordinary 0.747249484 entropy_value 5.6142621 glob_norm 0.296598822\n",
      "Iteration 150 L -4.8892765 loss -4.888834 loss_ordinary 0.717650414 entropy_value 5.60648441 glob_norm 0.380206913\n",
      "Iteration 200 L -4.86719 loss -4.86673355 loss_ordinary 0.750567853 entropy_value 5.61730146 glob_norm 0.409623\n",
      "Iteration 250 L -4.91568279 loss -4.91538429 loss_ordinary 0.699825704 entropy_value 5.61520958 glob_norm 0.453149885\n",
      "Iteration 300 L -4.9178195 loss -4.91762352 loss_ordinary 0.693592548 entropy_value 5.61121607 glob_norm 0.454513162\n",
      "Iteration 350 L -4.89497328 loss -4.89468861 loss_ordinary 0.722072423 entropy_value 5.61676121 glob_norm 0.428645462\n",
      "Iteration 400 L -4.90318489 loss -4.902843 loss_ordinary 0.714670777 entropy_value 5.61751413 glob_norm 0.464596063\n",
      "Iteration 450 L -4.88527441 loss -4.88486481 loss_ordinary 0.726392388 entropy_value 5.61125708 glob_norm 0.278660148\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power -0.247370079 lambd_papr -0.00255656918 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89454794 loss -4.89454794 loss_ordinary 0.720262289 entropy_value 5.61481 glob_norm 0.287196398\n",
      "Iteration 50 L -4.90771866 loss -4.90771866 loss_ordinary 0.703210235 entropy_value 5.61092901 glob_norm 0.285247326\n",
      "Iteration 100 L -4.88842869 loss -4.88842869 loss_ordinary 0.731530607 entropy_value 5.61995935 glob_norm 0.357549042\n",
      "Iteration 150 L -4.92452478 loss -4.92452478 loss_ordinary 0.690497339 entropy_value 5.61502171 glob_norm 0.452815592\n",
      "Iteration 200 L -4.90816498 loss -4.90816498 loss_ordinary 0.70725286 entropy_value 5.61541796 glob_norm 0.415148854\n",
      "Iteration 250 L -4.88449097 loss -4.88449097 loss_ordinary 0.727145374 entropy_value 5.61163616 glob_norm 0.350894839\n",
      "Iteration 300 L -4.86268616 loss -4.86268616 loss_ordinary 0.756722093 entropy_value 5.61940813 glob_norm 0.353669435\n",
      "Iteration 350 L -4.87458086 loss -4.87458086 loss_ordinary 0.742367685 entropy_value 5.6169486 glob_norm 0.401153028\n",
      "Iteration 400 L -4.89013 loss -4.89013 loss_ordinary 0.726050913 entropy_value 5.6161809 glob_norm 0.30425778\n",
      "Iteration 450 L -4.90558624 loss -4.90558624 loss_ordinary 0.718719 entropy_value 5.62430525 glob_norm 0.330727547\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0 lambd_papr 0 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88289452 loss -4.88289595 loss_ordinary 0.732359588 entropy_value 5.61525536 glob_norm 0.314511567\n",
      "Iteration 50 L -4.90459633 loss -4.90459633 loss_ordinary 0.708467364 entropy_value 5.61306381 glob_norm 0.262637109\n",
      "Iteration 100 L -4.86994267 loss -4.86994267 loss_ordinary 0.744962275 entropy_value 5.61490488 glob_norm 0.376614898\n",
      "Iteration 150 L -4.89066458 loss -4.89072 loss_ordinary 0.724496782 entropy_value 5.61521673 glob_norm 0.317037255\n",
      "Iteration 200 L -4.889431 loss -4.889431 loss_ordinary 0.727492452 entropy_value 5.61692333 glob_norm 0.44126454\n",
      "Iteration 250 L -4.86529541 loss -4.86529541 loss_ordinary 0.743541121 entropy_value 5.60883617 glob_norm 0.432540953\n",
      "Iteration 300 L -4.90953922 loss -4.90953922 loss_ordinary 0.701230109 entropy_value 5.61076927 glob_norm 0.349024326\n",
      "Iteration 350 L -4.89306545 loss -4.89306545 loss_ordinary 0.725358665 entropy_value 5.61842394 glob_norm 0.348917305\n",
      "Iteration 400 L -4.90232563 loss -4.90232563 loss_ordinary 0.711724281 entropy_value 5.61405039 glob_norm 0.329641193\n",
      "Iteration 450 L -4.90140581 loss -4.90140581 loss_ordinary 0.713719666 entropy_value 5.61512566 glob_norm 0.264946848\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0 lambd_papr 0 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88591576 loss -4.88591576 loss_ordinary 0.728704154 entropy_value 5.61462 glob_norm 0.352008015\n",
      "Iteration 50 L -4.89634037 loss -4.89634037 loss_ordinary 0.723383069 entropy_value 5.6197238 glob_norm 0.34400025\n",
      "Iteration 100 L -4.88293648 loss -4.88293648 loss_ordinary 0.727553785 entropy_value 5.61049032 glob_norm 0.294828802\n",
      "Iteration 150 L -4.89812183 loss -4.89812183 loss_ordinary 0.723156869 entropy_value 5.62127876 glob_norm 0.524865627\n",
      "Iteration 200 L -4.88736248 loss -4.88736248 loss_ordinary 0.729453921 entropy_value 5.61681652 glob_norm 0.319979489\n",
      "Iteration 250 L -4.90963697 loss -4.90963697 loss_ordinary 0.708151877 entropy_value 5.61778879 glob_norm 0.350996971\n",
      "Iteration 300 L -4.87168312 loss -4.87168312 loss_ordinary 0.735243559 entropy_value 5.60692692 glob_norm 0.318501681\n",
      "Iteration 350 L -4.90526724 loss -4.9054327 loss_ordinary 0.706677794 entropy_value 5.61211 glob_norm 0.330836296\n",
      "Iteration 400 L -4.86842775 loss -4.86842775 loss_ordinary 0.745530188 entropy_value 5.61395788 glob_norm 0.399540514\n",
      "Iteration 450 L -4.89354944 loss -4.8935523 loss_ordinary 0.717524529 entropy_value 5.61107683 glob_norm 0.331485748\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.185646772 lambd_papr 0 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88696146 loss -4.88670254 loss_ordinary 0.716014266 entropy_value 5.60271692 glob_norm 0.458252877\n",
      "Iteration 50 L -4.89931488 loss -4.89905596 loss_ordinary 0.716272056 entropy_value 5.61532784 glob_norm 0.408308029\n",
      "Iteration 100 L -4.90857601 loss -4.90831757 loss_ordinary 0.699706733 entropy_value 5.60802412 glob_norm 0.460709512\n",
      "Iteration 150 L -4.89337492 loss -4.893116 loss_ordinary 0.722640276 entropy_value 5.61575651 glob_norm 0.329388171\n",
      "Iteration 200 L -4.90776205 loss -4.9075036 loss_ordinary 0.706215262 entropy_value 5.61371851 glob_norm 0.330942065\n",
      "Iteration 250 L -4.87210369 loss -4.87184525 loss_ordinary 0.745117664 entropy_value 5.61696243 glob_norm 0.335450441\n",
      "Iteration 300 L -4.87496948 loss -4.87471056 loss_ordinary 0.746129513 entropy_value 5.62084 glob_norm 0.421934843\n",
      "Iteration 350 L -4.88376093 loss -4.88350248 loss_ordinary 0.724328816 entropy_value 5.60783148 glob_norm 0.376550138\n",
      "Iteration 400 L -4.90975475 loss -4.90949631 loss_ordinary 0.70567888 entropy_value 5.61517477 glob_norm 0.3829602\n",
      "Iteration 450 L -4.89621305 loss -4.89595413 loss_ordinary 0.722906291 entropy_value 5.61886072 glob_norm 0.356253177\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power -0.137668848 lambd_papr -0.00193597889 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90135622 loss -4.90133953 loss_ordinary 0.712313235 entropy_value 5.61365271 glob_norm 0.391336352\n",
      "Iteration 50 L -4.88942289 loss -4.8894062 loss_ordinary 0.726340711 entropy_value 5.61574697 glob_norm 0.318425119\n",
      "Iteration 100 L -4.91063452 loss -4.91061783 loss_ordinary 0.704583287 entropy_value 5.615201 glob_norm 0.3221488\n",
      "Iteration 150 L -4.89051628 loss -4.89098167 loss_ordinary 0.727478325 entropy_value 5.6184597 glob_norm 0.338456333\n",
      "Iteration 200 L -4.89779949 loss -4.89778233 loss_ordinary 0.720223844 entropy_value 5.61800623 glob_norm 0.378854424\n",
      "Iteration 250 L -4.88569307 loss -4.88567638 loss_ordinary 0.722812831 entropy_value 5.60848904 glob_norm 0.372156799\n",
      "Iteration 300 L -4.93092918 loss -4.93091249 loss_ordinary 0.680040777 entropy_value 5.61095333 glob_norm 0.436728507\n",
      "Iteration 350 L -4.89508629 loss -4.89506912 loss_ordinary 0.719783723 entropy_value 5.61485291 glob_norm 0.347487092\n",
      "Iteration 400 L -4.88321877 loss -4.88328266 loss_ordinary 0.728370488 entropy_value 5.61165333 glob_norm 0.315312713\n",
      "Iteration 450 L -4.86998558 loss -4.87017775 loss_ordinary 0.740303755 entropy_value 5.61048174 glob_norm 0.398443669\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power -0.047280807 lambd_papr -0.00049602089 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.9022789 loss -4.9022789 loss_ordinary 0.713498294 entropy_value 5.61577702 glob_norm 0.347795784\n",
      "Iteration 50 L -4.89435816 loss -4.89435816 loss_ordinary 0.717637479 entropy_value 5.6119957 glob_norm 0.356773078\n",
      "Iteration 100 L -4.91383553 loss -4.91383553 loss_ordinary 0.6963346 entropy_value 5.61017036 glob_norm 0.431691051\n",
      "Iteration 150 L -4.89371777 loss -4.89371777 loss_ordinary 0.72202 entropy_value 5.61573792 glob_norm 0.365345687\n",
      "Iteration 200 L -4.90301228 loss -4.90301228 loss_ordinary 0.706776 entropy_value 5.60978842 glob_norm 0.354505152\n",
      "Iteration 250 L -4.9033885 loss -4.9033885 loss_ordinary 0.712428808 entropy_value 5.61581755 glob_norm 0.282759756\n",
      "Iteration 300 L -4.86504889 loss -4.86504889 loss_ordinary 0.748397291 entropy_value 5.61344624 glob_norm 0.316410691\n",
      "Iteration 350 L -4.88696146 loss -4.88696194 loss_ordinary 0.72776252 entropy_value 5.61472464 glob_norm 0.387236714\n",
      "Iteration 400 L -4.89336681 loss -4.89336681 loss_ordinary 0.722239077 entropy_value 5.61560583 glob_norm 0.359142929\n",
      "Iteration 450 L -4.86245 loss -4.86245 loss_ordinary 0.749402702 entropy_value 5.61185312 glob_norm 0.328084946\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0 lambd_papr 0 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87784433 loss -4.87784433 loss_ordinary 0.741507947 entropy_value 5.61935234 glob_norm 0.552646697\n",
      "Iteration 50 L -4.88026428 loss -4.88026428 loss_ordinary 0.732884288 entropy_value 5.61314869 glob_norm 0.364694357\n",
      "Iteration 100 L -4.91692066 loss -4.91692066 loss_ordinary 0.697173655 entropy_value 5.61409426 glob_norm 0.445142299\n",
      "Iteration 150 L -4.90654659 loss -4.90660286 loss_ordinary 0.701055825 entropy_value 5.60765886 glob_norm 0.316866815\n",
      "Iteration 200 L -4.92026281 loss -4.92026281 loss_ordinary 0.691022098 entropy_value 5.61128521 glob_norm 0.422867626\n",
      "Iteration 250 L -4.92909718 loss -4.92909718 loss_ordinary 0.679967225 entropy_value 5.6090641 glob_norm 0.414444149\n",
      "Iteration 300 L -4.86374617 loss -4.86374617 loss_ordinary 0.746418297 entropy_value 5.61016464 glob_norm 0.419411033\n",
      "Iteration 350 L -4.86875391 loss -4.86875391 loss_ordinary 0.741910934 entropy_value 5.61066437 glob_norm 0.348859251\n",
      "Iteration 400 L -4.89594555 loss -4.89594555 loss_ordinary 0.717975676 entropy_value 5.61392117 glob_norm 0.314251751\n",
      "Iteration 450 L -4.88057899 loss -4.88057947 loss_ordinary 0.735310256 entropy_value 5.61588955 glob_norm 0.376515985\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0 lambd_papr 0 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89699364 loss -4.89699364 loss_ordinary 0.719053566 entropy_value 5.61604738 glob_norm 0.36527136\n",
      "Iteration 50 L -4.85869789 loss -4.85869789 loss_ordinary 0.754871666 entropy_value 5.61356974 glob_norm 0.367073029\n",
      "Iteration 100 L -4.91532516 loss -4.91532516 loss_ordinary 0.69901675 entropy_value 5.61434221 glob_norm 0.406835645\n",
      "Iteration 150 L -4.93152142 loss -4.93152142 loss_ordinary 0.680168331 entropy_value 5.61169 glob_norm 0.321824789\n",
      "Iteration 200 L -4.88624763 loss -4.88624763 loss_ordinary 0.724955857 entropy_value 5.61120415 glob_norm 0.37077713\n",
      "Iteration 250 L -4.8957386 loss -4.8957386 loss_ordinary 0.714237869 entropy_value 5.60997629 glob_norm 0.368731081\n",
      "Iteration 300 L -4.89214563 loss -4.89214563 loss_ordinary 0.723877907 entropy_value 5.61602306 glob_norm 0.382106721\n",
      "Iteration 350 L -4.91618156 loss -4.91618156 loss_ordinary 0.701223493 entropy_value 5.61740494 glob_norm 0.366775364\n",
      "Iteration 400 L -4.8830409 loss -4.88304234 loss_ordinary 0.735981941 entropy_value 5.6190238 glob_norm 0.384301126\n",
      "Iteration 450 L -4.93160629 loss -4.93160629 loss_ordinary 0.691391468 entropy_value 5.62299776 glob_norm 0.345658\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0 lambd_papr 0 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89741421 loss -4.89741421 loss_ordinary 0.71686691 entropy_value 5.61428118 glob_norm 0.390735537\n",
      "Iteration 50 L -4.90135908 loss -4.90135908 loss_ordinary 0.714710772 entropy_value 5.61607 glob_norm 0.327107728\n",
      "Iteration 100 L -4.87238359 loss -4.87238359 loss_ordinary 0.743795037 entropy_value 5.61617851 glob_norm 0.421025217\n",
      "Iteration 150 L -4.89227533 loss -4.89227533 loss_ordinary 0.716243088 entropy_value 5.6085186 glob_norm 0.367257684\n",
      "Iteration 200 L -4.84527636 loss -4.84527636 loss_ordinary 0.765273929 entropy_value 5.6105504 glob_norm 0.515508354\n",
      "Iteration 250 L -4.90140152 loss -4.90140247 loss_ordinary 0.711435 entropy_value 5.61283731 glob_norm 0.425556183\n",
      "Iteration 300 L -4.89502573 loss -4.89502573 loss_ordinary 0.717457056 entropy_value 5.61248255 glob_norm 0.284431159\n",
      "Iteration 350 L -4.88860941 loss -4.88863 loss_ordinary 0.722346067 entropy_value 5.61097574 glob_norm 0.264747143\n",
      "Iteration 400 L -4.90114069 loss -4.90114069 loss_ordinary 0.710222244 entropy_value 5.61136341 glob_norm 0.33346054\n",
      "Iteration 450 L -4.88608742 loss -4.88609743 loss_ordinary 0.730237126 entropy_value 5.61633396 glob_norm 0.307588071\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0 lambd_papr 0 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89054346 loss -4.89054346 loss_ordinary 0.722866297 entropy_value 5.61340952 glob_norm 0.336454421\n",
      "Iteration 50 L -4.90935087 loss -4.90935087 loss_ordinary 0.708731651 entropy_value 5.61808252 glob_norm 0.267295808\n",
      "Iteration 100 L -4.89260244 loss -4.89260244 loss_ordinary 0.722534537 entropy_value 5.61513662 glob_norm 0.401034504\n",
      "Iteration 150 L -4.8680048 loss -4.86809111 loss_ordinary 0.73912853 entropy_value 5.60721922 glob_norm 0.345826387\n",
      "Iteration 200 L -4.85842896 loss -4.85842896 loss_ordinary 0.753192246 entropy_value 5.61162138 glob_norm 0.414008\n",
      "Iteration 250 L -4.88607597 loss -4.88607597 loss_ordinary 0.728392601 entropy_value 5.61446857 glob_norm 0.352725357\n",
      "Iteration 300 L -4.90947771 loss -4.9099803 loss_ordinary 0.69801873 entropy_value 5.60799932 glob_norm 0.247707561\n",
      "Iteration 350 L -4.91560268 loss -4.91560268 loss_ordinary 0.6915254 entropy_value 5.60712814 glob_norm 0.311304957\n",
      "Iteration 400 L -4.91071272 loss -4.91071272 loss_ordinary 0.698811054 entropy_value 5.60952377 glob_norm 0.360003114\n",
      "Iteration 450 L -4.87103415 loss -4.87103415 loss_ordinary 0.741287768 entropy_value 5.61232185 glob_norm 0.3290371\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power 0 lambd_papr 0 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91410589 loss -4.91410685 loss_ordinary 0.701318562 entropy_value 5.61542559 glob_norm 0.311845452\n",
      "Iteration 50 L -4.90794086 loss -4.90794086 loss_ordinary 0.707026184 entropy_value 5.61496687 glob_norm 0.292864889\n",
      "Iteration 100 L -4.88187456 loss -4.88188791 loss_ordinary 0.738750756 entropy_value 5.62063837 glob_norm 0.361967802\n",
      "Iteration 150 L -4.91483593 loss -4.91483593 loss_ordinary 0.699660063 entropy_value 5.61449623 glob_norm 0.295408726\n",
      "Iteration 200 L -4.89220285 loss -4.89221859 loss_ordinary 0.71959877 entropy_value 5.61181736 glob_norm 0.405175924\n",
      "Iteration 250 L -4.88936 loss -4.88936 loss_ordinary 0.722912192 entropy_value 5.61227226 glob_norm 0.359074831\n",
      "Iteration 300 L -4.87487841 loss -4.87487841 loss_ordinary 0.741446376 entropy_value 5.6163249 glob_norm 0.330568\n",
      "Iteration 350 L -4.89197779 loss -4.89197779 loss_ordinary 0.720653236 entropy_value 5.61263084 glob_norm 0.301638454\n",
      "Iteration 400 L -4.90648413 loss -4.90648413 loss_ordinary 0.710903823 entropy_value 5.61738777 glob_norm 0.362623692\n",
      "Iteration 450 L -4.88845062 loss -4.88845062 loss_ordinary 0.72773236 entropy_value 5.6161828 glob_norm 0.329204291\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power 0 lambd_papr 0 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89058924 loss -4.89058924 loss_ordinary 0.721039295 entropy_value 5.61162853 glob_norm 0.343355\n",
      "Iteration 50 L -4.89180517 loss -4.89180517 loss_ordinary 0.723665237 entropy_value 5.61547 glob_norm 0.350788862\n",
      "Iteration 100 L -4.90737534 loss -4.90737534 loss_ordinary 0.709049106 entropy_value 5.61642408 glob_norm 0.305562913\n",
      "Iteration 150 L -4.88620949 loss -4.88620949 loss_ordinary 0.727251172 entropy_value 5.61346054 glob_norm 0.29532814\n",
      "Iteration 200 L -4.89301682 loss -4.89301682 loss_ordinary 0.718025804 entropy_value 5.6110425 glob_norm 0.363263875\n",
      "Iteration 250 L -4.92799664 loss -4.92799664 loss_ordinary 0.680513561 entropy_value 5.60851049 glob_norm 0.252508223\n",
      "Iteration 300 L -4.93692875 loss -4.93692875 loss_ordinary 0.682768285 entropy_value 5.61969709 glob_norm 0.282873452\n",
      "Iteration 350 L -4.90955257 loss -4.90955257 loss_ordinary 0.705687821 entropy_value 5.61524057 glob_norm 0.360496551\n",
      "Iteration 400 L -4.86485529 loss -4.86524534 loss_ordinary 0.745321214 entropy_value 5.61056662 glob_norm 0.260909498\n",
      "Iteration 450 L -4.89672709 loss -4.89672709 loss_ordinary 0.722572446 entropy_value 5.61929941 glob_norm 0.317360938\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0 lambd_papr 0 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90198278 loss -4.90198278 loss_ordinary 0.708901942 entropy_value 5.61088419 glob_norm 0.448639899\n",
      "Iteration 50 L -4.87059546 loss -4.87119722 loss_ordinary 0.732684255 entropy_value 5.60388136 glob_norm 0.335598409\n",
      "Iteration 100 L -4.9085865 loss -4.9085865 loss_ordinary 0.705082417 entropy_value 5.61366892 glob_norm 0.49467656\n",
      "Iteration 150 L -4.89934397 loss -4.89934397 loss_ordinary 0.716573298 entropy_value 5.61591721 glob_norm 0.301571816\n",
      "Iteration 200 L -4.9144907 loss -4.9144907 loss_ordinary 0.70019 entropy_value 5.61468077 glob_norm 0.415833056\n",
      "Iteration 250 L -4.88746834 loss -4.88746834 loss_ordinary 0.724856496 entropy_value 5.61232471 glob_norm 0.370159835\n",
      "Iteration 300 L -4.89431953 loss -4.89431953 loss_ordinary 0.721730232 entropy_value 5.61605024 glob_norm 0.284851879\n",
      "Iteration 350 L -4.86623383 loss -4.86623383 loss_ordinary 0.748735309 entropy_value 5.61496925 glob_norm 0.308542281\n",
      "Iteration 400 L -4.88051033 loss -4.88051033 loss_ordinary 0.730013609 entropy_value 5.6105237 glob_norm 0.349137127\n",
      "Iteration 450 L -4.86187124 loss -4.86190557 loss_ordinary 0.752070487 entropy_value 5.613976 glob_norm 0.432990402\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0 lambd_papr 0 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.925 loss -4.925 loss_ordinary 0.690656781 entropy_value 5.61565685 glob_norm 0.322049946\n",
      "Iteration 50 L -4.887568 loss -4.887568 loss_ordinary 0.724884 entropy_value 5.61245203 glob_norm 0.380735815\n",
      "Iteration 100 L -4.88017273 loss -4.88017273 loss_ordinary 0.733006358 entropy_value 5.61317921 glob_norm 0.372167617\n",
      "Iteration 150 L -4.85761 loss -4.85761166 loss_ordinary 0.754408419 entropy_value 5.61202 glob_norm 0.377572507\n",
      "Iteration 200 L -4.89379454 loss -4.89379454 loss_ordinary 0.714676321 entropy_value 5.60847092 glob_norm 0.379867136\n",
      "Iteration 250 L -4.91492 loss -4.91492 loss_ordinary 0.702070475 entropy_value 5.61699 glob_norm 0.277614385\n",
      "Iteration 300 L -4.8837719 loss -4.88379526 loss_ordinary 0.729396462 entropy_value 5.6131916 glob_norm 0.497567534\n",
      "Iteration 350 L -4.89483595 loss -4.89483595 loss_ordinary 0.723194599 entropy_value 5.61803055 glob_norm 0.344560564\n",
      "Iteration 400 L -4.90119362 loss -4.90120459 loss_ordinary 0.708417833 entropy_value 5.60962248 glob_norm 0.26998505\n",
      "Iteration 450 L -4.88733673 loss -4.88733673 loss_ordinary 0.724462628 entropy_value 5.61179924 glob_norm 0.311142206\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power 0 lambd_papr 0 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90083075 loss -4.90084171 loss_ordinary 0.704607904 entropy_value 5.60544968 glob_norm 0.30854395\n",
      "Iteration 50 L -4.88184834 loss -4.88184834 loss_ordinary 0.728501141 entropy_value 5.61034966 glob_norm 0.290702045\n",
      "Iteration 100 L -4.90310907 loss -4.90310907 loss_ordinary 0.706506371 entropy_value 5.60961533 glob_norm 0.275876552\n",
      "Iteration 150 L -4.89235497 loss -4.89235497 loss_ordinary 0.727731943 entropy_value 5.62008667 glob_norm 0.359523982\n",
      "Iteration 200 L -4.90605354 loss -4.90605354 loss_ordinary 0.710928738 entropy_value 5.61698246 glob_norm 0.332941353\n",
      "Iteration 250 L -4.90768433 loss -4.90768433 loss_ordinary 0.703705728 entropy_value 5.61139 glob_norm 0.386743456\n",
      "Iteration 300 L -4.89206934 loss -4.89206934 loss_ordinary 0.719535232 entropy_value 5.61160469 glob_norm 0.334735394\n",
      "Iteration 350 L -4.89431477 loss -4.89431477 loss_ordinary 0.722772062 entropy_value 5.61708641 glob_norm 0.437578291\n",
      "Iteration 400 L -4.9047184 loss -4.90472031 loss_ordinary 0.710769951 entropy_value 5.61549 glob_norm 0.393992454\n",
      "Iteration 450 L -4.87300682 loss -4.87300682 loss_ordinary 0.745127916 entropy_value 5.6181345 glob_norm 0.297704399\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0 lambd_papr 0 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88278532 loss -4.88278532 loss_ordinary 0.727517962 entropy_value 5.61030293 glob_norm 0.373968422\n",
      "Iteration 50 L -4.86397839 loss -4.8640933 loss_ordinary 0.746920586 entropy_value 5.61101389 glob_norm 0.302780211\n",
      "Iteration 100 L -4.88704967 loss -4.88704967 loss_ordinary 0.724284291 entropy_value 5.61133385 glob_norm 0.434005678\n",
      "Iteration 150 L -4.91786337 loss -4.91786337 loss_ordinary 0.696694851 entropy_value 5.61455822 glob_norm 0.298368067\n",
      "Iteration 200 L -4.9082 loss -4.9082 loss_ordinary 0.70249629 entropy_value 5.61069584 glob_norm 0.229592219\n",
      "Iteration 250 L -4.92401409 loss -4.92500257 loss_ordinary 0.689085722 entropy_value 5.61408806 glob_norm 0.300726682\n",
      "Iteration 300 L -4.89142132 loss -4.89142132 loss_ordinary 0.72599566 entropy_value 5.61741686 glob_norm 0.426153809\n",
      "Iteration 350 L -4.888309 loss -4.888309 loss_ordinary 0.725741506 entropy_value 5.61405039 glob_norm 0.367296159\n",
      "Iteration 400 L -4.8896656 loss -4.8896656 loss_ordinary 0.721352339 entropy_value 5.6110177 glob_norm 0.349046707\n",
      "Iteration 450 L -4.90535116 loss -4.90535116 loss_ordinary 0.707701147 entropy_value 5.61305237 glob_norm 0.301062107\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0 lambd_papr 0 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90120697 loss -4.90120697 loss_ordinary 0.707082391 entropy_value 5.60828972 glob_norm 0.32925269\n",
      "Iteration 50 L -4.90462828 loss -4.90462828 loss_ordinary 0.706543744 entropy_value 5.61117172 glob_norm 0.350716382\n",
      "Iteration 100 L -4.92409325 loss -4.92409325 loss_ordinary 0.692400753 entropy_value 5.61649418 glob_norm 0.274469\n",
      "Iteration 150 L -4.88523817 loss -4.88523817 loss_ordinary 0.723363221 entropy_value 5.60860109 glob_norm 0.371052861\n",
      "Iteration 200 L -4.91273403 loss -4.91275311 loss_ordinary 0.69907093 entropy_value 5.61182404 glob_norm 0.419613391\n",
      "Iteration 250 L -4.90705729 loss -4.9071312 loss_ordinary 0.707573354 entropy_value 5.61470461 glob_norm 0.284971148\n",
      "Iteration 300 L -4.88508368 loss -4.88508368 loss_ordinary 0.724745274 entropy_value 5.60982895 glob_norm 0.350801051\n",
      "Iteration 350 L -4.8841629 loss -4.8841629 loss_ordinary 0.721991956 entropy_value 5.60615444 glob_norm 0.412974924\n",
      "Iteration 400 L -4.87978315 loss -4.87985229 loss_ordinary 0.738045156 entropy_value 5.61789703 glob_norm 0.367999494\n",
      "Iteration 450 L -4.87387753 loss -4.87387753 loss_ordinary 0.740216076 entropy_value 5.61409378 glob_norm 0.456294447\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0 lambd_papr 0 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89383125 loss -4.89386654 loss_ordinary 0.719662905 entropy_value 5.61352921 glob_norm 0.267630428\n",
      "Iteration 50 L -4.87647152 loss -4.87647152 loss_ordinary 0.742890418 entropy_value 5.61936188 glob_norm 0.397694319\n",
      "Iteration 100 L -4.92615271 loss -4.92615271 loss_ordinary 0.691950798 entropy_value 5.6181035 glob_norm 0.344160974\n",
      "Iteration 150 L -4.88480139 loss -4.88480139 loss_ordinary 0.725460291 entropy_value 5.61026192 glob_norm 0.425083041\n",
      "Iteration 200 L -4.8773756 loss -4.8773756 loss_ordinary 0.739792824 entropy_value 5.61716843 glob_norm 0.464417219\n",
      "Iteration 250 L -4.90064907 loss -4.90064907 loss_ordinary 0.717951894 entropy_value 5.61860085 glob_norm 0.323642403\n",
      "Iteration 300 L -4.89812756 loss -4.89812756 loss_ordinary 0.720110774 entropy_value 5.61823845 glob_norm 0.348369\n",
      "Iteration 350 L -4.8723979 loss -4.8723979 loss_ordinary 0.741838872 entropy_value 5.61423683 glob_norm 0.347843707\n",
      "Iteration 400 L -4.86887455 loss -4.86887455 loss_ordinary 0.741101861 entropy_value 5.60997629 glob_norm 0.253800064\n",
      "Iteration 450 L -4.89989519 loss -4.89989519 loss_ordinary 0.714810193 entropy_value 5.61470509 glob_norm 0.350208789\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0 lambd_papr 0 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89776421 loss -4.89776516 loss_ordinary 0.715735316 entropy_value 5.6135006 glob_norm 0.315088898\n",
      "Iteration 50 L -4.89128256 loss -4.89128256 loss_ordinary 0.730454743 entropy_value 5.621737 glob_norm 0.458491892\n",
      "Iteration 100 L -4.88420534 loss -4.88420534 loss_ordinary 0.726270497 entropy_value 5.61047554 glob_norm 0.368253618\n",
      "Iteration 150 L -4.89028 loss -4.89028 loss_ordinary 0.717895 entropy_value 5.6081748 glob_norm 0.328488618\n",
      "Iteration 200 L -4.89779806 loss -4.89779806 loss_ordinary 0.718209147 entropy_value 5.61600733 glob_norm 0.377389699\n",
      "Iteration 250 L -4.88835478 loss -4.88835478 loss_ordinary 0.724675119 entropy_value 5.61302948 glob_norm 0.401346654\n",
      "Iteration 300 L -4.8878684 loss -4.88791418 loss_ordinary 0.722495317 entropy_value 5.61040974 glob_norm 0.474499375\n",
      "Iteration 350 L -4.86884642 loss -4.86939621 loss_ordinary 0.749230087 entropy_value 5.61862612 glob_norm 0.393866599\n",
      "Iteration 400 L -4.91474 loss -4.91474 loss_ordinary 0.700624406 entropy_value 5.61536407 glob_norm 0.326257855\n",
      "Iteration 450 L -4.88260412 loss -4.88260412 loss_ordinary 0.73292768 entropy_value 5.61553192 glob_norm 0.441495895\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0 lambd_papr 0 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.91627264 loss -4.91627264 loss_ordinary 0.702272415 entropy_value 5.61854506 glob_norm 0.344089687\n",
      "Iteration 50 L -4.89770412 loss -4.89770412 loss_ordinary 0.720070481 entropy_value 5.61777449 glob_norm 0.27436617\n",
      "Iteration 100 L -4.88041067 loss -4.88041067 loss_ordinary 0.735465825 entropy_value 5.61587667 glob_norm 0.314744294\n",
      "Iteration 150 L -4.90573454 loss -4.90573454 loss_ordinary 0.706492603 entropy_value 5.61222744 glob_norm 0.29700622\n",
      "Iteration 200 L -4.88356447 loss -4.8837595 loss_ordinary 0.735286295 entropy_value 5.61904621 glob_norm 0.314332515\n",
      "Iteration 250 L -4.88120937 loss -4.88120937 loss_ordinary 0.732995749 entropy_value 5.61420488 glob_norm 0.328157634\n",
      "Iteration 300 L -4.8990016 loss -4.8990016 loss_ordinary 0.714285791 entropy_value 5.61328745 glob_norm 0.297101289\n",
      "Iteration 350 L -4.89578819 loss -4.89578819 loss_ordinary 0.722527683 entropy_value 5.6183157 glob_norm 0.381186\n",
      "Iteration 400 L -4.88811779 loss -4.88812447 loss_ordinary 0.725970089 entropy_value 5.61409473 glob_norm 0.313824952\n",
      "Iteration 450 L -4.90941238 loss -4.90941238 loss_ordinary 0.70105 entropy_value 5.61046219 glob_norm 0.31497404\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0 lambd_papr 0 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89372444 loss -4.89372444 loss_ordinary 0.725923181 entropy_value 5.6196475 glob_norm 0.334535211\n",
      "Iteration 50 L -4.88226509 loss -4.88226509 loss_ordinary 0.735087216 entropy_value 5.61735249 glob_norm 0.411169976\n",
      "Iteration 100 L -4.91590691 loss -4.91590691 loss_ordinary 0.699312 entropy_value 5.61521912 glob_norm 0.287586063\n",
      "Iteration 150 L -4.87466431 loss -4.87466431 loss_ordinary 0.733068109 entropy_value 5.60773277 glob_norm 0.345537663\n",
      "Iteration 200 L -4.92005062 loss -4.92005062 loss_ordinary 0.693840504 entropy_value 5.61389112 glob_norm 0.275736481\n",
      "Iteration 250 L -4.89601421 loss -4.89601421 loss_ordinary 0.718737602 entropy_value 5.61475182 glob_norm 0.364340276\n",
      "Iteration 300 L -4.90434694 loss -4.90434694 loss_ordinary 0.70494771 entropy_value 5.60929441 glob_norm 0.26379016\n",
      "Iteration 350 L -4.87537861 loss -4.87537861 loss_ordinary 0.739801049 entropy_value 5.61518 glob_norm 0.379175276\n",
      "Iteration 400 L -4.8870039 loss -4.8870039 loss_ordinary 0.730355263 entropy_value 5.61735916 glob_norm 0.361662179\n",
      "Iteration 450 L -4.87764359 loss -4.87764359 loss_ordinary 0.734390318 entropy_value 5.61203384 glob_norm 0.305096328\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0 lambd_papr 0 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89152479 loss -4.89152479 loss_ordinary 0.719657481 entropy_value 5.61118269 glob_norm 0.354705632\n",
      "Iteration 50 L -4.90933609 loss -4.90933609 loss_ordinary 0.702977717 entropy_value 5.61231375 glob_norm 0.314058363\n",
      "Iteration 100 L -4.89025736 loss -4.89025736 loss_ordinary 0.717743874 entropy_value 5.60800123 glob_norm 0.347094595\n",
      "Iteration 150 L -4.91605806 loss -4.91605806 loss_ordinary 0.696702659 entropy_value 5.61276054 glob_norm 0.310522318\n",
      "Iteration 200 L -4.87754202 loss -4.87754202 loss_ordinary 0.73801589 entropy_value 5.61555815 glob_norm 0.388885409\n",
      "Iteration 250 L -4.893 loss -4.893 loss_ordinary 0.718598902 entropy_value 5.61159897 glob_norm 0.34886384\n",
      "Iteration 300 L -4.8795948 loss -4.8795948 loss_ordinary 0.734247267 entropy_value 5.61384201 glob_norm 0.357008934\n",
      "Iteration 350 L -4.85136318 loss -4.85136318 loss_ordinary 0.763416111 entropy_value 5.61477947 glob_norm 0.339094728\n",
      "Iteration 400 L -4.89305639 loss -4.89305639 loss_ordinary 0.725275576 entropy_value 5.61833191 glob_norm 0.360752165\n",
      "Iteration 450 L -4.90629244 loss -4.90629244 loss_ordinary 0.711330891 entropy_value 5.61762333 glob_norm 0.30969277\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0 lambd_papr 0 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.86915064 loss -4.86915064 loss_ordinary 0.747228563 entropy_value 5.61637926 glob_norm 0.251458436\n",
      "Iteration 50 L -4.90637875 loss -4.90637875 loss_ordinary 0.706634283 entropy_value 5.61301327 glob_norm 0.312055677\n",
      "Iteration 100 L -4.90432501 loss -4.90432501 loss_ordinary 0.709101558 entropy_value 5.61342669 glob_norm 0.319964767\n",
      "Iteration 150 L -4.89429092 loss -4.89429092 loss_ordinary 0.717661679 entropy_value 5.6119523 glob_norm 0.311637312\n",
      "Iteration 200 L -4.89824295 loss -4.89824295 loss_ordinary 0.712145 entropy_value 5.6103878 glob_norm 0.391682893\n",
      "Iteration 250 L -4.88023663 loss -4.88023663 loss_ordinary 0.736854255 entropy_value 5.6170907 glob_norm 0.340257078\n",
      "Iteration 300 L -4.89142132 loss -4.89142132 loss_ordinary 0.71937114 entropy_value 5.61079264 glob_norm 0.448187351\n",
      "Iteration 350 L -4.88305 loss -4.88305 loss_ordinary 0.730116308 entropy_value 5.61316633 glob_norm 0.316259325\n",
      "Iteration 400 L -4.86744881 loss -4.86746 loss_ordinary 0.747867405 entropy_value 5.61532688 glob_norm 0.380132139\n",
      "Iteration 450 L -4.91501427 loss -4.91501427 loss_ordinary 0.702996075 entropy_value 5.61801052 glob_norm 0.321114898\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0 lambd_papr 0 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90130377 loss -4.90130377 loss_ordinary 0.717424 entropy_value 5.61872768 glob_norm 0.334047258\n",
      "Iteration 50 L -4.895504 loss -4.895504 loss_ordinary 0.721797585 entropy_value 5.61730146 glob_norm 0.378012657\n",
      "Iteration 100 L -4.88967323 loss -4.88967323 loss_ordinary 0.720744312 entropy_value 5.61041737 glob_norm 0.32175228\n",
      "Iteration 150 L -4.93650341 loss -4.93650341 loss_ordinary 0.684223652 entropy_value 5.62072706 glob_norm 0.385772973\n",
      "Iteration 200 L -4.89850521 loss -4.89850521 loss_ordinary 0.720410168 entropy_value 5.61891556 glob_norm 0.372766018\n",
      "Iteration 250 L -4.90987825 loss -4.90987825 loss_ordinary 0.708608031 entropy_value 5.6184864 glob_norm 0.273059845\n",
      "Iteration 300 L -4.89333 loss -4.89345503 loss_ordinary 0.721722066 entropy_value 5.61517715 glob_norm 0.42220521\n",
      "Iteration 350 L -4.88943672 loss -4.88943672 loss_ordinary 0.72585386 entropy_value 5.61529064 glob_norm 0.291057914\n",
      "Iteration 400 L -4.8805995 loss -4.8805995 loss_ordinary 0.731573284 entropy_value 5.61217308 glob_norm 0.334270686\n",
      "Iteration 450 L -4.90212202 loss -4.9030304 loss_ordinary 0.717288733 entropy_value 5.62031889 glob_norm 0.349375278\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0 lambd_papr 0 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87425375 loss -4.87425375 loss_ordinary 0.741581 entropy_value 5.61583471 glob_norm 0.367529958\n",
      "Iteration 50 L -4.89504051 loss -4.89504051 loss_ordinary 0.712150812 entropy_value 5.60719156 glob_norm 0.514701784\n",
      "Iteration 100 L -4.9192915 loss -4.9192915 loss_ordinary 0.698417485 entropy_value 5.61770916 glob_norm 0.321870893\n",
      "Iteration 150 L -4.89493084 loss -4.89493084 loss_ordinary 0.716421664 entropy_value 5.61135244 glob_norm 0.284546942\n",
      "Iteration 200 L -4.91035795 loss -4.91035795 loss_ordinary 0.706241786 entropy_value 5.61659956 glob_norm 0.331842959\n",
      "Iteration 250 L -4.90141773 loss -4.90141773 loss_ordinary 0.713682175 entropy_value 5.6151 glob_norm 0.318853348\n",
      "Iteration 300 L -4.8946228 loss -4.8946228 loss_ordinary 0.719282091 entropy_value 5.61390495 glob_norm 0.35188815\n",
      "Iteration 350 L -4.90867805 loss -4.90867805 loss_ordinary 0.706147254 entropy_value 5.61482525 glob_norm 0.285618067\n",
      "Iteration 400 L -4.91074657 loss -4.91077518 loss_ordinary 0.701623321 entropy_value 5.61239815 glob_norm 0.329692334\n",
      "Iteration 450 L -4.90882158 loss -4.90882158 loss_ordinary 0.706532776 entropy_value 5.61535454 glob_norm 0.3563824\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0 lambd_papr 0 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.87039948 loss -4.87039948 loss_ordinary 0.74622792 entropy_value 5.61662722 glob_norm 0.423725486\n",
      "Iteration 50 L -4.91399 loss -4.91399717 loss_ordinary 0.702694952 entropy_value 5.61669207 glob_norm 0.294284523\n",
      "Iteration 100 L -4.9103117 loss -4.9103117 loss_ordinary 0.710154116 entropy_value 5.62046576 glob_norm 0.26824674\n",
      "Iteration 150 L -4.88796377 loss -4.88796377 loss_ordinary 0.726220191 entropy_value 5.6141839 glob_norm 0.293799\n",
      "Iteration 200 L -4.89668226 loss -4.89668226 loss_ordinary 0.714731395 entropy_value 5.61141348 glob_norm 0.268777519\n",
      "Iteration 250 L -4.86043024 loss -4.86061287 loss_ordinary 0.753940463 entropy_value 5.61455297 glob_norm 0.343507469\n",
      "Iteration 300 L -4.92977047 loss -4.92977047 loss_ordinary 0.684277415 entropy_value 5.614048 glob_norm 0.23949188\n",
      "Iteration 350 L -4.84741783 loss -4.84741783 loss_ordinary 0.76895076 entropy_value 5.61636829 glob_norm 0.331162333\n",
      "Iteration 400 L -4.90711164 loss -4.90711164 loss_ordinary 0.709215105 entropy_value 5.61632681 glob_norm 0.358351082\n",
      "Iteration 450 L -4.90439224 loss -4.90439224 loss_ordinary 0.709723651 entropy_value 5.61411572 glob_norm 0.469482\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power 0 lambd_papr 0 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88871527 loss -4.88871527 loss_ordinary 0.724830508 entropy_value 5.61354542 glob_norm 0.425349057\n",
      "Iteration 50 L -4.88457966 loss -4.88457966 loss_ordinary 0.733435154 entropy_value 5.61801481 glob_norm 0.400249779\n",
      "Iteration 100 L -4.89441299 loss -4.89441299 loss_ordinary 0.721739531 entropy_value 5.61615276 glob_norm 0.315107703\n",
      "Iteration 150 L -4.89966345 loss -4.89966345 loss_ordinary 0.709680557 entropy_value 5.60934401 glob_norm 0.313493699\n",
      "Iteration 200 L -4.91554832 loss -4.91554832 loss_ordinary 0.700902879 entropy_value 5.61645126 glob_norm 0.311696768\n",
      "Iteration 250 L -4.88737202 loss -4.88737583 loss_ordinary 0.727447033 entropy_value 5.61482286 glob_norm 0.294875711\n",
      "Iteration 300 L -4.90287161 loss -4.90287161 loss_ordinary 0.711702108 entropy_value 5.61457348 glob_norm 0.278042644\n",
      "Iteration 350 L -4.8883462 loss -4.8883462 loss_ordinary 0.721449673 entropy_value 5.60979605 glob_norm 0.346577406\n",
      "Iteration 400 L -4.89591026 loss -4.89591026 loss_ordinary 0.719089448 entropy_value 5.615 glob_norm 0.266108662\n",
      "Iteration 450 L -4.92496204 loss -4.92496204 loss_ordinary 0.68704 entropy_value 5.61200237 glob_norm 0.411325783\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.0361373425 lambd_papr 0 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89002371 loss -4.89001369 loss_ordinary 0.722703397 entropy_value 5.61271715 glob_norm 0.304627985\n",
      "Iteration 50 L -4.90533352 loss -4.90532303 loss_ordinary 0.708121955 entropy_value 5.61344528 glob_norm 0.261272669\n",
      "Iteration 100 L -4.84570742 loss -4.84569693 loss_ordinary 0.769071162 entropy_value 5.61476803 glob_norm 0.370535344\n",
      "Iteration 150 L -4.85261679 loss -4.8526063 loss_ordinary 0.767685592 entropy_value 5.62029171 glob_norm 0.302164882\n",
      "Iteration 200 L -4.89211655 loss -4.89210606 loss_ordinary 0.719117582 entropy_value 5.6112237 glob_norm 0.455598712\n",
      "Iteration 250 L -4.92831469 loss -4.92830467 loss_ordinary 0.683243573 entropy_value 5.61154842 glob_norm 0.342252135\n",
      "Iteration 300 L -4.90098333 loss -4.90097284 loss_ordinary 0.710306346 entropy_value 5.61127949 glob_norm 0.304896\n",
      "Iteration 350 L -4.90777302 loss -4.90776253 loss_ordinary 0.709150136 entropy_value 5.61691284 glob_norm 0.355923414\n",
      "Iteration 400 L -4.88314104 loss -4.88313055 loss_ordinary 0.733319223 entropy_value 5.61645 glob_norm 0.332228631\n",
      "Iteration 450 L -4.90505505 loss -4.90505791 loss_ordinary 0.703087032 entropy_value 5.60814524 glob_norm 0.330442071\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.0360292569 lambd_papr -0.000404941209 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.8627944 loss -4.8627944 loss_ordinary 0.749599278 entropy_value 5.61239386 glob_norm 0.345509768\n",
      "Iteration 50 L -4.9238739 loss -4.9238739 loss_ordinary 0.694556296 entropy_value 5.61843 glob_norm 0.416847259\n",
      "Iteration 100 L -4.917171 loss -4.917171 loss_ordinary 0.699167967 entropy_value 5.61633921 glob_norm 0.304645956\n",
      "Iteration 150 L -4.90543604 loss -4.90543604 loss_ordinary 0.708437383 entropy_value 5.61387348 glob_norm 0.302115589\n",
      "Iteration 200 L -4.86564 loss -4.86571598 loss_ordinary 0.746859848 entropy_value 5.61257553 glob_norm 0.334427\n",
      "Iteration 250 L -4.87155914 loss -4.87155914 loss_ordinary 0.743091464 entropy_value 5.61465025 glob_norm 0.435434878\n",
      "Iteration 300 L -4.88253593 loss -4.88253593 loss_ordinary 0.733424544 entropy_value 5.6159606 glob_norm 0.284296244\n",
      "Iteration 350 L -4.91881657 loss -4.91881657 loss_ordinary 0.701138854 entropy_value 5.61995554 glob_norm 0.411978215\n",
      "Iteration 400 L -4.87378168 loss -4.87378168 loss_ordinary 0.738380849 entropy_value 5.61216307 glob_norm 0.453118235\n",
      "Iteration 450 L -4.89491796 loss -4.89491796 loss_ordinary 0.717894 entropy_value 5.61281204 glob_norm 0.271128625\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 2.58174015e-09 lambd_papr 2.91038305e-11 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89469242 loss -4.89469242 loss_ordinary 0.721624255 entropy_value 5.6163168 glob_norm 0.306850761\n",
      "Iteration 50 L -4.90263 loss -4.90263 loss_ordinary 0.70947969 entropy_value 5.61210966 glob_norm 0.287323356\n",
      "Iteration 100 L -4.88485193 loss -4.88485193 loss_ordinary 0.729990184 entropy_value 5.61484194 glob_norm 0.289491981\n",
      "Iteration 150 L -4.87381554 loss -4.87381554 loss_ordinary 0.740190268 entropy_value 5.61400604 glob_norm 0.355431348\n",
      "Iteration 200 L -4.89184904 loss -4.89184904 loss_ordinary 0.721434355 entropy_value 5.61328363 glob_norm 0.306470364\n",
      "Iteration 250 L -4.88866234 loss -4.88866234 loss_ordinary 0.726384044 entropy_value 5.6150465 glob_norm 0.366892606\n",
      "Iteration 300 L -4.89522266 loss -4.89530087 loss_ordinary 0.713771045 entropy_value 5.60907221 glob_norm 0.461302966\n",
      "Iteration 350 L -4.88873482 loss -4.88873482 loss_ordinary 0.729062676 entropy_value 5.61779737 glob_norm 0.330579966\n",
      "Iteration 400 L -4.90028906 loss -4.9007349 loss_ordinary 0.715452492 entropy_value 5.61618757 glob_norm 0.333006859\n",
      "Iteration 450 L -4.88423729 loss -4.88430309 loss_ordinary 0.722185433 entropy_value 5.6064887 glob_norm 0.332282275\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0 lambd_papr 0 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.9033432 loss -4.90338182 loss_ordinary 0.71472609 entropy_value 5.6181078 glob_norm 0.343201697\n",
      "Iteration 50 L -4.90990925 loss -4.90990925 loss_ordinary 0.709674358 entropy_value 5.61958361 glob_norm 0.373185396\n",
      "Iteration 100 L -4.90550852 loss -4.90550852 loss_ordinary 0.699240625 entropy_value 5.6047492 glob_norm 0.319817871\n",
      "Iteration 150 L -4.91910887 loss -4.91910887 loss_ordinary 0.692641199 entropy_value 5.61175 glob_norm 0.30807963\n",
      "Iteration 200 L -4.85834551 loss -4.85834551 loss_ordinary 0.751189768 entropy_value 5.60953522 glob_norm 0.369601965\n",
      "Iteration 250 L -4.93356228 loss -4.93356228 loss_ordinary 0.683520198 entropy_value 5.6170826 glob_norm 0.447913229\n",
      "Iteration 300 L -4.89831638 loss -4.89831638 loss_ordinary 0.718187571 entropy_value 5.61650419 glob_norm 0.41436854\n",
      "Iteration 350 L -4.91215658 loss -4.91215658 loss_ordinary 0.701268733 entropy_value 5.61342573 glob_norm 0.26788649\n",
      "Iteration 400 L -4.89501953 loss -4.89501953 loss_ordinary 0.717429638 entropy_value 5.61244917 glob_norm 0.274741411\n",
      "Iteration 450 L -4.91487598 loss -4.91487598 loss_ordinary 0.696315765 entropy_value 5.61119175 glob_norm 0.325207621\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0 lambd_papr 0 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.88215065 loss -4.88215065 loss_ordinary 0.729376853 entropy_value 5.61152744 glob_norm 0.373750776\n",
      "Iteration 50 L -4.91453028 loss -4.91514111 loss_ordinary 0.699279726 entropy_value 5.61442089 glob_norm 0.268301755\n",
      "Iteration 100 L -4.89581299 loss -4.89581299 loss_ordinary 0.717275 entropy_value 5.61308813 glob_norm 0.362015\n",
      "Iteration 150 L -4.91478395 loss -4.91478395 loss_ordinary 0.699168444 entropy_value 5.61395264 glob_norm 0.452697456\n",
      "Iteration 200 L -4.90640545 loss -4.90644073 loss_ordinary 0.706426203 entropy_value 5.61286688 glob_norm 0.308533251\n",
      "Iteration 250 L -4.89784336 loss -4.8986063 loss_ordinary 0.713897467 entropy_value 5.61250401 glob_norm 0.411004394\n",
      "Iteration 300 L -4.8996172 loss -4.8996172 loss_ordinary 0.71423167 entropy_value 5.61384869 glob_norm 0.289068222\n",
      "Iteration 350 L -4.85196495 loss -4.85196495 loss_ordinary 0.758804142 entropy_value 5.6107688 glob_norm 0.368745446\n",
      "Iteration 400 L -4.91400909 loss -4.91400909 loss_ordinary 0.698352516 entropy_value 5.61236143 glob_norm 0.350526154\n",
      "Iteration 450 L -4.87719917 loss -4.87726831 loss_ordinary 0.739432693 entropy_value 5.61670113 glob_norm 0.419918954\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power 0 lambd_papr 0 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89625025 loss -4.89625025 loss_ordinary 0.717849195 entropy_value 5.6140995 glob_norm 0.298681974\n",
      "Iteration 50 L -4.88407326 loss -4.88407326 loss_ordinary 0.734430432 entropy_value 5.61850405 glob_norm 0.287148148\n",
      "Iteration 100 L -4.90894508 loss -4.90894508 loss_ordinary 0.706687093 entropy_value 5.61563206 glob_norm 0.308079094\n",
      "Iteration 150 L -4.90381956 loss -4.90381956 loss_ordinary 0.710570574 entropy_value 5.61439 glob_norm 0.312665373\n",
      "Iteration 200 L -4.88956404 loss -4.88956404 loss_ordinary 0.724695563 entropy_value 5.61425972 glob_norm 0.337716132\n",
      "Iteration 250 L -4.89810514 loss -4.89824 loss_ordinary 0.714398205 entropy_value 5.612638 glob_norm 0.393460065\n",
      "Iteration 300 L -4.8894043 loss -4.8894043 loss_ordinary 0.724686384 entropy_value 5.61409092 glob_norm 0.274332821\n",
      "Iteration 350 L -4.90583515 loss -4.9058547 loss_ordinary 0.711425126 entropy_value 5.61727953 glob_norm 0.329157859\n",
      "Iteration 400 L -4.86284065 loss -4.86284065 loss_ordinary 0.752429962 entropy_value 5.61527061 glob_norm 0.449109256\n",
      "Iteration 450 L -4.88327169 loss -4.88327169 loss_ordinary 0.729630291 entropy_value 5.61290169 glob_norm 0.325235724\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.338975668 lambd_papr 0 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90539455 loss -4.90531778 loss_ordinary 0.708476186 entropy_value 5.61379433 glob_norm 0.244870812\n",
      "Iteration 50 L -4.89404 loss -4.89429474 loss_ordinary 0.720506251 entropy_value 5.61480093 glob_norm 0.410424262\n",
      "Iteration 100 L -4.92492485 loss -4.92401457 loss_ordinary 0.685637 entropy_value 5.60965157 glob_norm 0.441509157\n",
      "Iteration 150 L -4.86767673 loss -4.86723518 loss_ordinary 0.743597567 entropy_value 5.61083269 glob_norm 0.324528486\n",
      "Iteration 200 L -4.88755274 loss -4.88677168 loss_ordinary 0.727306 entropy_value 5.61407757 glob_norm 0.32190448\n",
      "Iteration 250 L -4.92139864 loss -4.92277575 loss_ordinary 0.695270538 entropy_value 5.61804628 glob_norm 0.376177\n",
      "Iteration 300 L -4.89093542 loss -4.89055872 loss_ordinary 0.725264251 entropy_value 5.61582327 glob_norm 0.325920343\n",
      "Iteration 350 L -4.89516401 loss -4.89424658 loss_ordinary 0.720090687 entropy_value 5.61433697 glob_norm 0.28170678\n",
      "Iteration 400 L -4.90039825 loss -4.89945555 loss_ordinary 0.715698719 entropy_value 5.61515379 glob_norm 0.253981948\n",
      "Iteration 450 L -4.89657 loss -4.8956275 loss_ordinary 0.723416448 entropy_value 5.61904383 glob_norm 0.377131522\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power -0.337961763 lambd_papr -0.00386731839 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.9052844 loss -4.9052844 loss_ordinary 0.714232087 entropy_value 5.61951637 glob_norm 0.321568787\n",
      "Iteration 50 L -4.92328691 loss -4.92328691 loss_ordinary 0.701659203 entropy_value 5.62494659 glob_norm 0.354476511\n",
      "Iteration 100 L -4.88872766 loss -4.88872766 loss_ordinary 0.732987285 entropy_value 5.62171507 glob_norm 0.324813396\n",
      "Iteration 150 L -4.87950087 loss -4.87950087 loss_ordinary 0.736365914 entropy_value 5.61586618 glob_norm 0.327688873\n",
      "Iteration 200 L -4.88777447 loss -4.88777447 loss_ordinary 0.72112 entropy_value 5.60889435 glob_norm 0.416145146\n",
      "Iteration 250 L -4.91440582 loss -4.91440582 loss_ordinary 0.69686228 entropy_value 5.61126804 glob_norm 0.414679229\n",
      "Iteration 300 L -4.86976767 loss -4.86976767 loss_ordinary 0.749583304 entropy_value 5.61935091 glob_norm 0.384628415\n",
      "Iteration 350 L -4.89858484 loss -4.89858484 loss_ordinary 0.713709354 entropy_value 5.6122942 glob_norm 0.360764056\n",
      "Iteration 400 L -4.89108753 loss -4.89108753 loss_ordinary 0.724532485 entropy_value 5.61562 glob_norm 0.395796061\n",
      "Iteration 450 L -4.88921452 loss -4.88921452 loss_ordinary 0.722177148 entropy_value 5.61139154 glob_norm 0.329907864\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power -2.028602e-08 lambd_papr -2.32830644e-10 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.90405416 loss -4.90405416 loss_ordinary 0.712218344 entropy_value 5.61627245 glob_norm 0.342272341\n",
      "Iteration 50 L -4.87638712 loss -4.87638712 loss_ordinary 0.737757206 entropy_value 5.61414433 glob_norm 0.301097274\n",
      "Iteration 100 L -4.91024733 loss -4.91024733 loss_ordinary 0.706174791 entropy_value 5.61642218 glob_norm 0.310344934\n",
      "Iteration 150 L -4.86331034 loss -4.86331034 loss_ordinary 0.747459233 entropy_value 5.61076975 glob_norm 0.325516641\n",
      "Iteration 200 L -4.9147 loss -4.9147 loss_ordinary 0.697539032 entropy_value 5.61223888 glob_norm 0.302865416\n",
      "Iteration 250 L -4.89608049 loss -4.89608049 loss_ordinary 0.716385484 entropy_value 5.61246586 glob_norm 0.403516918\n",
      "Iteration 300 L -4.90677691 loss -4.90687323 loss_ordinary 0.70911926 entropy_value 5.61599207 glob_norm 0.253042221\n",
      "Iteration 350 L -4.91261435 loss -4.91261435 loss_ordinary 0.701265931 entropy_value 5.61388 glob_norm 0.406284153\n",
      "Iteration 400 L -4.87844467 loss -4.87844467 loss_ordinary 0.73918128 entropy_value 5.61762619 glob_norm 0.296692967\n",
      "Iteration 450 L -4.86315536 loss -4.86315536 loss_ordinary 0.751274049 entropy_value 5.61442947 glob_norm 0.368569\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0 lambd_papr 0 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89916 loss -4.89916 loss_ordinary 0.716938913 entropy_value 5.61609888 glob_norm 0.309162855\n",
      "Iteration 50 L -4.91973925 loss -4.91973925 loss_ordinary 0.696508586 entropy_value 5.61624813 glob_norm 0.346991092\n",
      "Iteration 100 L -4.90476274 loss -4.90476274 loss_ordinary 0.707394123 entropy_value 5.61215687 glob_norm 0.349268734\n",
      "Iteration 150 L -4.86980677 loss -4.86980677 loss_ordinary 0.741164446 entropy_value 5.61097097 glob_norm 0.345421\n",
      "Iteration 200 L -4.90701246 loss -4.90701246 loss_ordinary 0.705254614 entropy_value 5.61226702 glob_norm 0.328824937\n",
      "Iteration 250 L -4.8855648 loss -4.8855648 loss_ordinary 0.726632 entropy_value 5.61219692 glob_norm 0.362899601\n",
      "Iteration 300 L -4.87988329 loss -4.87988329 loss_ordinary 0.734179676 entropy_value 5.61406279 glob_norm 0.306112319\n",
      "Iteration 350 L -4.91597557 loss -4.91597557 loss_ordinary 0.70015192 entropy_value 5.61612797 glob_norm 0.307849169\n",
      "Iteration 400 L -4.92340517 loss -4.92340517 loss_ordinary 0.689544797 entropy_value 5.61295 glob_norm 0.311017573\n",
      "Iteration 450 L -4.89085 loss -4.89085 loss_ordinary 0.728363037 entropy_value 5.6192131 glob_norm 0.2862252\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0 lambd_papr 0 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -4.89108276 loss -4.89108276 loss_ordinary 0.723340511 entropy_value 5.61442327 glob_norm 0.274944484\n",
      "Iteration 50 L -4.89901876 loss -4.89901876 loss_ordinary 0.71834743 entropy_value 5.61736584 glob_norm 0.298704118\n",
      "Iteration 100 L -4.88055468 loss -4.88055468 loss_ordinary 0.729948699 entropy_value 5.6105032 glob_norm 0.391341358\n",
      "Iteration 150 L -4.91811657 loss -4.91811657 loss_ordinary 0.696670175 entropy_value 5.61478662 glob_norm 0.393096983\n",
      "Iteration 200 L -4.89379644 loss -4.89379644 loss_ordinary 0.718291581 entropy_value 5.6120882 glob_norm 0.319965631\n",
      "Iteration 250 L -4.87689352 loss -4.87689352 loss_ordinary 0.735463083 entropy_value 5.61235666 glob_norm 0.355413646\n",
      "Iteration 300 L -4.89698887 loss -4.89698887 loss_ordinary 0.724462092 entropy_value 5.6214509 glob_norm 0.332596362\n",
      "Iteration 350 L -4.90006 loss -4.90006 loss_ordinary 0.713467 entropy_value 5.6135273 glob_norm 0.419995785\n",
      "Iteration 400 L -4.89011908 loss -4.89011908 loss_ordinary 0.723436415 entropy_value 5.61355543 glob_norm 0.352725774\n",
      "Iteration 450 L -4.88037586 loss -4.88037586 loss_ordinary 0.727656066 entropy_value 5.60803223 glob_norm 0.286783\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0 lambd_papr 0 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_15_papr_8.0\n",
      "\n",
      "===== Running SNR=17 dB | PAPR=6.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0186928604 loss 0.017692199 loss_ordinary 6.00887585 entropy_value 5.99118328 glob_norm 0.64192462\n",
      "Iteration 50 L -3.42171836 loss -3.42225933 loss_ordinary 2.55253696 entropy_value 5.9747963 glob_norm 0.402898192\n",
      "Iteration 100 L -4.34458303 loss -4.34668064 loss_ordinary 1.61846781 entropy_value 5.96514845 glob_norm 0.334809959\n",
      "Iteration 150 L -4.79959106 loss -4.80653143 loss_ordinary 1.11192799 entropy_value 5.91845942 glob_norm 0.440405905\n",
      "Iteration 200 L -5.09767246 loss -5.10808706 loss_ordinary 0.743846595 entropy_value 5.85193396 glob_norm 0.461679041\n",
      "Iteration 250 L -5.22848558 loss -5.24112701 loss_ordinary 0.602789462 entropy_value 5.84391689 glob_norm 0.44190979\n",
      "Iteration 300 L -5.27561951 loss -5.28814 loss_ordinary 0.548902 entropy_value 5.83704138 glob_norm 0.418093324\n",
      "Iteration 350 L -5.3055687 loss -5.31570864 loss_ordinary 0.526195228 entropy_value 5.84190369 glob_norm 0.48648122\n",
      "Iteration 400 L -5.32263374 loss -5.33539677 loss_ordinary 0.49565357 entropy_value 5.8310504 glob_norm 0.373321533\n",
      "Iteration 450 L -5.3469 loss -5.35842657 loss_ordinary 0.476357788 entropy_value 5.83478451 glob_norm 0.341522455\n",
      "Iteration 500 L -5.3535676 loss -5.36384964 loss_ordinary 0.469099283 entropy_value 5.83294916 glob_norm 0.333574623\n",
      "Iteration 550 L -5.35388708 loss -5.36559391 loss_ordinary 0.470538855 entropy_value 5.836133 glob_norm 0.355057836\n",
      "Iteration 600 L -5.33879948 loss -5.3500452 loss_ordinary 0.479910016 entropy_value 5.8299551 glob_norm 0.330659926\n",
      "Iteration 650 L -5.3611722 loss -5.37088251 loss_ordinary 0.457113534 entropy_value 5.82799578 glob_norm 0.305919111\n",
      "Iteration 700 L -5.3412118 loss -5.35172796 loss_ordinary 0.479050964 entropy_value 5.8307786 glob_norm 0.29638508\n",
      "Iteration 750 L -5.35062599 loss -5.3624897 loss_ordinary 0.466420382 entropy_value 5.82891035 glob_norm 0.324183851\n",
      "Iteration 800 L -5.34473562 loss -5.35466099 loss_ordinary 0.473884523 entropy_value 5.82854557 glob_norm 0.381603897\n",
      "Iteration 850 L -5.3610568 loss -5.37064743 loss_ordinary 0.458198398 entropy_value 5.8288455 glob_norm 0.387224168\n",
      "Iteration 900 L -5.35500813 loss -5.36605453 loss_ordinary 0.464066535 entropy_value 5.83012104 glob_norm 0.390851349\n",
      "Iteration 950 L -5.35448313 loss -5.36614 loss_ordinary 0.456276208 entropy_value 5.82241631 glob_norm 0.311905742\n",
      "Iteration 1000 L -5.34535027 loss -5.35480356 loss_ordinary 0.472364187 entropy_value 5.82716751 glob_norm 0.39692536\n",
      "Iteration 1050 L -5.35359716 loss -5.36195946 loss_ordinary 0.464928269 entropy_value 5.82688761 glob_norm 0.332631648\n",
      "Iteration 1100 L -5.32905865 loss -5.33848333 loss_ordinary 0.487756371 entropy_value 5.82623959 glob_norm 0.299579561\n",
      "Iteration 1150 L -5.36290741 loss -5.37492132 loss_ordinary 0.455415636 entropy_value 5.83033705 glob_norm 0.345188886\n",
      "Iteration 1200 L -5.3594718 loss -5.37083244 loss_ordinary 0.454580396 entropy_value 5.82541275 glob_norm 0.303827971\n",
      "Iteration 1250 L -5.35008335 loss -5.3581214 loss_ordinary 0.468121022 entropy_value 5.82624245 glob_norm 0.436933\n",
      "Iteration 1300 L -5.34732628 loss -5.35799885 loss_ordinary 0.46896258 entropy_value 5.82696152 glob_norm 0.389905423\n",
      "Iteration 1350 L -5.36284399 loss -5.37322617 loss_ordinary 0.452312 entropy_value 5.82553816 glob_norm 0.331287354\n",
      "Iteration 1400 L -5.35088539 loss -5.3605094 loss_ordinary 0.463147342 entropy_value 5.82365656 glob_norm 0.391662687\n",
      "Iteration 1450 L -5.34560108 loss -5.35703039 loss_ordinary 0.470567137 entropy_value 5.82759762 glob_norm 0.461844206\n",
      "Iteration 1500 L -5.3444066 loss -5.35533142 loss_ordinary 0.469415724 entropy_value 5.82474709 glob_norm 0.368311435\n",
      "Iteration 1550 L -5.34878588 loss -5.360672 loss_ordinary 0.464330822 entropy_value 5.82500267 glob_norm 0.388123691\n",
      "Iteration 1600 L -5.35424757 loss -5.3637538 loss_ordinary 0.459413558 entropy_value 5.82316732 glob_norm 0.387507617\n",
      "Iteration 1650 L -5.37285948 loss -5.3839407 loss_ordinary 0.442743659 entropy_value 5.826684 glob_norm 0.241938114\n",
      "Iteration 1700 L -5.37325478 loss -5.38403082 loss_ordinary 0.439861804 entropy_value 5.82389259 glob_norm 0.349953026\n",
      "Iteration 1750 L -5.36264563 loss -5.37244034 loss_ordinary 0.448712111 entropy_value 5.82115221 glob_norm 0.414280206\n",
      "Iteration 1800 L -5.35004139 loss -5.36009264 loss_ordinary 0.463945627 entropy_value 5.82403851 glob_norm 0.317197293\n",
      "Iteration 1850 L -5.35786676 loss -5.36926317 loss_ordinary 0.455980271 entropy_value 5.82524347 glob_norm 0.422253191\n",
      "Iteration 1900 L -5.35648489 loss -5.36703968 loss_ordinary 0.456569701 entropy_value 5.82360888 glob_norm 0.336539984\n",
      "Iteration 1950 L -5.34485388 loss -5.3560462 loss_ordinary 0.467314184 entropy_value 5.82336 glob_norm 0.375677794\n",
      "Iteration 2000 L -5.34623814 loss -5.35571241 loss_ordinary 0.464617372 entropy_value 5.82032967 glob_norm 0.31401965\n",
      "Iteration 2050 L -5.3732357 loss -5.38435555 loss_ordinary 0.439669251 entropy_value 5.82402468 glob_norm 0.476391613\n",
      "Iteration 2100 L -5.34574223 loss -5.35710049 loss_ordinary 0.46400851 entropy_value 5.82110929 glob_norm 0.484146386\n",
      "Iteration 2150 L -5.35455561 loss -5.36561632 loss_ordinary 0.459944725 entropy_value 5.82556152 glob_norm 0.491478562\n",
      "Iteration 2200 L -5.36445761 loss -5.37488747 loss_ordinary 0.447764128 entropy_value 5.82265139 glob_norm 0.40142554\n",
      "Iteration 2250 L -5.35629845 loss -5.36517191 loss_ordinary 0.461674184 entropy_value 5.8268466 glob_norm 0.342528522\n",
      "Iteration 2300 L -5.34533167 loss -5.35417366 loss_ordinary 0.471471906 entropy_value 5.82564545 glob_norm 0.332916528\n",
      "Iteration 2350 L -5.33344078 loss -5.34476376 loss_ordinary 0.479793072 entropy_value 5.82455683 glob_norm 0.332659036\n",
      "Iteration 2400 L -5.36004591 loss -5.36926222 loss_ordinary 0.458835 entropy_value 5.82809687 glob_norm 0.386966735\n",
      "Iteration 2450 L -5.33314657 loss -5.3431077 loss_ordinary 0.47808519 entropy_value 5.82119322 glob_norm 0.405160248\n",
      "Iteration 2500 L -5.36138773 loss -5.37194157 loss_ordinary 0.447354 entropy_value 5.81929588 glob_norm 0.353856\n",
      "Iteration 2550 L -5.33322763 loss -5.34271479 loss_ordinary 0.480020761 entropy_value 5.82273531 glob_norm 0.492805123\n",
      "Iteration 2600 L -5.36158037 loss -5.37138271 loss_ordinary 0.449299932 entropy_value 5.82068253 glob_norm 0.360372245\n",
      "Iteration 2650 L -5.34262848 loss -5.35343122 loss_ordinary 0.466642588 entropy_value 5.8200736 glob_norm 0.284242392\n",
      "Iteration 2700 L -5.37961626 loss -5.3906908 loss_ordinary 0.435130715 entropy_value 5.8258214 glob_norm 0.38926512\n",
      "Iteration 2750 L -5.36522 loss -5.37487316 loss_ordinary 0.450064778 entropy_value 5.8249383 glob_norm 0.339237869\n",
      "Iteration 2800 L -5.34148741 loss -5.35191202 loss_ordinary 0.468976557 entropy_value 5.820889 glob_norm 0.301526695\n",
      "Iteration 2850 L -5.34995556 loss -5.36098194 loss_ordinary 0.46138078 entropy_value 5.82236242 glob_norm 0.285566151\n",
      "Iteration 2900 L -5.37126684 loss -5.38285685 loss_ordinary 0.435760379 entropy_value 5.81861734 glob_norm 0.30999577\n",
      "Iteration 2950 L -5.36139441 loss -5.37058592 loss_ordinary 0.455159396 entropy_value 5.82574511 glob_norm 0.267776132\n",
      "Iteration 3000 L -5.36795282 loss -5.37885571 loss_ordinary 0.445675015 entropy_value 5.82453108 glob_norm 0.308451235\n",
      "Iteration 3050 L -5.35368204 loss -5.3624835 loss_ordinary 0.463144362 entropy_value 5.82562828 glob_norm 0.369602621\n",
      "Iteration 3100 L -5.35806608 loss -5.36904764 loss_ordinary 0.457061529 entropy_value 5.82610893 glob_norm 0.439085335\n",
      "Iteration 3150 L -5.36535072 loss -5.37592649 loss_ordinary 0.446162283 entropy_value 5.82208872 glob_norm 0.378073961\n",
      "Iteration 3200 L -5.36978483 loss -5.3792429 loss_ordinary 0.441162586 entropy_value 5.82040548 glob_norm 0.325709909\n",
      "Iteration 3250 L -5.36365175 loss -5.37156963 loss_ordinary 0.456253588 entropy_value 5.82782316 glob_norm 0.328233898\n",
      "Iteration 3300 L -5.37149382 loss -5.38151789 loss_ordinary 0.444475383 entropy_value 5.82599354 glob_norm 0.305149734\n",
      "Iteration 3350 L -5.35657787 loss -5.36818933 loss_ordinary 0.454606473 entropy_value 5.82279587 glob_norm 0.397351384\n",
      "Iteration 3400 L -5.34557676 loss -5.35532045 loss_ordinary 0.466606647 entropy_value 5.82192707 glob_norm 0.317961842\n",
      "Iteration 3450 L -5.33592844 loss -5.34444427 loss_ordinary 0.48091045 entropy_value 5.8253541 glob_norm 0.46805051\n",
      "Iteration 3500 L -5.36890125 loss -5.37880087 loss_ordinary 0.449444652 entropy_value 5.82824564 glob_norm 0.359823763\n",
      "Iteration 3550 L -5.36960888 loss -5.37944841 loss_ordinary 0.446699142 entropy_value 5.82614756 glob_norm 0.431045085\n",
      "Iteration 3600 L -5.35793 loss -5.36860609 loss_ordinary 0.45630908 entropy_value 5.82491541 glob_norm 0.284824967\n",
      "Iteration 3650 L -5.35328484 loss -5.36244249 loss_ordinary 0.458567798 entropy_value 5.82101 glob_norm 0.382661611\n",
      "Iteration 3700 L -5.3639164 loss -5.37444 loss_ordinary 0.449466079 entropy_value 5.82390642 glob_norm 0.381915063\n",
      "Iteration 3750 L -5.35086536 loss -5.36084175 loss_ordinary 0.460352868 entropy_value 5.82119417 glob_norm 0.368621171\n",
      "Iteration 3800 L -5.37011433 loss -5.37995768 loss_ordinary 0.449128568 entropy_value 5.8290863 glob_norm 0.354932338\n",
      "Iteration 3850 L -5.37142086 loss -5.38070917 loss_ordinary 0.44299987 entropy_value 5.82370901 glob_norm 0.353040546\n",
      "Iteration 3900 L -5.36498547 loss -5.37580109 loss_ordinary 0.443182528 entropy_value 5.81898355 glob_norm 0.421797782\n",
      "Iteration 3950 L -5.33860254 loss -5.3491354 loss_ordinary 0.472747535 entropy_value 5.8218832 glob_norm 0.378377318\n",
      "Iteration 4000 L -5.3416791 loss -5.3513813 loss_ordinary 0.480153441 entropy_value 5.83153486 glob_norm 0.385184497\n",
      "Iteration 4050 L -5.35253716 loss -5.36321497 loss_ordinary 0.458645344 entropy_value 5.82186031 glob_norm 0.396977127\n",
      "Iteration 4100 L -5.36129856 loss -5.37075853 loss_ordinary 0.45207119 entropy_value 5.82282972 glob_norm 0.306940556\n",
      "Iteration 4150 L -5.3461771 loss -5.35581064 loss_ordinary 0.471117407 entropy_value 5.82692814 glob_norm 0.477652043\n",
      "Iteration 4200 L -5.37462 loss -5.38603592 loss_ordinary 0.435884953 entropy_value 5.82192087 glob_norm 0.321331382\n",
      "Iteration 4250 L -5.36904907 loss -5.38014221 loss_ordinary 0.441004694 entropy_value 5.82114697 glob_norm 0.282941431\n",
      "Iteration 4300 L -5.36227226 loss -5.37220716 loss_ordinary 0.451129407 entropy_value 5.8233366 glob_norm 0.305791527\n",
      "Iteration 4350 L -5.34313393 loss -5.35490561 loss_ordinary 0.467637509 entropy_value 5.82254267 glob_norm 0.354023099\n",
      "Iteration 4400 L -5.35518503 loss -5.36756372 loss_ordinary 0.454460293 entropy_value 5.82202387 glob_norm 0.389294267\n",
      "Iteration 4450 L -5.37347364 loss -5.38568974 loss_ordinary 0.435127527 entropy_value 5.82081747 glob_norm 0.394904763\n",
      "Iteration 4500 L -5.33869886 loss -5.34834957 loss_ordinary 0.47872445 entropy_value 5.82707405 glob_norm 0.306937695\n",
      "Iteration 4550 L -5.32710171 loss -5.33632803 loss_ordinary 0.488863289 entropy_value 5.8251915 glob_norm 0.386817873\n",
      "Iteration 4600 L -5.34348 loss -5.35506392 loss_ordinary 0.463801 entropy_value 5.81886482 glob_norm 0.358743131\n",
      "Iteration 4650 L -5.36044598 loss -5.3692708 loss_ordinary 0.453305662 entropy_value 5.82257652 glob_norm 0.285533041\n",
      "Iteration 4700 L -5.33920288 loss -5.3504405 loss_ordinary 0.47479713 entropy_value 5.82523823 glob_norm 0.433421165\n",
      "Iteration 4750 L -5.35568142 loss -5.36588287 loss_ordinary 0.462321609 entropy_value 5.82820463 glob_norm 0.36967206\n",
      "Iteration 4800 L -5.33688116 loss -5.34577227 loss_ordinary 0.482788473 entropy_value 5.82856083 glob_norm 0.344568133\n",
      "Iteration 4850 L -5.3745656 loss -5.38543367 loss_ordinary 0.43712917 entropy_value 5.82256269 glob_norm 0.441383183\n",
      "Iteration 4900 L -5.35016489 loss -5.36173153 loss_ordinary 0.458598197 entropy_value 5.82032967 glob_norm 0.424353451\n",
      "Iteration 4950 L -5.34385252 loss -5.35443735 loss_ordinary 0.467190385 entropy_value 5.82162762 glob_norm 0.40092665\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 1.22466564 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3437376 loss -5.37611723 loss_ordinary 0.447019786 entropy_value 5.82313728 glob_norm 0.381990135\n",
      "Iteration 50 L -5.33271 loss -5.36058283 loss_ordinary 0.4647955 entropy_value 5.82537842 glob_norm 0.300314218\n",
      "Iteration 100 L -5.33676815 loss -5.36690569 loss_ordinary 0.455954969 entropy_value 5.82286072 glob_norm 0.431960762\n",
      "Iteration 150 L -5.33913755 loss -5.36330605 loss_ordinary 0.465532571 entropy_value 5.82883883 glob_norm 0.441765904\n",
      "Iteration 200 L -5.32403135 loss -5.34807777 loss_ordinary 0.478925407 entropy_value 5.82700348 glob_norm 0.301593542\n",
      "Iteration 250 L -5.3243742 loss -5.35168457 loss_ordinary 0.475261062 entropy_value 5.8269453 glob_norm 0.299101055\n",
      "Iteration 300 L -5.36044693 loss -5.38623857 loss_ordinary 0.444145828 entropy_value 5.83038425 glob_norm 0.334583074\n",
      "Iteration 350 L -5.33548594 loss -5.36345863 loss_ordinary 0.464816123 entropy_value 5.82827473 glob_norm 0.417378604\n",
      "Iteration 400 L -5.3371191 loss -5.36335373 loss_ordinary 0.462887079 entropy_value 5.82624102 glob_norm 0.262066036\n",
      "Iteration 450 L -5.32218599 loss -5.35021734 loss_ordinary 0.477870226 entropy_value 5.82808733 glob_norm 0.338753611\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 1.09255242 lambd_papr -0.0122466562 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.32060671 loss -5.36278868 loss_ordinary 0.465705931 entropy_value 5.82849455 glob_norm 0.299372375\n",
      "Iteration 50 L -5.32101917 loss -5.36148834 loss_ordinary 0.466377527 entropy_value 5.82786608 glob_norm 0.340274811\n",
      "Iteration 100 L -5.28379 loss -5.32121038 loss_ordinary 0.510416806 entropy_value 5.83162737 glob_norm 0.381379366\n",
      "Iteration 150 L -5.31951094 loss -5.35381556 loss_ordinary 0.477059931 entropy_value 5.83087587 glob_norm 0.450585485\n",
      "Iteration 200 L -5.32115173 loss -5.3581152 loss_ordinary 0.473476499 entropy_value 5.83159161 glob_norm 0.419287056\n",
      "Iteration 250 L -5.32043505 loss -5.35077524 loss_ordinary 0.477766722 entropy_value 5.82854223 glob_norm 0.294908911\n",
      "Iteration 300 L -5.33810711 loss -5.37598753 loss_ordinary 0.458042413 entropy_value 5.83402967 glob_norm 0.335958719\n",
      "Iteration 350 L -5.30982924 loss -5.35269165 loss_ordinary 0.475399971 entropy_value 5.82809162 glob_norm 0.427870512\n",
      "Iteration 400 L -5.33085585 loss -5.36762238 loss_ordinary 0.463685244 entropy_value 5.83130789 glob_norm 0.291592419\n",
      "Iteration 450 L -5.30173349 loss -5.34024143 loss_ordinary 0.493830472 entropy_value 5.83407164 glob_norm 0.463539571\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0.873569965 lambd_papr -0.0232049562 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.29985142 loss -5.34876204 loss_ordinary 0.482862771 entropy_value 5.83162498 glob_norm 0.601533234\n",
      "Iteration 50 L -5.30727339 loss -5.33939791 loss_ordinary 0.496175975 entropy_value 5.83557415 glob_norm 0.416854888\n",
      "Iteration 100 L -5.31301 loss -5.3592 loss_ordinary 0.477778971 entropy_value 5.83697891 glob_norm 0.397367626\n",
      "Iteration 150 L -5.337 loss -5.3694663 loss_ordinary 0.46510154 entropy_value 5.83456755 glob_norm 0.482667834\n",
      "Iteration 200 L -5.3195138 loss -5.37332439 loss_ordinary 0.462706685 entropy_value 5.83603096 glob_norm 0.370301127\n",
      "Iteration 250 L -5.33827066 loss -5.37613916 loss_ordinary 0.455661714 entropy_value 5.83180094 glob_norm 0.481803715\n",
      "Iteration 300 L -5.28955078 loss -5.32803965 loss_ordinary 0.506627262 entropy_value 5.83466673 glob_norm 0.341314197\n",
      "Iteration 350 L -5.29383421 loss -5.33522177 loss_ordinary 0.501333833 entropy_value 5.83655596 glob_norm 0.438247919\n",
      "Iteration 400 L -5.29871273 loss -5.34423399 loss_ordinary 0.489364773 entropy_value 5.83359909 glob_norm 0.405590802\n",
      "Iteration 450 L -5.32862854 loss -5.366961 loss_ordinary 0.471028537 entropy_value 5.83798933 glob_norm 0.356175452\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0.736564875 lambd_papr -0.031993147 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.28444099 loss -5.33903551 loss_ordinary 0.495270908 entropy_value 5.83430624 glob_norm 0.364893287\n",
      "Iteration 50 L -5.30889225 loss -5.35273 loss_ordinary 0.480705529 entropy_value 5.83343554 glob_norm 0.387474269\n",
      "Iteration 100 L -5.32897234 loss -5.37442 loss_ordinary 0.466011852 entropy_value 5.84043169 glob_norm 0.422370732\n",
      "Iteration 150 L -5.2909193 loss -5.34496498 loss_ordinary 0.491019845 entropy_value 5.83598471 glob_norm 0.32760483\n",
      "Iteration 200 L -5.32903528 loss -5.36630821 loss_ordinary 0.471085489 entropy_value 5.83739376 glob_norm 0.348050922\n",
      "Iteration 250 L -5.32618952 loss -5.36421394 loss_ordinary 0.471973866 entropy_value 5.83618784 glob_norm 0.264692932\n",
      "Iteration 300 L -5.28114748 loss -5.33027935 loss_ordinary 0.506581783 entropy_value 5.83686113 glob_norm 0.432598263\n",
      "Iteration 350 L -5.30725765 loss -5.35632372 loss_ordinary 0.481530905 entropy_value 5.83785486 glob_norm 0.438961595\n",
      "Iteration 400 L -5.31473351 loss -5.36179304 loss_ordinary 0.473250061 entropy_value 5.83504295 glob_norm 0.341482729\n",
      "Iteration 450 L -5.30805445 loss -5.34490061 loss_ordinary 0.491374433 entropy_value 5.8362751 glob_norm 0.389808387\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0.65009141 lambd_papr -0.0394252837 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.31171942 loss -5.36386728 loss_ordinary 0.476612329 entropy_value 5.84048 glob_norm 0.325095415\n",
      "Iteration 50 L -5.29361486 loss -5.35055304 loss_ordinary 0.486084282 entropy_value 5.83663702 glob_norm 0.331731737\n",
      "Iteration 100 L -5.31195307 loss -5.37105608 loss_ordinary 0.469596744 entropy_value 5.84065247 glob_norm 0.39572227\n",
      "Iteration 150 L -5.26929235 loss -5.3152256 loss_ordinary 0.527975619 entropy_value 5.84320116 glob_norm 0.32791248\n",
      "Iteration 200 L -5.26057291 loss -5.31279469 loss_ordinary 0.52781713 entropy_value 5.84061193 glob_norm 0.370432884\n",
      "Iteration 250 L -5.2839303 loss -5.33245611 loss_ordinary 0.50630945 entropy_value 5.83876562 glob_norm 0.384031117\n",
      "Iteration 300 L -5.27886724 loss -5.31885815 loss_ordinary 0.524130642 entropy_value 5.84298849 glob_norm 0.38404429\n",
      "Iteration 350 L -5.30874586 loss -5.36760664 loss_ordinary 0.472233921 entropy_value 5.83984089 glob_norm 0.313030452\n",
      "Iteration 400 L -5.32378149 loss -5.35867596 loss_ordinary 0.481203884 entropy_value 5.83988 glob_norm 0.419150084\n",
      "Iteration 450 L -5.29860353 loss -5.34290361 loss_ordinary 0.496530533 entropy_value 5.83943415 glob_norm 0.430540234\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.842265606 lambd_papr -0.0460045598 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.31318903 loss -5.36251402 loss_ordinary 0.47511375 entropy_value 5.83762789 glob_norm 0.314373106\n",
      "Iteration 50 L -5.32997084 loss -5.37786865 loss_ordinary 0.464300603 entropy_value 5.84216928 glob_norm 0.450128734\n",
      "Iteration 100 L -5.26337576 loss -5.31715155 loss_ordinary 0.528073132 entropy_value 5.84522438 glob_norm 0.441254556\n",
      "Iteration 150 L -5.29119 loss -5.33548498 loss_ordinary 0.508173048 entropy_value 5.84365797 glob_norm 0.428294063\n",
      "Iteration 200 L -5.26579285 loss -5.32202 loss_ordinary 0.516624629 entropy_value 5.8386445 glob_norm 0.442574024\n",
      "Iteration 250 L -5.28216839 loss -5.32990885 loss_ordinary 0.51326108 entropy_value 5.84316969 glob_norm 0.431914389\n",
      "Iteration 300 L -5.30598831 loss -5.34856653 loss_ordinary 0.496990412 entropy_value 5.84555674 glob_norm 0.527762473\n",
      "Iteration 350 L -5.29899073 loss -5.33990717 loss_ordinary 0.506962121 entropy_value 5.84686947 glob_norm 0.408940703\n",
      "Iteration 400 L -5.30281878 loss -5.34372044 loss_ordinary 0.49982208 entropy_value 5.84354258 glob_norm 0.520735\n",
      "Iteration 450 L -5.31933546 loss -5.36254835 loss_ordinary 0.480409443 entropy_value 5.84295797 glob_norm 0.346725136\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0.58302927 lambd_papr -0.0545543171 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.30077267 loss -5.35245895 loss_ordinary 0.492328376 entropy_value 5.8447876 glob_norm 0.399201453\n",
      "Iteration 50 L -5.29439831 loss -5.34609795 loss_ordinary 0.496978432 entropy_value 5.84307623 glob_norm 0.28983897\n",
      "Iteration 100 L -5.27998686 loss -5.34305811 loss_ordinary 0.502688289 entropy_value 5.84574652 glob_norm 0.382965207\n",
      "Iteration 150 L -5.26398802 loss -5.329072 loss_ordinary 0.513183832 entropy_value 5.84225607 glob_norm 0.455143511\n",
      "Iteration 200 L -5.27078056 loss -5.33244228 loss_ordinary 0.513606668 entropy_value 5.84604883 glob_norm 0.369228929\n",
      "Iteration 250 L -5.28313398 loss -5.35351562 loss_ordinary 0.490796685 entropy_value 5.84431219 glob_norm 0.437115222\n",
      "Iteration 300 L -5.28273582 loss -5.34396029 loss_ordinary 0.499859929 entropy_value 5.84382057 glob_norm 0.592077672\n",
      "Iteration 350 L -5.28727722 loss -5.33662033 loss_ordinary 0.510403156 entropy_value 5.84702349 glob_norm 0.398361385\n",
      "Iteration 400 L -5.28673697 loss -5.34068155 loss_ordinary 0.502312839 entropy_value 5.84299421 glob_norm 0.447128475\n",
      "Iteration 450 L -5.27863407 loss -5.33640528 loss_ordinary 0.506092191 entropy_value 5.84249735 glob_norm 0.397761464\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0.521748304 lambd_papr -0.0604903474 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.29294968 loss -5.34403133 loss_ordinary 0.504161656 entropy_value 5.84819269 glob_norm 0.411636442\n",
      "Iteration 50 L -5.26161909 loss -5.31366873 loss_ordinary 0.529926181 entropy_value 5.84359455 glob_norm 0.380193293\n",
      "Iteration 100 L -5.28053379 loss -5.32429886 loss_ordinary 0.523228049 entropy_value 5.84752703 glob_norm 0.45054996\n",
      "Iteration 150 L -5.28421497 loss -5.33520269 loss_ordinary 0.512772679 entropy_value 5.84797573 glob_norm 0.355013072\n",
      "Iteration 200 L -5.29406643 loss -5.3609972 loss_ordinary 0.485968262 entropy_value 5.84696579 glob_norm 0.322179407\n",
      "Iteration 250 L -5.27780199 loss -5.33192635 loss_ordinary 0.51209 entropy_value 5.84401655 glob_norm 0.339764297\n",
      "Iteration 300 L -5.26963139 loss -5.32931376 loss_ordinary 0.515590906 entropy_value 5.84490442 glob_norm 0.443823218\n",
      "Iteration 350 L -5.24459887 loss -5.29259348 loss_ordinary 0.552718103 entropy_value 5.84531164 glob_norm 0.575116813\n",
      "Iteration 400 L -5.32396078 loss -5.35952 loss_ordinary 0.487589896 entropy_value 5.84711027 glob_norm 0.476734787\n",
      "Iteration 450 L -5.30453253 loss -5.33681965 loss_ordinary 0.512780786 entropy_value 5.84960032 glob_norm 0.321707487\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.462509871 lambd_papr -0.0658183917 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3066082 loss -5.33443737 loss_ordinary 0.511987388 entropy_value 5.84642506 glob_norm 0.331462145\n",
      "Iteration 50 L -5.27005 loss -5.31156874 loss_ordinary 0.537549675 entropy_value 5.84911823 glob_norm 0.372872859\n",
      "Iteration 100 L -5.27122307 loss -5.32205534 loss_ordinary 0.527752757 entropy_value 5.84980822 glob_norm 0.467535317\n",
      "Iteration 150 L -5.34138441 loss -5.34618664 loss_ordinary 0.506026089 entropy_value 5.85221243 glob_norm 0.46426028\n",
      "Iteration 200 L -5.27646351 loss -5.3095212 loss_ordinary 0.536164701 entropy_value 5.84568596 glob_norm 0.464997321\n",
      "Iteration 250 L -5.30964041 loss -5.35627842 loss_ordinary 0.492536336 entropy_value 5.84881496 glob_norm 0.290135443\n",
      "Iteration 300 L -5.28599453 loss -5.33060789 loss_ordinary 0.517716587 entropy_value 5.8483243 glob_norm 0.341577291\n",
      "Iteration 350 L -5.25969696 loss -5.3326025 loss_ordinary 0.514747143 entropy_value 5.84734964 glob_norm 0.37465027\n",
      "Iteration 400 L -5.27921963 loss -5.33516216 loss_ordinary 0.515261829 entropy_value 5.85042381 glob_norm 0.388525069\n",
      "Iteration 450 L -5.28871155 loss -5.32951784 loss_ordinary 0.517766654 entropy_value 5.84728479 glob_norm 0.406559348\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0.435025454 lambd_papr -0.0705556646 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.267272 loss -5.29026794 loss_ordinary 0.55779475 entropy_value 5.84806299 glob_norm 0.51479435\n",
      "Iteration 50 L -5.26932144 loss -5.31692696 loss_ordinary 0.530584872 entropy_value 5.84751177 glob_norm 0.394870162\n",
      "Iteration 100 L -5.25522327 loss -5.31957579 loss_ordinary 0.528247714 entropy_value 5.84782362 glob_norm 0.328640908\n",
      "Iteration 150 L -5.26352739 loss -5.31876659 loss_ordinary 0.530218661 entropy_value 5.8489852 glob_norm 0.55511409\n",
      "Iteration 200 L -5.25368118 loss -5.32528 loss_ordinary 0.521234095 entropy_value 5.84651423 glob_norm 0.412232339\n",
      "Iteration 250 L -5.26254702 loss -5.30876303 loss_ordinary 0.537524045 entropy_value 5.84628725 glob_norm 0.436639965\n",
      "Iteration 300 L -5.27334833 loss -5.33540344 loss_ordinary 0.517863035 entropy_value 5.85326624 glob_norm 0.580340385\n",
      "Iteration 350 L -5.29798508 loss -5.34582376 loss_ordinary 0.501546323 entropy_value 5.84737 glob_norm 0.448633105\n",
      "Iteration 400 L -5.28054 loss -5.33999968 loss_ordinary 0.50525707 entropy_value 5.84525681 glob_norm 0.379811347\n",
      "Iteration 450 L -5.27491236 loss -5.32901049 loss_ordinary 0.521496475 entropy_value 5.85050726 glob_norm 0.471960694\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0.255291462 lambd_papr -0.0750248 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.27463198 loss -5.30789614 loss_ordinary 0.542868495 entropy_value 5.85076427 glob_norm 0.383267581\n",
      "Iteration 50 L -5.25624466 loss -5.31155157 loss_ordinary 0.537440717 entropy_value 5.84899235 glob_norm 0.416547298\n",
      "Iteration 100 L -5.28714132 loss -5.33701515 loss_ordinary 0.509022534 entropy_value 5.84603786 glob_norm 0.471315414\n",
      "Iteration 150 L -5.29011059 loss -5.32828712 loss_ordinary 0.52363193 entropy_value 5.85191965 glob_norm 0.358589768\n",
      "Iteration 200 L -5.26951218 loss -5.30845404 loss_ordinary 0.543827951 entropy_value 5.85228205 glob_norm 0.435356826\n",
      "Iteration 250 L -5.30121 loss -5.3281951 loss_ordinary 0.51843071 entropy_value 5.8466258 glob_norm 0.4150756\n",
      "Iteration 300 L -5.29149532 loss -5.33025217 loss_ordinary 0.519795656 entropy_value 5.85004759 glob_norm 0.492820591\n",
      "Iteration 350 L -5.28477621 loss -5.31762791 loss_ordinary 0.529204369 entropy_value 5.84683228 glob_norm 0.392102301\n",
      "Iteration 400 L -5.25807667 loss -5.29353237 loss_ordinary 0.556828797 entropy_value 5.85036135 glob_norm 0.40492931\n",
      "Iteration 450 L -5.29505777 loss -5.33552694 loss_ordinary 0.516126215 entropy_value 5.8516531 glob_norm 0.437751383\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0.45426321 lambd_papr -0.0776553452 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.28592062 loss -5.3401804 loss_ordinary 0.509327292 entropy_value 5.84950733 glob_norm 0.378549516\n",
      "Iteration 50 L -5.2564559 loss -5.32314205 loss_ordinary 0.527393878 entropy_value 5.85053587 glob_norm 0.333449811\n",
      "Iteration 100 L -5.26675558 loss -5.32346392 loss_ordinary 0.524310708 entropy_value 5.84777451 glob_norm 0.450917959\n",
      "Iteration 150 L -5.28325367 loss -5.32154751 loss_ordinary 0.529270589 entropy_value 5.85081816 glob_norm 0.4857243\n",
      "Iteration 200 L -5.28284216 loss -5.350142 loss_ordinary 0.501435757 entropy_value 5.85157776 glob_norm 0.37917152\n",
      "Iteration 250 L -5.29243422 loss -5.33409 loss_ordinary 0.517081559 entropy_value 5.85117149 glob_norm 0.458069295\n",
      "Iteration 300 L -5.26477766 loss -5.30870867 loss_ordinary 0.541908801 entropy_value 5.85061741 glob_norm 0.436138928\n",
      "Iteration 350 L -5.27072382 loss -5.32170868 loss_ordinary 0.527835965 entropy_value 5.84954453 glob_norm 0.440048784\n",
      "Iteration 400 L -5.27783442 loss -5.32862186 loss_ordinary 0.521824539 entropy_value 5.8504467 glob_norm 0.441898912\n",
      "Iteration 450 L -5.31353188 loss -5.32037354 loss_ordinary 0.532725811 entropy_value 5.85309935 glob_norm 0.446772069\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.361186266 lambd_papr -0.0823501572 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.30454779 loss -5.30467939 loss_ordinary 0.552203119 entropy_value 5.85688305 glob_norm 0.474339813\n",
      "Iteration 50 L -5.25396824 loss -5.30935192 loss_ordinary 0.542895675 entropy_value 5.85224771 glob_norm 0.440823346\n",
      "Iteration 100 L -5.24310112 loss -5.3053484 loss_ordinary 0.539894164 entropy_value 5.8452425 glob_norm 0.500254571\n",
      "Iteration 150 L -5.26422215 loss -5.32212639 loss_ordinary 0.530134857 entropy_value 5.85226154 glob_norm 0.534335136\n",
      "Iteration 200 L -5.2672267 loss -5.30771971 loss_ordinary 0.542004168 entropy_value 5.84972334 glob_norm 0.395656288\n",
      "Iteration 250 L -5.27277136 loss -5.32217455 loss_ordinary 0.528923512 entropy_value 5.85109806 glob_norm 0.441657782\n",
      "Iteration 300 L -5.29331064 loss -5.33738804 loss_ordinary 0.513528585 entropy_value 5.85091639 glob_norm 0.42203787\n",
      "Iteration 350 L -5.27313566 loss -5.31264353 loss_ordinary 0.537472665 entropy_value 5.85011625 glob_norm 0.439947605\n",
      "Iteration 400 L -5.25983953 loss -5.32404852 loss_ordinary 0.529151201 entropy_value 5.85319948 glob_norm 0.632053554\n",
      "Iteration 450 L -5.26854277 loss -5.31472254 loss_ordinary 0.536989689 entropy_value 5.85171223 glob_norm 0.352956861\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.364508867 lambd_papr -0.0860942155 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.24339724 loss -5.30406475 loss_ordinary 0.549688339 entropy_value 5.85375261 glob_norm 0.436579406\n",
      "Iteration 50 L -5.31452 loss -5.35067654 loss_ordinary 0.497879893 entropy_value 5.84855604 glob_norm 0.383662969\n",
      "Iteration 100 L -5.27306557 loss -5.29980421 loss_ordinary 0.551913142 entropy_value 5.851717 glob_norm 0.41123423\n",
      "Iteration 150 L -5.34952784 loss -5.35609913 loss_ordinary 0.497283906 entropy_value 5.85338354 glob_norm 0.3948\n",
      "Iteration 200 L -5.25393677 loss -5.32297754 loss_ordinary 0.531193435 entropy_value 5.8541708 glob_norm 0.360522062\n",
      "Iteration 250 L -5.29334641 loss -5.32771635 loss_ordinary 0.525868058 entropy_value 5.85358429 glob_norm 0.487410814\n",
      "Iteration 300 L -5.265903 loss -5.33371449 loss_ordinary 0.517370582 entropy_value 5.85108519 glob_norm 0.478904486\n",
      "Iteration 350 L -5.28674555 loss -5.33213377 loss_ordinary 0.524535775 entropy_value 5.85666943 glob_norm 0.556479096\n",
      "Iteration 400 L -5.24077 loss -5.32315207 loss_ordinary 0.528087 entropy_value 5.8512392 glob_norm 0.422258049\n",
      "Iteration 450 L -5.30838 loss -5.31464 loss_ordinary 0.539849401 entropy_value 5.85448933 glob_norm 0.548071504\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0.467209578 lambd_papr -0.0898840502 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23102188 loss -5.3049655 loss_ordinary 0.547476053 entropy_value 5.85244179 glob_norm 0.462833703\n",
      "Iteration 50 L -5.23083258 loss -5.30629635 loss_ordinary 0.546634197 entropy_value 5.85293055 glob_norm 0.36830619\n",
      "Iteration 100 L -5.27719498 loss -5.29471874 loss_ordinary 0.5548473 entropy_value 5.84956598 glob_norm 0.457429379\n",
      "Iteration 150 L -5.27837706 loss -5.33189678 loss_ordinary 0.523772538 entropy_value 5.8556695 glob_norm 0.43310681\n",
      "Iteration 200 L -5.28581047 loss -5.35353899 loss_ordinary 0.495647371 entropy_value 5.84918642 glob_norm 0.398682266\n",
      "Iteration 250 L -5.27604294 loss -5.30135918 loss_ordinary 0.55311 entropy_value 5.85446882 glob_norm 0.522277355\n",
      "Iteration 300 L -5.2905817 loss -5.30202484 loss_ordinary 0.552743137 entropy_value 5.85476828 glob_norm 0.545308411\n",
      "Iteration 350 L -5.2792387 loss -5.32888937 loss_ordinary 0.521335483 entropy_value 5.85022497 glob_norm 0.322796971\n",
      "Iteration 400 L -5.29392 loss -5.32842493 loss_ordinary 0.525023878 entropy_value 5.85344887 glob_norm 0.475399524\n",
      "Iteration 450 L -5.25648832 loss -5.33816862 loss_ordinary 0.515558302 entropy_value 5.85372686 glob_norm 0.356373817\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.287198067 lambd_papr -0.0947562456 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.30202055 loss -5.32644558 loss_ordinary 0.530943394 entropy_value 5.85738897 glob_norm 0.405172348\n",
      "Iteration 50 L -5.2269392 loss -5.28333521 loss_ordinary 0.569400668 entropy_value 5.852736 glob_norm 0.483685762\n",
      "Iteration 100 L -5.27288437 loss -5.29933405 loss_ordinary 0.552414775 entropy_value 5.85174894 glob_norm 0.439628929\n",
      "Iteration 150 L -5.27357531 loss -5.29719305 loss_ordinary 0.554939032 entropy_value 5.85213184 glob_norm 0.389926672\n",
      "Iteration 200 L -5.23505068 loss -5.29304075 loss_ordinary 0.562119484 entropy_value 5.85516 glob_norm 0.483324915\n",
      "Iteration 250 L -5.2559371 loss -5.30746937 loss_ordinary 0.548616052 entropy_value 5.85608578 glob_norm 0.525834143\n",
      "Iteration 300 L -5.24725199 loss -5.33434439 loss_ordinary 0.52049011 entropy_value 5.85483408 glob_norm 0.44142276\n",
      "Iteration 350 L -5.29134274 loss -5.31605959 loss_ordinary 0.540864408 entropy_value 5.85692406 glob_norm 0.331538886\n",
      "Iteration 400 L -5.25429296 loss -5.31292152 loss_ordinary 0.541758478 entropy_value 5.85468 glob_norm 0.476841658\n",
      "Iteration 450 L -5.24885654 loss -5.30465 loss_ordinary 0.548484206 entropy_value 5.85313416 glob_norm 0.409234375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0.287168741 lambd_papr -0.0977602154 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.25478554 loss -5.30654573 loss_ordinary 0.545250237 entropy_value 5.85179615 glob_norm 0.627271175\n",
      "Iteration 50 L -5.27647591 loss -5.32235956 loss_ordinary 0.530771 entropy_value 5.85313082 glob_norm 0.508815825\n",
      "Iteration 100 L -5.27574825 loss -5.31621122 loss_ordinary 0.536753297 entropy_value 5.8529644 glob_norm 0.571597397\n",
      "Iteration 150 L -5.24742603 loss -5.28952932 loss_ordinary 0.563470185 entropy_value 5.85299969 glob_norm 0.539125\n",
      "Iteration 200 L -5.2367177 loss -5.30089092 loss_ordinary 0.555864632 entropy_value 5.85675573 glob_norm 0.384726733\n",
      "Iteration 250 L -5.27342033 loss -5.30554533 loss_ordinary 0.549906731 entropy_value 5.85545206 glob_norm 0.457964212\n",
      "Iteration 300 L -5.30087423 loss -5.31586313 loss_ordinary 0.538788259 entropy_value 5.85465097 glob_norm 0.43227607\n",
      "Iteration 350 L -5.26423311 loss -5.31196213 loss_ordinary 0.539145589 entropy_value 5.8511076 glob_norm 0.490960896\n",
      "Iteration 400 L -5.23817444 loss -5.26656771 loss_ordinary 0.588494182 entropy_value 5.85506201 glob_norm 0.557906\n",
      "Iteration 450 L -5.26384068 loss -5.30763769 loss_ordinary 0.544294119 entropy_value 5.85193205 glob_norm 0.401936591\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0.429610491 lambd_papr -0.100772887 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26263475 loss -5.29506493 loss_ordinary 0.562624812 entropy_value 5.85769 glob_norm 0.543833554\n",
      "Iteration 50 L -5.28686666 loss -5.31285715 loss_ordinary 0.543362439 entropy_value 5.85622 glob_norm 0.463611543\n",
      "Iteration 100 L -5.30758572 loss -5.30429173 loss_ordinary 0.55342555 entropy_value 5.85771751 glob_norm 0.422726631\n",
      "Iteration 150 L -5.25573969 loss -5.29713106 loss_ordinary 0.560160577 entropy_value 5.8572917 glob_norm 0.485107869\n",
      "Iteration 200 L -5.26774 loss -5.30329132 loss_ordinary 0.554813266 entropy_value 5.85810471 glob_norm 0.402136743\n",
      "Iteration 250 L -5.27083826 loss -5.28982162 loss_ordinary 0.566218317 entropy_value 5.85604 glob_norm 0.4392097\n",
      "Iteration 300 L -5.29846096 loss -5.34062862 loss_ordinary 0.516723692 entropy_value 5.85735226 glob_norm 0.320798278\n",
      "Iteration 350 L -5.28661442 loss -5.3114934 loss_ordinary 0.544793546 entropy_value 5.856287 glob_norm 0.463674635\n",
      "Iteration 400 L -5.20936203 loss -5.2645154 loss_ordinary 0.590233624 entropy_value 5.85474873 glob_norm 0.535356283\n",
      "Iteration 450 L -5.24802446 loss -5.28542662 loss_ordinary 0.568411052 entropy_value 5.85383749 glob_norm 0.478044361\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0.26440239 lambd_papr -0.10529343 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.28367853 loss -5.30771732 loss_ordinary 0.553422689 entropy_value 5.86114 glob_norm 0.48116371\n",
      "Iteration 50 L -5.26727295 loss -5.3103137 loss_ordinary 0.546453536 entropy_value 5.85676718 glob_norm 0.398432672\n",
      "Iteration 100 L -5.27862167 loss -5.30905771 loss_ordinary 0.547295392 entropy_value 5.85635328 glob_norm 0.509257078\n",
      "Iteration 150 L -5.23828936 loss -5.28954315 loss_ordinary 0.56582135 entropy_value 5.8553648 glob_norm 0.667018771\n",
      "Iteration 200 L -5.20534706 loss -5.28225 loss_ordinary 0.574220955 entropy_value 5.85647058 glob_norm 0.446071535\n",
      "Iteration 250 L -5.2857976 loss -5.30254364 loss_ordinary 0.552753091 entropy_value 5.85529661 glob_norm 0.407756925\n",
      "Iteration 300 L -5.27409744 loss -5.32040548 loss_ordinary 0.538660467 entropy_value 5.85906649 glob_norm 0.410801679\n",
      "Iteration 350 L -5.25313187 loss -5.29416418 loss_ordinary 0.564872563 entropy_value 5.85903692 glob_norm 0.491544753\n",
      "Iteration 400 L -5.30029821 loss -5.30825281 loss_ordinary 0.549509764 entropy_value 5.85776281 glob_norm 0.429103434\n",
      "Iteration 450 L -5.30100727 loss -5.30094385 loss_ordinary 0.555522203 entropy_value 5.85646582 glob_norm 0.573922276\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0.176816463 lambd_papr -0.108083934 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23101234 loss -5.29795074 loss_ordinary 0.5598827 entropy_value 5.85783339 glob_norm 0.505334377\n",
      "Iteration 50 L -5.23913908 loss -5.28722525 loss_ordinary 0.574997306 entropy_value 5.86222267 glob_norm 0.428008229\n",
      "Iteration 100 L -5.31619835 loss -5.32040691 loss_ordinary 0.536844 entropy_value 5.85725069 glob_norm 0.512454212\n",
      "Iteration 150 L -5.22876167 loss -5.27535534 loss_ordinary 0.582606137 entropy_value 5.85796165 glob_norm 0.853737235\n",
      "Iteration 200 L -5.2735815 loss -5.28587437 loss_ordinary 0.57618171 entropy_value 5.86205626 glob_norm 0.34890151\n",
      "Iteration 250 L -5.33015585 loss -5.33022881 loss_ordinary 0.526390672 entropy_value 5.85661936 glob_norm 0.445233345\n",
      "Iteration 300 L -5.28472424 loss -5.30993414 loss_ordinary 0.549371839 entropy_value 5.85930586 glob_norm 0.470768958\n",
      "Iteration 350 L -5.32036209 loss -5.33755875 loss_ordinary 0.516099036 entropy_value 5.85365772 glob_norm 0.354349136\n",
      "Iteration 400 L -5.27744865 loss -5.28869343 loss_ordinary 0.567832947 entropy_value 5.85652637 glob_norm 0.522778034\n",
      "Iteration 450 L -5.29419327 loss -5.29275703 loss_ordinary 0.565157712 entropy_value 5.85791492 glob_norm 0.402216792\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.205515146 lambd_papr -0.109955654 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.21139574 loss -5.27307081 loss_ordinary 0.585170686 entropy_value 5.85824156 glob_norm 0.476198912\n",
      "Iteration 50 L -5.26452112 loss -5.32004 loss_ordinary 0.536054075 entropy_value 5.85609436 glob_norm 0.334385842\n",
      "Iteration 100 L -5.30347443 loss -5.3038888 loss_ordinary 0.554148376 entropy_value 5.85803699 glob_norm 0.521206617\n",
      "Iteration 150 L -5.25443411 loss -5.2881856 loss_ordinary 0.570087075 entropy_value 5.85827255 glob_norm 0.400039\n",
      "Iteration 200 L -5.23604441 loss -5.27909613 loss_ordinary 0.58024931 entropy_value 5.85934544 glob_norm 0.441693813\n",
      "Iteration 250 L -5.23011255 loss -5.29041 loss_ordinary 0.565131247 entropy_value 5.85554123 glob_norm 0.384138435\n",
      "Iteration 300 L -5.26405096 loss -5.29263163 loss_ordinary 0.567748547 entropy_value 5.86038 glob_norm 0.33444941\n",
      "Iteration 350 L -5.25253439 loss -5.30093908 loss_ordinary 0.554354787 entropy_value 5.85529375 glob_norm 0.426259905\n",
      "Iteration 400 L -5.2901988 loss -5.31753 loss_ordinary 0.542615771 entropy_value 5.86014557 glob_norm 0.421392471\n",
      "Iteration 450 L -5.27485 loss -5.2861495 loss_ordinary 0.573959827 entropy_value 5.86010933 glob_norm 0.440008223\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power -5.24520874e-05 lambd_papr -0.11213769 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.2647028 loss -5.28968048 loss_ordinary 0.5679456 entropy_value 5.85762596 glob_norm 0.574596763\n",
      "Iteration 50 L -5.25884819 loss -5.29902267 loss_ordinary 0.56252569 entropy_value 5.86154842 glob_norm 0.425332874\n",
      "Iteration 100 L -5.23255301 loss -5.27644491 loss_ordinary 0.580686927 entropy_value 5.85713196 glob_norm 0.525628746\n",
      "Iteration 150 L -5.31797266 loss -5.30957508 loss_ordinary 0.544801 entropy_value 5.85437584 glob_norm 0.491283983\n",
      "Iteration 200 L -5.23968887 loss -5.27650452 loss_ordinary 0.582852244 entropy_value 5.85935688 glob_norm 0.540326893\n",
      "Iteration 250 L -5.26637268 loss -5.30957031 loss_ordinary 0.548049212 entropy_value 5.85762 glob_norm 0.435991377\n",
      "Iteration 300 L -5.21265602 loss -5.27049828 loss_ordinary 0.585087478 entropy_value 5.85558558 glob_norm 0.486712277\n",
      "Iteration 350 L -5.25810242 loss -5.29120827 loss_ordinary 0.568577826 entropy_value 5.85978603 glob_norm 0.609085798\n",
      "Iteration 400 L -5.26974249 loss -5.32064247 loss_ordinary 0.534998238 entropy_value 5.85564041 glob_norm 0.50249511\n",
      "Iteration 450 L -5.26143217 loss -5.30176401 loss_ordinary 0.554570496 entropy_value 5.85633469 glob_norm 0.288949102\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power 0.232185602 lambd_papr -0.112137131 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.29189253 loss -5.3066287 loss_ordinary 0.551874757 entropy_value 5.85850382 glob_norm 0.580347598\n",
      "Iteration 50 L -5.268929 loss -5.29511595 loss_ordinary 0.564909875 entropy_value 5.86002588 glob_norm 0.396634787\n",
      "Iteration 100 L -5.26098776 loss -5.29088163 loss_ordinary 0.56816 entropy_value 5.85904169 glob_norm 0.471690059\n",
      "Iteration 150 L -5.32748127 loss -5.32497644 loss_ordinary 0.532238185 entropy_value 5.85721445 glob_norm 0.477010489\n",
      "Iteration 200 L -5.26851892 loss -5.28940392 loss_ordinary 0.572663426 entropy_value 5.86206722 glob_norm 0.475658685\n",
      "Iteration 250 L -5.32211971 loss -5.3075242 loss_ordinary 0.55153662 entropy_value 5.85906076 glob_norm 0.480754763\n",
      "Iteration 300 L -5.26218367 loss -5.29772568 loss_ordinary 0.562952 entropy_value 5.86067772 glob_norm 0.446155697\n",
      "Iteration 350 L -5.27799797 loss -5.27625036 loss_ordinary 0.585100293 entropy_value 5.86135 glob_norm 0.455239445\n",
      "Iteration 400 L -5.26210165 loss -5.28282261 loss_ordinary 0.573293686 entropy_value 5.85611629 glob_norm 0.451967597\n",
      "Iteration 450 L -5.2364645 loss -5.28674698 loss_ordinary 0.573111057 entropy_value 5.85985804 glob_norm 0.612333894\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0.265956402 lambd_papr -0.114617154 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.30682611 loss -5.3335042 loss_ordinary 0.521359563 entropy_value 5.85486364 glob_norm 0.517820597\n",
      "Iteration 50 L -5.27182484 loss -5.28022623 loss_ordinary 0.57996285 entropy_value 5.86018896 glob_norm 0.580137908\n",
      "Iteration 100 L -5.24897623 loss -5.28620434 loss_ordinary 0.574133575 entropy_value 5.86033773 glob_norm 0.406438619\n",
      "Iteration 150 L -5.22597075 loss -5.29747438 loss_ordinary 0.560513318 entropy_value 5.85798788 glob_norm 0.4750579\n",
      "Iteration 200 L -5.31306171 loss -5.30067778 loss_ordinary 0.556321502 entropy_value 5.85699892 glob_norm 0.527839959\n",
      "Iteration 250 L -5.22050285 loss -5.27278042 loss_ordinary 0.585082471 entropy_value 5.85786295 glob_norm 0.460513413\n",
      "Iteration 300 L -5.25810528 loss -5.27723885 loss_ordinary 0.579037547 entropy_value 5.85627604 glob_norm 0.457918167\n",
      "Iteration 350 L -5.18577051 loss -5.28569412 loss_ordinary 0.574972451 entropy_value 5.86066628 glob_norm 0.396951765\n",
      "Iteration 400 L -5.27988243 loss -5.2814784 loss_ordinary 0.580579042 entropy_value 5.86205769 glob_norm 0.477518141\n",
      "Iteration 450 L -5.30855083 loss -5.30053568 loss_ordinary 0.558945179 entropy_value 5.85948038 glob_norm 0.52260232\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.0354819298 lambd_papr -0.117466412 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.24512529 loss -5.2945857 loss_ordinary 0.561080337 entropy_value 5.85566568 glob_norm 0.455008566\n",
      "Iteration 50 L -5.23750544 loss -5.26012659 loss_ordinary 0.599961102 entropy_value 5.86008787 glob_norm 0.547945857\n",
      "Iteration 100 L -5.23893738 loss -5.282022 loss_ordinary 0.576396346 entropy_value 5.85841846 glob_norm 0.406938374\n",
      "Iteration 150 L -5.21203 loss -5.27174807 loss_ordinary 0.588219583 entropy_value 5.85996771 glob_norm 0.380081922\n",
      "Iteration 200 L -5.2622838 loss -5.29784203 loss_ordinary 0.56374681 entropy_value 5.86158895 glob_norm 0.526483893\n",
      "Iteration 250 L -5.21026278 loss -5.27734184 loss_ordinary 0.582875431 entropy_value 5.86021709 glob_norm 0.38951984\n",
      "Iteration 300 L -5.27288532 loss -5.29810619 loss_ordinary 0.562143624 entropy_value 5.86024952 glob_norm 0.430572271\n",
      "Iteration 350 L -5.28996944 loss -5.30932713 loss_ordinary 0.549699605 entropy_value 5.85902643 glob_norm 0.570212305\n",
      "Iteration 400 L -5.24565363 loss -5.2741704 loss_ordinary 0.58451879 entropy_value 5.85868931 glob_norm 0.505981207\n",
      "Iteration 450 L -5.27708483 loss -5.29825211 loss_ordinary 0.562464416 entropy_value 5.86071682 glob_norm 0.627476871\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power -0.0475246906 lambd_papr -0.117847681 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26395082 loss -5.2914381 loss_ordinary 0.567318499 entropy_value 5.85875654 glob_norm 0.539737165\n",
      "Iteration 50 L -5.27587891 loss -5.2853241 loss_ordinary 0.573454857 entropy_value 5.85877895 glob_norm 0.703959\n",
      "Iteration 100 L -5.26645565 loss -5.29788303 loss_ordinary 0.563728571 entropy_value 5.86161184 glob_norm 0.425934941\n",
      "Iteration 150 L -5.26323509 loss -5.27951384 loss_ordinary 0.58166337 entropy_value 5.86117697 glob_norm 0.381296784\n",
      "Iteration 200 L -5.23069 loss -5.25699139 loss_ordinary 0.601172507 entropy_value 5.85816383 glob_norm 0.655553758\n",
      "Iteration 250 L -5.30746078 loss -5.31075907 loss_ordinary 0.545177579 entropy_value 5.85593605 glob_norm 0.468903244\n",
      "Iteration 300 L -5.24782 loss -5.30385923 loss_ordinary 0.555501699 entropy_value 5.85936069 glob_norm 0.42373246\n",
      "Iteration 350 L -5.2185359 loss -5.26932859 loss_ordinary 0.591208577 entropy_value 5.86053705 glob_norm 0.381211758\n",
      "Iteration 400 L -5.23024702 loss -5.2762413 loss_ordinary 0.584465086 entropy_value 5.86070633 glob_norm 0.639211237\n",
      "Iteration 450 L -5.25889349 loss -5.29183722 loss_ordinary 0.566147506 entropy_value 5.85798502 glob_norm 0.636817217\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.312108755 lambd_papr -0.117335476 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.24370432 loss -5.28311443 loss_ordinary 0.576344 entropy_value 5.85945845 glob_norm 0.514491379\n",
      "Iteration 50 L -5.22431135 loss -5.25357771 loss_ordinary 0.604474485 entropy_value 5.85805225 glob_norm 0.390875697\n",
      "Iteration 100 L -5.27860975 loss -5.26651144 loss_ordinary 0.594587 entropy_value 5.86109829 glob_norm 0.574700177\n",
      "Iteration 150 L -5.21961355 loss -5.27294207 loss_ordinary 0.586615801 entropy_value 5.85955763 glob_norm 0.626021445\n",
      "Iteration 200 L -5.31007814 loss -5.30288696 loss_ordinary 0.558726251 entropy_value 5.86161327 glob_norm 0.436867893\n",
      "Iteration 250 L -5.24125862 loss -5.26414061 loss_ordinary 0.594493806 entropy_value 5.85863447 glob_norm 0.516842663\n",
      "Iteration 300 L -5.31461906 loss -5.30434513 loss_ordinary 0.554992 entropy_value 5.85933733 glob_norm 0.425439\n",
      "Iteration 350 L -5.25608778 loss -5.30745506 loss_ordinary 0.554937303 entropy_value 5.86239243 glob_norm 0.426636457\n",
      "Iteration 400 L -5.22579861 loss -5.25763893 loss_ordinary 0.600739717 entropy_value 5.85837841 glob_norm 0.459328413\n",
      "Iteration 450 L -5.29108763 loss -5.28986168 loss_ordinary 0.574186802 entropy_value 5.86404848 glob_norm 0.561273694\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0.162584543 lambd_papr -0.12070936 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.28419876 loss -5.27806759 loss_ordinary 0.584329724 entropy_value 5.86239719 glob_norm 0.588481486\n",
      "Iteration 50 L -5.30279827 loss -5.29691744 loss_ordinary 0.563243687 entropy_value 5.8601613 glob_norm 0.64789921\n",
      "Iteration 100 L -5.27163696 loss -5.28861046 loss_ordinary 0.57518357 entropy_value 5.86379385 glob_norm 0.553304434\n",
      "Iteration 150 L -5.29235649 loss -5.28629589 loss_ordinary 0.575725734 entropy_value 5.86202192 glob_norm 0.438771158\n",
      "Iteration 200 L -5.28072262 loss -5.28962755 loss_ordinary 0.57172519 entropy_value 5.86135292 glob_norm 0.446961552\n",
      "Iteration 250 L -5.2555604 loss -5.26274 loss_ordinary 0.595104456 entropy_value 5.85784435 glob_norm 0.575818777\n",
      "Iteration 300 L -5.22665119 loss -5.27871418 loss_ordinary 0.582909048 entropy_value 5.86162329 glob_norm 0.477003455\n",
      "Iteration 350 L -5.21006727 loss -5.24350691 loss_ordinary 0.618312359 entropy_value 5.86181927 glob_norm 0.511580467\n",
      "Iteration 400 L -5.24371576 loss -5.27439356 loss_ordinary 0.587693 entropy_value 5.8620863 glob_norm 0.465468287\n",
      "Iteration 450 L -5.25390625 loss -5.28813124 loss_ordinary 0.572434902 entropy_value 5.86056614 glob_norm 0.681885183\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0.0856630802 lambd_papr -0.122472167 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.2617712 loss -5.28919268 loss_ordinary 0.572278559 entropy_value 5.86147118 glob_norm 0.410269141\n",
      "Iteration 50 L -5.28549576 loss -5.30136824 loss_ordinary 0.56236583 entropy_value 5.86373377 glob_norm 0.453286916\n",
      "Iteration 100 L -5.23572397 loss -5.25918722 loss_ordinary 0.601808906 entropy_value 5.86099577 glob_norm 0.645197093\n",
      "Iteration 150 L -5.2347908 loss -5.26660728 loss_ordinary 0.595969915 entropy_value 5.86257744 glob_norm 0.480428785\n",
      "Iteration 200 L -5.25416565 loss -5.28939295 loss_ordinary 0.569571078 entropy_value 5.85896397 glob_norm 0.511974514\n",
      "Iteration 250 L -5.29255915 loss -5.29564524 loss_ordinary 0.569809 entropy_value 5.86545467 glob_norm 0.470898807\n",
      "Iteration 300 L -5.31855774 loss -5.30412626 loss_ordinary 0.556006551 entropy_value 5.86013269 glob_norm 0.543382406\n",
      "Iteration 350 L -5.28110266 loss -5.2728591 loss_ordinary 0.589065075 entropy_value 5.86192417 glob_norm 0.410565376\n",
      "Iteration 400 L -5.29093 loss -5.27434111 loss_ordinary 0.586263418 entropy_value 5.86060476 glob_norm 0.433746129\n",
      "Iteration 450 L -5.30467 loss -5.30205202 loss_ordinary 0.557919741 entropy_value 5.85997152 glob_norm 0.499953538\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power -0.0165705681 lambd_papr -0.12340375 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23567057 loss -5.27599239 loss_ordinary 0.586926103 entropy_value 5.86291885 glob_norm 0.612772405\n",
      "Iteration 50 L -5.28731298 loss -5.26473 loss_ordinary 0.597102106 entropy_value 5.86183167 glob_norm 0.538781404\n",
      "Iteration 100 L -5.2198143 loss -5.25579882 loss_ordinary 0.603244364 entropy_value 5.85904312 glob_norm 0.679094374\n",
      "Iteration 150 L -5.3195343 loss -5.27532291 loss_ordinary 0.587809205 entropy_value 5.863132 glob_norm 0.738632143\n",
      "Iteration 200 L -5.18769264 loss -5.27915144 loss_ordinary 0.581819 entropy_value 5.8609705 glob_norm 0.34887597\n",
      "Iteration 250 L -5.27483273 loss -5.29200172 loss_ordinary 0.568217576 entropy_value 5.86021948 glob_norm 0.488374114\n",
      "Iteration 300 L -5.2930479 loss -5.3056426 loss_ordinary 0.55597043 entropy_value 5.86161327 glob_norm 0.442482978\n",
      "Iteration 350 L -5.26464844 loss -5.28342438 loss_ordinary 0.574718893 entropy_value 5.85814333 glob_norm 0.466030031\n",
      "Iteration 400 L -5.22894192 loss -5.27987623 loss_ordinary 0.581963658 entropy_value 5.86184025 glob_norm 0.64129\n",
      "Iteration 450 L -5.29546261 loss -5.28646374 loss_ordinary 0.575909138 entropy_value 5.8623724 glob_norm 0.674666166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.0969214439 lambd_papr -0.123223007 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.2377224 loss -5.2723937 loss_ordinary 0.593777537 entropy_value 5.86617136 glob_norm 0.59117\n",
      "Iteration 50 L -5.30947685 loss -5.26906395 loss_ordinary 0.5922153 entropy_value 5.86127949 glob_norm 0.662206829\n",
      "Iteration 100 L -5.25816345 loss -5.25874424 loss_ordinary 0.599685 entropy_value 5.85842943 glob_norm 0.678542733\n",
      "Iteration 150 L -5.25038195 loss -5.2672 loss_ordinary 0.597191155 entropy_value 5.86439085 glob_norm 0.479556918\n",
      "Iteration 200 L -5.25183 loss -5.26662827 loss_ordinary 0.596035719 entropy_value 5.86266422 glob_norm 0.504990339\n",
      "Iteration 250 L -5.2798748 loss -5.29394293 loss_ordinary 0.567669511 entropy_value 5.86161232 glob_norm 0.539378762\n",
      "Iteration 300 L -5.26824856 loss -5.30890942 loss_ordinary 0.550798237 entropy_value 5.85970736 glob_norm 0.405106276\n",
      "Iteration 350 L -5.26807785 loss -5.2597332 loss_ordinary 0.602268338 entropy_value 5.8620019 glob_norm 0.485174894\n",
      "Iteration 400 L -5.27753401 loss -5.28751421 loss_ordinary 0.574275494 entropy_value 5.8617897 glob_norm 0.597525537\n",
      "Iteration 450 L -5.32512379 loss -5.29638815 loss_ordinary 0.568070412 entropy_value 5.86445856 glob_norm 0.582233131\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0.24967742 lambd_papr -0.124283351 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26822472 loss -5.30057907 loss_ordinary 0.559887707 entropy_value 5.86046696 glob_norm 0.542647064\n",
      "Iteration 50 L -5.24971104 loss -5.28287506 loss_ordinary 0.580929756 entropy_value 5.86380482 glob_norm 0.388154536\n",
      "Iteration 100 L -5.2522254 loss -5.25801706 loss_ordinary 0.604711175 entropy_value 5.86272812 glob_norm 0.584312141\n",
      "Iteration 150 L -5.26293039 loss -5.28258133 loss_ordinary 0.577963412 entropy_value 5.86054468 glob_norm 0.470339507\n",
      "Iteration 200 L -5.26753187 loss -5.27951336 loss_ordinary 0.581690907 entropy_value 5.86120462 glob_norm 0.458509386\n",
      "Iteration 250 L -5.28870153 loss -5.27201366 loss_ordinary 0.590128839 entropy_value 5.86214256 glob_norm 0.583285272\n",
      "Iteration 300 L -5.28404522 loss -5.25176716 loss_ordinary 0.612246096 entropy_value 5.8640132 glob_norm 0.442995369\n",
      "Iteration 350 L -5.27638817 loss -5.28794289 loss_ordinary 0.574579597 entropy_value 5.8625226 glob_norm 0.524383\n",
      "Iteration 400 L -5.27676249 loss -5.27128887 loss_ordinary 0.590906799 entropy_value 5.86219597 glob_norm 0.528921664\n",
      "Iteration 450 L -5.22076225 loss -5.25249767 loss_ordinary 0.605646789 entropy_value 5.85814428 glob_norm 0.4824965\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0.321466208 lambd_papr -0.127023086 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.22689056 loss -5.28299618 loss_ordinary 0.581520259 entropy_value 5.86451626 glob_norm 0.598735511\n",
      "Iteration 50 L -5.28705835 loss -5.26295328 loss_ordinary 0.597297966 entropy_value 5.86025095 glob_norm 0.469214052\n",
      "Iteration 100 L -5.29356241 loss -5.29012585 loss_ordinary 0.571674645 entropy_value 5.8618 glob_norm 0.53635788\n",
      "Iteration 150 L -5.24981 loss -5.2882843 loss_ordinary 0.572282076 entropy_value 5.86056614 glob_norm 0.53015089\n",
      "Iteration 200 L -5.29746819 loss -5.28791666 loss_ordinary 0.572345853 entropy_value 5.86026287 glob_norm 0.540795624\n",
      "Iteration 250 L -5.24505854 loss -5.25270939 loss_ordinary 0.611968398 entropy_value 5.86467791 glob_norm 0.698037744\n",
      "Iteration 300 L -5.28383684 loss -5.28973198 loss_ordinary 0.573942125 entropy_value 5.86367416 glob_norm 0.443760782\n",
      "Iteration 350 L -5.29157257 loss -5.26088285 loss_ordinary 0.600505173 entropy_value 5.86138821 glob_norm 0.576373577\n",
      "Iteration 400 L -5.22854137 loss -5.23936224 loss_ordinary 0.623036385 entropy_value 5.86239862 glob_norm 0.475238413\n",
      "Iteration 450 L -5.25383234 loss -5.27464294 loss_ordinary 0.587827504 entropy_value 5.86247 glob_norm 0.390065849\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.0287423134 lambd_papr -0.130561143 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26001549 loss -5.2784605 loss_ordinary 0.585092604 entropy_value 5.86355305 glob_norm 0.513972461\n",
      "Iteration 50 L -5.24078274 loss -5.27534628 loss_ordinary 0.587094963 entropy_value 5.86244154 glob_norm 0.597088873\n",
      "Iteration 100 L -5.36349 loss -5.28519726 loss_ordinary 0.579506278 entropy_value 5.86470318 glob_norm 0.670498669\n",
      "Iteration 150 L -5.27180147 loss -5.26018858 loss_ordinary 0.604748845 entropy_value 5.86493731 glob_norm 0.499092042\n",
      "Iteration 200 L -5.29542303 loss -5.29783058 loss_ordinary 0.566261828 entropy_value 5.86409235 glob_norm 0.453205049\n",
      "Iteration 250 L -5.23898029 loss -5.27634907 loss_ordinary 0.585720718 entropy_value 5.86207 glob_norm 0.530588269\n",
      "Iteration 300 L -5.27279854 loss -5.25832319 loss_ordinary 0.606123388 entropy_value 5.86444664 glob_norm 0.534675241\n",
      "Iteration 350 L -5.23305655 loss -5.24599218 loss_ordinary 0.619786382 entropy_value 5.86577845 glob_norm 0.44660908\n",
      "Iteration 400 L -5.26024389 loss -5.28836536 loss_ordinary 0.574961483 entropy_value 5.86332655 glob_norm 0.51199466\n",
      "Iteration 450 L -5.30404949 loss -5.27743769 loss_ordinary 0.586457849 entropy_value 5.86389542 glob_norm 0.65434134\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0.0809817314 lambd_papr -0.130878434 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23155308 loss -5.24961853 loss_ordinary 0.615683258 entropy_value 5.86530161 glob_norm 0.529171646\n",
      "Iteration 50 L -5.29135418 loss -5.29194689 loss_ordinary 0.572136581 entropy_value 5.86408329 glob_norm 0.43127349\n",
      "Iteration 100 L -5.30072641 loss -5.25716686 loss_ordinary 0.606847048 entropy_value 5.86401415 glob_norm 0.566061676\n",
      "Iteration 150 L -5.28063917 loss -5.30995035 loss_ordinary 0.554311395 entropy_value 5.86426163 glob_norm 0.598063\n",
      "Iteration 200 L -5.24458456 loss -5.24137926 loss_ordinary 0.621729255 entropy_value 5.86310863 glob_norm 0.622408509\n",
      "Iteration 250 L -5.22911882 loss -5.25509691 loss_ordinary 0.607033908 entropy_value 5.86213112 glob_norm 0.646782935\n",
      "Iteration 300 L -5.30145073 loss -5.26761961 loss_ordinary 0.594512522 entropy_value 5.8621316 glob_norm 0.540095091\n",
      "Iteration 350 L -5.27756739 loss -5.27364922 loss_ordinary 0.588144302 entropy_value 5.86179352 glob_norm 0.585388422\n",
      "Iteration 400 L -5.2599659 loss -5.27475405 loss_ordinary 0.589832127 entropy_value 5.86458635 glob_norm 0.417988539\n",
      "Iteration 450 L -5.23713255 loss -5.25533104 loss_ordinary 0.609806955 entropy_value 5.86513805 glob_norm 0.530328691\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0.0253269672 lambd_papr -0.131775081 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26294565 loss -5.24277115 loss_ordinary 0.622514 entropy_value 5.8652854 glob_norm 0.511576653\n",
      "Iteration 50 L -5.23893499 loss -5.25481939 loss_ordinary 0.61022228 entropy_value 5.86504173 glob_norm 0.366657436\n",
      "Iteration 100 L -5.28072739 loss -5.26913166 loss_ordinary 0.593917608 entropy_value 5.86304951 glob_norm 0.503739119\n",
      "Iteration 150 L -5.29210806 loss -5.27929878 loss_ordinary 0.584696054 entropy_value 5.8639946 glob_norm 0.452126443\n",
      "Iteration 200 L -5.25779104 loss -5.24870157 loss_ordinary 0.61788094 entropy_value 5.86658287 glob_norm 0.550575674\n",
      "Iteration 250 L -5.19179583 loss -5.26649094 loss_ordinary 0.596668601 entropy_value 5.86315966 glob_norm 0.33365193\n",
      "Iteration 300 L -5.31424618 loss -5.28792858 loss_ordinary 0.57794416 entropy_value 5.86587286 glob_norm 0.480896562\n",
      "Iteration 350 L -5.27004099 loss -5.26105261 loss_ordinary 0.600209713 entropy_value 5.86126232 glob_norm 0.543720365\n",
      "Iteration 400 L -5.20934439 loss -5.27566624 loss_ordinary 0.587439656 entropy_value 5.86310577 glob_norm 0.614626348\n",
      "Iteration 450 L -5.26882744 loss -5.26853228 loss_ordinary 0.595027804 entropy_value 5.86355972 glob_norm 0.502540529\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.227641582 lambd_papr -0.132056341 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34623623 loss -5.28512335 loss_ordinary 0.581212163 entropy_value 5.86633587 glob_norm 0.616289556\n",
      "Iteration 50 L -5.21621561 loss -5.2433815 loss_ordinary 0.619562149 entropy_value 5.86294365 glob_norm 0.669484496\n",
      "Iteration 100 L -5.22933722 loss -5.24255753 loss_ordinary 0.623452485 entropy_value 5.86601 glob_norm 0.565792501\n",
      "Iteration 150 L -5.25902 loss -5.28206539 loss_ordinary 0.580198467 entropy_value 5.86226368 glob_norm 0.444501758\n",
      "Iteration 200 L -5.27685833 loss -5.26095963 loss_ordinary 0.602499068 entropy_value 5.86345863 glob_norm 0.616982043\n",
      "Iteration 250 L -5.27254057 loss -5.25629759 loss_ordinary 0.606927395 entropy_value 5.86322498 glob_norm 0.519606113\n",
      "Iteration 300 L -5.33996725 loss -5.26418781 loss_ordinary 0.602382183 entropy_value 5.86657047 glob_norm 0.673235595\n",
      "Iteration 350 L -5.29142284 loss -5.26797485 loss_ordinary 0.597285867 entropy_value 5.8652606 glob_norm 0.497480899\n",
      "Iteration 400 L -5.21479034 loss -5.23802137 loss_ordinary 0.627517164 entropy_value 5.8655386 glob_norm 0.550607681\n",
      "Iteration 450 L -5.27942848 loss -5.282722 loss_ordinary 0.580277085 entropy_value 5.86299944 glob_norm 0.461946547\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power -0.066608429 lambd_papr -0.134591967 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.31685591 loss -5.27594566 loss_ordinary 0.587306559 entropy_value 5.86325264 glob_norm 0.749259174\n",
      "Iteration 50 L -5.24777317 loss -5.26878309 loss_ordinary 0.595749557 entropy_value 5.86453247 glob_norm 0.607278228\n",
      "Iteration 100 L -5.31344366 loss -5.24983215 loss_ordinary 0.614472568 entropy_value 5.86430502 glob_norm 0.778375804\n",
      "Iteration 150 L -5.27295113 loss -5.2694149 loss_ordinary 0.595292568 entropy_value 5.86470747 glob_norm 0.542780221\n",
      "Iteration 200 L -5.2595315 loss -5.25289 loss_ordinary 0.610550106 entropy_value 5.86344 glob_norm 0.558500767\n",
      "Iteration 250 L -5.25152731 loss -5.26098156 loss_ordinary 0.602925181 entropy_value 5.86390686 glob_norm 0.487019867\n",
      "Iteration 300 L -5.24680662 loss -5.28771 loss_ordinary 0.576972961 entropy_value 5.86468315 glob_norm 0.337047368\n",
      "Iteration 350 L -5.27641344 loss -5.26428223 loss_ordinary 0.599570215 entropy_value 5.8638525 glob_norm 0.53787297\n",
      "Iteration 400 L -5.24239683 loss -5.26886511 loss_ordinary 0.592613399 entropy_value 5.86147833 glob_norm 0.466074467\n",
      "Iteration 450 L -5.33278847 loss -5.26496553 loss_ordinary 0.59817034 entropy_value 5.86313629 glob_norm 0.660738\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0.263118982 lambd_papr -0.133847818 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26462746 loss -5.27033567 loss_ordinary 0.593099594 entropy_value 5.86343527 glob_norm 0.466833323\n",
      "Iteration 50 L -5.28156281 loss -5.23978949 loss_ordinary 0.624353647 entropy_value 5.86414337 glob_norm 0.588015735\n",
      "Iteration 100 L -5.28139639 loss -5.27515125 loss_ordinary 0.590654731 entropy_value 5.8658061 glob_norm 0.48911947\n",
      "Iteration 150 L -5.27377462 loss -5.26052141 loss_ordinary 0.604925573 entropy_value 5.86544704 glob_norm 0.488915801\n",
      "Iteration 200 L -5.25234365 loss -5.27426815 loss_ordinary 0.592037857 entropy_value 5.8663063 glob_norm 0.626000166\n",
      "Iteration 250 L -5.30678606 loss -5.27919292 loss_ordinary 0.585902333 entropy_value 5.86509514 glob_norm 0.542976141\n",
      "Iteration 300 L -5.27115 loss -5.27639389 loss_ordinary 0.586772442 entropy_value 5.86316633 glob_norm 0.508442461\n",
      "Iteration 350 L -5.22773266 loss -5.2604413 loss_ordinary 0.606682718 entropy_value 5.86712408 glob_norm 0.411290199\n",
      "Iteration 400 L -5.34540319 loss -5.28202868 loss_ordinary 0.583197773 entropy_value 5.86522627 glob_norm 0.526169837\n",
      "Iteration 450 L -5.26119661 loss -5.25918388 loss_ordinary 0.605290294 entropy_value 5.8644743 glob_norm 0.482455432\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.0208261013 lambd_papr -0.136796221 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.2249341 loss -5.245543 loss_ordinary 0.617410243 entropy_value 5.86295319 glob_norm 0.494297743\n",
      "Iteration 50 L -5.25162 loss -5.23932266 loss_ordinary 0.622110069 entropy_value 5.86143303 glob_norm 0.473420173\n",
      "Iteration 100 L -5.17966413 loss -5.24858427 loss_ordinary 0.615907 entropy_value 5.86449146 glob_norm 0.432284445\n",
      "Iteration 150 L -5.23936796 loss -5.26194 loss_ordinary 0.603079855 entropy_value 5.86502 glob_norm 0.460780144\n",
      "Iteration 200 L -5.26192379 loss -5.27846575 loss_ordinary 0.586176395 entropy_value 5.86464214 glob_norm 0.4979828\n",
      "Iteration 250 L -5.25767851 loss -5.25333261 loss_ordinary 0.609022081 entropy_value 5.86235476 glob_norm 0.432203591\n",
      "Iteration 300 L -5.27133131 loss -5.26163149 loss_ordinary 0.60371244 entropy_value 5.86534357 glob_norm 0.504639149\n",
      "Iteration 350 L -5.31436443 loss -5.2363205 loss_ordinary 0.628670037 entropy_value 5.86499071 glob_norm 0.777143717\n",
      "Iteration 400 L -5.31807852 loss -5.28096581 loss_ordinary 0.582827687 entropy_value 5.86379385 glob_norm 0.645381749\n",
      "Iteration 450 L -5.26571083 loss -5.25079584 loss_ordinary 0.611303627 entropy_value 5.86209965 glob_norm 0.492436558\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0.244538546 lambd_papr -0.136562154 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.26908445 loss -5.26524401 loss_ordinary 0.603424 entropy_value 5.8686676 glob_norm 0.492381811\n",
      "Iteration 50 L -5.27003288 loss -5.24967384 loss_ordinary 0.614573956 entropy_value 5.8642478 glob_norm 0.525098503\n",
      "Iteration 100 L -5.19078827 loss -5.23368502 loss_ordinary 0.632702649 entropy_value 5.86638737 glob_norm 0.43386054\n",
      "Iteration 150 L -5.24823475 loss -5.24487448 loss_ordinary 0.623238742 entropy_value 5.86811352 glob_norm 0.500454187\n",
      "Iteration 200 L -5.24862862 loss -5.23351765 loss_ordinary 0.634728551 entropy_value 5.86824608 glob_norm 0.609654844\n",
      "Iteration 250 L -5.30268621 loss -5.27844572 loss_ordinary 0.586465359 entropy_value 5.86491108 glob_norm 0.592046261\n",
      "Iteration 300 L -5.28390551 loss -5.27043867 loss_ordinary 0.595777214 entropy_value 5.86621618 glob_norm 0.433238775\n",
      "Iteration 350 L -5.24442101 loss -5.22617292 loss_ordinary 0.641852438 entropy_value 5.8680253 glob_norm 0.499784142\n",
      "Iteration 400 L -5.27513218 loss -5.26012564 loss_ordinary 0.606270492 entropy_value 5.86639643 glob_norm 0.664700508\n",
      "Iteration 450 L -5.26366568 loss -5.24116182 loss_ordinary 0.621362627 entropy_value 5.86252451 glob_norm 0.527694821\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power -0.0626194477 lambd_papr -0.139318824 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.2896719 loss -5.27704287 loss_ordinary 0.591085196 entropy_value 5.86812782 glob_norm 0.578172386\n",
      "Iteration 50 L -5.26541805 loss -5.22086334 loss_ordinary 0.645415425 entropy_value 5.86627865 glob_norm 0.61714828\n",
      "Iteration 100 L -5.25682783 loss -5.25157 loss_ordinary 0.617624521 entropy_value 5.86919498 glob_norm 0.498619348\n",
      "Iteration 150 L -5.29943275 loss -5.26992655 loss_ordinary 0.593230069 entropy_value 5.8631568 glob_norm 0.514316857\n",
      "Iteration 200 L -5.42926931 loss -5.27808475 loss_ordinary 0.587278962 entropy_value 5.8653636 glob_norm 0.952061772\n",
      "Iteration 250 L -5.2642808 loss -5.23348618 loss_ordinary 0.632751048 entropy_value 5.86623716 glob_norm 0.573992372\n",
      "Iteration 300 L -5.25518179 loss -5.25639629 loss_ordinary 0.608107269 entropy_value 5.86450386 glob_norm 0.658849061\n",
      "Iteration 350 L -5.28320122 loss -5.25856113 loss_ordinary 0.608299553 entropy_value 5.86686039 glob_norm 0.584914684\n",
      "Iteration 400 L -5.27869129 loss -5.2466116 loss_ordinary 0.620408773 entropy_value 5.86702 glob_norm 0.510891378\n",
      "Iteration 450 L -5.26507425 loss -5.23394251 loss_ordinary 0.632955432 entropy_value 5.86689758 glob_norm 0.54715395\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power -0.250755787 lambd_papr -0.138610795 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.28856468 loss -5.25848722 loss_ordinary 0.606698811 entropy_value 5.86518621 glob_norm 0.63076967\n",
      "Iteration 50 L -5.40756226 loss -5.25450182 loss_ordinary 0.611545205 entropy_value 5.86604691 glob_norm 0.964557\n",
      "Iteration 100 L -5.23650312 loss -5.28284836 loss_ordinary 0.583175719 entropy_value 5.86602402 glob_norm 0.396462113\n",
      "Iteration 150 L -5.27140093 loss -5.27539587 loss_ordinary 0.589795411 entropy_value 5.86519098 glob_norm 0.398088694\n",
      "Iteration 200 L -5.25189304 loss -5.26501226 loss_ordinary 0.600570083 entropy_value 5.86558247 glob_norm 0.53252387\n",
      "Iteration 250 L -5.26386309 loss -5.2828021 loss_ordinary 0.583841145 entropy_value 5.86664343 glob_norm 0.602681875\n",
      "Iteration 300 L -5.28734493 loss -5.26529 loss_ordinary 0.598606706 entropy_value 5.86389637 glob_norm 0.566572726\n",
      "Iteration 350 L -5.28275442 loss -5.22552 loss_ordinary 0.636441767 entropy_value 5.86196184 glob_norm 0.840065062\n",
      "Iteration 400 L -5.2547164 loss -5.26442432 loss_ordinary 0.598513186 entropy_value 5.86293745 glob_norm 0.406264693\n",
      "Iteration 450 L -5.26161385 loss -5.27735424 loss_ordinary 0.589597762 entropy_value 5.86695194 glob_norm 0.5614025\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.289640188 lambd_papr -0.135767058 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.25880575 loss -5.27112246 loss_ordinary 0.587337315 entropy_value 5.85845947 glob_norm 0.733264685\n",
      "Iteration 50 L -5.2834692 loss -5.28425789 loss_ordinary 0.57559 entropy_value 5.85984802 glob_norm 0.522575\n",
      "Iteration 100 L -5.33364058 loss -5.27375126 loss_ordinary 0.592340231 entropy_value 5.86609173 glob_norm 0.588292956\n",
      "Iteration 150 L -5.30757618 loss -5.29223919 loss_ordinary 0.572817802 entropy_value 5.86505699 glob_norm 0.5027408\n",
      "Iteration 200 L -5.30151033 loss -5.26297855 loss_ordinary 0.601488531 entropy_value 5.86446714 glob_norm 0.635474503\n",
      "Iteration 250 L -5.26484394 loss -5.2447834 loss_ordinary 0.621809185 entropy_value 5.86659241 glob_norm 0.633879602\n",
      "Iteration 300 L -5.20903206 loss -5.25346231 loss_ordinary 0.609054863 entropy_value 5.86251688 glob_norm 0.50040704\n",
      "Iteration 350 L -5.28229856 loss -5.27433968 loss_ordinary 0.591380596 entropy_value 5.86572 glob_norm 0.557062328\n",
      "Iteration 400 L -5.27969694 loss -5.28021622 loss_ordinary 0.583824933 entropy_value 5.86404133 glob_norm 0.460901141\n",
      "Iteration 450 L -5.25029039 loss -5.26080751 loss_ordinary 0.601616561 entropy_value 5.86242437 glob_norm 0.824881494\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.13395 lambd_papr -0.132472485 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.25622177 loss -5.28672075 loss_ordinary 0.579530895 entropy_value 5.86625195 glob_norm 0.520591915\n",
      "Iteration 50 L -5.26236582 loss -5.27788448 loss_ordinary 0.586670816 entropy_value 5.86455536 glob_norm 0.475765407\n",
      "Iteration 100 L -5.26521349 loss -5.21801472 loss_ordinary 0.650492907 entropy_value 5.86850739 glob_norm 0.428389\n",
      "Iteration 150 L -5.24332952 loss -5.25272512 loss_ordinary 0.611838341 entropy_value 5.86456347 glob_norm 0.596002221\n",
      "Iteration 200 L -5.28893805 loss -5.29145 loss_ordinary 0.573493958 entropy_value 5.86494398 glob_norm 0.727119803\n",
      "Iteration 250 L -5.22713041 loss -5.27718925 loss_ordinary 0.590762436 entropy_value 5.86795187 glob_norm 0.369651645\n",
      "Iteration 300 L -5.28809595 loss -5.26596689 loss_ordinary 0.599144816 entropy_value 5.86511183 glob_norm 0.472540021\n",
      "Iteration 350 L -5.24829817 loss -5.23431301 loss_ordinary 0.633260548 entropy_value 5.86757326 glob_norm 0.538003147\n",
      "Iteration 400 L -5.23245955 loss -5.24563503 loss_ordinary 0.622511923 entropy_value 5.8681469 glob_norm 0.452503383\n",
      "Iteration 450 L -5.21340609 loss -5.22519445 loss_ordinary 0.641061425 entropy_value 5.86625576 glob_norm 0.555314302\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power 0.0155918598 lambd_papr -0.134000704 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23607302 loss -5.25964737 loss_ordinary 0.603451669 entropy_value 5.8630991 glob_norm 0.686687529\n",
      "Iteration 50 L -5.24731159 loss -5.24685431 loss_ordinary 0.617840171 entropy_value 5.86469412 glob_norm 0.57364136\n",
      "Iteration 100 L -5.2908473 loss -5.25395775 loss_ordinary 0.612371862 entropy_value 5.86632967 glob_norm 0.555683851\n",
      "Iteration 150 L -5.28694868 loss -5.27568197 loss_ordinary 0.588089 entropy_value 5.86377096 glob_norm 0.539558113\n",
      "Iteration 200 L -5.32110357 loss -5.26201439 loss_ordinary 0.604869485 entropy_value 5.86688375 glob_norm 0.547096\n",
      "Iteration 250 L -5.26663685 loss -5.26183033 loss_ordinary 0.601180196 entropy_value 5.86301041 glob_norm 0.512074172\n",
      "Iteration 300 L -5.30809736 loss -5.27955723 loss_ordinary 0.584649324 entropy_value 5.86420679 glob_norm 0.539695382\n",
      "Iteration 350 L -5.25487804 loss -5.26078415 loss_ordinary 0.601589918 entropy_value 5.86237383 glob_norm 0.491942793\n",
      "Iteration 400 L -5.28046513 loss -5.26878357 loss_ordinary 0.594058156 entropy_value 5.86284161 glob_norm 0.496678352\n",
      "Iteration 450 L -5.24582195 loss -5.26625538 loss_ordinary 0.598862708 entropy_value 5.86511803 glob_norm 0.543410778\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power 0.235757113 lambd_papr -0.134179115 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.23165274 loss -5.22952414 loss_ordinary 0.636911273 entropy_value 5.86643553 glob_norm 0.494322687\n",
      "Iteration 50 L -5.2733345 loss -5.26105547 loss_ordinary 0.601846039 entropy_value 5.86290169 glob_norm 0.490511119\n",
      "Iteration 100 L -5.33410358 loss -5.27785349 loss_ordinary 0.58439815 entropy_value 5.86225128 glob_norm 0.563585103\n",
      "Iteration 150 L -5.29131746 loss -5.25618935 loss_ordinary 0.611041248 entropy_value 5.86723089 glob_norm 0.582179546\n",
      "Iteration 200 L -5.30996656 loss -5.24636173 loss_ordinary 0.620676279 entropy_value 5.86703825 glob_norm 0.604562759\n",
      "Iteration 250 L -5.24518251 loss -5.26021385 loss_ordinary 0.604019582 entropy_value 5.86423349 glob_norm 0.444325715\n",
      "Iteration 300 L -5.24320507 loss -5.27154684 loss_ordinary 0.590218902 entropy_value 5.86176586 glob_norm 0.551603734\n",
      "Iteration 350 L -5.26993561 loss -5.26576376 loss_ordinary 0.597148955 entropy_value 5.86291265 glob_norm 0.679672778\n",
      "Iteration 400 L -5.20062208 loss -5.26181412 loss_ordinary 0.602753758 entropy_value 5.86456776 glob_norm 0.792508125\n",
      "Iteration 450 L -5.25774431 loss -5.26699829 loss_ordinary 0.59563458 entropy_value 5.86263275 glob_norm 0.463786304\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.120537519 lambd_papr -0.136884987 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.31404591 loss -5.28209352 loss_ordinary 0.581629634 entropy_value 5.8637228 glob_norm 0.468944252\n",
      "Iteration 50 L -5.24956846 loss -5.24399328 loss_ordinary 0.622582197 entropy_value 5.86657524 glob_norm 0.609284699\n",
      "Iteration 100 L -5.21090412 loss -5.25624847 loss_ordinary 0.608111 entropy_value 5.86435938 glob_norm 0.579020917\n",
      "Iteration 150 L -5.27853155 loss -5.25576401 loss_ordinary 0.610916436 entropy_value 5.86668 glob_norm 0.518901825\n",
      "Iteration 200 L -5.27170515 loss -5.25618505 loss_ordinary 0.611161411 entropy_value 5.86734629 glob_norm 0.56327486\n",
      "Iteration 250 L -5.24786425 loss -5.25308371 loss_ordinary 0.610728502 entropy_value 5.86381245 glob_norm 0.616158962\n",
      "Iteration 300 L -5.2962985 loss -5.26168966 loss_ordinary 0.604519725 entropy_value 5.86620903 glob_norm 0.571743846\n",
      "Iteration 350 L -5.2439332 loss -5.20637 loss_ordinary 0.660913169 entropy_value 5.86728287 glob_norm 0.589139104\n",
      "Iteration 400 L -5.26949 loss -5.26787615 loss_ordinary 0.596141458 entropy_value 5.86401749 glob_norm 0.601055503\n",
      "Iteration 450 L -5.23444653 loss -5.25064325 loss_ordinary 0.616471648 entropy_value 5.86711502 glob_norm 0.686756134\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0.0279867649 lambd_papr -0.138272598 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.27428 loss -5.26719093 loss_ordinary 0.596744537 entropy_value 5.86393547 glob_norm 0.711324871\n",
      "Iteration 50 L -5.2698245 loss -5.20967388 loss_ordinary 0.656261444 entropy_value 5.86593533 glob_norm 0.529527187\n",
      "Iteration 100 L -5.29189 loss -5.25960588 loss_ordinary 0.608818829 entropy_value 5.86842489 glob_norm 0.779894233\n",
      "Iteration 150 L -5.23580742 loss -5.26854038 loss_ordinary 0.598420739 entropy_value 5.866961 glob_norm 0.704773605\n",
      "Iteration 200 L -5.29762745 loss -5.25406075 loss_ordinary 0.614452481 entropy_value 5.86851311 glob_norm 0.524941683\n",
      "Iteration 250 L -5.28438139 loss -5.23594379 loss_ordinary 0.630237162 entropy_value 5.8661809 glob_norm 0.61223191\n",
      "Iteration 300 L -5.24475861 loss -5.26414442 loss_ordinary 0.606020272 entropy_value 5.87016487 glob_norm 0.871382415\n",
      "Iteration 350 L -5.22687721 loss -5.23737097 loss_ordinary 0.62390548 entropy_value 5.86127663 glob_norm 0.711331904\n",
      "Iteration 400 L -5.22579765 loss -5.2756834 loss_ordinary 0.588707626 entropy_value 5.86439085 glob_norm 0.649743795\n",
      "Iteration 450 L -5.31303644 loss -5.26118851 loss_ordinary 0.600768387 entropy_value 5.86195707 glob_norm 0.726598\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.0059967041 lambd_papr -0.138595745 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_17_papr_6.0\n",
      "\n",
      "===== Running SNR=17 dB | PAPR=7.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0167483576 loss 0.0167483576 loss_ordinary 6.00793171 entropy_value 5.99118328 glob_norm 0.640359879\n",
      "Iteration 50 L -3.32805228 loss -3.32805228 loss_ordinary 2.64662886 entropy_value 5.97468138 glob_norm 0.417313755\n",
      "Iteration 100 L -4.18407774 loss -4.18407774 loss_ordinary 1.79017 entropy_value 5.97424793 glob_norm 0.290652812\n",
      "Iteration 150 L -4.64853477 loss -4.64853477 loss_ordinary 1.27635 entropy_value 5.9248848 glob_norm 0.34806937\n",
      "Iteration 200 L -5.00909424 loss -5.01033831 loss_ordinary 0.843838274 entropy_value 5.85417652 glob_norm 0.3536731\n",
      "Iteration 250 L -5.18913221 loss -5.18937445 loss_ordinary 0.637218058 entropy_value 5.82659245 glob_norm 0.346617341\n",
      "Iteration 300 L -5.26636267 loss -5.26788044 loss_ordinary 0.563741624 entropy_value 5.83162212 glob_norm 0.351129204\n",
      "Iteration 350 L -5.30442715 loss -5.30709267 loss_ordinary 0.520612299 entropy_value 5.82770491 glob_norm 0.414136171\n",
      "Iteration 400 L -5.32625198 loss -5.32779264 loss_ordinary 0.496625423 entropy_value 5.82441807 glob_norm 0.301564306\n",
      "Iteration 450 L -5.33475351 loss -5.33492041 loss_ordinary 0.490811557 entropy_value 5.82573175 glob_norm 0.463541895\n",
      "Iteration 500 L -5.35285902 loss -5.35314178 loss_ordinary 0.472976714 entropy_value 5.82611847 glob_norm 0.426006705\n",
      "Iteration 550 L -5.34801197 loss -5.35004377 loss_ordinary 0.474625289 entropy_value 5.82466936 glob_norm 0.334822297\n",
      "Iteration 600 L -5.35652637 loss -5.35735321 loss_ordinary 0.462715566 entropy_value 5.82006884 glob_norm 0.534802556\n",
      "Iteration 650 L -5.36298943 loss -5.36392 loss_ordinary 0.455823213 entropy_value 5.81974363 glob_norm 0.395108044\n",
      "Iteration 700 L -5.35877752 loss -5.35897255 loss_ordinary 0.466306955 entropy_value 5.82527924 glob_norm 0.409740269\n",
      "Iteration 750 L -5.37183666 loss -5.37276602 loss_ordinary 0.450257272 entropy_value 5.8230238 glob_norm 0.300694168\n",
      "Iteration 800 L -5.38362312 loss -5.38440323 loss_ordinary 0.443213016 entropy_value 5.82761621 glob_norm 0.373758793\n",
      "Iteration 850 L -5.3749 loss -5.37580681 loss_ordinary 0.445978522 entropy_value 5.82178545 glob_norm 0.476082683\n",
      "Iteration 900 L -5.3570075 loss -5.3590703 loss_ordinary 0.462661624 entropy_value 5.82173157 glob_norm 0.412094951\n",
      "Iteration 950 L -5.35705709 loss -5.35769653 loss_ordinary 0.464399278 entropy_value 5.82209539 glob_norm 0.35346806\n",
      "Iteration 1000 L -5.36683226 loss -5.36811113 loss_ordinary 0.455227196 entropy_value 5.82333803 glob_norm 0.462701231\n",
      "Iteration 1050 L -5.37220383 loss -5.37323475 loss_ordinary 0.448012263 entropy_value 5.82124758 glob_norm 0.386264235\n",
      "Iteration 1100 L -5.32645607 loss -5.3280921 loss_ordinary 0.490395576 entropy_value 5.81848717 glob_norm 0.363962501\n",
      "Iteration 1150 L -5.38261414 loss -5.38322258 loss_ordinary 0.441156685 entropy_value 5.82437944 glob_norm 0.532708526\n",
      "Iteration 1200 L -5.3577919 loss -5.35790205 loss_ordinary 0.460668027 entropy_value 5.81857 glob_norm 0.388132334\n",
      "Iteration 1250 L -5.38509703 loss -5.38516521 loss_ordinary 0.434853315 entropy_value 5.82001877 glob_norm 0.368406922\n",
      "Iteration 1300 L -5.36784172 loss -5.36891556 loss_ordinary 0.448603243 entropy_value 5.81751871 glob_norm 0.392074525\n",
      "Iteration 1350 L -5.34631062 loss -5.34677076 loss_ordinary 0.477246702 entropy_value 5.82401752 glob_norm 0.432067037\n",
      "Iteration 1400 L -5.37094402 loss -5.37202263 loss_ordinary 0.452623129 entropy_value 5.82464552 glob_norm 0.415882021\n",
      "Iteration 1450 L -5.36654186 loss -5.36667061 loss_ordinary 0.453401297 entropy_value 5.8200717 glob_norm 0.471129298\n",
      "Iteration 1500 L -5.3880949 loss -5.38816833 loss_ordinary 0.429820329 entropy_value 5.81798887 glob_norm 0.453663468\n",
      "Iteration 1550 L -5.32796144 loss -5.32832193 loss_ordinary 0.488698512 entropy_value 5.81702 glob_norm 0.449429244\n",
      "Iteration 1600 L -5.36169624 loss -5.36242056 loss_ordinary 0.46049118 entropy_value 5.82291126 glob_norm 0.322049618\n",
      "Iteration 1650 L -5.36875153 loss -5.37045383 loss_ordinary 0.450568706 entropy_value 5.82102251 glob_norm 0.336046815\n",
      "Iteration 1700 L -5.34971857 loss -5.34998894 loss_ordinary 0.468018889 entropy_value 5.81800795 glob_norm 0.471771926\n",
      "Iteration 1750 L -5.36453438 loss -5.36658049 loss_ordinary 0.451741278 entropy_value 5.8183217 glob_norm 0.454120487\n",
      "Iteration 1800 L -5.36418152 loss -5.36516237 loss_ordinary 0.45163694 entropy_value 5.81679916 glob_norm 0.373806685\n",
      "Iteration 1850 L -5.40044594 loss -5.40064955 loss_ordinary 0.420996189 entropy_value 5.82164574 glob_norm 0.363951445\n",
      "Iteration 1900 L -5.35401249 loss -5.35435581 loss_ordinary 0.466987759 entropy_value 5.8213439 glob_norm 0.325569063\n",
      "Iteration 1950 L -5.37530518 loss -5.37534571 loss_ordinary 0.447949797 entropy_value 5.82329512 glob_norm 0.288705736\n",
      "Iteration 2000 L -5.35525751 loss -5.35609055 loss_ordinary 0.460505605 entropy_value 5.81659603 glob_norm 0.351855665\n",
      "Iteration 2050 L -5.37684 loss -5.37740469 loss_ordinary 0.443487704 entropy_value 5.82089233 glob_norm 0.424232692\n",
      "Iteration 2100 L -5.37110233 loss -5.37181282 loss_ordinary 0.448199809 entropy_value 5.82001257 glob_norm 0.352566391\n",
      "Iteration 2150 L -5.37265778 loss -5.37279224 loss_ordinary 0.447187215 entropy_value 5.81997967 glob_norm 0.33953768\n",
      "Iteration 2200 L -5.37056971 loss -5.37130308 loss_ordinary 0.450230807 entropy_value 5.82153368 glob_norm 0.325234324\n",
      "Iteration 2250 L -5.34452581 loss -5.34522 loss_ordinary 0.475170851 entropy_value 5.8203907 glob_norm 0.544298649\n",
      "Iteration 2300 L -5.363029 loss -5.3640461 loss_ordinary 0.452793866 entropy_value 5.81683969 glob_norm 0.458897293\n",
      "Iteration 2350 L -5.3618021 loss -5.36188459 loss_ordinary 0.460018128 entropy_value 5.82190275 glob_norm 0.468273282\n",
      "Iteration 2400 L -5.36942196 loss -5.36965179 loss_ordinary 0.44462803 entropy_value 5.81428 glob_norm 0.515552878\n",
      "Iteration 2450 L -5.37491131 loss -5.37491131 loss_ordinary 0.443033397 entropy_value 5.81794453 glob_norm 0.25420776\n",
      "Iteration 2500 L -5.35664129 loss -5.35677481 loss_ordinary 0.466174453 entropy_value 5.82294941 glob_norm 0.323777765\n",
      "Iteration 2550 L -5.38698959 loss -5.3874 loss_ordinary 0.429569 entropy_value 5.81696892 glob_norm 0.282398313\n",
      "Iteration 2600 L -5.36420918 loss -5.3642931 loss_ordinary 0.453678 entropy_value 5.81797075 glob_norm 0.373791426\n",
      "Iteration 2650 L -5.37073421 loss -5.37082291 loss_ordinary 0.447809368 entropy_value 5.8186326 glob_norm 0.439466327\n",
      "Iteration 2700 L -5.35660696 loss -5.35773706 loss_ordinary 0.460139841 entropy_value 5.81787729 glob_norm 0.529325306\n",
      "Iteration 2750 L -5.37962294 loss -5.38016891 loss_ordinary 0.433121115 entropy_value 5.81329 glob_norm 0.441744208\n",
      "Iteration 2800 L -5.36348391 loss -5.36447191 loss_ordinary 0.449756861 entropy_value 5.81422901 glob_norm 0.389104486\n",
      "Iteration 2850 L -5.35783577 loss -5.35783577 loss_ordinary 0.464877188 entropy_value 5.82271338 glob_norm 0.386205584\n",
      "Iteration 2900 L -5.3432579 loss -5.34388 loss_ordinary 0.471951216 entropy_value 5.81583118 glob_norm 0.304652035\n",
      "Iteration 2950 L -5.37311459 loss -5.37375 loss_ordinary 0.448698938 entropy_value 5.82244921 glob_norm 0.383895516\n",
      "Iteration 3000 L -5.35211754 loss -5.35235405 loss_ordinary 0.468877226 entropy_value 5.82123137 glob_norm 0.298717946\n",
      "Iteration 3050 L -5.37559414 loss -5.3763504 loss_ordinary 0.441636771 entropy_value 5.81798744 glob_norm 0.358247578\n",
      "Iteration 3100 L -5.36766386 loss -5.3679328 loss_ordinary 0.448545098 entropy_value 5.81647778 glob_norm 0.389458358\n",
      "Iteration 3150 L -5.38804722 loss -5.39012766 loss_ordinary 0.431361496 entropy_value 5.82148886 glob_norm 0.312175095\n",
      "Iteration 3200 L -5.37360048 loss -5.37452 loss_ordinary 0.440956503 entropy_value 5.81547642 glob_norm 0.283541054\n",
      "Iteration 3250 L -5.39056921 loss -5.3908906 loss_ordinary 0.433630824 entropy_value 5.82452106 glob_norm 0.387036771\n",
      "Iteration 3300 L -5.36041403 loss -5.36134052 loss_ordinary 0.458327055 entropy_value 5.81966734 glob_norm 0.391041756\n",
      "Iteration 3350 L -5.36371803 loss -5.36372423 loss_ordinary 0.455413938 entropy_value 5.81913805 glob_norm 0.349762559\n",
      "Iteration 3400 L -5.36748743 loss -5.36834049 loss_ordinary 0.445210636 entropy_value 5.81355143 glob_norm 0.527000785\n",
      "Iteration 3450 L -5.37425232 loss -5.37565279 loss_ordinary 0.441678822 entropy_value 5.81733179 glob_norm 0.357184112\n",
      "Iteration 3500 L -5.38712 loss -5.38752937 loss_ordinary 0.428439736 entropy_value 5.81596899 glob_norm 0.399274349\n",
      "Iteration 3550 L -5.37419605 loss -5.37512732 loss_ordinary 0.442301273 entropy_value 5.81742859 glob_norm 0.30597043\n",
      "Iteration 3600 L -5.36297703 loss -5.36366844 loss_ordinary 0.452429801 entropy_value 5.81609821 glob_norm 0.354432136\n",
      "Iteration 3650 L -5.3674221 loss -5.36826277 loss_ordinary 0.450980306 entropy_value 5.81924343 glob_norm 0.328779966\n",
      "Iteration 3700 L -5.3715086 loss -5.3717947 loss_ordinary 0.445560873 entropy_value 5.81735563 glob_norm 0.330409229\n",
      "Iteration 3750 L -5.37166882 loss -5.37244844 loss_ordinary 0.444417953 entropy_value 5.8168664 glob_norm 0.343742967\n",
      "Iteration 3800 L -5.35639048 loss -5.35737944 loss_ordinary 0.462797135 entropy_value 5.82017612 glob_norm 0.385625154\n",
      "Iteration 3850 L -5.37920809 loss -5.38030529 loss_ordinary 0.437579036 entropy_value 5.81788397 glob_norm 0.252363384\n",
      "Iteration 3900 L -5.36975908 loss -5.36975908 loss_ordinary 0.446989 entropy_value 5.81674814 glob_norm 0.342881083\n",
      "Iteration 3950 L -5.3625226 loss -5.36289787 loss_ordinary 0.451834053 entropy_value 5.81473207 glob_norm 0.414482385\n",
      "Iteration 4000 L -5.37292814 loss -5.3729434 loss_ordinary 0.449211448 entropy_value 5.82215452 glob_norm 0.329608947\n",
      "Iteration 4050 L -5.35044861 loss -5.35057163 loss_ordinary 0.468403339 entropy_value 5.81897497 glob_norm 0.411314\n",
      "Iteration 4100 L -5.35379934 loss -5.35492802 loss_ordinary 0.463659883 entropy_value 5.81858778 glob_norm 0.370960891\n",
      "Iteration 4150 L -5.37277317 loss -5.37342739 loss_ordinary 0.440676123 entropy_value 5.81410313 glob_norm 0.398622096\n",
      "Iteration 4200 L -5.3780489 loss -5.37929583 loss_ordinary 0.436150134 entropy_value 5.8154459 glob_norm 0.356918514\n",
      "Iteration 4250 L -5.38380194 loss -5.38389158 loss_ordinary 0.438216984 entropy_value 5.82210875 glob_norm 0.291214406\n",
      "Iteration 4300 L -5.37922525 loss -5.37961245 loss_ordinary 0.438717246 entropy_value 5.81833 glob_norm 0.356352806\n",
      "Iteration 4350 L -5.3635931 loss -5.36414 loss_ordinary 0.457695782 entropy_value 5.82183552 glob_norm 0.405835807\n",
      "Iteration 4400 L -5.38255692 loss -5.38255692 loss_ordinary 0.440618515 entropy_value 5.82317543 glob_norm 0.403735399\n",
      "Iteration 4450 L -5.36934566 loss -5.36937523 loss_ordinary 0.447409332 entropy_value 5.81678486 glob_norm 0.289620817\n",
      "Iteration 4500 L -5.37686396 loss -5.37748957 loss_ordinary 0.442404121 entropy_value 5.81989336 glob_norm 0.364686668\n",
      "Iteration 4550 L -5.3499136 loss -5.35111618 loss_ordinary 0.464847744 entropy_value 5.81596422 glob_norm 0.470071465\n",
      "Iteration 4600 L -5.3676281 loss -5.36796761 loss_ordinary 0.450914 entropy_value 5.81888151 glob_norm 0.369766086\n",
      "Iteration 4650 L -5.37756681 loss -5.37898922 loss_ordinary 0.436554492 entropy_value 5.81554365 glob_norm 0.44513309\n",
      "Iteration 4700 L -5.37430525 loss -5.37480927 loss_ordinary 0.446660966 entropy_value 5.82147026 glob_norm 0.375238836\n",
      "Iteration 4750 L -5.35177946 loss -5.35256 loss_ordinary 0.462789953 entropy_value 5.81534958 glob_norm 0.457714558\n",
      "Iteration 4800 L -5.37731695 loss -5.37795448 loss_ordinary 0.44757393 entropy_value 5.82552814 glob_norm 0.37224251\n",
      "Iteration 4850 L -5.36986399 loss -5.36996889 loss_ordinary 0.445780903 entropy_value 5.81575 glob_norm 0.289953053\n",
      "Iteration 4900 L -5.37734461 loss -5.3779583 loss_ordinary 0.443318605 entropy_value 5.82127714 glob_norm 0.363080025\n",
      "Iteration 4950 L -5.3718071 loss -5.37219667 loss_ordinary 0.442050368 entropy_value 5.81424713 glob_norm 0.30044046\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 0.243350744 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39496803 loss -5.3959341 loss_ordinary 0.416948974 entropy_value 5.8128829 glob_norm 0.340405434\n",
      "Iteration 50 L -5.34662199 loss -5.34724665 loss_ordinary 0.468978196 entropy_value 5.81622458 glob_norm 0.351603538\n",
      "Iteration 100 L -5.37895632 loss -5.37993908 loss_ordinary 0.438476384 entropy_value 5.81841516 glob_norm 0.378298849\n",
      "Iteration 150 L -5.38804054 loss -5.38865471 loss_ordinary 0.430372745 entropy_value 5.81902742 glob_norm 0.30084148\n",
      "Iteration 200 L -5.38741207 loss -5.38978767 loss_ordinary 0.432137281 entropy_value 5.82192516 glob_norm 0.331238359\n",
      "Iteration 250 L -5.37948275 loss -5.38343477 loss_ordinary 0.437024504 entropy_value 5.82045889 glob_norm 0.467600137\n",
      "Iteration 300 L -5.36936522 loss -5.37090206 loss_ordinary 0.449571729 entropy_value 5.82047367 glob_norm 0.395144552\n",
      "Iteration 350 L -5.37044954 loss -5.37100506 loss_ordinary 0.444811195 entropy_value 5.81581593 glob_norm 0.346995115\n",
      "Iteration 400 L -5.36366844 loss -5.36508846 loss_ordinary 0.453288227 entropy_value 5.81837654 glob_norm 0.400602102\n",
      "Iteration 450 L -5.38272238 loss -5.38278151 loss_ordinary 0.434403479 entropy_value 5.81718493 glob_norm 0.32570678\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 0.168527365 lambd_papr -0.00243350747 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.390903 loss -5.39065599 loss_ordinary 0.429606169 entropy_value 5.82026243 glob_norm 0.437322378\n",
      "Iteration 50 L -5.35855103 loss -5.36088133 loss_ordinary 0.456780314 entropy_value 5.81766176 glob_norm 0.305503577\n",
      "Iteration 100 L -5.37751389 loss -5.37710238 loss_ordinary 0.442911267 entropy_value 5.820014 glob_norm 0.363588601\n",
      "Iteration 150 L -5.38243 loss -5.3852272 loss_ordinary 0.431039095 entropy_value 5.81626606 glob_norm 0.423303157\n",
      "Iteration 200 L -5.3683691 loss -5.36809731 loss_ordinary 0.452797294 entropy_value 5.82089424 glob_norm 0.3483845\n",
      "Iteration 250 L -5.40081072 loss -5.40028667 loss_ordinary 0.420675755 entropy_value 5.82096243 glob_norm 0.360589415\n",
      "Iteration 300 L -5.36131239 loss -5.3625536 loss_ordinary 0.457115591 entropy_value 5.81966925 glob_norm 0.284521848\n",
      "Iteration 350 L -5.36296797 loss -5.36418819 loss_ordinary 0.458906621 entropy_value 5.82309532 glob_norm 0.398384541\n",
      "Iteration 400 L -5.37963772 loss -5.38328314 loss_ordinary 0.436069 entropy_value 5.81935215 glob_norm 0.427986085\n",
      "Iteration 450 L -5.32867193 loss -5.32992125 loss_ordinary 0.493049324 entropy_value 5.82297087 glob_norm 0.425760895\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0.413152456 lambd_papr -0.00412383676 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37861872 loss -5.37682533 loss_ordinary 0.444762617 entropy_value 5.82158804 glob_norm 0.310869128\n",
      "Iteration 50 L -5.33308268 loss -5.33341312 loss_ordinary 0.484878242 entropy_value 5.81829119 glob_norm 0.411744386\n",
      "Iteration 100 L -5.38006973 loss -5.38086 loss_ordinary 0.445388794 entropy_value 5.82624865 glob_norm 0.373805642\n",
      "Iteration 150 L -5.35412884 loss -5.35264444 loss_ordinary 0.467738241 entropy_value 5.8203826 glob_norm 0.409858227\n",
      "Iteration 200 L -5.36416721 loss -5.36433315 loss_ordinary 0.45570749 entropy_value 5.8200407 glob_norm 0.460463703\n",
      "Iteration 250 L -5.37485313 loss -5.3744607 loss_ordinary 0.448131502 entropy_value 5.82259226 glob_norm 0.350992501\n",
      "Iteration 300 L -5.35872364 loss -5.36096907 loss_ordinary 0.461027294 entropy_value 5.82199669 glob_norm 0.399032742\n",
      "Iteration 350 L -5.37315035 loss -5.37170601 loss_ordinary 0.449182719 entropy_value 5.820889 glob_norm 0.305644453\n",
      "Iteration 400 L -5.37605286 loss -5.37838 loss_ordinary 0.44675374 entropy_value 5.82513332 glob_norm 0.323729306\n",
      "Iteration 450 L -5.39634228 loss -5.39844418 loss_ordinary 0.425098896 entropy_value 5.82354307 glob_norm 0.324354023\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0.188974142 lambd_papr -0.00828018785 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.33375931 loss -5.33486891 loss_ordinary 0.493865371 entropy_value 5.82873392 glob_norm 0.474624336\n",
      "Iteration 50 L -5.36971426 loss -5.36313772 loss_ordinary 0.460243016 entropy_value 5.82338047 glob_norm 0.331545711\n",
      "Iteration 100 L -5.35708904 loss -5.35957527 loss_ordinary 0.469563544 entropy_value 5.82913876 glob_norm 0.334896147\n",
      "Iteration 150 L -5.36166477 loss -5.35662317 loss_ordinary 0.465874672 entropy_value 5.82249784 glob_norm 0.423532933\n",
      "Iteration 200 L -5.38689756 loss -5.38404322 loss_ordinary 0.437127769 entropy_value 5.82117081 glob_norm 0.337716222\n",
      "Iteration 250 L -5.39625692 loss -5.39007568 loss_ordinary 0.433916867 entropy_value 5.82399273 glob_norm 0.304487348\n",
      "Iteration 300 L -5.35546446 loss -5.35784292 loss_ordinary 0.465218663 entropy_value 5.82306147 glob_norm 0.366808206\n",
      "Iteration 350 L -5.39104795 loss -5.39010286 loss_ordinary 0.433930337 entropy_value 5.82403326 glob_norm 0.348287612\n",
      "Iteration 400 L -5.35281086 loss -5.35217142 loss_ordinary 0.47396794 entropy_value 5.82613945 glob_norm 0.332209229\n",
      "Iteration 450 L -5.36960411 loss -5.36726 loss_ordinary 0.456200302 entropy_value 5.82346058 glob_norm 0.517325282\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power -0.136473417 lambd_papr -0.0101869879 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37812042 loss -5.37409544 loss_ordinary 0.450102448 entropy_value 5.82419777 glob_norm 0.46744743\n",
      "Iteration 50 L -5.34546232 loss -5.34635878 loss_ordinary 0.476139903 entropy_value 5.8224988 glob_norm 0.446058393\n",
      "Iteration 100 L -5.3619771 loss -5.36048937 loss_ordinary 0.466198862 entropy_value 5.82668829 glob_norm 0.420903325\n",
      "Iteration 150 L -5.38175201 loss -5.38261747 loss_ordinary 0.440228552 entropy_value 5.82284594 glob_norm 0.244008109\n",
      "Iteration 200 L -5.38331556 loss -5.383533 loss_ordinary 0.442027181 entropy_value 5.82556 glob_norm 0.365776569\n",
      "Iteration 250 L -5.36335373 loss -5.36563635 loss_ordinary 0.454614073 entropy_value 5.82025051 glob_norm 0.33573243\n",
      "Iteration 300 L -5.3585844 loss -5.36271954 loss_ordinary 0.463413596 entropy_value 5.82613325 glob_norm 0.31843251\n",
      "Iteration 350 L -5.39458275 loss -5.39332104 loss_ordinary 0.428410053 entropy_value 5.82173109 glob_norm 0.397630215\n",
      "Iteration 400 L -5.36146116 loss -5.36084604 loss_ordinary 0.465858608 entropy_value 5.8267045 glob_norm 0.328009903\n",
      "Iteration 450 L -5.37288141 loss -5.37194252 loss_ordinary 0.450755775 entropy_value 5.82269812 glob_norm 0.453121871\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0.200597525 lambd_papr -0.00880580302 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35066557 loss -5.35267782 loss_ordinary 0.467330635 entropy_value 5.82000828 glob_norm 0.461774379\n",
      "Iteration 50 L -5.37551212 loss -5.37522221 loss_ordinary 0.45084855 entropy_value 5.82607031 glob_norm 0.363827616\n",
      "Iteration 100 L -5.33494473 loss -5.33269691 loss_ordinary 0.495247513 entropy_value 5.82794428 glob_norm 0.448078424\n",
      "Iteration 150 L -5.36828041 loss -5.37253952 loss_ordinary 0.45126906 entropy_value 5.82380867 glob_norm 0.427180022\n",
      "Iteration 200 L -5.38101864 loss -5.37891579 loss_ordinary 0.444711536 entropy_value 5.823627 glob_norm 0.272180319\n",
      "Iteration 250 L -5.35286379 loss -5.35078907 loss_ordinary 0.48057 entropy_value 5.83135939 glob_norm 0.380230933\n",
      "Iteration 300 L -5.34032 loss -5.34453678 loss_ordinary 0.482665867 entropy_value 5.8272028 glob_norm 0.41999954\n",
      "Iteration 350 L -5.36907768 loss -5.36560917 loss_ordinary 0.459417582 entropy_value 5.82502699 glob_norm 0.367443651\n",
      "Iteration 400 L -5.39641953 loss -5.39456129 loss_ordinary 0.425770134 entropy_value 5.82033157 glob_norm 0.478385985\n",
      "Iteration 450 L -5.37731075 loss -5.3774209 loss_ordinary 0.44187519 entropy_value 5.81929588 glob_norm 0.583180845\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power -0.204733372 lambd_papr -0.0108420495 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36428404 loss -5.3631587 loss_ordinary 0.460812122 entropy_value 5.82397079 glob_norm 0.309341252\n",
      "Iteration 50 L -5.34381199 loss -5.34344912 loss_ordinary 0.482630879 entropy_value 5.82608 glob_norm 0.400121421\n",
      "Iteration 100 L -5.38457 loss -5.38622522 loss_ordinary 0.439283848 entropy_value 5.82550907 glob_norm 0.313850582\n",
      "Iteration 150 L -5.39515257 loss -5.39532614 loss_ordinary 0.428891152 entropy_value 5.82421732 glob_norm 0.324023545\n",
      "Iteration 200 L -5.38201761 loss -5.38447 loss_ordinary 0.438775122 entropy_value 5.82324505 glob_norm 0.419876158\n",
      "Iteration 250 L -5.3626852 loss -5.35966635 loss_ordinary 0.465900689 entropy_value 5.82556677 glob_norm 0.36946246\n",
      "Iteration 300 L -5.33324242 loss -5.33236408 loss_ordinary 0.492639393 entropy_value 5.82500362 glob_norm 0.383730352\n",
      "Iteration 350 L -5.35898113 loss -5.35912371 loss_ordinary 0.464455664 entropy_value 5.82357931 glob_norm 0.303587258\n",
      "Iteration 400 L -5.36830616 loss -5.36937857 loss_ordinary 0.455711961 entropy_value 5.82509089 glob_norm 0.335978687\n",
      "Iteration 450 L -5.37096691 loss -5.37067223 loss_ordinary 0.454152524 entropy_value 5.82482481 glob_norm 0.312697828\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power -0.477541924 lambd_papr -0.00875758566 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35551786 loss -5.35477781 loss_ordinary 0.471632361 entropy_value 5.82641029 glob_norm 0.465152711\n",
      "Iteration 50 L -5.34315348 loss -5.34380865 loss_ordinary 0.474915981 entropy_value 5.81872463 glob_norm 0.501334786\n",
      "Iteration 100 L -5.37179279 loss -5.37113523 loss_ordinary 0.45073995 entropy_value 5.82187557 glob_norm 0.328834772\n",
      "Iteration 150 L -5.36702585 loss -5.36710453 loss_ordinary 0.455619 entropy_value 5.82272387 glob_norm 0.450954169\n",
      "Iteration 200 L -5.36220312 loss -5.36178732 loss_ordinary 0.46129629 entropy_value 5.8230834 glob_norm 0.45106107\n",
      "Iteration 250 L -5.35635185 loss -5.35643864 loss_ordinary 0.46842888 entropy_value 5.82486725 glob_norm 0.383779615\n",
      "Iteration 300 L -5.38189173 loss -5.38303614 loss_ordinary 0.440160394 entropy_value 5.82319641 glob_norm 0.290652186\n",
      "Iteration 350 L -5.37880468 loss -5.37954569 loss_ordinary 0.445044398 entropy_value 5.82459 glob_norm 0.309918523\n",
      "Iteration 400 L -5.32657528 loss -5.32625437 loss_ordinary 0.493104696 entropy_value 5.81935883 glob_norm 0.443965673\n",
      "Iteration 450 L -5.36713648 loss -5.36643648 loss_ordinary 0.462567359 entropy_value 5.82900381 glob_norm 0.506554604\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0.0508921146 lambd_papr -0.00388097484 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36514711 loss -5.36424637 loss_ordinary 0.454926789 entropy_value 5.81917334 glob_norm 0.289937079\n",
      "Iteration 50 L -5.35779762 loss -5.35715342 loss_ordinary 0.465079874 entropy_value 5.8222332 glob_norm 0.372428566\n",
      "Iteration 100 L -5.378438 loss -5.3788271 loss_ordinary 0.442946434 entropy_value 5.82177353 glob_norm 0.248625815\n",
      "Iteration 150 L -5.3584075 loss -5.35840082 loss_ordinary 0.465598434 entropy_value 5.82399893 glob_norm 0.355425179\n",
      "Iteration 200 L -5.38321638 loss -5.38485384 loss_ordinary 0.435955554 entropy_value 5.82080936 glob_norm 0.302445084\n",
      "Iteration 250 L -5.37184477 loss -5.37361431 loss_ordinary 0.446303189 entropy_value 5.81991768 glob_norm 0.407295793\n",
      "Iteration 300 L -5.34616089 loss -5.3475461 loss_ordinary 0.473372787 entropy_value 5.82091856 glob_norm 0.393746614\n",
      "Iteration 350 L -5.37374496 loss -5.37351656 loss_ordinary 0.449076533 entropy_value 5.82259274 glob_norm 0.321065754\n",
      "Iteration 400 L -5.37306643 loss -5.37434578 loss_ordinary 0.4506163 entropy_value 5.82496214 glob_norm 0.40593636\n",
      "Iteration 450 L -5.37147045 loss -5.37306499 loss_ordinary 0.446831912 entropy_value 5.81989717 glob_norm 0.40714711\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power -0.0533144474 lambd_papr -0.00440223934 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35018778 loss -5.3493247 loss_ordinary 0.474497885 entropy_value 5.82382298 glob_norm 0.428792506\n",
      "Iteration 50 L -5.35314894 loss -5.35720158 loss_ordinary 0.462788701 entropy_value 5.81999063 glob_norm 0.293145597\n",
      "Iteration 100 L -5.3868885 loss -5.38802576 loss_ordinary 0.436208546 entropy_value 5.82423449 glob_norm 0.431657\n",
      "Iteration 150 L -5.37929201 loss -5.37994957 loss_ordinary 0.438684314 entropy_value 5.81863403 glob_norm 0.337274671\n",
      "Iteration 200 L -5.36022091 loss -5.36136913 loss_ordinary 0.463229746 entropy_value 5.82459879 glob_norm 0.384457886\n",
      "Iteration 250 L -5.33407497 loss -5.3355875 loss_ordinary 0.485328943 entropy_value 5.82091665 glob_norm 0.401162297\n",
      "Iteration 300 L -5.38711119 loss -5.38625574 loss_ordinary 0.433590263 entropy_value 5.81984615 glob_norm 0.306224674\n",
      "Iteration 350 L -5.37621832 loss -5.3777647 loss_ordinary 0.443043739 entropy_value 5.82080841 glob_norm 0.307468057\n",
      "Iteration 400 L -5.33530855 loss -5.33745337 loss_ordinary 0.484323859 entropy_value 5.82177687 glob_norm 0.439183593\n",
      "Iteration 450 L -5.35488653 loss -5.35529041 loss_ordinary 0.469812095 entropy_value 5.82510233 glob_norm 0.264870942\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power -0.0515899658 lambd_papr -0.00385452597 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34347773 loss -5.34460831 loss_ordinary 0.474267602 entropy_value 5.81887627 glob_norm 0.400883168\n",
      "Iteration 50 L -5.34711552 loss -5.34805727 loss_ordinary 0.472988844 entropy_value 5.82104588 glob_norm 0.457574546\n",
      "Iteration 100 L -5.37632465 loss -5.37584257 loss_ordinary 0.446321875 entropy_value 5.82216454 glob_norm 0.357928753\n",
      "Iteration 150 L -5.34510708 loss -5.34491682 loss_ordinary 0.475976199 entropy_value 5.82089329 glob_norm 0.311301917\n",
      "Iteration 200 L -5.35813713 loss -5.35788679 loss_ordinary 0.46491918 entropy_value 5.82280636 glob_norm 0.377221584\n",
      "Iteration 250 L -5.36558676 loss -5.36781788 loss_ordinary 0.453595281 entropy_value 5.82141304 glob_norm 0.361959964\n",
      "Iteration 300 L -5.37899828 loss -5.38196182 loss_ordinary 0.435278803 entropy_value 5.81724072 glob_norm 0.525571942\n",
      "Iteration 350 L -5.36148214 loss -5.3619 loss_ordinary 0.455307811 entropy_value 5.81720781 glob_norm 0.537928641\n",
      "Iteration 400 L -5.36551142 loss -5.36531401 loss_ordinary 0.460091889 entropy_value 5.82540607 glob_norm 0.343135804\n",
      "Iteration 450 L -5.36616802 loss -5.36723566 loss_ordinary 0.455325603 entropy_value 5.82256126 glob_norm 0.447003484\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0.101143837 lambd_papr -0.00332293846 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36880493 loss -5.36886024 loss_ordinary 0.449709207 entropy_value 5.81856918 glob_norm 0.291859925\n",
      "Iteration 50 L -5.33672714 loss -5.34075165 loss_ordinary 0.480789453 entropy_value 5.82154131 glob_norm 0.299528778\n",
      "Iteration 100 L -5.37229967 loss -5.37411833 loss_ordinary 0.443621278 entropy_value 5.81773949 glob_norm 0.334504\n",
      "Iteration 150 L -5.36482906 loss -5.36403 loss_ordinary 0.460637301 entropy_value 5.82466698 glob_norm 0.406219184\n",
      "Iteration 200 L -5.35514736 loss -5.35866594 loss_ordinary 0.464113504 entropy_value 5.82277918 glob_norm 0.312403709\n",
      "Iteration 250 L -5.36023045 loss -5.36267138 loss_ordinary 0.457040966 entropy_value 5.81971264 glob_norm 0.414571166\n",
      "Iteration 300 L -5.37893248 loss -5.37867117 loss_ordinary 0.444704592 entropy_value 5.8233757 glob_norm 0.329495281\n",
      "Iteration 350 L -5.38295221 loss -5.38165331 loss_ordinary 0.441488832 entropy_value 5.82314205 glob_norm 0.426141769\n",
      "Iteration 400 L -5.35621119 loss -5.35692835 loss_ordinary 0.469947666 entropy_value 5.82687616 glob_norm 0.39071697\n",
      "Iteration 450 L -5.38170671 loss -5.38306189 loss_ordinary 0.442277163 entropy_value 5.82533932 glob_norm 0.396016\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0.170378685 lambd_papr -0.00436825957 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38413954 loss -5.38594913 loss_ordinary 0.437039524 entropy_value 5.82298851 glob_norm 0.40858677\n",
      "Iteration 50 L -5.3737464 loss -5.37413836 loss_ordinary 0.451255739 entropy_value 5.82539415 glob_norm 0.410500407\n",
      "Iteration 100 L -5.37229919 loss -5.37076759 loss_ordinary 0.45238325 entropy_value 5.82315063 glob_norm 0.476755589\n",
      "Iteration 150 L -5.35837412 loss -5.36052322 loss_ordinary 0.461439162 entropy_value 5.82196236 glob_norm 0.376612186\n",
      "Iteration 200 L -5.33893967 loss -5.33636284 loss_ordinary 0.491253138 entropy_value 5.82761621 glob_norm 0.326298892\n",
      "Iteration 250 L -5.33699083 loss -5.33948326 loss_ordinary 0.480763137 entropy_value 5.82024622 glob_norm 0.523252189\n",
      "Iteration 300 L -5.35473 loss -5.35515213 loss_ordinary 0.460865676 entropy_value 5.81601763 glob_norm 0.348890245\n",
      "Iteration 350 L -5.35155296 loss -5.35166788 loss_ordinary 0.470160156 entropy_value 5.82182789 glob_norm 0.332624018\n",
      "Iteration 400 L -5.35538 loss -5.35430527 loss_ordinary 0.46866402 entropy_value 5.82296944 glob_norm 0.35273537\n",
      "Iteration 450 L -5.33555603 loss -5.33650827 loss_ordinary 0.491004556 entropy_value 5.82751322 glob_norm 0.377205133\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0.300780773 lambd_papr -0.00613440573 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39363813 loss -5.39452791 loss_ordinary 0.425823957 entropy_value 5.8203516 glob_norm 0.413262397\n",
      "Iteration 50 L -5.34650755 loss -5.34234571 loss_ordinary 0.487473816 entropy_value 5.82981968 glob_norm 0.559098482\n",
      "Iteration 100 L -5.36355209 loss -5.3626976 loss_ordinary 0.462846726 entropy_value 5.82554436 glob_norm 0.349794596\n",
      "Iteration 150 L -5.38133764 loss -5.37801361 loss_ordinary 0.443994015 entropy_value 5.82200766 glob_norm 0.329702258\n",
      "Iteration 200 L -5.38341188 loss -5.38339758 loss_ordinary 0.437774 entropy_value 5.82117176 glob_norm 0.320962042\n",
      "Iteration 250 L -5.3468523 loss -5.3468895 loss_ordinary 0.478129983 entropy_value 5.82501936 glob_norm 0.542516232\n",
      "Iteration 300 L -5.3519187 loss -5.35654497 loss_ordinary 0.468763739 entropy_value 5.8253088 glob_norm 0.272034317\n",
      "Iteration 350 L -5.37315845 loss -5.37137842 loss_ordinary 0.451454937 entropy_value 5.82283306 glob_norm 0.25467664\n",
      "Iteration 400 L -5.36682606 loss -5.36598063 loss_ordinary 0.460060716 entropy_value 5.8260417 glob_norm 0.274389654\n",
      "Iteration 450 L -5.37108 loss -5.37030125 loss_ordinary 0.453274578 entropy_value 5.82357597 glob_norm 0.490328133\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power -0.607095242 lambd_papr -0.00926165376 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34791756 loss -5.34732533 loss_ordinary 0.476323068 entropy_value 5.82364845 glob_norm 0.294384122\n",
      "Iteration 50 L -5.35887432 loss -5.36061478 loss_ordinary 0.463792652 entropy_value 5.8244071 glob_norm 0.459417731\n",
      "Iteration 100 L -5.35162926 loss -5.35103798 loss_ordinary 0.472132176 entropy_value 5.82317 glob_norm 0.535454631\n",
      "Iteration 150 L -5.38717365 loss -5.38862896 loss_ordinary 0.432676643 entropy_value 5.82130575 glob_norm 0.434534639\n",
      "Iteration 200 L -5.36907196 loss -5.36986 loss_ordinary 0.455151916 entropy_value 5.82501221 glob_norm 0.356127053\n",
      "Iteration 250 L -5.3347826 loss -5.33648777 loss_ordinary 0.486982375 entropy_value 5.82347 glob_norm 0.465524673\n",
      "Iteration 300 L -5.36858273 loss -5.37007475 loss_ordinary 0.450033695 entropy_value 5.82010889 glob_norm 0.381015122\n",
      "Iteration 350 L -5.3511591 loss -5.35184813 loss_ordinary 0.470698804 entropy_value 5.82254696 glob_norm 0.350117832\n",
      "Iteration 400 L -5.37824678 loss -5.37924576 loss_ordinary 0.440313935 entropy_value 5.81956 glob_norm 0.437606812\n",
      "Iteration 450 L -5.35215521 loss -5.35182142 loss_ordinary 0.468962878 entropy_value 5.82078457 glob_norm 0.373153538\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0.28200841 lambd_papr -0.00293068681 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37942171 loss -5.38235617 loss_ordinary 0.433241189 entropy_value 5.81559753 glob_norm 0.278378636\n",
      "Iteration 50 L -5.37897539 loss -5.37789202 loss_ordinary 0.441728532 entropy_value 5.81962061 glob_norm 0.338251978\n",
      "Iteration 100 L -5.37616205 loss -5.3761735 loss_ordinary 0.447352886 entropy_value 5.82352638 glob_norm 0.37437731\n",
      "Iteration 150 L -5.37255383 loss -5.37303066 loss_ordinary 0.446973473 entropy_value 5.82000446 glob_norm 0.320820659\n",
      "Iteration 200 L -5.3697958 loss -5.36867428 loss_ordinary 0.456088364 entropy_value 5.82476282 glob_norm 0.344681174\n",
      "Iteration 250 L -5.37575 loss -5.37765884 loss_ordinary 0.446205884 entropy_value 5.82386494 glob_norm 0.310729027\n",
      "Iteration 300 L -5.36851072 loss -5.36638689 loss_ordinary 0.454733849 entropy_value 5.82112074 glob_norm 0.491706\n",
      "Iteration 350 L -5.37650967 loss -5.37629652 loss_ordinary 0.448274225 entropy_value 5.82457066 glob_norm 0.454431742\n",
      "Iteration 400 L -5.39472485 loss -5.39415646 loss_ordinary 0.43216908 entropy_value 5.82632589 glob_norm 0.411822975\n",
      "Iteration 450 L -5.34924 loss -5.34755325 loss_ordinary 0.471886516 entropy_value 5.81944036 glob_norm 0.510686636\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power -0.123885393 lambd_papr -0.00588037539 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36389256 loss -5.36245441 loss_ordinary 0.457897872 entropy_value 5.82035255 glob_norm 0.360972345\n",
      "Iteration 50 L -5.35688543 loss -5.3567996 loss_ordinary 0.465850562 entropy_value 5.82265 glob_norm 0.354789913\n",
      "Iteration 100 L -5.34696245 loss -5.34604311 loss_ordinary 0.481231093 entropy_value 5.82727432 glob_norm 0.549838483\n",
      "Iteration 150 L -5.38068247 loss -5.37935352 loss_ordinary 0.44301939 entropy_value 5.82237291 glob_norm 0.34877345\n",
      "Iteration 200 L -5.36547375 loss -5.36504269 loss_ordinary 0.456002444 entropy_value 5.82104492 glob_norm 0.358670503\n",
      "Iteration 250 L -5.33283234 loss -5.33218193 loss_ordinary 0.492800206 entropy_value 5.82498217 glob_norm 0.381954283\n",
      "Iteration 300 L -5.36122036 loss -5.36164093 loss_ordinary 0.456006497 entropy_value 5.81764746 glob_norm 0.314991\n",
      "Iteration 350 L -5.35186768 loss -5.35192394 loss_ordinary 0.470112473 entropy_value 5.82203627 glob_norm 0.30503428\n",
      "Iteration 400 L -5.35663795 loss -5.35731268 loss_ordinary 0.459636778 entropy_value 5.81694937 glob_norm 0.434569061\n",
      "Iteration 450 L -5.34206629 loss -5.34298849 loss_ordinary 0.479750842 entropy_value 5.8227396 glob_norm 0.30879885\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power -0.21807313 lambd_papr -0.00458069891 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36626053 loss -5.36622 loss_ordinary 0.456365258 entropy_value 5.82258558 glob_norm 0.461032569\n",
      "Iteration 50 L -5.3618269 loss -5.3629303 loss_ordinary 0.456864417 entropy_value 5.81979465 glob_norm 0.374187738\n",
      "Iteration 100 L -5.35218382 loss -5.35377216 loss_ordinary 0.467712671 entropy_value 5.82148457 glob_norm 0.376860261\n",
      "Iteration 150 L -5.3789978 loss -5.38075495 loss_ordinary 0.442502022 entropy_value 5.82325697 glob_norm 0.406481147\n",
      "Iteration 200 L -5.3558712 loss -5.3568697 loss_ordinary 0.468893915 entropy_value 5.8257637 glob_norm 0.363479137\n",
      "Iteration 250 L -5.34876299 loss -5.35093641 loss_ordinary 0.472302616 entropy_value 5.82323885 glob_norm 0.472966045\n",
      "Iteration 300 L -5.36823893 loss -5.36854315 loss_ordinary 0.453833818 entropy_value 5.82237673 glob_norm 0.38921991\n",
      "Iteration 350 L -5.3657093 loss -5.36742449 loss_ordinary 0.452885598 entropy_value 5.82031059 glob_norm 0.35766083\n",
      "Iteration 400 L -5.36449099 loss -5.36420059 loss_ordinary 0.460413963 entropy_value 5.824615 glob_norm 0.36717549\n",
      "Iteration 450 L -5.36700726 loss -5.36879683 loss_ordinary 0.453853339 entropy_value 5.82265 glob_norm 0.347026378\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power -0.0880875587 lambd_papr -0.00228603976 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36036444 loss -5.36067438 loss_ordinary 0.456802547 entropy_value 5.81747675 glob_norm 0.359697849\n",
      "Iteration 50 L -5.36725855 loss -5.36717176 loss_ordinary 0.455811322 entropy_value 5.82298279 glob_norm 0.422127575\n",
      "Iteration 100 L -5.37892151 loss -5.37898493 loss_ordinary 0.441282719 entropy_value 5.82026768 glob_norm 0.263868719\n",
      "Iteration 150 L -5.36002874 loss -5.3623662 loss_ordinary 0.462246835 entropy_value 5.82461262 glob_norm 0.328929454\n",
      "Iteration 200 L -5.35138369 loss -5.3522625 loss_ordinary 0.466341108 entropy_value 5.81860352 glob_norm 0.470763743\n",
      "Iteration 250 L -5.37593 loss -5.37586069 loss_ordinary 0.446236 entropy_value 5.82209682 glob_norm 0.363831908\n",
      "Iteration 300 L -5.34446621 loss -5.34434032 loss_ordinary 0.476472169 entropy_value 5.8208127 glob_norm 0.362529248\n",
      "Iteration 350 L -5.34892941 loss -5.34911346 loss_ordinary 0.474233 entropy_value 5.82334614 glob_norm 0.367712706\n",
      "Iteration 400 L -5.39247417 loss -5.39332676 loss_ordinary 0.426933378 entropy_value 5.82026 glob_norm 0.256085962\n",
      "Iteration 450 L -5.37393618 loss -5.37534952 loss_ordinary 0.44705981 entropy_value 5.82240915 glob_norm 0.314946145\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0.275225639 lambd_papr -0.001356364 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37151861 loss -5.37474871 loss_ordinary 0.445315957 entropy_value 5.82006502 glob_norm 0.460980237\n",
      "Iteration 50 L -5.34692383 loss -5.34588289 loss_ordinary 0.472637504 entropy_value 5.81852055 glob_norm 0.454079211\n",
      "Iteration 100 L -5.37075758 loss -5.37503719 loss_ordinary 0.447595 entropy_value 5.82263231 glob_norm 0.376799047\n",
      "Iteration 150 L -5.36561584 loss -5.36437702 loss_ordinary 0.453028172 entropy_value 5.81740522 glob_norm 0.389776289\n",
      "Iteration 200 L -5.3681221 loss -5.37012529 loss_ordinary 0.450378269 entropy_value 5.82050371 glob_norm 0.521098\n",
      "Iteration 250 L -5.36795044 loss -5.36683607 loss_ordinary 0.457045317 entropy_value 5.82388163 glob_norm 0.36911878\n",
      "Iteration 300 L -5.37635469 loss -5.37631321 loss_ordinary 0.44611612 entropy_value 5.82242918 glob_norm 0.407673597\n",
      "Iteration 350 L -5.38293 loss -5.38247299 loss_ordinary 0.438549936 entropy_value 5.82102299 glob_norm 0.354959428\n",
      "Iteration 400 L -5.34896755 loss -5.34869337 loss_ordinary 0.473854691 entropy_value 5.82254839 glob_norm 0.446790367\n",
      "Iteration 450 L -5.38361168 loss -5.38287592 loss_ordinary 0.439526945 entropy_value 5.82240295 glob_norm 0.250314206\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0.0246033669 lambd_papr -0.00426980853 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.33887625 loss -5.33912754 loss_ordinary 0.487117946 entropy_value 5.82624531 glob_norm 0.443813652\n",
      "Iteration 50 L -5.35400915 loss -5.35652351 loss_ordinary 0.465058923 entropy_value 5.82158232 glob_norm 0.393430352\n",
      "Iteration 100 L -5.37204742 loss -5.37249517 loss_ordinary 0.44971472 entropy_value 5.82221 glob_norm 0.414735407\n",
      "Iteration 150 L -5.3681469 loss -5.36843491 loss_ordinary 0.453835368 entropy_value 5.82227039 glob_norm 0.309166\n",
      "Iteration 200 L -5.3589015 loss -5.35790396 loss_ordinary 0.464932919 entropy_value 5.82283735 glob_norm 0.379791647\n",
      "Iteration 250 L -5.34928179 loss -5.35182619 loss_ordinary 0.467263132 entropy_value 5.81908941 glob_norm 0.304887414\n",
      "Iteration 300 L -5.38112164 loss -5.38150883 loss_ordinary 0.444894522 entropy_value 5.82640362 glob_norm 0.375241101\n",
      "Iteration 350 L -5.35699129 loss -5.35774088 loss_ordinary 0.464040399 entropy_value 5.82178116 glob_norm 0.27977863\n",
      "Iteration 400 L -5.36556864 loss -5.36531687 loss_ordinary 0.45730707 entropy_value 5.82262373 glob_norm 0.260566294\n",
      "Iteration 450 L -5.37161541 loss -5.37237453 loss_ordinary 0.44666332 entropy_value 5.81903791 glob_norm 0.269404292\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power 0.135583401 lambd_papr -0.00453103287 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39144945 loss -5.39444351 loss_ordinary 0.427931517 entropy_value 5.82237482 glob_norm 0.251526862\n",
      "Iteration 50 L -5.37248707 loss -5.37316942 loss_ordinary 0.446741343 entropy_value 5.81991053 glob_norm 0.332303494\n",
      "Iteration 100 L -5.35672522 loss -5.35809469 loss_ordinary 0.465913475 entropy_value 5.82400799 glob_norm 0.341676414\n",
      "Iteration 150 L -5.37974 loss -5.38111353 loss_ordinary 0.442027062 entropy_value 5.82314062 glob_norm 0.341000587\n",
      "Iteration 200 L -5.35647821 loss -5.35640192 loss_ordinary 0.465819567 entropy_value 5.82222128 glob_norm 0.330690026\n",
      "Iteration 250 L -5.36453247 loss -5.36252 loss_ordinary 0.46143806 entropy_value 5.8239584 glob_norm 0.37215364\n",
      "Iteration 300 L -5.37137842 loss -5.37280083 loss_ordinary 0.445571482 entropy_value 5.81837273 glob_norm 0.307355642\n",
      "Iteration 350 L -5.36901474 loss -5.37120485 loss_ordinary 0.458251536 entropy_value 5.82945633 glob_norm 0.422358483\n",
      "Iteration 400 L -5.37558842 loss -5.3753767 loss_ordinary 0.450899214 entropy_value 5.8262763 glob_norm 0.369426489\n",
      "Iteration 450 L -5.35042524 loss -5.35087156 loss_ordinary 0.469889909 entropy_value 5.82076168 glob_norm 0.351937771\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power -0.288565397 lambd_papr -0.00597489718 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.383214 loss -5.38265085 loss_ordinary 0.441866279 entropy_value 5.82451725 glob_norm 0.355801821\n",
      "Iteration 50 L -5.35875082 loss -5.3581872 loss_ordinary 0.467496663 entropy_value 5.82568359 glob_norm 0.50644654\n",
      "Iteration 100 L -5.39937782 loss -5.40032625 loss_ordinary 0.418098688 entropy_value 5.8184247 glob_norm 0.330356538\n",
      "Iteration 150 L -5.38842201 loss -5.38799763 loss_ordinary 0.436481506 entropy_value 5.8244791 glob_norm 0.298138201\n",
      "Iteration 200 L -5.36793756 loss -5.36803102 loss_ordinary 0.449742109 entropy_value 5.81777334 glob_norm 0.394155413\n",
      "Iteration 250 L -5.3743124 loss -5.37520838 loss_ordinary 0.447680414 entropy_value 5.82288885 glob_norm 0.455747277\n",
      "Iteration 300 L -5.35844088 loss -5.35898399 loss_ordinary 0.459598869 entropy_value 5.81858301 glob_norm 0.402852356\n",
      "Iteration 350 L -5.38468504 loss -5.38471889 loss_ordinary 0.439734101 entropy_value 5.82445335 glob_norm 0.281489462\n",
      "Iteration 400 L -5.36191845 loss -5.36468 loss_ordinary 0.451940566 entropy_value 5.81662035 glob_norm 0.345758885\n",
      "Iteration 450 L -5.39134789 loss -5.39183 loss_ordinary 0.423633456 entropy_value 5.81546307 glob_norm 0.374220461\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0.178750992 lambd_papr -0.00289266766 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37802172 loss -5.3791604 loss_ordinary 0.443255514 entropy_value 5.82241631 glob_norm 0.464463\n",
      "Iteration 50 L -5.3781085 loss -5.37668848 loss_ordinary 0.443561405 entropy_value 5.82025 glob_norm 0.292207688\n",
      "Iteration 100 L -5.33982897 loss -5.33947563 loss_ordinary 0.481604546 entropy_value 5.82108 glob_norm 0.415783197\n",
      "Iteration 150 L -5.34732246 loss -5.34965 loss_ordinary 0.474305689 entropy_value 5.82395554 glob_norm 0.413066477\n",
      "Iteration 200 L -5.3609 loss -5.36076069 loss_ordinary 0.464510381 entropy_value 5.82527113 glob_norm 0.346149117\n",
      "Iteration 250 L -5.3721962 loss -5.3742795 loss_ordinary 0.449843913 entropy_value 5.82412338 glob_norm 0.410688728\n",
      "Iteration 300 L -5.35819244 loss -5.35703421 loss_ordinary 0.460832566 entropy_value 5.8178668 glob_norm 0.331699729\n",
      "Iteration 350 L -5.37735415 loss -5.37737 loss_ordinary 0.445573837 entropy_value 5.82294369 glob_norm 0.37372452\n",
      "Iteration 400 L -5.36660957 loss -5.369 loss_ordinary 0.451447666 entropy_value 5.82044744 glob_norm 0.293697953\n",
      "Iteration 450 L -5.35338831 loss -5.3524065 loss_ordinary 0.472293645 entropy_value 5.8247 glob_norm 0.39233163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0.0790164471 lambd_papr -0.00480767339 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36232901 loss -5.36370373 loss_ordinary 0.464194626 entropy_value 5.8278985 glob_norm 0.362930298\n",
      "Iteration 50 L -5.38369274 loss -5.38338041 loss_ordinary 0.437966287 entropy_value 5.82134628 glob_norm 0.413047075\n",
      "Iteration 100 L -5.34264612 loss -5.34176111 loss_ordinary 0.478310615 entropy_value 5.8200717 glob_norm 0.359561622\n",
      "Iteration 150 L -5.36153 loss -5.36265 loss_ordinary 0.45879975 entropy_value 5.82144976 glob_norm 0.360293388\n",
      "Iteration 200 L -5.36863422 loss -5.36702251 loss_ordinary 0.452941895 entropy_value 5.81996441 glob_norm 0.400639802\n",
      "Iteration 250 L -5.35854053 loss -5.35946941 loss_ordinary 0.463175803 entropy_value 5.82264519 glob_norm 0.252787352\n",
      "Iteration 300 L -5.36654949 loss -5.37123156 loss_ordinary 0.447357178 entropy_value 5.81858873 glob_norm 0.334835768\n",
      "Iteration 350 L -5.35641289 loss -5.35451317 loss_ordinary 0.470290244 entropy_value 5.82480335 glob_norm 0.473745346\n",
      "Iteration 400 L -5.36473131 loss -5.36448431 loss_ordinary 0.458264887 entropy_value 5.82274914 glob_norm 0.334482521\n",
      "Iteration 450 L -5.38530254 loss -5.38675308 loss_ordinary 0.438072324 entropy_value 5.82482529 glob_norm 0.311416924\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power -0.0651316643 lambd_papr -0.0056567369 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36323214 loss -5.36198 loss_ordinary 0.462158561 entropy_value 5.82413864 glob_norm 0.305610567\n",
      "Iteration 50 L -5.37577057 loss -5.37575674 loss_ordinary 0.443102896 entropy_value 5.81885958 glob_norm 0.301129162\n",
      "Iteration 100 L -5.3827157 loss -5.38417339 loss_ordinary 0.440184176 entropy_value 5.82435751 glob_norm 0.350025237\n",
      "Iteration 150 L -5.34599876 loss -5.34874153 loss_ordinary 0.476833642 entropy_value 5.82557535 glob_norm 0.355125815\n",
      "Iteration 200 L -5.35381317 loss -5.35588932 loss_ordinary 0.464001358 entropy_value 5.81989098 glob_norm 0.326152802\n",
      "Iteration 250 L -5.37324238 loss -5.37203407 loss_ordinary 0.451118231 entropy_value 5.82315207 glob_norm 0.312195659\n",
      "Iteration 300 L -5.36574507 loss -5.3641839 loss_ordinary 0.460702747 entropy_value 5.82488632 glob_norm 0.390121937\n",
      "Iteration 350 L -5.34681606 loss -5.34592485 loss_ordinary 0.474823803 entropy_value 5.82074881 glob_norm 0.425082386\n",
      "Iteration 400 L -5.35584116 loss -5.35558748 loss_ordinary 0.467784792 entropy_value 5.82337236 glob_norm 0.389032364\n",
      "Iteration 450 L -5.37418127 loss -5.37655687 loss_ordinary 0.449536502 entropy_value 5.8260932 glob_norm 0.356311\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0.044728756 lambd_papr -0.0049547716 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36906338 loss -5.36917353 loss_ordinary 0.454374969 entropy_value 5.82354832 glob_norm 0.419311076\n",
      "Iteration 50 L -5.3664608 loss -5.36737585 loss_ordinary 0.458050668 entropy_value 5.82542658 glob_norm 0.339737654\n",
      "Iteration 100 L -5.35402918 loss -5.35568953 loss_ordinary 0.467909932 entropy_value 5.82359934 glob_norm 0.329023719\n",
      "Iteration 150 L -5.36196089 loss -5.35999632 loss_ordinary 0.461766481 entropy_value 5.82176256 glob_norm 0.349030107\n",
      "Iteration 200 L -5.35741091 loss -5.35671473 loss_ordinary 0.4699696 entropy_value 5.826684 glob_norm 0.440163404\n",
      "Iteration 250 L -5.35876226 loss -5.35913897 loss_ordinary 0.463640541 entropy_value 5.82277918 glob_norm 0.447238058\n",
      "Iteration 300 L -5.37901 loss -5.37986326 loss_ordinary 0.439750403 entropy_value 5.81961346 glob_norm 0.474236727\n",
      "Iteration 350 L -5.3431797 loss -5.34668589 loss_ordinary 0.481378406 entropy_value 5.82806396 glob_norm 0.382644475\n",
      "Iteration 400 L -5.36909103 loss -5.3679924 loss_ordinary 0.452516586 entropy_value 5.82050943 glob_norm 0.373681635\n",
      "Iteration 450 L -5.36173391 loss -5.3618 loss_ordinary 0.461914867 entropy_value 5.82371473 glob_norm 0.358304262\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power -0.0769577 lambd_papr -0.00543828821 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36566544 loss -5.36465836 loss_ordinary 0.45317629 entropy_value 5.81783438 glob_norm 0.404946685\n",
      "Iteration 50 L -5.33923054 loss -5.33787441 loss_ordinary 0.484042406 entropy_value 5.82191658 glob_norm 0.382774591\n",
      "Iteration 100 L -5.36593246 loss -5.37033415 loss_ordinary 0.451229572 entropy_value 5.82156372 glob_norm 0.457556099\n",
      "Iteration 150 L -5.36384153 loss -5.36381245 loss_ordinary 0.454983801 entropy_value 5.81879616 glob_norm 0.527430058\n",
      "Iteration 200 L -5.36540079 loss -5.36448669 loss_ordinary 0.457634658 entropy_value 5.82212162 glob_norm 0.284469604\n",
      "Iteration 250 L -5.36234522 loss -5.36363268 loss_ordinary 0.45510298 entropy_value 5.8187356 glob_norm 0.295230716\n",
      "Iteration 300 L -5.37156963 loss -5.37270546 loss_ordinary 0.449668974 entropy_value 5.82237434 glob_norm 0.363727093\n",
      "Iteration 350 L -5.35862732 loss -5.35777044 loss_ordinary 0.461475939 entropy_value 5.81924629 glob_norm 0.288616747\n",
      "Iteration 400 L -5.34570503 loss -5.34442139 loss_ordinary 0.479949236 entropy_value 5.82437038 glob_norm 0.361524075\n",
      "Iteration 450 L -5.36048937 loss -5.35911655 loss_ordinary 0.460003853 entropy_value 5.81912041 glob_norm 0.377521843\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power -0.0111308098 lambd_papr -0.00460388185 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35898781 loss -5.35935974 loss_ordinary 0.463542163 entropy_value 5.82290173 glob_norm 0.320186555\n",
      "Iteration 50 L -5.38287163 loss -5.38518 loss_ordinary 0.431558818 entropy_value 5.81673861 glob_norm 0.2651622\n",
      "Iteration 100 L -5.36973429 loss -5.3690753 loss_ordinary 0.454953253 entropy_value 5.82402849 glob_norm 0.341469139\n",
      "Iteration 150 L -5.35937405 loss -5.36058712 loss_ordinary 0.461247325 entropy_value 5.82183409 glob_norm 0.290335774\n",
      "Iteration 200 L -5.35869741 loss -5.35909843 loss_ordinary 0.46019882 entropy_value 5.81929731 glob_norm 0.387993425\n",
      "Iteration 250 L -5.38413572 loss -5.38397646 loss_ordinary 0.436527044 entropy_value 5.82050371 glob_norm 0.343524665\n",
      "Iteration 300 L -5.38443518 loss -5.38496351 loss_ordinary 0.431987792 entropy_value 5.81695127 glob_norm 0.268313259\n",
      "Iteration 350 L -5.36048651 loss -5.36435413 loss_ordinary 0.45661822 entropy_value 5.82097197 glob_norm 0.388774693\n",
      "Iteration 400 L -5.36038351 loss -5.36257744 loss_ordinary 0.462996334 entropy_value 5.82557392 glob_norm 0.299927592\n",
      "Iteration 450 L -5.35909557 loss -5.35804653 loss_ordinary 0.465046406 entropy_value 5.82309294 glob_norm 0.369542807\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power -0.201051235 lambd_papr -0.00448283507 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36586666 loss -5.36714458 loss_ordinary 0.455308527 entropy_value 5.8224535 glob_norm 0.367246807\n",
      "Iteration 50 L -5.39089632 loss -5.39076471 loss_ordinary 0.431307286 entropy_value 5.82207203 glob_norm 0.390558958\n",
      "Iteration 100 L -5.37566 loss -5.37755728 loss_ordinary 0.444141418 entropy_value 5.82169867 glob_norm 0.326388419\n",
      "Iteration 150 L -5.36283207 loss -5.3626976 loss_ordinary 0.460206896 entropy_value 5.82290459 glob_norm 0.364898324\n",
      "Iteration 200 L -5.3718338 loss -5.37422228 loss_ordinary 0.44866854 entropy_value 5.82289076 glob_norm 0.341342777\n",
      "Iteration 250 L -5.36762381 loss -5.36915112 loss_ordinary 0.454134643 entropy_value 5.82328558 glob_norm 0.37133047\n",
      "Iteration 300 L -5.37939119 loss -5.38021517 loss_ordinary 0.444001555 entropy_value 5.82421637 glob_norm 0.312524408\n",
      "Iteration 350 L -5.3496356 loss -5.34929 loss_ordinary 0.476688445 entropy_value 5.82597828 glob_norm 0.36798954\n",
      "Iteration 400 L -5.35872936 loss -5.36042833 loss_ordinary 0.459802836 entropy_value 5.82023144 glob_norm 0.371452868\n",
      "Iteration 450 L -5.35353279 loss -5.35344648 loss_ordinary 0.469301164 entropy_value 5.82274771 glob_norm 0.303945303\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0.269849539 lambd_papr -0.00228985795 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34858799 loss -5.34808064 loss_ordinary 0.472623706 entropy_value 5.82070446 glob_norm 0.397727311\n",
      "Iteration 50 L -5.37949228 loss -5.37856627 loss_ordinary 0.445535243 entropy_value 5.82410145 glob_norm 0.350035161\n",
      "Iteration 100 L -5.38137627 loss -5.38159895 loss_ordinary 0.441857398 entropy_value 5.82345629 glob_norm 0.289701909\n",
      "Iteration 150 L -5.35582829 loss -5.35603046 loss_ordinary 0.466081023 entropy_value 5.82211161 glob_norm 0.376881838\n",
      "Iteration 200 L -5.38087177 loss -5.38256264 loss_ordinary 0.440431476 entropy_value 5.82299423 glob_norm 0.339419454\n",
      "Iteration 250 L -5.3959775 loss -5.3987937 loss_ordinary 0.424301416 entropy_value 5.82309532 glob_norm 0.336403728\n",
      "Iteration 300 L -5.35806561 loss -5.36160564 loss_ordinary 0.46017912 entropy_value 5.8217845 glob_norm 0.395029128\n",
      "Iteration 350 L -5.37637 loss -5.37874508 loss_ordinary 0.444347233 entropy_value 5.82309246 glob_norm 0.307395875\n",
      "Iteration 400 L -5.3625946 loss -5.36472654 loss_ordinary 0.459218055 entropy_value 5.82394457 glob_norm 0.355053157\n",
      "Iteration 450 L -5.36707544 loss -5.36599731 loss_ordinary 0.455114722 entropy_value 5.82111168 glob_norm 0.37327233\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power -0.0841448307 lambd_papr -0.00524208648 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36968851 loss -5.37048 loss_ordinary 0.448840827 entropy_value 5.81932116 glob_norm 0.381991416\n",
      "Iteration 50 L -5.38083649 loss -5.38073397 loss_ordinary 0.441141844 entropy_value 5.82187557 glob_norm 0.287033945\n",
      "Iteration 100 L -5.36449432 loss -5.36540365 loss_ordinary 0.457811266 entropy_value 5.82321501 glob_norm 0.358086526\n",
      "Iteration 150 L -5.35329914 loss -5.35258341 loss_ordinary 0.469352514 entropy_value 5.82193613 glob_norm 0.427491397\n",
      "Iteration 200 L -5.36447334 loss -5.3675828 loss_ordinary 0.455665886 entropy_value 5.82324839 glob_norm 0.273046732\n",
      "Iteration 250 L -5.37022 loss -5.37166786 loss_ordinary 0.450451016 entropy_value 5.82211876 glob_norm 0.385496646\n",
      "Iteration 300 L -5.3589406 loss -5.36279869 loss_ordinary 0.461260229 entropy_value 5.82405901 glob_norm 0.397878557\n",
      "Iteration 350 L -5.35812 loss -5.36031961 loss_ordinary 0.462875396 entropy_value 5.82319498 glob_norm 0.26281637\n",
      "Iteration 400 L -5.35238934 loss -5.35132933 loss_ordinary 0.470280588 entropy_value 5.82161 glob_norm 0.406236529\n",
      "Iteration 450 L -5.34458637 loss -5.34646225 loss_ordinary 0.475598156 entropy_value 5.82206059 glob_norm 0.383838952\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0.113259077 lambd_papr -0.00431875698 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3792491 loss -5.37834024 loss_ordinary 0.446143061 entropy_value 5.82448339 glob_norm 0.455540478\n",
      "Iteration 50 L -5.36339235 loss -5.36194515 loss_ordinary 0.455952406 entropy_value 5.8178978 glob_norm 0.554429591\n",
      "Iteration 100 L -5.34580421 loss -5.34599304 loss_ordinary 0.47735703 entropy_value 5.82335043 glob_norm 0.451910943\n",
      "Iteration 150 L -5.36077595 loss -5.361413 loss_ordinary 0.459970981 entropy_value 5.82138443 glob_norm 0.425113171\n",
      "Iteration 200 L -5.36118603 loss -5.36060333 loss_ordinary 0.461799115 entropy_value 5.82240248 glob_norm 0.385723591\n",
      "Iteration 250 L -5.36088371 loss -5.36125 loss_ordinary 0.461695939 entropy_value 5.82294607 glob_norm 0.350846589\n",
      "Iteration 300 L -5.37029457 loss -5.37056 loss_ordinary 0.449851602 entropy_value 5.82041168 glob_norm 0.273937643\n",
      "Iteration 350 L -5.38378143 loss -5.38316441 loss_ordinary 0.441022247 entropy_value 5.8241868 glob_norm 0.339969814\n",
      "Iteration 400 L -5.35605526 loss -5.35451937 loss_ordinary 0.468272895 entropy_value 5.82279253 glob_norm 0.347809225\n",
      "Iteration 450 L -5.35797167 loss -5.36061335 loss_ordinary 0.458256751 entropy_value 5.81887 glob_norm 0.332758665\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0.352455378 lambd_papr -0.00556528848 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35331869 loss -5.35236597 loss_ordinary 0.473555386 entropy_value 5.82592106 glob_norm 0.350128\n",
      "Iteration 50 L -5.36541748 loss -5.36321926 loss_ordinary 0.460715383 entropy_value 5.82393456 glob_norm 0.361827672\n",
      "Iteration 100 L -5.39424467 loss -5.39504337 loss_ordinary 0.428978354 entropy_value 5.82402182 glob_norm 0.285869867\n",
      "Iteration 150 L -5.38191319 loss -5.37936354 loss_ordinary 0.443347454 entropy_value 5.82271147 glob_norm 0.338118345\n",
      "Iteration 200 L -5.34471321 loss -5.3416152 loss_ordinary 0.484115928 entropy_value 5.82573128 glob_norm 0.392918706\n",
      "Iteration 250 L -5.36948347 loss -5.36901712 loss_ordinary 0.454804718 entropy_value 5.82382154 glob_norm 0.270826131\n",
      "Iteration 300 L -5.35887289 loss -5.35402346 loss_ordinary 0.470685 entropy_value 5.82470846 glob_norm 0.362670273\n",
      "Iteration 350 L -5.3451643 loss -5.34459496 loss_ordinary 0.478096962 entropy_value 5.82269192 glob_norm 0.403740376\n",
      "Iteration 400 L -5.3570509 loss -5.3619194 loss_ordinary 0.46541363 entropy_value 5.82733297 glob_norm 0.407437414\n",
      "Iteration 450 L -5.3609252 loss -5.36268377 loss_ordinary 0.462412685 entropy_value 5.82509613 glob_norm 0.400179923\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power -0.477327108 lambd_papr -0.00945605524 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.367558 loss -5.36710358 loss_ordinary 0.457422882 entropy_value 5.82452679 glob_norm 0.299587488\n",
      "Iteration 50 L -5.39331245 loss -5.39402151 loss_ordinary 0.428514451 entropy_value 5.82253599 glob_norm 0.272265702\n",
      "Iteration 100 L -5.38828278 loss -5.38715506 loss_ordinary 0.436745048 entropy_value 5.8239 glob_norm 0.421062768\n",
      "Iteration 150 L -5.36897516 loss -5.36939812 loss_ordinary 0.45395577 entropy_value 5.82335377 glob_norm 0.329978526\n",
      "Iteration 200 L -5.38491869 loss -5.38487291 loss_ordinary 0.437297106 entropy_value 5.82217 glob_norm 0.422135413\n",
      "Iteration 250 L -5.39870119 loss -5.40082359 loss_ordinary 0.422733 entropy_value 5.8235569 glob_norm 0.461892307\n",
      "Iteration 300 L -5.39183855 loss -5.39190197 loss_ordinary 0.432879984 entropy_value 5.82478189 glob_norm 0.275992751\n",
      "Iteration 350 L -5.34135342 loss -5.34277391 loss_ordinary 0.480572671 entropy_value 5.82334614 glob_norm 0.304131687\n",
      "Iteration 400 L -5.35352516 loss -5.3560853 loss_ordinary 0.469414353 entropy_value 5.82549953 glob_norm 0.298728675\n",
      "Iteration 450 L -5.35261774 loss -5.35169744 loss_ordinary 0.467983752 entropy_value 5.81968117 glob_norm 0.347020745\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0.13489604 lambd_papr -0.00417101709 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39148188 loss -5.39125824 loss_ordinary 0.43065384 entropy_value 5.82191181 glob_norm 0.301956475\n",
      "Iteration 50 L -5.36196041 loss -5.36094189 loss_ordinary 0.463589281 entropy_value 5.82453108 glob_norm 0.390443414\n",
      "Iteration 100 L -5.37161541 loss -5.37398911 loss_ordinary 0.450147 entropy_value 5.82413578 glob_norm 0.358525217\n",
      "Iteration 150 L -5.38762522 loss -5.38962889 loss_ordinary 0.435929835 entropy_value 5.82555866 glob_norm 0.341134697\n",
      "Iteration 200 L -5.37860203 loss -5.37932634 loss_ordinary 0.444719702 entropy_value 5.82404566 glob_norm 0.299662232\n",
      "Iteration 250 L -5.36060047 loss -5.36073256 loss_ordinary 0.466178566 entropy_value 5.82691097 glob_norm 0.307948828\n",
      "Iteration 300 L -5.37422609 loss -5.3732028 loss_ordinary 0.450834751 entropy_value 5.82403755 glob_norm 0.428895026\n",
      "Iteration 350 L -5.34614 loss -5.34418583 loss_ordinary 0.476713628 entropy_value 5.82089949 glob_norm 0.36542815\n",
      "Iteration 400 L -5.35686445 loss -5.35698032 loss_ordinary 0.470252723 entropy_value 5.82723284 glob_norm 0.368860424\n",
      "Iteration 450 L -5.36161327 loss -5.36337709 loss_ordinary 0.458134949 entropy_value 5.82151222 glob_norm 0.307139456\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0.00891280174 lambd_papr -0.00566908717 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37813 loss -5.37601519 loss_ordinary 0.447881341 entropy_value 5.82389641 glob_norm 0.409710467\n",
      "Iteration 50 L -5.37882423 loss -5.37964869 loss_ordinary 0.442065746 entropy_value 5.8217144 glob_norm 0.290708274\n",
      "Iteration 100 L -5.39438391 loss -5.39491892 loss_ordinary 0.428072453 entropy_value 5.82299137 glob_norm 0.265698373\n",
      "Iteration 150 L -5.35903215 loss -5.35745811 loss_ordinary 0.464257479 entropy_value 5.82171583 glob_norm 0.339251846\n",
      "Iteration 200 L -5.35418653 loss -5.35463524 loss_ordinary 0.46445325 entropy_value 5.81908846 glob_norm 0.325981021\n",
      "Iteration 250 L -5.38643169 loss -5.38676453 loss_ordinary 0.438450038 entropy_value 5.82521486 glob_norm 0.448979139\n",
      "Iteration 300 L -5.35691929 loss -5.35529757 loss_ordinary 0.468506068 entropy_value 5.8238039 glob_norm 0.322639495\n",
      "Iteration 350 L -5.35870028 loss -5.3603282 loss_ordinary 0.460417062 entropy_value 5.82074499 glob_norm 0.397980779\n",
      "Iteration 400 L -5.332 loss -5.33271503 loss_ordinary 0.489975303 entropy_value 5.82269 glob_norm 0.472660691\n",
      "Iteration 450 L -5.36978 loss -5.36937809 loss_ordinary 0.459885895 entropy_value 5.82926369 glob_norm 0.307442337\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power 0.0804183483 lambd_papr -0.00576836383 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36375618 loss -5.36374235 loss_ordinary 0.456723064 entropy_value 5.82046509 glob_norm 0.29790014\n",
      "Iteration 50 L -5.36967325 loss -5.36785269 loss_ordinary 0.452759713 entropy_value 5.82061243 glob_norm 0.424979448\n",
      "Iteration 100 L -5.33143616 loss -5.33121967 loss_ordinary 0.489597797 entropy_value 5.82081747 glob_norm 0.438524693\n",
      "Iteration 150 L -5.34850025 loss -5.35039616 loss_ordinary 0.470981747 entropy_value 5.82137823 glob_norm 0.395945907\n",
      "Iteration 200 L -5.36479044 loss -5.36473227 loss_ordinary 0.456653446 entropy_value 5.82138586 glob_norm 0.467422038\n",
      "Iteration 250 L -5.3607378 loss -5.36021566 loss_ordinary 0.464803755 entropy_value 5.82501936 glob_norm 0.423867285\n",
      "Iteration 300 L -5.3599329 loss -5.35910606 loss_ordinary 0.462711573 entropy_value 5.82181787 glob_norm 0.236840636\n",
      "Iteration 350 L -5.35973835 loss -5.35869694 loss_ordinary 0.465161115 entropy_value 5.82385826 glob_norm 0.369028717\n",
      "Iteration 400 L -5.39307404 loss -5.39420414 loss_ordinary 0.430965096 entropy_value 5.82516909 glob_norm 0.358933151\n",
      "Iteration 450 L -5.36986876 loss -5.37097406 loss_ordinary 0.4506751 entropy_value 5.82164907 glob_norm 0.467976809\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power -0.103044271 lambd_papr -0.0066668056 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37853241 loss -5.37867737 loss_ordinary 0.447140098 entropy_value 5.82581711 glob_norm 0.322946757\n",
      "Iteration 50 L -5.36586428 loss -5.36676598 loss_ordinary 0.457140356 entropy_value 5.82390642 glob_norm 0.297548801\n",
      "Iteration 100 L -5.35658073 loss -5.35523796 loss_ordinary 0.4701114 entropy_value 5.82534933 glob_norm 0.31650731\n",
      "Iteration 150 L -5.3500452 loss -5.34960794 loss_ordinary 0.470147192 entropy_value 5.81975508 glob_norm 0.463531613\n",
      "Iteration 200 L -5.37519503 loss -5.37664509 loss_ordinary 0.445226371 entropy_value 5.82187128 glob_norm 0.439618707\n",
      "Iteration 250 L -5.34117603 loss -5.34105253 loss_ordinary 0.482527077 entropy_value 5.82357931 glob_norm 0.300432444\n",
      "Iteration 300 L -5.35453844 loss -5.35654783 loss_ordinary 0.468284249 entropy_value 5.82483196 glob_norm 0.324256927\n",
      "Iteration 350 L -5.38455868 loss -5.38503 loss_ordinary 0.438225389 entropy_value 5.82325554 glob_norm 0.424493492\n",
      "Iteration 400 L -5.34059811 loss -5.33917522 loss_ordinary 0.483847588 entropy_value 5.82302284 glob_norm 0.299219102\n",
      "Iteration 450 L -5.37948465 loss -5.37907648 loss_ordinary 0.440926522 entropy_value 5.82000303 glob_norm 0.374611169\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power -0.236050367 lambd_papr -0.00551213091 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36498451 loss -5.36491442 loss_ordinary 0.455572069 entropy_value 5.82048655 glob_norm 0.29854998\n",
      "Iteration 50 L -5.37587357 loss -5.37733841 loss_ordinary 0.445904493 entropy_value 5.82324314 glob_norm 0.340091199\n",
      "Iteration 100 L -5.38450146 loss -5.38535404 loss_ordinary 0.434515268 entropy_value 5.81986952 glob_norm 0.406884909\n",
      "Iteration 150 L -5.37128067 loss -5.37084723 loss_ordinary 0.455414534 entropy_value 5.82626152 glob_norm 0.340313613\n",
      "Iteration 200 L -5.35892105 loss -5.35839796 loss_ordinary 0.463075668 entropy_value 5.8214736 glob_norm 0.327656835\n",
      "Iteration 250 L -5.3732481 loss -5.37431049 loss_ordinary 0.448461086 entropy_value 5.82277203 glob_norm 0.330172747\n",
      "Iteration 300 L -5.34188271 loss -5.34263945 loss_ordinary 0.481895804 entropy_value 5.82453489 glob_norm 0.357880056\n",
      "Iteration 350 L -5.36245251 loss -5.36256409 loss_ordinary 0.460454464 entropy_value 5.82301855 glob_norm 0.413054556\n",
      "Iteration 400 L -5.36424112 loss -5.36371803 loss_ordinary 0.455878973 entropy_value 5.81959724 glob_norm 0.346472681\n",
      "Iteration 450 L -5.39343548 loss -5.39291286 loss_ordinary 0.425299495 entropy_value 5.81821203 glob_norm 0.269608378\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0.0622479916 lambd_papr -0.00285910582 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38007355 loss -5.38134241 loss_ordinary 0.434158921 entropy_value 5.81550121 glob_norm 0.310634971\n",
      "Iteration 50 L -5.3626914 loss -5.36463118 loss_ordinary 0.459777206 entropy_value 5.82440853 glob_norm 0.297390163\n",
      "Iteration 100 L -5.37417078 loss -5.37530184 loss_ordinary 0.445109576 entropy_value 5.82041168 glob_norm 0.275571942\n",
      "Iteration 150 L -5.34459782 loss -5.34514666 loss_ordinary 0.479039341 entropy_value 5.82418633 glob_norm 0.346491575\n",
      "Iteration 200 L -5.36294031 loss -5.36340189 loss_ordinary 0.458298832 entropy_value 5.82170057 glob_norm 0.298694819\n",
      "Iteration 250 L -5.35524654 loss -5.35677052 loss_ordinary 0.461163163 entropy_value 5.81793356 glob_norm 0.419183731\n",
      "Iteration 300 L -5.37115145 loss -5.37181854 loss_ordinary 0.450813562 entropy_value 5.82263231 glob_norm 0.285038352\n",
      "Iteration 350 L -5.35912561 loss -5.35920429 loss_ordinary 0.467005253 entropy_value 5.82620955 glob_norm 0.300707847\n",
      "Iteration 400 L -5.36019182 loss -5.3605876 loss_ordinary 0.458076209 entropy_value 5.8186636 glob_norm 0.421363384\n",
      "Iteration 450 L -5.36243582 loss -5.3648138 loss_ordinary 0.45956257 entropy_value 5.82437611 glob_norm 0.30345574\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power -0.0141270161 lambd_papr -0.00356082432 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35431671 loss -5.35420513 loss_ordinary 0.464964777 entropy_value 5.81917 glob_norm 0.46881938\n",
      "Iteration 50 L -5.37335873 loss -5.37385368 loss_ordinary 0.446348459 entropy_value 5.82020235 glob_norm 0.277388364\n",
      "Iteration 100 L -5.38169193 loss -5.38195658 loss_ordinary 0.437951356 entropy_value 5.81990814 glob_norm 0.432607651\n",
      "Iteration 150 L -5.38881159 loss -5.39009857 loss_ordinary 0.433795363 entropy_value 5.82389402 glob_norm 0.403859258\n",
      "Iteration 200 L -5.38574076 loss -5.3870821 loss_ordinary 0.432670504 entropy_value 5.81975269 glob_norm 0.39587754\n",
      "Iteration 250 L -5.36499 loss -5.36578083 loss_ordinary 0.455705255 entropy_value 5.821486 glob_norm 0.388848633\n",
      "Iteration 300 L -5.3786726 loss -5.37962151 loss_ordinary 0.441447824 entropy_value 5.82106924 glob_norm 0.325896591\n",
      "Iteration 350 L -5.34641457 loss -5.34927273 loss_ordinary 0.469145447 entropy_value 5.81841803 glob_norm 0.309062153\n",
      "Iteration 400 L -5.38724566 loss -5.38766479 loss_ordinary 0.432133585 entropy_value 5.81979847 glob_norm 0.470332056\n",
      "Iteration 450 L -5.34931946 loss -5.34977484 loss_ordinary 0.474409461 entropy_value 5.82418394 glob_norm 0.495532304\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0.265162706 lambd_papr -0.00340109342 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36735725 loss -5.36693 loss_ordinary 0.454618663 entropy_value 5.82154846 glob_norm 0.283595\n",
      "Iteration 50 L -5.35288525 loss -5.35217667 loss_ordinary 0.470086068 entropy_value 5.82226276 glob_norm 0.327519983\n",
      "Iteration 100 L -5.37733221 loss -5.37855577 loss_ordinary 0.445094377 entropy_value 5.82365036 glob_norm 0.413385183\n",
      "Iteration 150 L -5.37668896 loss -5.37499952 loss_ordinary 0.442401022 entropy_value 5.81740046 glob_norm 0.369788915\n",
      "Iteration 200 L -5.3759675 loss -5.37411976 loss_ordinary 0.446628094 entropy_value 5.82074785 glob_norm 0.349116236\n",
      "Iteration 250 L -5.37452126 loss -5.37508 loss_ordinary 0.449194252 entropy_value 5.82427406 glob_norm 0.458427757\n",
      "Iteration 300 L -5.37126541 loss -5.36886883 loss_ordinary 0.452026904 entropy_value 5.82089567 glob_norm 0.362762868\n",
      "Iteration 350 L -5.36821461 loss -5.36802435 loss_ordinary 0.455725729 entropy_value 5.82375 glob_norm 0.382070929\n",
      "Iteration 400 L -5.36009312 loss -5.35923815 loss_ordinary 0.464057505 entropy_value 5.82329512 glob_norm 0.25111419\n",
      "Iteration 450 L -5.36133766 loss -5.36336851 loss_ordinary 0.460048884 entropy_value 5.82341719 glob_norm 0.349292725\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power -0.461530447 lambd_papr -0.00640822202 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36036253 loss -5.36027765 loss_ordinary 0.465501577 entropy_value 5.82577944 glob_norm 0.311193079\n",
      "Iteration 50 L -5.39522696 loss -5.39618063 loss_ordinary 0.423647612 entropy_value 5.81982803 glob_norm 0.264562368\n",
      "Iteration 100 L -5.3446703 loss -5.34580898 loss_ordinary 0.477745175 entropy_value 5.82355404 glob_norm 0.426660895\n",
      "Iteration 150 L -5.35117865 loss -5.35165739 loss_ordinary 0.470385969 entropy_value 5.82204342 glob_norm 0.301100582\n",
      "Iteration 200 L -5.3516283 loss -5.35301781 loss_ordinary 0.469588488 entropy_value 5.82260609 glob_norm 0.319479555\n",
      "Iteration 250 L -5.34690809 loss -5.34682322 loss_ordinary 0.475855619 entropy_value 5.82267904 glob_norm 0.296494097\n",
      "Iteration 300 L -5.36596203 loss -5.3670125 loss_ordinary 0.454777747 entropy_value 5.82179 glob_norm 0.330959499\n",
      "Iteration 350 L -5.36401701 loss -5.3659935 loss_ordinary 0.450771868 entropy_value 5.81676531 glob_norm 0.305064499\n",
      "Iteration 400 L -5.3553772 loss -5.35660172 loss_ordinary 0.462964207 entropy_value 5.81956625 glob_norm 0.32415995\n",
      "Iteration 450 L -5.36686802 loss -5.36797142 loss_ordinary 0.453931123 entropy_value 5.82190228 glob_norm 0.41340211\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0.0322263241 lambd_papr -0.00115844561 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35928392 loss -5.3605094 loss_ordinary 0.458233446 entropy_value 5.81874275 glob_norm 0.359507948\n",
      "Iteration 50 L -5.35034466 loss -5.35054398 loss_ordinary 0.469529063 entropy_value 5.82007313 glob_norm 0.295826346\n",
      "Iteration 100 L -5.35326719 loss -5.35313654 loss_ordinary 0.469780505 entropy_value 5.82291698 glob_norm 0.393103838\n",
      "Iteration 150 L -5.36205244 loss -5.36224413 loss_ordinary 0.455586135 entropy_value 5.81783056 glob_norm 0.258060247\n",
      "Iteration 200 L -5.37232351 loss -5.37229824 loss_ordinary 0.447087049 entropy_value 5.81938505 glob_norm 0.262241334\n",
      "Iteration 250 L -5.37478399 loss -5.37543583 loss_ordinary 0.445354968 entropy_value 5.82079077 glob_norm 0.398479611\n",
      "Iteration 300 L -5.35844326 loss -5.35829639 loss_ordinary 0.462360054 entropy_value 5.8206563 glob_norm 0.31423828\n",
      "Iteration 350 L -5.40240812 loss -5.40373611 loss_ordinary 0.416930109 entropy_value 5.82066584 glob_norm 0.297085315\n",
      "Iteration 400 L -5.35469437 loss -5.35524511 loss_ordinary 0.463547617 entropy_value 5.81879282 glob_norm 0.360593766\n",
      "Iteration 450 L -5.3625865 loss -5.36447096 loss_ordinary 0.456390828 entropy_value 5.82086134 glob_norm 0.337090939\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power -0.00959992409 lambd_papr -0.00152611057 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37160349 loss -5.37232542 loss_ordinary 0.452201188 entropy_value 5.82452679 glob_norm 0.368909836\n",
      "Iteration 50 L -5.35604954 loss -5.3566165 loss_ordinary 0.464676827 entropy_value 5.82129335 glob_norm 0.277523369\n",
      "Iteration 100 L -5.35433722 loss -5.3542552 loss_ordinary 0.463137269 entropy_value 5.81739235 glob_norm 0.34929958\n",
      "Iteration 150 L -5.38757324 loss -5.38769579 loss_ordinary 0.432772696 entropy_value 5.82046843 glob_norm 0.290359825\n",
      "Iteration 200 L -5.39088583 loss -5.39156 loss_ordinary 0.428469688 entropy_value 5.82002974 glob_norm 0.344165981\n",
      "Iteration 250 L -5.38903904 loss -5.38891363 loss_ordinary 0.433788657 entropy_value 5.82270241 glob_norm 0.423960567\n",
      "Iteration 300 L -5.40460205 loss -5.40508556 loss_ordinary 0.413452268 entropy_value 5.81853771 glob_norm 0.363602906\n",
      "Iteration 350 L -5.38176966 loss -5.38202429 loss_ordinary 0.434754819 entropy_value 5.81677914 glob_norm 0.375154108\n",
      "Iteration 400 L -5.34981918 loss -5.35004425 loss_ordinary 0.469763368 entropy_value 5.81980753 glob_norm 0.398857683\n",
      "Iteration 450 L -5.36795664 loss -5.36800861 loss_ordinary 0.451928794 entropy_value 5.81993771 glob_norm 0.410509259\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power 0.0966618061 lambd_papr -0.00141625805 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37972403 loss -5.37933969 loss_ordinary 0.442394882 entropy_value 5.82173443 glob_norm 0.262445658\n",
      "Iteration 50 L -5.38064909 loss -5.38125134 loss_ordinary 0.442167819 entropy_value 5.82341909 glob_norm 0.350548029\n",
      "Iteration 100 L -5.38605785 loss -5.38798857 loss_ordinary 0.429928601 entropy_value 5.81791687 glob_norm 0.300801098\n",
      "Iteration 150 L -5.35994911 loss -5.36024523 loss_ordinary 0.460684389 entropy_value 5.82092953 glob_norm 0.270676792\n",
      "Iteration 200 L -5.36832571 loss -5.37063885 loss_ordinary 0.451383591 entropy_value 5.82202244 glob_norm 0.331228554\n",
      "Iteration 250 L -5.36803389 loss -5.36881351 loss_ordinary 0.449567258 entropy_value 5.81838083 glob_norm 0.292029023\n",
      "Iteration 300 L -5.38080549 loss -5.38400316 loss_ordinary 0.437803596 entropy_value 5.82180643 glob_norm 0.286557\n",
      "Iteration 350 L -5.37498426 loss -5.37492752 loss_ordinary 0.448519856 entropy_value 5.82344723 glob_norm 0.390237749\n",
      "Iteration 400 L -5.34361315 loss -5.34548759 loss_ordinary 0.472833782 entropy_value 5.8183217 glob_norm 0.227696493\n",
      "Iteration 450 L -5.36668921 loss -5.36668396 loss_ordinary 0.456340313 entropy_value 5.82302427 glob_norm 0.27311042\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0.137813568 lambd_papr -0.00252568373 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38789558 loss -5.38995 loss_ordinary 0.429565102 entropy_value 5.81951523 glob_norm 0.264769346\n",
      "Iteration 50 L -5.36297655 loss -5.36388683 loss_ordinary 0.459898084 entropy_value 5.82378531 glob_norm 0.329762816\n",
      "Iteration 100 L -5.36403608 loss -5.36452627 loss_ordinary 0.457770467 entropy_value 5.82229662 glob_norm 0.447783619\n",
      "Iteration 150 L -5.35320568 loss -5.35270691 loss_ordinary 0.467782795 entropy_value 5.82049 glob_norm 0.424379617\n",
      "Iteration 200 L -5.34730673 loss -5.34735632 loss_ordinary 0.471604288 entropy_value 5.81896067 glob_norm 0.394606531\n",
      "Iteration 250 L -5.35865927 loss -5.3579855 loss_ordinary 0.46533516 entropy_value 5.82332087 glob_norm 0.331702858\n",
      "Iteration 300 L -5.36611271 loss -5.36576366 loss_ordinary 0.45337525 entropy_value 5.819139 glob_norm 0.302511245\n",
      "Iteration 350 L -5.35830402 loss -5.35816526 loss_ordinary 0.462241501 entropy_value 5.82040691 glob_norm 0.293732554\n",
      "Iteration 400 L -5.36245251 loss -5.362113 loss_ordinary 0.460740924 entropy_value 5.82285357 glob_norm 0.507778347\n",
      "Iteration 450 L -5.38210344 loss -5.38417196 loss_ordinary 0.437037319 entropy_value 5.82120943 glob_norm 0.247530758\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power -0.0728802681 lambd_papr -0.00411216961 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39742661 loss -5.39757299 loss_ordinary 0.42381683 entropy_value 5.82138968 glob_norm 0.352148443\n",
      "Iteration 50 L -5.36191416 loss -5.36154795 loss_ordinary 0.458015025 entropy_value 5.81956244 glob_norm 0.573800743\n",
      "Iteration 100 L -5.38897038 loss -5.39107752 loss_ordinary 0.428578824 entropy_value 5.81965637 glob_norm 0.48877421\n",
      "Iteration 150 L -5.35774708 loss -5.35837889 loss_ordinary 0.460034847 entropy_value 5.81841373 glob_norm 0.395641387\n",
      "Iteration 200 L -5.36982489 loss -5.3710537 loss_ordinary 0.454843551 entropy_value 5.82589722 glob_norm 0.292135\n",
      "Iteration 250 L -5.34869432 loss -5.34975195 loss_ordinary 0.475460142 entropy_value 5.825212 glob_norm 0.342651248\n",
      "Iteration 300 L -5.37132645 loss -5.37066031 loss_ordinary 0.449502021 entropy_value 5.8201623 glob_norm 0.373336285\n",
      "Iteration 350 L -5.37201595 loss -5.37256336 loss_ordinary 0.45162335 entropy_value 5.8241868 glob_norm 0.318581581\n",
      "Iteration 400 L -5.37263632 loss -5.37269735 loss_ordinary 0.448326528 entropy_value 5.82102394 glob_norm 0.2520051\n",
      "Iteration 450 L -5.37199783 loss -5.3723979 loss_ordinary 0.445517957 entropy_value 5.81791592 glob_norm 0.31667158\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0.136029959 lambd_papr -0.00327066751 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_17_papr_7.0\n",
      "\n",
      "===== Running SNR=17 dB | PAPR=8.0 dB =====\n",
      "\n",
      "Iteration 0 L 0.0199953914 loss 0.0199953914 loss_ordinary 6.01117897 entropy_value 5.99118328 glob_norm 0.639375865\n",
      "Iteration 50 L -3.42684793 loss -3.42684793 loss_ordinary 2.54688048 entropy_value 5.97372866 glob_norm 0.434210151\n",
      "Iteration 100 L -4.33166695 loss -4.33166695 loss_ordinary 1.63107383 entropy_value 5.9627409 glob_norm 0.395339876\n",
      "Iteration 150 L -4.79426289 loss -4.79426289 loss_ordinary 1.1159544 entropy_value 5.91021729 glob_norm 0.317187339\n",
      "Iteration 200 L -5.11155844 loss -5.11155844 loss_ordinary 0.735228717 entropy_value 5.84678698 glob_norm 0.384643227\n",
      "Iteration 250 L -5.24893761 loss -5.24893761 loss_ordinary 0.579416037 entropy_value 5.82835388 glob_norm 0.528433144\n",
      "Iteration 300 L -5.29262352 loss -5.29262352 loss_ordinary 0.531828165 entropy_value 5.82445192 glob_norm 0.346785\n",
      "Iteration 350 L -5.31862926 loss -5.31862926 loss_ordinary 0.505750299 entropy_value 5.82437944 glob_norm 0.413743734\n",
      "Iteration 400 L -5.35776329 loss -5.35776329 loss_ordinary 0.466254503 entropy_value 5.82401752 glob_norm 0.397720605\n",
      "Iteration 450 L -5.34024191 loss -5.34024191 loss_ordinary 0.477538973 entropy_value 5.81778097 glob_norm 0.295579225\n",
      "Iteration 500 L -5.37695503 loss -5.37695503 loss_ordinary 0.448499888 entropy_value 5.82545471 glob_norm 0.42133975\n",
      "Iteration 550 L -5.37099 loss -5.37099 loss_ordinary 0.44816649 entropy_value 5.81915617 glob_norm 0.351324767\n",
      "Iteration 600 L -5.35877132 loss -5.35877132 loss_ordinary 0.464976758 entropy_value 5.82374811 glob_norm 0.339090705\n",
      "Iteration 650 L -5.32518244 loss -5.32518244 loss_ordinary 0.493960857 entropy_value 5.81914377 glob_norm 0.480022311\n",
      "Iteration 700 L -5.36373425 loss -5.36373425 loss_ordinary 0.459424645 entropy_value 5.82315922 glob_norm 0.328347921\n",
      "Iteration 750 L -5.37614298 loss -5.37614298 loss_ordinary 0.447834522 entropy_value 5.82397795 glob_norm 0.424353749\n",
      "Iteration 800 L -5.36173439 loss -5.36173439 loss_ordinary 0.451907665 entropy_value 5.8136425 glob_norm 0.463161469\n",
      "Iteration 850 L -5.33881807 loss -5.33881807 loss_ordinary 0.481713027 entropy_value 5.82053137 glob_norm 0.497615725\n",
      "Iteration 900 L -5.36895657 loss -5.36895657 loss_ordinary 0.448501199 entropy_value 5.81745768 glob_norm 0.347398549\n",
      "Iteration 950 L -5.35081339 loss -5.35081339 loss_ordinary 0.468931854 entropy_value 5.81974554 glob_norm 0.350303084\n",
      "Iteration 1000 L -5.39682579 loss -5.39682579 loss_ordinary 0.420729548 entropy_value 5.81755543 glob_norm 0.333395213\n",
      "Iteration 1050 L -5.37395096 loss -5.37395096 loss_ordinary 0.445076257 entropy_value 5.81902742 glob_norm 0.493332446\n",
      "Iteration 1100 L -5.38699198 loss -5.38699198 loss_ordinary 0.433130145 entropy_value 5.82012177 glob_norm 0.32436502\n",
      "Iteration 1150 L -5.36089277 loss -5.36089277 loss_ordinary 0.457820088 entropy_value 5.81871319 glob_norm 0.406993121\n",
      "Iteration 1200 L -5.35153103 loss -5.35153103 loss_ordinary 0.469568491 entropy_value 5.82109928 glob_norm 0.328410208\n",
      "Iteration 1250 L -5.37828684 loss -5.37828684 loss_ordinary 0.438046724 entropy_value 5.81633329 glob_norm 0.356258661\n",
      "Iteration 1300 L -5.38324976 loss -5.38324976 loss_ordinary 0.432167381 entropy_value 5.81541729 glob_norm 0.393373549\n",
      "Iteration 1350 L -5.36565065 loss -5.36565065 loss_ordinary 0.449709892 entropy_value 5.81536055 glob_norm 0.335656404\n",
      "Iteration 1400 L -5.36812258 loss -5.36812258 loss_ordinary 0.448363543 entropy_value 5.81648636 glob_norm 0.370264739\n",
      "Iteration 1450 L -5.37130165 loss -5.37130165 loss_ordinary 0.445958316 entropy_value 5.81726027 glob_norm 0.335556924\n",
      "Iteration 1500 L -5.38267422 loss -5.38267422 loss_ordinary 0.440452516 entropy_value 5.82312679 glob_norm 0.485372156\n",
      "Iteration 1550 L -5.39369488 loss -5.39369488 loss_ordinary 0.424558073 entropy_value 5.81825256 glob_norm 0.364745736\n",
      "Iteration 1600 L -5.41394472 loss -5.41394472 loss_ordinary 0.403742641 entropy_value 5.81768751 glob_norm 0.352889389\n",
      "Iteration 1650 L -5.37142277 loss -5.37142277 loss_ordinary 0.44544524 entropy_value 5.81686783 glob_norm 0.352776647\n",
      "Iteration 1700 L -5.36667776 loss -5.36667776 loss_ordinary 0.448135108 entropy_value 5.81481314 glob_norm 0.355040371\n",
      "Iteration 1750 L -5.34762287 loss -5.34762287 loss_ordinary 0.468596816 entropy_value 5.81622 glob_norm 0.362409413\n",
      "Iteration 1800 L -5.36987877 loss -5.36987877 loss_ordinary 0.443732172 entropy_value 5.81361055 glob_norm 0.369865984\n",
      "Iteration 1850 L -5.34369469 loss -5.34369469 loss_ordinary 0.475780785 entropy_value 5.81947517 glob_norm 0.406706691\n",
      "Iteration 1900 L -5.37449169 loss -5.37449169 loss_ordinary 0.444042951 entropy_value 5.81853485 glob_norm 0.39596343\n",
      "Iteration 1950 L -5.35842562 loss -5.35842562 loss_ordinary 0.455306 entropy_value 5.81373167 glob_norm 0.42705816\n",
      "Iteration 2000 L -5.36663389 loss -5.36663389 loss_ordinary 0.452447921 entropy_value 5.81908178 glob_norm 0.581921101\n",
      "Iteration 2050 L -5.37426424 loss -5.37426424 loss_ordinary 0.44082284 entropy_value 5.81508684 glob_norm 0.409310132\n",
      "Iteration 2100 L -5.36026382 loss -5.36026382 loss_ordinary 0.455179125 entropy_value 5.81544352 glob_norm 0.394945145\n",
      "Iteration 2150 L -5.37190819 loss -5.37190819 loss_ordinary 0.441906 entropy_value 5.81381416 glob_norm 0.359899163\n",
      "Iteration 2200 L -5.34817743 loss -5.34817743 loss_ordinary 0.463040441 entropy_value 5.81121778 glob_norm 0.353127271\n",
      "Iteration 2250 L -5.35990858 loss -5.35990858 loss_ordinary 0.457129836 entropy_value 5.81703854 glob_norm 0.48937735\n",
      "Iteration 2300 L -5.35737371 loss -5.35737371 loss_ordinary 0.459149659 entropy_value 5.81652355 glob_norm 0.353217095\n",
      "Iteration 2350 L -5.3867178 loss -5.3867178 loss_ordinary 0.427315861 entropy_value 5.81403351 glob_norm 0.35509482\n",
      "Iteration 2400 L -5.39350843 loss -5.39350843 loss_ordinary 0.421634972 entropy_value 5.81514359 glob_norm 0.302543849\n",
      "Iteration 2450 L -5.36235094 loss -5.36235094 loss_ordinary 0.450998366 entropy_value 5.81334925 glob_norm 0.337202668\n",
      "Iteration 2500 L -5.35737085 loss -5.35737085 loss_ordinary 0.459992975 entropy_value 5.81736422 glob_norm 0.3564426\n",
      "Iteration 2550 L -5.39312696 loss -5.39312696 loss_ordinary 0.41863063 entropy_value 5.81175756 glob_norm 0.330169737\n",
      "Iteration 2600 L -5.37497091 loss -5.37497091 loss_ordinary 0.436696887 entropy_value 5.81166792 glob_norm 0.31836468\n",
      "Iteration 2650 L -5.36459351 loss -5.36459351 loss_ordinary 0.45070526 entropy_value 5.81529903 glob_norm 0.346554607\n",
      "Iteration 2700 L -5.37853956 loss -5.37853956 loss_ordinary 0.43765229 entropy_value 5.81619167 glob_norm 0.297993124\n",
      "Iteration 2750 L -5.36371231 loss -5.36371231 loss_ordinary 0.455227911 entropy_value 5.81894 glob_norm 0.472627521\n",
      "Iteration 2800 L -5.38358355 loss -5.38358355 loss_ordinary 0.433040321 entropy_value 5.81662369 glob_norm 0.477106452\n",
      "Iteration 2850 L -5.35612392 loss -5.35612392 loss_ordinary 0.461037755 entropy_value 5.81716156 glob_norm 0.352724075\n",
      "Iteration 2900 L -5.37573147 loss -5.37573147 loss_ordinary 0.439479381 entropy_value 5.81521082 glob_norm 0.431049615\n",
      "Iteration 2950 L -5.38561487 loss -5.38561487 loss_ordinary 0.426807702 entropy_value 5.81242275 glob_norm 0.455628306\n",
      "Iteration 3000 L -5.37137556 loss -5.37137556 loss_ordinary 0.444493502 entropy_value 5.81586933 glob_norm 0.382792085\n",
      "Iteration 3050 L -5.3552165 loss -5.3552165 loss_ordinary 0.461044967 entropy_value 5.81626129 glob_norm 0.408153057\n",
      "Iteration 3100 L -5.37368 loss -5.37368 loss_ordinary 0.442749768 entropy_value 5.81642962 glob_norm 0.420058519\n",
      "Iteration 3150 L -5.36865807 loss -5.36865807 loss_ordinary 0.445480675 entropy_value 5.81413889 glob_norm 0.374833822\n",
      "Iteration 3200 L -5.35667801 loss -5.35667801 loss_ordinary 0.460334867 entropy_value 5.81701326 glob_norm 0.499748707\n",
      "Iteration 3250 L -5.34276676 loss -5.34276676 loss_ordinary 0.466262281 entropy_value 5.8090291 glob_norm 0.366315\n",
      "Iteration 3300 L -5.36974335 loss -5.36974335 loss_ordinary 0.441850156 entropy_value 5.81159353 glob_norm 0.408720613\n",
      "Iteration 3350 L -5.35146284 loss -5.35146284 loss_ordinary 0.460721314 entropy_value 5.81218386 glob_norm 0.325352907\n",
      "Iteration 3400 L -5.3738842 loss -5.3738842 loss_ordinary 0.439191043 entropy_value 5.81307554 glob_norm 0.381268591\n",
      "Iteration 3450 L -5.3815608 loss -5.3815608 loss_ordinary 0.433593333 entropy_value 5.81515455 glob_norm 0.358836889\n",
      "Iteration 3500 L -5.3660264 loss -5.3660264 loss_ordinary 0.448010772 entropy_value 5.81403732 glob_norm 0.367546052\n",
      "Iteration 3550 L -5.35293484 loss -5.35293484 loss_ordinary 0.459645391 entropy_value 5.81258 glob_norm 0.305636\n",
      "Iteration 3600 L -5.37325478 loss -5.37325478 loss_ordinary 0.443552107 entropy_value 5.81680679 glob_norm 0.337491781\n",
      "Iteration 3650 L -5.37171555 loss -5.37171555 loss_ordinary 0.447647393 entropy_value 5.81936312 glob_norm 0.329181045\n",
      "Iteration 3700 L -5.36540127 loss -5.36540127 loss_ordinary 0.449358195 entropy_value 5.81475925 glob_norm 0.300558269\n",
      "Iteration 3750 L -5.37360096 loss -5.37360096 loss_ordinary 0.439504117 entropy_value 5.81310511 glob_norm 0.422273278\n",
      "Iteration 3800 L -5.37846804 loss -5.37846804 loss_ordinary 0.435599387 entropy_value 5.81406736 glob_norm 0.330889463\n",
      "Iteration 3850 L -5.36483765 loss -5.36483765 loss_ordinary 0.446778 entropy_value 5.81161547 glob_norm 0.426561654\n",
      "Iteration 3900 L -5.34313679 loss -5.34313679 loss_ordinary 0.467517167 entropy_value 5.81065369 glob_norm 0.352011293\n",
      "Iteration 3950 L -5.36688 loss -5.36688 loss_ordinary 0.447452515 entropy_value 5.81433249 glob_norm 0.367487818\n",
      "Iteration 4000 L -5.37754679 loss -5.37754679 loss_ordinary 0.434411138 entropy_value 5.81195736 glob_norm 0.397719294\n",
      "Iteration 4050 L -5.35881376 loss -5.35881376 loss_ordinary 0.453123063 entropy_value 5.81193686 glob_norm 0.775645435\n",
      "Iteration 4100 L -5.36210918 loss -5.36210918 loss_ordinary 0.452093035 entropy_value 5.81420231 glob_norm 0.529224455\n",
      "Iteration 4150 L -5.37001801 loss -5.37001801 loss_ordinary 0.442611963 entropy_value 5.8126297 glob_norm 0.408690661\n",
      "Iteration 4200 L -5.34101725 loss -5.34101725 loss_ordinary 0.47222212 entropy_value 5.8132391 glob_norm 0.4140113\n",
      "Iteration 4250 L -5.36742878 loss -5.36742878 loss_ordinary 0.448301971 entropy_value 5.81573105 glob_norm 0.277317017\n",
      "Iteration 4300 L -5.37969685 loss -5.37969685 loss_ordinary 0.436616033 entropy_value 5.81631279 glob_norm 0.355390757\n",
      "Iteration 4350 L -5.37964392 loss -5.37964392 loss_ordinary 0.431261569 entropy_value 5.81090593 glob_norm 0.558353364\n",
      "Iteration 4400 L -5.35700369 loss -5.35700369 loss_ordinary 0.457907408 entropy_value 5.81491089 glob_norm 0.43797332\n",
      "Iteration 4450 L -5.3532095 loss -5.3532095 loss_ordinary 0.461754739 entropy_value 5.81496429 glob_norm 0.36616087\n",
      "Iteration 4500 L -5.36831903 loss -5.36831903 loss_ordinary 0.443277508 entropy_value 5.81159639 glob_norm 0.427316934\n",
      "Iteration 4550 L -5.37943411 loss -5.37943411 loss_ordinary 0.432206154 entropy_value 5.81164026 glob_norm 0.333496749\n",
      "Iteration 4600 L -5.39557 loss -5.39557 loss_ordinary 0.417503 entropy_value 5.81307268 glob_norm 0.380605489\n",
      "Iteration 4650 L -5.35887098 loss -5.35887098 loss_ordinary 0.45452857 entropy_value 5.81339931 glob_norm 0.410372049\n",
      "Iteration 4700 L -5.37626123 loss -5.37626123 loss_ordinary 0.439074725 entropy_value 5.81533575 glob_norm 0.420136154\n",
      "Iteration 4750 L -5.39725113 loss -5.39725113 loss_ordinary 0.420140713 entropy_value 5.8173914 glob_norm 0.30966875\n",
      "Iteration 4800 L -5.36839676 loss -5.36839676 loss_ordinary 0.441080809 entropy_value 5.80947733 glob_norm 0.415998727\n",
      "Iteration 4850 L -5.35755301 loss -5.35755301 loss_ordinary 0.457422584 entropy_value 5.81497526 glob_norm 0.489430338\n",
      "Iteration 4900 L -5.36794424 loss -5.36794424 loss_ordinary 0.4424496 entropy_value 5.81039381 glob_norm 0.443771362\n",
      "Iteration 4950 L -5.36413765 loss -5.36413765 loss_ordinary 0.448248655 entropy_value 5.81238604 glob_norm 0.362745881\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  0  %  c_excess_power 0 lambd_papr 0 mu 0.01\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36152792 loss -5.36152792 loss_ordinary 0.45180741 entropy_value 5.81333542 glob_norm 0.351788253\n",
      "Iteration 50 L -5.36969614 loss -5.36969614 loss_ordinary 0.449459016 entropy_value 5.81915522 glob_norm 0.329550952\n",
      "Iteration 100 L -5.37012863 loss -5.37012863 loss_ordinary 0.441358268 entropy_value 5.8114872 glob_norm 0.308027625\n",
      "Iteration 150 L -5.35700417 loss -5.35700417 loss_ordinary 0.454661727 entropy_value 5.81166601 glob_norm 0.368667185\n",
      "Iteration 200 L -5.34548903 loss -5.34548903 loss_ordinary 0.469899416 entropy_value 5.8153882 glob_norm 0.404808611\n",
      "Iteration 250 L -5.37451649 loss -5.37451649 loss_ordinary 0.439550877 entropy_value 5.81406736 glob_norm 0.466863602\n",
      "Iteration 300 L -5.37184858 loss -5.37184858 loss_ordinary 0.443959445 entropy_value 5.81580782 glob_norm 0.545855701\n",
      "Iteration 350 L -5.36000586 loss -5.36000586 loss_ordinary 0.450823456 entropy_value 5.81082916 glob_norm 0.320644\n",
      "Iteration 400 L -5.34610033 loss -5.34610033 loss_ordinary 0.468857259 entropy_value 5.81495762 glob_norm 0.550149679\n",
      "Iteration 450 L -5.35588646 loss -5.35588646 loss_ordinary 0.460018486 entropy_value 5.81590509 glob_norm 0.310049236\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  1  %  c_excess_power 0 lambd_papr 0 mu 0.01003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34898281 loss -5.34898281 loss_ordinary 0.467442304 entropy_value 5.81642485 glob_norm 0.567221344\n",
      "Iteration 50 L -5.3416481 loss -5.3416481 loss_ordinary 0.470914453 entropy_value 5.81256294 glob_norm 0.485215157\n",
      "Iteration 100 L -5.39028502 loss -5.39028502 loss_ordinary 0.425476819 entropy_value 5.81576157 glob_norm 0.434265703\n",
      "Iteration 150 L -5.36736536 loss -5.36736536 loss_ordinary 0.452505529 entropy_value 5.81987095 glob_norm 0.368347138\n",
      "Iteration 200 L -5.34146786 loss -5.34146786 loss_ordinary 0.475727141 entropy_value 5.81719494 glob_norm 0.340872586\n",
      "Iteration 250 L -5.37498665 loss -5.37498665 loss_ordinary 0.439646244 entropy_value 5.81463289 glob_norm 0.298017055\n",
      "Iteration 300 L -5.34392691 loss -5.34392691 loss_ordinary 0.467026591 entropy_value 5.81095314 glob_norm 0.382114857\n",
      "Iteration 350 L -5.38548803 loss -5.38548803 loss_ordinary 0.429873884 entropy_value 5.81536198 glob_norm 0.372548729\n",
      "Iteration 400 L -5.3668232 loss -5.3668232 loss_ordinary 0.441643 entropy_value 5.80846643 glob_norm 0.390482843\n",
      "Iteration 450 L -5.37910891 loss -5.37910891 loss_ordinary 0.434373051 entropy_value 5.81348181 glob_norm 0.344539911\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  2  %  c_excess_power 0 lambd_papr 0 mu 0.0100600896\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3801918 loss -5.3801918 loss_ordinary 0.433997214 entropy_value 5.81418896 glob_norm 0.346980691\n",
      "Iteration 50 L -5.38199282 loss -5.38199282 loss_ordinary 0.43337369 entropy_value 5.81536627 glob_norm 0.29001683\n",
      "Iteration 100 L -5.37764168 loss -5.37764168 loss_ordinary 0.435935944 entropy_value 5.81357765 glob_norm 0.398530036\n",
      "Iteration 150 L -5.36042404 loss -5.36042404 loss_ordinary 0.454121649 entropy_value 5.81454563 glob_norm 0.409366757\n",
      "Iteration 200 L -5.3768 loss -5.3768 loss_ordinary 0.438846648 entropy_value 5.81564713 glob_norm 0.448048443\n",
      "Iteration 250 L -5.39308071 loss -5.39308071 loss_ordinary 0.426588506 entropy_value 5.81966925 glob_norm 0.420655787\n",
      "Iteration 300 L -5.34412193 loss -5.34412193 loss_ordinary 0.466145784 entropy_value 5.81026793 glob_norm 0.432696193\n",
      "Iteration 350 L -5.3767004 loss -5.3767004 loss_ordinary 0.438243419 entropy_value 5.81494379 glob_norm 0.238719314\n",
      "Iteration 400 L -5.37049627 loss -5.37049627 loss_ordinary 0.44440487 entropy_value 5.81490135 glob_norm 0.380975127\n",
      "Iteration 450 L -5.37591028 loss -5.37591028 loss_ordinary 0.442379624 entropy_value 5.81828976 glob_norm 0.323364377\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  3  %  c_excess_power 0 lambd_papr 0 mu 0.0100902701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.33714485 loss -5.33714485 loss_ordinary 0.475510925 entropy_value 5.81265593 glob_norm 0.312115133\n",
      "Iteration 50 L -5.37070084 loss -5.37070084 loss_ordinary 0.440161169 entropy_value 5.81086159 glob_norm 0.313615561\n",
      "Iteration 100 L -5.35562277 loss -5.35562277 loss_ordinary 0.456331104 entropy_value 5.81195402 glob_norm 0.335011393\n",
      "Iteration 150 L -5.38674355 loss -5.38674355 loss_ordinary 0.423501641 entropy_value 5.81024551 glob_norm 0.491103947\n",
      "Iteration 200 L -5.38304186 loss -5.38304186 loss_ordinary 0.429990858 entropy_value 5.81303263 glob_norm 0.305685252\n",
      "Iteration 250 L -5.3734436 loss -5.3734436 loss_ordinary 0.436925352 entropy_value 5.81036901 glob_norm 0.265505165\n",
      "Iteration 300 L -5.36544847 loss -5.36544847 loss_ordinary 0.452397257 entropy_value 5.81784534 glob_norm 0.334697127\n",
      "Iteration 350 L -5.35771608 loss -5.35771608 loss_ordinary 0.456192374 entropy_value 5.81390858 glob_norm 0.449008554\n",
      "Iteration 400 L -5.35944176 loss -5.35944176 loss_ordinary 0.453689873 entropy_value 5.81313181 glob_norm 0.338771164\n",
      "Iteration 450 L -5.36357546 loss -5.36357546 loss_ordinary 0.450640768 entropy_value 5.81421614 glob_norm 0.32029888\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  4  %  c_excess_power 0 lambd_papr 0 mu 0.0101205409\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36115265 loss -5.36115265 loss_ordinary 0.453617901 entropy_value 5.8147707 glob_norm 0.267130315\n",
      "Iteration 50 L -5.37244606 loss -5.37244606 loss_ordinary 0.443293184 entropy_value 5.81573915 glob_norm 0.295572966\n",
      "Iteration 100 L -5.35246372 loss -5.35246372 loss_ordinary 0.463077039 entropy_value 5.81554079 glob_norm 0.340402037\n",
      "Iteration 150 L -5.35473537 loss -5.35473537 loss_ordinary 0.456974059 entropy_value 5.8117094 glob_norm 0.472960383\n",
      "Iteration 200 L -5.36179161 loss -5.36179161 loss_ordinary 0.452000678 entropy_value 5.81379223 glob_norm 0.380503088\n",
      "Iteration 250 L -5.37751436 loss -5.37751436 loss_ordinary 0.432951838 entropy_value 5.81046629 glob_norm 0.406598657\n",
      "Iteration 300 L -5.37191916 loss -5.37191916 loss_ordinary 0.442810953 entropy_value 5.81472969 glob_norm 0.313879251\n",
      "Iteration 350 L -5.36525583 loss -5.36525583 loss_ordinary 0.451190472 entropy_value 5.8164463 glob_norm 0.367798656\n",
      "Iteration 400 L -5.37257814 loss -5.37257814 loss_ordinary 0.439103425 entropy_value 5.81168175 glob_norm 0.414792627\n",
      "Iteration 450 L -5.38512468 loss -5.38512468 loss_ordinary 0.431969345 entropy_value 5.81709433 glob_norm 0.26031357\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  5  %  c_excess_power 0 lambd_papr 0 mu 0.0101509029\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37640715 loss -5.37640715 loss_ordinary 0.438308269 entropy_value 5.81471539 glob_norm 0.391975731\n",
      "Iteration 50 L -5.35524082 loss -5.35524082 loss_ordinary 0.455635965 entropy_value 5.81087685 glob_norm 0.38615796\n",
      "Iteration 100 L -5.37739277 loss -5.37739277 loss_ordinary 0.434788167 entropy_value 5.812181 glob_norm 0.465787143\n",
      "Iteration 150 L -5.35199594 loss -5.35199594 loss_ordinary 0.466081619 entropy_value 5.81807756 glob_norm 0.37383011\n",
      "Iteration 200 L -5.36779785 loss -5.36779785 loss_ordinary 0.442798138 entropy_value 5.81059599 glob_norm 0.354103595\n",
      "Iteration 250 L -5.40484524 loss -5.40484524 loss_ordinary 0.410767227 entropy_value 5.81561232 glob_norm 0.485383689\n",
      "Iteration 300 L -5.36168337 loss -5.36168337 loss_ordinary 0.458024025 entropy_value 5.81970787 glob_norm 0.397522867\n",
      "Iteration 350 L -5.36779261 loss -5.36779261 loss_ordinary 0.442916811 entropy_value 5.81070948 glob_norm 0.343216419\n",
      "Iteration 400 L -5.33555079 loss -5.33555079 loss_ordinary 0.481541455 entropy_value 5.81709242 glob_norm 0.499680102\n",
      "Iteration 450 L -5.3676939 loss -5.3676939 loss_ordinary 0.447012961 entropy_value 5.81470633 glob_norm 0.324483633\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  6  %  c_excess_power 0 lambd_papr 0 mu 0.0101813562\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36778736 loss -5.36778736 loss_ordinary 0.448439479 entropy_value 5.81622696 glob_norm 0.255370021\n",
      "Iteration 50 L -5.3753581 loss -5.3753581 loss_ordinary 0.435809106 entropy_value 5.81116724 glob_norm 0.347304851\n",
      "Iteration 100 L -5.36662 loss -5.36662 loss_ordinary 0.444893152 entropy_value 5.81151295 glob_norm 0.36177671\n",
      "Iteration 150 L -5.35338545 loss -5.35338545 loss_ordinary 0.463501066 entropy_value 5.81688643 glob_norm 0.351972669\n",
      "Iteration 200 L -5.36992645 loss -5.36992645 loss_ordinary 0.445420444 entropy_value 5.81534719 glob_norm 0.359694242\n",
      "Iteration 250 L -5.35366 loss -5.35366 loss_ordinary 0.460686922 entropy_value 5.81434679 glob_norm 0.388211459\n",
      "Iteration 300 L -5.36407614 loss -5.36407614 loss_ordinary 0.450818032 entropy_value 5.8148942 glob_norm 0.447888285\n",
      "Iteration 350 L -5.37676764 loss -5.37676764 loss_ordinary 0.438828468 entropy_value 5.8155961 glob_norm 0.392256886\n",
      "Iteration 400 L -5.37094545 loss -5.37094545 loss_ordinary 0.440487206 entropy_value 5.81143284 glob_norm 0.331317544\n",
      "Iteration 450 L -5.36213207 loss -5.36213207 loss_ordinary 0.452438831 entropy_value 5.8145709 glob_norm 0.509379804\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  7  %  c_excess_power 0 lambd_papr 0 mu 0.0102119008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36915 loss -5.36915 loss_ordinary 0.442959189 entropy_value 5.81210947 glob_norm 0.347172737\n",
      "Iteration 50 L -5.35638762 loss -5.35638762 loss_ordinary 0.458136767 entropy_value 5.81452417 glob_norm 0.456857651\n",
      "Iteration 100 L -5.35446739 loss -5.35446739 loss_ordinary 0.457845747 entropy_value 5.81231308 glob_norm 0.39158684\n",
      "Iteration 150 L -5.38130617 loss -5.38130617 loss_ordinary 0.435356289 entropy_value 5.81666231 glob_norm 0.59096837\n",
      "Iteration 200 L -5.37279224 loss -5.37279224 loss_ordinary 0.443461388 entropy_value 5.81625366 glob_norm 0.48496893\n",
      "Iteration 250 L -5.36854315 loss -5.36854315 loss_ordinary 0.44512251 entropy_value 5.81366587 glob_norm 0.423450112\n",
      "Iteration 300 L -5.37947607 loss -5.37947607 loss_ordinary 0.433295876 entropy_value 5.81277227 glob_norm 0.461644113\n",
      "Iteration 350 L -5.37318659 loss -5.37318659 loss_ordinary 0.441665322 entropy_value 5.81485176 glob_norm 0.344022214\n",
      "Iteration 400 L -5.35841 loss -5.35841 loss_ordinary 0.449094713 entropy_value 5.80750465 glob_norm 0.443367302\n",
      "Iteration 450 L -5.35347319 loss -5.35347319 loss_ordinary 0.458864063 entropy_value 5.8123374 glob_norm 0.238707557\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  8  %  c_excess_power 0 lambd_papr 0 mu 0.0102425367\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38284731 loss -5.38284731 loss_ordinary 0.42942974 entropy_value 5.81227684 glob_norm 0.355443507\n",
      "Iteration 50 L -5.36199856 loss -5.36199856 loss_ordinary 0.455372036 entropy_value 5.81737089 glob_norm 0.377163768\n",
      "Iteration 100 L -5.35939026 loss -5.35939026 loss_ordinary 0.454506367 entropy_value 5.81389666 glob_norm 0.482161283\n",
      "Iteration 150 L -5.37099409 loss -5.37099409 loss_ordinary 0.447308421 entropy_value 5.81830215 glob_norm 0.329597324\n",
      "Iteration 200 L -5.39551544 loss -5.39551544 loss_ordinary 0.421325833 entropy_value 5.81684113 glob_norm 0.330049336\n",
      "Iteration 250 L -5.35263443 loss -5.35263443 loss_ordinary 0.4646689 entropy_value 5.81730366 glob_norm 0.329283953\n",
      "Iteration 300 L -5.37567568 loss -5.37567568 loss_ordinary 0.435596585 entropy_value 5.81127214 glob_norm 0.29961741\n",
      "Iteration 350 L -5.38466644 loss -5.38466644 loss_ordinary 0.431209594 entropy_value 5.81587601 glob_norm 0.352313638\n",
      "Iteration 400 L -5.3834095 loss -5.3834095 loss_ordinary 0.434781373 entropy_value 5.81819105 glob_norm 0.357187897\n",
      "Iteration 450 L -5.37617254 loss -5.37617254 loss_ordinary 0.437772632 entropy_value 5.81394482 glob_norm 0.410484374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  9  %  c_excess_power 0 lambd_papr 0 mu 0.0102732647\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36975622 loss -5.36975622 loss_ordinary 0.44494316 entropy_value 5.81469965 glob_norm 0.376529664\n",
      "Iteration 50 L -5.36439753 loss -5.36439753 loss_ordinary 0.449670732 entropy_value 5.81406832 glob_norm 0.454929799\n",
      "Iteration 100 L -5.36144972 loss -5.36144972 loss_ordinary 0.447501093 entropy_value 5.80895042 glob_norm 0.377379388\n",
      "Iteration 150 L -5.3822813 loss -5.3822813 loss_ordinary 0.433591425 entropy_value 5.81587267 glob_norm 0.378043801\n",
      "Iteration 200 L -5.37857819 loss -5.37857819 loss_ordinary 0.436111867 entropy_value 5.81469 glob_norm 0.362309933\n",
      "Iteration 250 L -5.36790848 loss -5.36790848 loss_ordinary 0.449012935 entropy_value 5.81692171 glob_norm 0.397768497\n",
      "Iteration 300 L -5.37010098 loss -5.37010098 loss_ordinary 0.445738435 entropy_value 5.81584 glob_norm 0.340780079\n",
      "Iteration 350 L -5.36774635 loss -5.36774635 loss_ordinary 0.446942836 entropy_value 5.81468916 glob_norm 0.45034188\n",
      "Iteration 400 L -5.38297653 loss -5.38297653 loss_ordinary 0.427901953 entropy_value 5.81087828 glob_norm 0.340265512\n",
      "Iteration 450 L -5.36785173 loss -5.36785173 loss_ordinary 0.447538674 entropy_value 5.81539 glob_norm 0.300731957\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  10  %  c_excess_power 0 lambd_papr 0 mu 0.010304085\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38937092 loss -5.38937092 loss_ordinary 0.424836904 entropy_value 5.81420755 glob_norm 0.403801143\n",
      "Iteration 50 L -5.36537504 loss -5.36537504 loss_ordinary 0.446731985 entropy_value 5.81210661 glob_norm 0.403695405\n",
      "Iteration 100 L -5.36813784 loss -5.36813784 loss_ordinary 0.443076134 entropy_value 5.81121397 glob_norm 0.314951479\n",
      "Iteration 150 L -5.35815 loss -5.35815 loss_ordinary 0.456852913 entropy_value 5.81500292 glob_norm 0.297509372\n",
      "Iteration 200 L -5.35269594 loss -5.35269594 loss_ordinary 0.459917545 entropy_value 5.81261301 glob_norm 0.384976596\n",
      "Iteration 250 L -5.39061 loss -5.39061 loss_ordinary 0.425190896 entropy_value 5.81580114 glob_norm 0.326943\n",
      "Iteration 300 L -5.39208889 loss -5.39208889 loss_ordinary 0.423513889 entropy_value 5.81560278 glob_norm 0.246276483\n",
      "Iteration 350 L -5.36237526 loss -5.36237526 loss_ordinary 0.452207536 entropy_value 5.81458282 glob_norm 0.311190188\n",
      "Iteration 400 L -5.39449406 loss -5.39449406 loss_ordinary 0.416878104 entropy_value 5.81137228 glob_norm 0.277386308\n",
      "Iteration 450 L -5.37056208 loss -5.37056208 loss_ordinary 0.443741888 entropy_value 5.81430387 glob_norm 0.266508967\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  11  %  c_excess_power 0 lambd_papr 0 mu 0.0103349974\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37840176 loss -5.37840176 loss_ordinary 0.436017841 entropy_value 5.81441975 glob_norm 0.259898722\n",
      "Iteration 50 L -5.36966562 loss -5.36966562 loss_ordinary 0.445806533 entropy_value 5.81547213 glob_norm 0.443741053\n",
      "Iteration 100 L -5.39258862 loss -5.39258862 loss_ordinary 0.422198474 entropy_value 5.81478691 glob_norm 0.332295984\n",
      "Iteration 150 L -5.3608861 loss -5.3608861 loss_ordinary 0.454475701 entropy_value 5.81536198 glob_norm 0.288609982\n",
      "Iteration 200 L -5.37094259 loss -5.37094259 loss_ordinary 0.442510784 entropy_value 5.8134532 glob_norm 0.325709671\n",
      "Iteration 250 L -5.3482976 loss -5.3482976 loss_ordinary 0.468923151 entropy_value 5.81722069 glob_norm 0.449738175\n",
      "Iteration 300 L -5.36275339 loss -5.36275339 loss_ordinary 0.449381 entropy_value 5.81213427 glob_norm 0.40883711\n",
      "Iteration 350 L -5.36727715 loss -5.36727715 loss_ordinary 0.448277086 entropy_value 5.81555414 glob_norm 0.274837792\n",
      "Iteration 400 L -5.36127472 loss -5.36127472 loss_ordinary 0.453076512 entropy_value 5.81435156 glob_norm 0.296360642\n",
      "Iteration 450 L -5.35468578 loss -5.35468578 loss_ordinary 0.460427046 entropy_value 5.81511307 glob_norm 0.26154238\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  12  %  c_excess_power 0 lambd_papr 0 mu 0.010366003\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3677516 loss -5.3677516 loss_ordinary 0.443292588 entropy_value 5.81104374 glob_norm 0.337537348\n",
      "Iteration 50 L -5.33130884 loss -5.33130884 loss_ordinary 0.481265664 entropy_value 5.81257439 glob_norm 0.456208676\n",
      "Iteration 100 L -5.38239336 loss -5.38239336 loss_ordinary 0.434688687 entropy_value 5.81708193 glob_norm 0.344758213\n",
      "Iteration 150 L -5.37698889 loss -5.37698889 loss_ordinary 0.438666433 entropy_value 5.81565523 glob_norm 0.359513551\n",
      "Iteration 200 L -5.33847666 loss -5.33847666 loss_ordinary 0.477178514 entropy_value 5.81565523 glob_norm 0.325411737\n",
      "Iteration 250 L -5.37354708 loss -5.37354708 loss_ordinary 0.442412734 entropy_value 5.81596 glob_norm 0.415204\n",
      "Iteration 300 L -5.37655592 loss -5.37655592 loss_ordinary 0.43912816 entropy_value 5.81568384 glob_norm 0.375721246\n",
      "Iteration 350 L -5.35593414 loss -5.35593414 loss_ordinary 0.456233084 entropy_value 5.81216717 glob_norm 0.346399248\n",
      "Iteration 400 L -5.37939358 loss -5.37939358 loss_ordinary 0.432476342 entropy_value 5.81187 glob_norm 0.352052927\n",
      "Iteration 450 L -5.37914 loss -5.37914 loss_ordinary 0.434088498 entropy_value 5.81322813 glob_norm 0.427223891\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  13  %  c_excess_power 0 lambd_papr 0 mu 0.0103971008\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37073088 loss -5.37073088 loss_ordinary 0.439939648 entropy_value 5.81067038 glob_norm 0.397849262\n",
      "Iteration 50 L -5.37721968 loss -5.37721968 loss_ordinary 0.435441583 entropy_value 5.81266117 glob_norm 0.419253021\n",
      "Iteration 100 L -5.3706336 loss -5.3706336 loss_ordinary 0.443511486 entropy_value 5.81414509 glob_norm 0.382207423\n",
      "Iteration 150 L -5.34701967 loss -5.34701967 loss_ordinary 0.470499635 entropy_value 5.81751966 glob_norm 0.383988589\n",
      "Iteration 200 L -5.38305664 loss -5.38305664 loss_ordinary 0.427097827 entropy_value 5.81015444 glob_norm 0.525872588\n",
      "Iteration 250 L -5.36718607 loss -5.36718607 loss_ordinary 0.445981652 entropy_value 5.81316757 glob_norm 0.314851522\n",
      "Iteration 300 L -5.34504128 loss -5.34504128 loss_ordinary 0.470341 entropy_value 5.815382 glob_norm 0.310645521\n",
      "Iteration 350 L -5.34386873 loss -5.34386873 loss_ordinary 0.469678581 entropy_value 5.81354713 glob_norm 0.484948456\n",
      "Iteration 400 L -5.37531614 loss -5.37531614 loss_ordinary 0.440387458 entropy_value 5.81570339 glob_norm 0.482486844\n",
      "Iteration 450 L -5.36327791 loss -5.36327791 loss_ordinary 0.453594983 entropy_value 5.8168726 glob_norm 0.318225026\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  14  %  c_excess_power 0 lambd_papr 0 mu 0.0104282927\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37626219 loss -5.37626219 loss_ordinary 0.441620559 entropy_value 5.81788254 glob_norm 0.576866329\n",
      "Iteration 50 L -5.39896584 loss -5.39896584 loss_ordinary 0.41710186 entropy_value 5.8160677 glob_norm 0.270518422\n",
      "Iteration 100 L -5.36583281 loss -5.36583281 loss_ordinary 0.449650496 entropy_value 5.81548309 glob_norm 0.304968983\n",
      "Iteration 150 L -5.38556 loss -5.38556 loss_ordinary 0.426148653 entropy_value 5.81170845 glob_norm 0.298754036\n",
      "Iteration 200 L -5.35665846 loss -5.35665846 loss_ordinary 0.456967711 entropy_value 5.81362581 glob_norm 0.460646093\n",
      "Iteration 250 L -5.36064 loss -5.36064 loss_ordinary 0.450652927 entropy_value 5.81129313 glob_norm 0.431768656\n",
      "Iteration 300 L -5.34959221 loss -5.34959221 loss_ordinary 0.468896 entropy_value 5.81848812 glob_norm 0.347990513\n",
      "Iteration 350 L -5.35260582 loss -5.35260582 loss_ordinary 0.462878585 entropy_value 5.81548452 glob_norm 0.521794379\n",
      "Iteration 400 L -5.35987806 loss -5.35987806 loss_ordinary 0.455779701 entropy_value 5.81565809 glob_norm 0.379215539\n",
      "Iteration 450 L -5.37103271 loss -5.37103271 loss_ordinary 0.439388663 entropy_value 5.81042147 glob_norm 0.381742716\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  15  %  c_excess_power 0 lambd_papr 0 mu 0.0104595777\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3798666 loss -5.3798666 loss_ordinary 0.439148277 entropy_value 5.81901503 glob_norm 0.452097595\n",
      "Iteration 50 L -5.35064507 loss -5.35064507 loss_ordinary 0.464893341 entropy_value 5.81553841 glob_norm 0.324121118\n",
      "Iteration 100 L -5.41172314 loss -5.41172314 loss_ordinary 0.402181774 entropy_value 5.81390524 glob_norm 0.448764741\n",
      "Iteration 150 L -5.3710618 loss -5.3710618 loss_ordinary 0.44386971 entropy_value 5.81493139 glob_norm 0.229652882\n",
      "Iteration 200 L -5.37195 loss -5.37195 loss_ordinary 0.445721984 entropy_value 5.81767225 glob_norm 0.374803662\n",
      "Iteration 250 L -5.36717749 loss -5.36717749 loss_ordinary 0.448822528 entropy_value 5.816 glob_norm 0.38516584\n",
      "Iteration 300 L -5.34416962 loss -5.34416962 loss_ordinary 0.465829521 entropy_value 5.80999899 glob_norm 0.484789193\n",
      "Iteration 350 L -5.36023331 loss -5.36023331 loss_ordinary 0.456518322 entropy_value 5.81675196 glob_norm 0.381613344\n",
      "Iteration 400 L -5.38417959 loss -5.38417959 loss_ordinary 0.429554343 entropy_value 5.81373358 glob_norm 0.386427522\n",
      "Iteration 450 L -5.36124516 loss -5.36124516 loss_ordinary 0.451655328 entropy_value 5.81290054 glob_norm 0.275720119\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  16  %  c_excess_power 0 lambd_papr 0 mu 0.0104909567\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36189222 loss -5.36189222 loss_ordinary 0.450057477 entropy_value 5.81195 glob_norm 0.305853695\n",
      "Iteration 50 L -5.38402128 loss -5.38402128 loss_ordinary 0.43005228 entropy_value 5.81407356 glob_norm 0.386768639\n",
      "Iteration 100 L -5.35596895 loss -5.35596895 loss_ordinary 0.458176911 entropy_value 5.81414604 glob_norm 0.414245218\n",
      "Iteration 150 L -5.3497324 loss -5.3497324 loss_ordinary 0.463668048 entropy_value 5.81340027 glob_norm 0.349931091\n",
      "Iteration 200 L -5.36311197 loss -5.36311197 loss_ordinary 0.45495078 entropy_value 5.81806278 glob_norm 0.424184471\n",
      "Iteration 250 L -5.37814522 loss -5.37814522 loss_ordinary 0.438606322 entropy_value 5.81675196 glob_norm 0.294628412\n",
      "Iteration 300 L -5.35237789 loss -5.35237789 loss_ordinary 0.455661058 entropy_value 5.80803919 glob_norm 0.383828849\n",
      "Iteration 350 L -5.38012791 loss -5.38012791 loss_ordinary 0.434771359 entropy_value 5.81489897 glob_norm 0.313424706\n",
      "Iteration 400 L -5.34634829 loss -5.34634829 loss_ordinary 0.467435688 entropy_value 5.81378412 glob_norm 0.353920162\n",
      "Iteration 450 L -5.36151075 loss -5.36151075 loss_ordinary 0.454426736 entropy_value 5.81593704 glob_norm 0.361646771\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  17  %  c_excess_power 0 lambd_papr 0 mu 0.0105224298\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35855293 loss -5.35855293 loss_ordinary 0.455952138 entropy_value 5.8145051 glob_norm 0.293104261\n",
      "Iteration 50 L -5.34658194 loss -5.34658194 loss_ordinary 0.467404068 entropy_value 5.8139863 glob_norm 0.396352\n",
      "Iteration 100 L -5.37517262 loss -5.37517262 loss_ordinary 0.441122979 entropy_value 5.81629562 glob_norm 0.333072\n",
      "Iteration 150 L -5.37838 loss -5.37838 loss_ordinary 0.437246352 entropy_value 5.81562614 glob_norm 0.336331\n",
      "Iteration 200 L -5.35957527 loss -5.35957527 loss_ordinary 0.456294417 entropy_value 5.81587 glob_norm 0.397485226\n",
      "Iteration 250 L -5.34812641 loss -5.34812641 loss_ordinary 0.465813637 entropy_value 5.81394 glob_norm 0.422580481\n",
      "Iteration 300 L -5.35308027 loss -5.35308027 loss_ordinary 0.462593585 entropy_value 5.81567383 glob_norm 0.341006458\n",
      "Iteration 350 L -5.34500933 loss -5.34500933 loss_ordinary 0.469515473 entropy_value 5.81452513 glob_norm 0.345552325\n",
      "Iteration 400 L -5.36893797 loss -5.36893797 loss_ordinary 0.448595256 entropy_value 5.81753302 glob_norm 0.424439192\n",
      "Iteration 450 L -5.3816905 loss -5.3816905 loss_ordinary 0.43609345 entropy_value 5.81778383 glob_norm 0.241366699\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  18  %  c_excess_power 0 lambd_papr 0 mu 0.010553997\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36196518 loss -5.36196518 loss_ordinary 0.456132472 entropy_value 5.81809711 glob_norm 0.303084165\n",
      "Iteration 50 L -5.33021355 loss -5.33021355 loss_ordinary 0.486946732 entropy_value 5.81716 glob_norm 0.473710507\n",
      "Iteration 100 L -5.36175251 loss -5.36175251 loss_ordinary 0.451386869 entropy_value 5.81313944 glob_norm 0.476553112\n",
      "Iteration 150 L -5.36502266 loss -5.36502266 loss_ordinary 0.450131 entropy_value 5.8151536 glob_norm 0.307982326\n",
      "Iteration 200 L -5.39518118 loss -5.39518118 loss_ordinary 0.417629838 entropy_value 5.81281137 glob_norm 0.472823173\n",
      "Iteration 250 L -5.37373304 loss -5.37373304 loss_ordinary 0.440474749 entropy_value 5.81420755 glob_norm 0.299476504\n",
      "Iteration 300 L -5.36479902 loss -5.36479902 loss_ordinary 0.449705511 entropy_value 5.81450415 glob_norm 0.296974331\n",
      "Iteration 350 L -5.35609293 loss -5.35609293 loss_ordinary 0.457111895 entropy_value 5.81320477 glob_norm 0.373002738\n",
      "Iteration 400 L -5.35260582 loss -5.35260582 loss_ordinary 0.462775379 entropy_value 5.81538153 glob_norm 0.290271372\n",
      "Iteration 450 L -5.35322285 loss -5.35322285 loss_ordinary 0.458488584 entropy_value 5.81171131 glob_norm 0.392599136\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  19  %  c_excess_power 0 lambd_papr 0 mu 0.0105856592\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38551903 loss -5.38551903 loss_ordinary 0.430749923 entropy_value 5.81626892 glob_norm 0.381169945\n",
      "Iteration 50 L -5.36597729 loss -5.36597729 loss_ordinary 0.446583658 entropy_value 5.81256104 glob_norm 0.358537257\n",
      "Iteration 100 L -5.36327553 loss -5.36327553 loss_ordinary 0.45288071 entropy_value 5.81615591 glob_norm 0.312836438\n",
      "Iteration 150 L -5.38576508 loss -5.38576508 loss_ordinary 0.426763892 entropy_value 5.81252909 glob_norm 0.302295089\n",
      "Iteration 200 L -5.35169411 loss -5.35169411 loss_ordinary 0.463991225 entropy_value 5.81568527 glob_norm 0.392379224\n",
      "Iteration 250 L -5.35832167 loss -5.35832167 loss_ordinary 0.45563966 entropy_value 5.81396151 glob_norm 0.420301914\n",
      "Iteration 300 L -5.38605976 loss -5.38605976 loss_ordinary 0.431957126 entropy_value 5.81801701 glob_norm 0.255854964\n",
      "Iteration 350 L -5.36019182 loss -5.36019182 loss_ordinary 0.455705523 entropy_value 5.81589746 glob_norm 0.33057946\n",
      "Iteration 400 L -5.38274813 loss -5.38274813 loss_ordinary 0.435436159 entropy_value 5.8181839 glob_norm 0.362868667\n",
      "Iteration 450 L -5.37235117 loss -5.37235117 loss_ordinary 0.441647142 entropy_value 5.8139987 glob_norm 0.320448607\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  20  %  c_excess_power 0 lambd_papr 0 mu 0.0106174164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37658882 loss -5.37658882 loss_ordinary 0.437784791 entropy_value 5.81437349 glob_norm 0.353657931\n",
      "Iteration 50 L -5.35786247 loss -5.35786247 loss_ordinary 0.454551131 entropy_value 5.81241369 glob_norm 0.390348703\n",
      "Iteration 100 L -5.3640461 loss -5.3640461 loss_ordinary 0.450370312 entropy_value 5.81441641 glob_norm 0.380573\n",
      "Iteration 150 L -5.37318611 loss -5.37318611 loss_ordinary 0.44054547 entropy_value 5.81373167 glob_norm 0.29350397\n",
      "Iteration 200 L -5.37923384 loss -5.37923384 loss_ordinary 0.436778694 entropy_value 5.81601286 glob_norm 0.318518698\n",
      "Iteration 250 L -5.33847713 loss -5.33847713 loss_ordinary 0.472897649 entropy_value 5.81137466 glob_norm 0.34100154\n",
      "Iteration 300 L -5.36222744 loss -5.36222744 loss_ordinary 0.450601667 entropy_value 5.81282902 glob_norm 0.46049282\n",
      "Iteration 350 L -5.36166143 loss -5.36166143 loss_ordinary 0.449813902 entropy_value 5.81147528 glob_norm 0.325450718\n",
      "Iteration 400 L -5.35369873 loss -5.35369873 loss_ordinary 0.46055159 entropy_value 5.81425047 glob_norm 0.325734109\n",
      "Iteration 450 L -5.35468531 loss -5.35468531 loss_ordinary 0.460782975 entropy_value 5.81546783 glob_norm 0.362732321\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  21  %  c_excess_power 0 lambd_papr 0 mu 0.0106492685\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34350586 loss -5.34350586 loss_ordinary 0.472453356 entropy_value 5.81595945 glob_norm 0.443082601\n",
      "Iteration 50 L -5.37087679 loss -5.37087679 loss_ordinary 0.440122545 entropy_value 5.81099939 glob_norm 0.408748358\n",
      "Iteration 100 L -5.35014963 loss -5.35014963 loss_ordinary 0.46216476 entropy_value 5.81231451 glob_norm 0.400677711\n",
      "Iteration 150 L -5.38912535 loss -5.38912535 loss_ordinary 0.418411851 entropy_value 5.80753708 glob_norm 0.3293778\n",
      "Iteration 200 L -5.37226391 loss -5.37226391 loss_ordinary 0.442746103 entropy_value 5.81501 glob_norm 0.336669326\n",
      "Iteration 250 L -5.36427212 loss -5.36427212 loss_ordinary 0.442305177 entropy_value 5.80657721 glob_norm 0.337401211\n",
      "Iteration 300 L -5.3803153 loss -5.3803153 loss_ordinary 0.43422085 entropy_value 5.81453609 glob_norm 0.34618929\n",
      "Iteration 350 L -5.35680342 loss -5.35680342 loss_ordinary 0.460214734 entropy_value 5.81701803 glob_norm 0.44043234\n",
      "Iteration 400 L -5.36428452 loss -5.36428452 loss_ordinary 0.453895569 entropy_value 5.81818 glob_norm 0.415040225\n",
      "Iteration 450 L -5.34766817 loss -5.34766817 loss_ordinary 0.465747684 entropy_value 5.813416 glob_norm 0.287463158\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  22  %  c_excess_power 0 lambd_papr 0 mu 0.0106812166\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34703779 loss -5.34703779 loss_ordinary 0.468049735 entropy_value 5.8150878 glob_norm 0.30894047\n",
      "Iteration 50 L -5.36602163 loss -5.36602163 loss_ordinary 0.44762823 entropy_value 5.81364965 glob_norm 0.338634044\n",
      "Iteration 100 L -5.37309551 loss -5.37309551 loss_ordinary 0.444986522 entropy_value 5.81808233 glob_norm 0.318639278\n",
      "Iteration 150 L -5.36261606 loss -5.36261606 loss_ordinary 0.454245687 entropy_value 5.81686163 glob_norm 0.337365061\n",
      "Iteration 200 L -5.36618662 loss -5.36618662 loss_ordinary 0.448848128 entropy_value 5.81503487 glob_norm 0.389974862\n",
      "Iteration 250 L -5.35097361 loss -5.35097361 loss_ordinary 0.461660296 entropy_value 5.81263399 glob_norm 0.554463744\n",
      "Iteration 300 L -5.34709358 loss -5.34709358 loss_ordinary 0.465728581 entropy_value 5.81282234 glob_norm 0.307589501\n",
      "Iteration 350 L -5.32244825 loss -5.32244825 loss_ordinary 0.493579745 entropy_value 5.81602812 glob_norm 0.283804566\n",
      "Iteration 400 L -5.35847569 loss -5.35847569 loss_ordinary 0.458516777 entropy_value 5.81699228 glob_norm 0.3335917\n",
      "Iteration 450 L -5.36419868 loss -5.36419868 loss_ordinary 0.449701518 entropy_value 5.81390047 glob_norm 0.340999305\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  23  %  c_excess_power 0 lambd_papr 0 mu 0.0107132606\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36833334 loss -5.36833334 loss_ordinary 0.445208043 entropy_value 5.81354094 glob_norm 0.264157891\n",
      "Iteration 50 L -5.35669661 loss -5.35669661 loss_ordinary 0.458442867 entropy_value 5.81513929 glob_norm 0.395127505\n",
      "Iteration 100 L -5.35903025 loss -5.35903025 loss_ordinary 0.453365624 entropy_value 5.81239557 glob_norm 0.306208342\n",
      "Iteration 150 L -5.41219378 loss -5.41219378 loss_ordinary 0.401765645 entropy_value 5.8139596 glob_norm 0.379559726\n",
      "Iteration 200 L -5.35894299 loss -5.35894299 loss_ordinary 0.462119311 entropy_value 5.82106209 glob_norm 0.391268492\n",
      "Iteration 250 L -5.35081625 loss -5.35081625 loss_ordinary 0.464770555 entropy_value 5.81558704 glob_norm 0.502015531\n",
      "Iteration 300 L -5.36119461 loss -5.36119461 loss_ordinary 0.452377737 entropy_value 5.81357193 glob_norm 0.478349298\n",
      "Iteration 350 L -5.35927868 loss -5.35927868 loss_ordinary 0.456644773 entropy_value 5.81592369 glob_norm 0.411722273\n",
      "Iteration 400 L -5.3980217 loss -5.3980217 loss_ordinary 0.416341573 entropy_value 5.81436348 glob_norm 0.468657523\n",
      "Iteration 450 L -5.36054516 loss -5.36054516 loss_ordinary 0.450957805 entropy_value 5.81150293 glob_norm 0.411010951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  24  %  c_excess_power 0 lambd_papr 0 mu 0.0107454006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36945724 loss -5.36945724 loss_ordinary 0.446918756 entropy_value 5.81637621 glob_norm 0.321522295\n",
      "Iteration 50 L -5.38447189 loss -5.38447189 loss_ordinary 0.428333879 entropy_value 5.81280565 glob_norm 0.291743577\n",
      "Iteration 100 L -5.33932638 loss -5.33932638 loss_ordinary 0.476227254 entropy_value 5.81555319 glob_norm 0.50036341\n",
      "Iteration 150 L -5.33118296 loss -5.33118296 loss_ordinary 0.484370649 entropy_value 5.81555319 glob_norm 0.321064502\n",
      "Iteration 200 L -5.35225296 loss -5.35225296 loss_ordinary 0.462500125 entropy_value 5.81475353 glob_norm 0.286177814\n",
      "Iteration 250 L -5.36036396 loss -5.36036396 loss_ordinary 0.458591312 entropy_value 5.81895494 glob_norm 0.305702776\n",
      "Iteration 300 L -5.38532495 loss -5.38532495 loss_ordinary 0.424284577 entropy_value 5.80960941 glob_norm 0.483296\n",
      "Iteration 350 L -5.37455797 loss -5.37455797 loss_ordinary 0.443695575 entropy_value 5.81825352 glob_norm 0.32825917\n",
      "Iteration 400 L -5.36952829 loss -5.36952829 loss_ordinary 0.44121483 entropy_value 5.81074333 glob_norm 0.465366423\n",
      "Iteration 450 L -5.36131096 loss -5.36131096 loss_ordinary 0.452732623 entropy_value 5.81404352 glob_norm 0.383584976\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  25  %  c_excess_power 0 lambd_papr 0 mu 0.0107776374\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36910629 loss -5.36910629 loss_ordinary 0.446285903 entropy_value 5.81539249 glob_norm 0.377724826\n",
      "Iteration 50 L -5.36412525 loss -5.36412525 loss_ordinary 0.450881749 entropy_value 5.81500721 glob_norm 0.297874719\n",
      "Iteration 100 L -5.386549 loss -5.386549 loss_ordinary 0.429450691 entropy_value 5.816 glob_norm 0.268690944\n",
      "Iteration 150 L -5.34789658 loss -5.34789658 loss_ordinary 0.469447881 entropy_value 5.81734467 glob_norm 0.4133358\n",
      "Iteration 200 L -5.3914237 loss -5.3914237 loss_ordinary 0.424217135 entropy_value 5.81564093 glob_norm 0.44254604\n",
      "Iteration 250 L -5.34974337 loss -5.34974337 loss_ordinary 0.465603977 entropy_value 5.81534719 glob_norm 0.291027576\n",
      "Iteration 300 L -5.37097359 loss -5.37097359 loss_ordinary 0.440217108 entropy_value 5.81119061 glob_norm 0.367342442\n",
      "Iteration 350 L -5.376513 loss -5.376513 loss_ordinary 0.438429445 entropy_value 5.81494236 glob_norm 0.368064463\n",
      "Iteration 400 L -5.39086 loss -5.39086 loss_ordinary 0.422555298 entropy_value 5.81341505 glob_norm 0.329880804\n",
      "Iteration 450 L -5.37275457 loss -5.37275457 loss_ordinary 0.445784092 entropy_value 5.81853914 glob_norm 0.390907258\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  26  %  c_excess_power 0 lambd_papr 0 mu 0.0108099701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3907156 loss -5.3907156 loss_ordinary 0.428343594 entropy_value 5.8190589 glob_norm 0.320256174\n",
      "Iteration 50 L -5.37949419 loss -5.37949419 loss_ordinary 0.430924624 entropy_value 5.81041861 glob_norm 0.370074123\n",
      "Iteration 100 L -5.35841322 loss -5.35841322 loss_ordinary 0.457065761 entropy_value 5.81547928 glob_norm 0.396434486\n",
      "Iteration 150 L -5.33528471 loss -5.33528471 loss_ordinary 0.482140839 entropy_value 5.81742573 glob_norm 0.491209745\n",
      "Iteration 200 L -5.3713789 loss -5.3713789 loss_ordinary 0.446219563 entropy_value 5.81759834 glob_norm 0.330165625\n",
      "Iteration 250 L -5.381423 loss -5.381423 loss_ordinary 0.428402036 entropy_value 5.80982494 glob_norm 0.450524211\n",
      "Iteration 300 L -5.38237286 loss -5.38237286 loss_ordinary 0.43088007 entropy_value 5.81325293 glob_norm 0.335081547\n",
      "Iteration 350 L -5.37420654 loss -5.37420654 loss_ordinary 0.440100253 entropy_value 5.81430674 glob_norm 0.354118586\n",
      "Iteration 400 L -5.37241411 loss -5.37241411 loss_ordinary 0.441527843 entropy_value 5.81394243 glob_norm 0.307834595\n",
      "Iteration 450 L -5.36002445 loss -5.36002445 loss_ordinary 0.451212913 entropy_value 5.81123734 glob_norm 0.342835516\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  27  %  c_excess_power 0 lambd_papr 0 mu 0.0108424006\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38393974 loss -5.38393974 loss_ordinary 0.434453189 entropy_value 5.81839323 glob_norm 0.385428965\n",
      "Iteration 50 L -5.3601675 loss -5.3601675 loss_ordinary 0.453941494 entropy_value 5.81410885 glob_norm 0.315420419\n",
      "Iteration 100 L -5.3723917 loss -5.3723917 loss_ordinary 0.444432616 entropy_value 5.81682444 glob_norm 0.342873961\n",
      "Iteration 150 L -5.36074924 loss -5.36074924 loss_ordinary 0.451603919 entropy_value 5.81235313 glob_norm 0.35220927\n",
      "Iteration 200 L -5.37938404 loss -5.37938404 loss_ordinary 0.43795374 entropy_value 5.81733799 glob_norm 0.344009429\n",
      "Iteration 250 L -5.38081026 loss -5.38081026 loss_ordinary 0.43604666 entropy_value 5.81685686 glob_norm 0.289181948\n",
      "Iteration 300 L -5.35922194 loss -5.35922194 loss_ordinary 0.454096794 entropy_value 5.81331873 glob_norm 0.361681\n",
      "Iteration 350 L -5.39906645 loss -5.39906645 loss_ordinary 0.415454924 entropy_value 5.81452131 glob_norm 0.412008107\n",
      "Iteration 400 L -5.36545324 loss -5.36545324 loss_ordinary 0.451023072 entropy_value 5.81647635 glob_norm 0.30717\n",
      "Iteration 450 L -5.36866808 loss -5.36866808 loss_ordinary 0.448251486 entropy_value 5.81692 glob_norm 0.394521892\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  28  %  c_excess_power 0 lambd_papr 0 mu 0.010874928\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3873558 loss -5.3873558 loss_ordinary 0.428251147 entropy_value 5.81560707 glob_norm 0.33075732\n",
      "Iteration 50 L -5.35333395 loss -5.35333395 loss_ordinary 0.460406244 entropy_value 5.81374 glob_norm 0.264519304\n",
      "Iteration 100 L -5.35625935 loss -5.35625935 loss_ordinary 0.452699482 entropy_value 5.80895901 glob_norm 0.398126841\n",
      "Iteration 150 L -5.38024 loss -5.38024 loss_ordinary 0.43113479 entropy_value 5.81137466 glob_norm 0.409385711\n",
      "Iteration 200 L -5.33964109 loss -5.33964109 loss_ordinary 0.478195518 entropy_value 5.81783676 glob_norm 0.32790333\n",
      "Iteration 250 L -5.36378193 loss -5.36378193 loss_ordinary 0.450367063 entropy_value 5.81414938 glob_norm 0.369778901\n",
      "Iteration 300 L -5.37560511 loss -5.37560511 loss_ordinary 0.436054945 entropy_value 5.81166029 glob_norm 0.308535397\n",
      "Iteration 350 L -5.3737092 loss -5.3737092 loss_ordinary 0.437762737 entropy_value 5.81147194 glob_norm 0.284570575\n",
      "Iteration 400 L -5.38383532 loss -5.38383532 loss_ordinary 0.428680778 entropy_value 5.81251621 glob_norm 0.451474279\n",
      "Iteration 450 L -5.36591864 loss -5.36591864 loss_ordinary 0.449755192 entropy_value 5.81567383 glob_norm 0.430226713\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  29  %  c_excess_power 0 lambd_papr 0 mu 0.0109075531\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38183117 loss -5.38183117 loss_ordinary 0.429643691 entropy_value 5.8114748 glob_norm 0.343467742\n",
      "Iteration 50 L -5.36676931 loss -5.36676931 loss_ordinary 0.44471243 entropy_value 5.81148148 glob_norm 0.36695683\n",
      "Iteration 100 L -5.38352251 loss -5.38352251 loss_ordinary 0.433080763 entropy_value 5.81660318 glob_norm 0.4346928\n",
      "Iteration 150 L -5.36754084 loss -5.36754084 loss_ordinary 0.445410043 entropy_value 5.81295109 glob_norm 0.425483316\n",
      "Iteration 200 L -5.37637281 loss -5.37637281 loss_ordinary 0.443239689 entropy_value 5.81961298 glob_norm 0.482164502\n",
      "Iteration 250 L -5.38080311 loss -5.38080311 loss_ordinary 0.437809169 entropy_value 5.81861258 glob_norm 0.295537949\n",
      "Iteration 300 L -5.35882139 loss -5.35882139 loss_ordinary 0.454870403 entropy_value 5.81369162 glob_norm 0.306971639\n",
      "Iteration 350 L -5.36367083 loss -5.36367083 loss_ordinary 0.455409765 entropy_value 5.81908035 glob_norm 0.359683156\n",
      "Iteration 400 L -5.36898661 loss -5.36898661 loss_ordinary 0.44469434 entropy_value 5.81368065 glob_norm 0.293535\n",
      "Iteration 450 L -5.39032888 loss -5.39032888 loss_ordinary 0.421466142 entropy_value 5.81179523 glob_norm 0.398973137\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  30  %  c_excess_power 0 lambd_papr 0 mu 0.0109402761\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37201738 loss -5.37201738 loss_ordinary 0.445455343 entropy_value 5.81747246 glob_norm 0.328484118\n",
      "Iteration 50 L -5.36914778 loss -5.36914778 loss_ordinary 0.442884386 entropy_value 5.81203175 glob_norm 0.315062672\n",
      "Iteration 100 L -5.35682917 loss -5.35682917 loss_ordinary 0.456586152 entropy_value 5.81341505 glob_norm 0.325707585\n",
      "Iteration 150 L -5.35928392 loss -5.35928392 loss_ordinary 0.456742913 entropy_value 5.81602669 glob_norm 0.392773092\n",
      "Iteration 200 L -5.38770342 loss -5.38770342 loss_ordinary 0.426884145 entropy_value 5.81458759 glob_norm 0.30690074\n",
      "Iteration 250 L -5.3414197 loss -5.3414197 loss_ordinary 0.475527167 entropy_value 5.81694698 glob_norm 0.300284773\n",
      "Iteration 300 L -5.37756205 loss -5.37756205 loss_ordinary 0.439119428 entropy_value 5.81668139 glob_norm 0.318838716\n",
      "Iteration 350 L -5.36160803 loss -5.36160803 loss_ordinary 0.455388635 entropy_value 5.81699657 glob_norm 0.352483571\n",
      "Iteration 400 L -5.36885643 loss -5.36885643 loss_ordinary 0.443157583 entropy_value 5.8120141 glob_norm 0.387316585\n",
      "Iteration 450 L -5.38648558 loss -5.38648558 loss_ordinary 0.428711593 entropy_value 5.81519699 glob_norm 0.236055121\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  31  %  c_excess_power 0 lambd_papr 0 mu 0.0109730968\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.33196 loss -5.33196 loss_ordinary 0.480363518 entropy_value 5.81232357 glob_norm 0.419295341\n",
      "Iteration 50 L -5.37791586 loss -5.37791586 loss_ordinary 0.439081281 entropy_value 5.81699753 glob_norm 0.290671021\n",
      "Iteration 100 L -5.36156 loss -5.36156 loss_ordinary 0.453255802 entropy_value 5.814816 glob_norm 0.430703223\n",
      "Iteration 150 L -5.37468195 loss -5.37468195 loss_ordinary 0.440556854 entropy_value 5.81523895 glob_norm 0.366108865\n",
      "Iteration 200 L -5.35140324 loss -5.35140324 loss_ordinary 0.462486655 entropy_value 5.81389 glob_norm 0.375518203\n",
      "Iteration 250 L -5.37551117 loss -5.37551117 loss_ordinary 0.436674267 entropy_value 5.81218529 glob_norm 0.317484707\n",
      "Iteration 300 L -5.33695698 loss -5.33695698 loss_ordinary 0.476828516 entropy_value 5.81378555 glob_norm 0.329533547\n",
      "Iteration 350 L -5.37632942 loss -5.37632942 loss_ordinary 0.438399941 entropy_value 5.81472921 glob_norm 0.275090486\n",
      "Iteration 400 L -5.37796116 loss -5.37796116 loss_ordinary 0.433799058 entropy_value 5.81176 glob_norm 0.450517595\n",
      "Iteration 450 L -5.33579445 loss -5.33579445 loss_ordinary 0.478910893 entropy_value 5.81470537 glob_norm 0.398898333\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  32  %  c_excess_power 0 lambd_papr 0 mu 0.0110060163\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3706069 loss -5.3706069 loss_ordinary 0.446556032 entropy_value 5.81716299 glob_norm 0.40606612\n",
      "Iteration 50 L -5.35290146 loss -5.35290146 loss_ordinary 0.457345277 entropy_value 5.81024647 glob_norm 0.38275674\n",
      "Iteration 100 L -5.35061455 loss -5.35061455 loss_ordinary 0.459803402 entropy_value 5.81041813 glob_norm 0.406543255\n",
      "Iteration 150 L -5.38282 loss -5.38282 loss_ordinary 0.433877081 entropy_value 5.8166976 glob_norm 0.3275581\n",
      "Iteration 200 L -5.35420084 loss -5.35420084 loss_ordinary 0.459595263 entropy_value 5.81379652 glob_norm 0.414919436\n",
      "Iteration 250 L -5.34765339 loss -5.34765339 loss_ordinary 0.463030875 entropy_value 5.8106842 glob_norm 0.456314474\n",
      "Iteration 300 L -5.38800573 loss -5.38800573 loss_ordinary 0.424421519 entropy_value 5.81242752 glob_norm 0.320292592\n",
      "Iteration 350 L -5.35896349 loss -5.35896349 loss_ordinary 0.456338197 entropy_value 5.81530142 glob_norm 0.357581496\n",
      "Iteration 400 L -5.39001131 loss -5.39001131 loss_ordinary 0.421838969 entropy_value 5.81185 glob_norm 0.387294799\n",
      "Iteration 450 L -5.38092375 loss -5.38092375 loss_ordinary 0.434178621 entropy_value 5.8151021 glob_norm 0.296961\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  33  %  c_excess_power 0 lambd_papr 0 mu 0.0110390345\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34891891 loss -5.34891891 loss_ordinary 0.464244276 entropy_value 5.81316328 glob_norm 0.351732314\n",
      "Iteration 50 L -5.38062096 loss -5.38062096 loss_ordinary 0.430693924 entropy_value 5.81131506 glob_norm 0.319173813\n",
      "Iteration 100 L -5.3926239 loss -5.3926239 loss_ordinary 0.421287864 entropy_value 5.81391191 glob_norm 0.304074556\n",
      "Iteration 150 L -5.37285566 loss -5.37285566 loss_ordinary 0.443600267 entropy_value 5.81645584 glob_norm 0.250441432\n",
      "Iteration 200 L -5.35676622 loss -5.35676622 loss_ordinary 0.457641 entropy_value 5.81440735 glob_norm 0.307944179\n",
      "Iteration 250 L -5.35745859 loss -5.35745859 loss_ordinary 0.455801189 entropy_value 5.8132596 glob_norm 0.292138547\n",
      "Iteration 300 L -5.36366081 loss -5.36366081 loss_ordinary 0.451046109 entropy_value 5.81470728 glob_norm 0.370838523\n",
      "Iteration 350 L -5.38159513 loss -5.38159513 loss_ordinary 0.434924 entropy_value 5.81651926 glob_norm 0.336473256\n",
      "Iteration 400 L -5.38508701 loss -5.38508701 loss_ordinary 0.428192675 entropy_value 5.81327963 glob_norm 0.290407479\n",
      "Iteration 450 L -5.36764145 loss -5.36764145 loss_ordinary 0.448299944 entropy_value 5.81594133 glob_norm 0.282756418\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  34  %  c_excess_power 0 lambd_papr 0 mu 0.0110721514\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36704445 loss -5.36704445 loss_ordinary 0.446711957 entropy_value 5.81375647 glob_norm 0.385486156\n",
      "Iteration 50 L -5.38893032 loss -5.38893032 loss_ordinary 0.424360126 entropy_value 5.8132906 glob_norm 0.324835688\n",
      "Iteration 100 L -5.36382961 loss -5.36382961 loss_ordinary 0.451063454 entropy_value 5.81489277 glob_norm 0.369246364\n",
      "Iteration 150 L -5.36554861 loss -5.36554861 loss_ordinary 0.447281301 entropy_value 5.81283 glob_norm 0.28067103\n",
      "Iteration 200 L -5.38137341 loss -5.38137341 loss_ordinary 0.429426581 entropy_value 5.8107996 glob_norm 0.415865928\n",
      "Iteration 250 L -5.38133621 loss -5.38133621 loss_ordinary 0.432440728 entropy_value 5.81377697 glob_norm 0.29247418\n",
      "Iteration 300 L -5.36355639 loss -5.36355639 loss_ordinary 0.449119866 entropy_value 5.81267643 glob_norm 0.281830132\n",
      "Iteration 350 L -5.38136196 loss -5.38136196 loss_ordinary 0.436317474 entropy_value 5.81768 glob_norm 0.312445283\n",
      "Iteration 400 L -5.37650299 loss -5.37650299 loss_ordinary 0.437221676 entropy_value 5.81372499 glob_norm 0.292909652\n",
      "Iteration 450 L -5.36435604 loss -5.36435604 loss_ordinary 0.447923392 entropy_value 5.8122797 glob_norm 0.375963241\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  35  %  c_excess_power 0 lambd_papr 0 mu 0.0111053679\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.36155272 loss -5.36155272 loss_ordinary 0.455757082 entropy_value 5.81731 glob_norm 0.340167254\n",
      "Iteration 50 L -5.3652482 loss -5.3652482 loss_ordinary 0.449359238 entropy_value 5.81460762 glob_norm 0.273795694\n",
      "Iteration 100 L -5.36621904 loss -5.36621904 loss_ordinary 0.446331352 entropy_value 5.81255054 glob_norm 0.350833684\n",
      "Iteration 150 L -5.36149693 loss -5.36149693 loss_ordinary 0.454458266 entropy_value 5.81595516 glob_norm 0.425035387\n",
      "Iteration 200 L -5.37006569 loss -5.37006569 loss_ordinary 0.441706 entropy_value 5.81177187 glob_norm 0.344941169\n",
      "Iteration 250 L -5.35019255 loss -5.35019255 loss_ordinary 0.46668148 entropy_value 5.81687403 glob_norm 0.486974269\n",
      "Iteration 300 L -5.37068367 loss -5.37068367 loss_ordinary 0.442834437 entropy_value 5.81351757 glob_norm 0.320482939\n",
      "Iteration 350 L -5.35741615 loss -5.35741615 loss_ordinary 0.459645182 entropy_value 5.81706142 glob_norm 0.25483492\n",
      "Iteration 400 L -5.3421669 loss -5.3421669 loss_ordinary 0.47153312 entropy_value 5.8137 glob_norm 0.393120795\n",
      "Iteration 450 L -5.38145828 loss -5.38145828 loss_ordinary 0.433365524 entropy_value 5.8148241 glob_norm 0.264916748\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  36  %  c_excess_power 0 lambd_papr 0 mu 0.0111386841\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38653278 loss -5.38653278 loss_ordinary 0.4269014 entropy_value 5.8134346 glob_norm 0.3560175\n",
      "Iteration 50 L -5.40060425 loss -5.40060425 loss_ordinary 0.413564175 entropy_value 5.81416845 glob_norm 0.312159121\n",
      "Iteration 100 L -5.37848234 loss -5.37848234 loss_ordinary 0.436538219 entropy_value 5.81502 glob_norm 0.410518974\n",
      "Iteration 150 L -5.35811472 loss -5.35811472 loss_ordinary 0.455091506 entropy_value 5.8132062 glob_norm 0.347224265\n",
      "Iteration 200 L -5.38843203 loss -5.38843203 loss_ordinary 0.425732523 entropy_value 5.81416464 glob_norm 0.322628319\n",
      "Iteration 250 L -5.38468456 loss -5.38468456 loss_ordinary 0.428276509 entropy_value 5.8129611 glob_norm 0.269995481\n",
      "Iteration 300 L -5.36896372 loss -5.36896372 loss_ordinary 0.44576934 entropy_value 5.81473351 glob_norm 0.386180639\n",
      "Iteration 350 L -5.34827471 loss -5.34827471 loss_ordinary 0.465635806 entropy_value 5.81391048 glob_norm 0.390483409\n",
      "Iteration 400 L -5.36061573 loss -5.36061573 loss_ordinary 0.454045147 entropy_value 5.81466103 glob_norm 0.399081767\n",
      "Iteration 450 L -5.35691595 loss -5.35691595 loss_ordinary 0.455080807 entropy_value 5.81199694 glob_norm 0.348053128\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  37  %  c_excess_power 0 lambd_papr 0 mu 0.0111721\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37159777 loss -5.37159777 loss_ordinary 0.44219327 entropy_value 5.8137908 glob_norm 0.293875366\n",
      "Iteration 50 L -5.37533236 loss -5.37533236 loss_ordinary 0.437601507 entropy_value 5.81293392 glob_norm 0.457032114\n",
      "Iteration 100 L -5.36256886 loss -5.36256886 loss_ordinary 0.450329125 entropy_value 5.81289816 glob_norm 0.333484739\n",
      "Iteration 150 L -5.38877106 loss -5.38877106 loss_ordinary 0.426679403 entropy_value 5.81545 glob_norm 0.34151265\n",
      "Iteration 200 L -5.35281801 loss -5.35281801 loss_ordinary 0.462826639 entropy_value 5.81564474 glob_norm 0.306496948\n",
      "Iteration 250 L -5.37211275 loss -5.37211275 loss_ordinary 0.44368729 entropy_value 5.8158 glob_norm 0.369131386\n",
      "Iteration 300 L -5.33354378 loss -5.33354378 loss_ordinary 0.482389927 entropy_value 5.8159337 glob_norm 0.317729712\n",
      "Iteration 350 L -5.37138 loss -5.37138 loss_ordinary 0.439221 entropy_value 5.81060076 glob_norm 0.33564052\n",
      "Iteration 400 L -5.37055111 loss -5.37055111 loss_ordinary 0.446351379 entropy_value 5.81690216 glob_norm 0.415388376\n",
      "Iteration 450 L -5.36376858 loss -5.36376858 loss_ordinary 0.449591786 entropy_value 5.81336 glob_norm 0.389298767\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  38  %  c_excess_power 0 lambd_papr 0 mu 0.0112056164\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37743187 loss -5.37743187 loss_ordinary 0.434337974 entropy_value 5.81177 glob_norm 0.402585924\n",
      "Iteration 50 L -5.3654871 loss -5.3654871 loss_ordinary 0.450229883 entropy_value 5.81571722 glob_norm 0.465231627\n",
      "Iteration 100 L -5.34976292 loss -5.34976292 loss_ordinary 0.464842111 entropy_value 5.81460524 glob_norm 0.332256883\n",
      "Iteration 150 L -5.37858582 loss -5.37858582 loss_ordinary 0.434344858 entropy_value 5.81293106 glob_norm 0.389709\n",
      "Iteration 200 L -5.36210585 loss -5.36210585 loss_ordinary 0.453673452 entropy_value 5.81577921 glob_norm 0.277616799\n",
      "Iteration 250 L -5.36611366 loss -5.36611366 loss_ordinary 0.449180037 entropy_value 5.81529379 glob_norm 0.36811015\n",
      "Iteration 300 L -5.36663198 loss -5.36663198 loss_ordinary 0.450946748 entropy_value 5.81757879 glob_norm 0.377651125\n",
      "Iteration 350 L -5.37195396 loss -5.37195396 loss_ordinary 0.443953 entropy_value 5.815907 glob_norm 0.418579817\n",
      "Iteration 400 L -5.34639311 loss -5.34639311 loss_ordinary 0.468564779 entropy_value 5.81495762 glob_norm 0.255508035\n",
      "Iteration 450 L -5.37233639 loss -5.37233639 loss_ordinary 0.443379313 entropy_value 5.81571579 glob_norm 0.341822594\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  39  %  c_excess_power 0 lambd_papr 0 mu 0.0112392334\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.38081169 loss -5.38081169 loss_ordinary 0.435600132 entropy_value 5.81641197 glob_norm 0.396223366\n",
      "Iteration 50 L -5.35387611 loss -5.35387611 loss_ordinary 0.461528 entropy_value 5.81540394 glob_norm 0.381612152\n",
      "Iteration 100 L -5.37615299 loss -5.37615299 loss_ordinary 0.437432587 entropy_value 5.81358576 glob_norm 0.281158209\n",
      "Iteration 150 L -5.37120581 loss -5.37120581 loss_ordinary 0.443217337 entropy_value 5.81442308 glob_norm 0.371415883\n",
      "Iteration 200 L -5.37071 loss -5.37071 loss_ordinary 0.441101 entropy_value 5.81181097 glob_norm 0.366529435\n",
      "Iteration 250 L -5.36508656 loss -5.36508656 loss_ordinary 0.448145717 entropy_value 5.81323242 glob_norm 0.326538771\n",
      "Iteration 300 L -5.36595583 loss -5.36595583 loss_ordinary 0.448528171 entropy_value 5.81448364 glob_norm 0.302667588\n",
      "Iteration 350 L -5.35321617 loss -5.35321617 loss_ordinary 0.462457478 entropy_value 5.81567383 glob_norm 0.367042333\n",
      "Iteration 400 L -5.36867046 loss -5.36867046 loss_ordinary 0.442863107 entropy_value 5.81153393 glob_norm 0.301058322\n",
      "Iteration 450 L -5.36394215 loss -5.36394215 loss_ordinary 0.450767815 entropy_value 5.81471 glob_norm 0.359503031\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  40  %  c_excess_power 0 lambd_papr 0 mu 0.011272951\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37377882 loss -5.37377882 loss_ordinary 0.442604363 entropy_value 5.81638288 glob_norm 0.30901441\n",
      "Iteration 50 L -5.35865688 loss -5.35865688 loss_ordinary 0.458036214 entropy_value 5.81669331 glob_norm 0.323569864\n",
      "Iteration 100 L -5.35998487 loss -5.35998487 loss_ordinary 0.460490853 entropy_value 5.82047558 glob_norm 0.425005257\n",
      "Iteration 150 L -5.39579535 loss -5.39579535 loss_ordinary 0.418329984 entropy_value 5.81412506 glob_norm 0.399670541\n",
      "Iteration 200 L -5.39788437 loss -5.39788437 loss_ordinary 0.415703118 entropy_value 5.81358719 glob_norm 0.292151213\n",
      "Iteration 250 L -5.37357 loss -5.37357 loss_ordinary 0.438953668 entropy_value 5.81252384 glob_norm 0.445884\n",
      "Iteration 300 L -5.37398624 loss -5.37398624 loss_ordinary 0.440749794 entropy_value 5.81473589 glob_norm 0.446226031\n",
      "Iteration 350 L -5.35806513 loss -5.35806513 loss_ordinary 0.452537954 entropy_value 5.81060314 glob_norm 0.324519247\n",
      "Iteration 400 L -5.36078882 loss -5.36078882 loss_ordinary 0.449281842 entropy_value 5.81007051 glob_norm 0.338511854\n",
      "Iteration 450 L -5.36420679 loss -5.36420679 loss_ordinary 0.45239222 entropy_value 5.81659889 glob_norm 0.332487732\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  41  %  c_excess_power 0 lambd_papr 0 mu 0.0113067701\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34209442 loss -5.34209442 loss_ordinary 0.470721036 entropy_value 5.81281519 glob_norm 0.304471284\n",
      "Iteration 50 L -5.37190914 loss -5.37190914 loss_ordinary 0.43846339 entropy_value 5.81037235 glob_norm 0.338734686\n",
      "Iteration 100 L -5.35180473 loss -5.35180473 loss_ordinary 0.463795245 entropy_value 5.8156 glob_norm 0.327521294\n",
      "Iteration 150 L -5.36731 loss -5.36731 loss_ordinary 0.445510298 entropy_value 5.81282043 glob_norm 0.33808741\n",
      "Iteration 200 L -5.34888029 loss -5.34888029 loss_ordinary 0.466117352 entropy_value 5.81499767 glob_norm 0.327305138\n",
      "Iteration 250 L -5.39140368 loss -5.39140368 loss_ordinary 0.418716609 entropy_value 5.81012 glob_norm 0.34316951\n",
      "Iteration 300 L -5.4006381 loss -5.4006381 loss_ordinary 0.414144933 entropy_value 5.8147831 glob_norm 0.286397547\n",
      "Iteration 350 L -5.36510658 loss -5.36510658 loss_ordinary 0.45112735 entropy_value 5.81623363 glob_norm 0.40075022\n",
      "Iteration 400 L -5.38165855 loss -5.38165855 loss_ordinary 0.433578581 entropy_value 5.81523705 glob_norm 0.327849656\n",
      "Iteration 450 L -5.34551859 loss -5.34551859 loss_ordinary 0.469007015 entropy_value 5.8145256 glob_norm 0.383192033\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  42  %  c_excess_power 0 lambd_papr 0 mu 0.0113406908\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.3898735 loss -5.3898735 loss_ordinary 0.426087707 entropy_value 5.81596136 glob_norm 0.399747431\n",
      "Iteration 50 L -5.3589139 loss -5.3589139 loss_ordinary 0.45158568 entropy_value 5.81049967 glob_norm 0.333542705\n",
      "Iteration 100 L -5.38432741 loss -5.38432741 loss_ordinary 0.428883314 entropy_value 5.81321096 glob_norm 0.270606548\n",
      "Iteration 150 L -5.35642195 loss -5.35642195 loss_ordinary 0.459299922 entropy_value 5.81572199 glob_norm 0.331834525\n",
      "Iteration 200 L -5.35265541 loss -5.35265541 loss_ordinary 0.463811934 entropy_value 5.81646681 glob_norm 0.318402439\n",
      "Iteration 250 L -5.37927485 loss -5.37927485 loss_ordinary 0.433238477 entropy_value 5.81251335 glob_norm 0.294736266\n",
      "Iteration 300 L -5.36953926 loss -5.36953926 loss_ordinary 0.442736864 entropy_value 5.81227589 glob_norm 0.328867644\n",
      "Iteration 350 L -5.39592409 loss -5.39592409 loss_ordinary 0.419310093 entropy_value 5.81523418 glob_norm 0.279265195\n",
      "Iteration 400 L -5.36416578 loss -5.36416578 loss_ordinary 0.448631495 entropy_value 5.81279755 glob_norm 0.321445137\n",
      "Iteration 450 L -5.38249159 loss -5.38249159 loss_ordinary 0.43402487 entropy_value 5.8165164 glob_norm 0.340271115\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  43  %  c_excess_power 0 lambd_papr 0 mu 0.0113747129\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35389376 loss -5.35389376 loss_ordinary 0.459697723 entropy_value 5.81359148 glob_norm 0.445792049\n",
      "Iteration 50 L -5.38518047 loss -5.38518047 loss_ordinary 0.429149836 entropy_value 5.81433 glob_norm 0.47808364\n",
      "Iteration 100 L -5.38440847 loss -5.38440847 loss_ordinary 0.42764613 entropy_value 5.81205463 glob_norm 0.372233093\n",
      "Iteration 150 L -5.34486914 loss -5.34486914 loss_ordinary 0.471270114 entropy_value 5.8161397 glob_norm 0.456106275\n",
      "Iteration 200 L -5.36153793 loss -5.36153793 loss_ordinary 0.452603728 entropy_value 5.81414175 glob_norm 0.363645971\n",
      "Iteration 250 L -5.37288666 loss -5.37288666 loss_ordinary 0.440078646 entropy_value 5.81296539 glob_norm 0.3988958\n",
      "Iteration 300 L -5.37629604 loss -5.37629604 loss_ordinary 0.435167521 entropy_value 5.81146383 glob_norm 0.302340478\n",
      "Iteration 350 L -5.37725639 loss -5.37725639 loss_ordinary 0.438780636 entropy_value 5.81603718 glob_norm 0.276525259\n",
      "Iteration 400 L -5.34893847 loss -5.34893847 loss_ordinary 0.465401381 entropy_value 5.81433964 glob_norm 0.340022564\n",
      "Iteration 450 L -5.37528038 loss -5.37528038 loss_ordinary 0.440149546 entropy_value 5.81543 glob_norm 0.276222825\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  44  %  c_excess_power 0 lambd_papr 0 mu 0.0114088375\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35057163 loss -5.35057163 loss_ordinary 0.461646497 entropy_value 5.81221819 glob_norm 0.366493881\n",
      "Iteration 50 L -5.37008619 loss -5.37008619 loss_ordinary 0.446264356 entropy_value 5.81635046 glob_norm 0.372110128\n",
      "Iteration 100 L -5.33481073 loss -5.33481073 loss_ordinary 0.478737056 entropy_value 5.81354809 glob_norm 0.321993828\n",
      "Iteration 150 L -5.37387943 loss -5.37387943 loss_ordinary 0.437613964 entropy_value 5.8114934 glob_norm 0.378766775\n",
      "Iteration 200 L -5.38221645 loss -5.38221645 loss_ordinary 0.43211931 entropy_value 5.81433582 glob_norm 0.244076014\n",
      "Iteration 250 L -5.37118101 loss -5.37118101 loss_ordinary 0.443604648 entropy_value 5.81478548 glob_norm 0.339773893\n",
      "Iteration 300 L -5.34310341 loss -5.34310341 loss_ordinary 0.468671769 entropy_value 5.81177521 glob_norm 0.288252503\n",
      "Iteration 350 L -5.34928274 loss -5.34928274 loss_ordinary 0.463796407 entropy_value 5.81307888 glob_norm 0.353968352\n",
      "Iteration 400 L -5.36938095 loss -5.36938095 loss_ordinary 0.441953838 entropy_value 5.81133509 glob_norm 0.33436361\n",
      "Iteration 450 L -5.37025 loss -5.37025 loss_ordinary 0.44219017 entropy_value 5.8124404 glob_norm 0.372238815\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  45  %  c_excess_power 0 lambd_papr 0 mu 0.0114430645\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.35135317 loss -5.35135317 loss_ordinary 0.46060136 entropy_value 5.81195402 glob_norm 0.319772065\n",
      "Iteration 50 L -5.34926701 loss -5.34926701 loss_ordinary 0.467959464 entropy_value 5.81722641 glob_norm 0.343188375\n",
      "Iteration 100 L -5.37490416 loss -5.37490416 loss_ordinary 0.441582561 entropy_value 5.81648684 glob_norm 0.288992792\n",
      "Iteration 150 L -5.34760666 loss -5.34760666 loss_ordinary 0.466605425 entropy_value 5.81421185 glob_norm 0.386339605\n",
      "Iteration 200 L -5.36895752 loss -5.36895752 loss_ordinary 0.44568795 entropy_value 5.81464529 glob_norm 0.314796805\n",
      "Iteration 250 L -5.37655926 loss -5.37655926 loss_ordinary 0.438134 entropy_value 5.81469345 glob_norm 0.287210226\n",
      "Iteration 300 L -5.3754468 loss -5.3754468 loss_ordinary 0.442418128 entropy_value 5.81786489 glob_norm 0.376491785\n",
      "Iteration 350 L -5.35835695 loss -5.35835695 loss_ordinary 0.457299888 entropy_value 5.81565666 glob_norm 0.290682614\n",
      "Iteration 400 L -5.37503099 loss -5.37503099 loss_ordinary 0.437969893 entropy_value 5.81300116 glob_norm 0.309494495\n",
      "Iteration 450 L -5.39086151 loss -5.39086151 loss_ordinary 0.422202826 entropy_value 5.81306458 glob_norm 0.372158408\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  46  %  c_excess_power 0 lambd_papr 0 mu 0.011477394\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.34861946 loss -5.34861946 loss_ordinary 0.463578194 entropy_value 5.81219769 glob_norm 0.368443698\n",
      "Iteration 50 L -5.38838434 loss -5.38838434 loss_ordinary 0.424115658 entropy_value 5.81250048 glob_norm 0.394479871\n",
      "Iteration 100 L -5.35369587 loss -5.35369587 loss_ordinary 0.459693551 entropy_value 5.8133893 glob_norm 0.313456953\n",
      "Iteration 150 L -5.378582 loss -5.378582 loss_ordinary 0.440460712 entropy_value 5.81904268 glob_norm 0.282559365\n",
      "Iteration 200 L -5.37414 loss -5.37414 loss_ordinary 0.439572781 entropy_value 5.8137126 glob_norm 0.346488\n",
      "Iteration 250 L -5.35142279 loss -5.35142279 loss_ordinary 0.461169153 entropy_value 5.81259203 glob_norm 0.361467779\n",
      "Iteration 300 L -5.37453699 loss -5.37453699 loss_ordinary 0.434892088 entropy_value 5.80942917 glob_norm 0.280956537\n",
      "Iteration 350 L -5.3564167 loss -5.3564167 loss_ordinary 0.456014931 entropy_value 5.81243134 glob_norm 0.272918701\n",
      "Iteration 400 L -5.37554932 loss -5.37554932 loss_ordinary 0.437996894 entropy_value 5.81354618 glob_norm 0.314766258\n",
      "Iteration 450 L -5.37152958 loss -5.37152958 loss_ordinary 0.441226631 entropy_value 5.81275606 glob_norm 0.268328756\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  47  %  c_excess_power 0 lambd_papr 0 mu 0.0115118269\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.39654255 loss -5.39654255 loss_ordinary 0.417976141 entropy_value 5.81451893 glob_norm 0.32249\n",
      "Iteration 50 L -5.33176708 loss -5.33176708 loss_ordinary 0.482290864 entropy_value 5.81405783 glob_norm 0.42579174\n",
      "Iteration 100 L -5.31824493 loss -5.31824493 loss_ordinary 0.49568826 entropy_value 5.81393337 glob_norm 0.359462529\n",
      "Iteration 150 L -5.36081123 loss -5.36081123 loss_ordinary 0.454348564 entropy_value 5.81516 glob_norm 0.435395151\n",
      "Iteration 200 L -5.36199 loss -5.36199 loss_ordinary 0.452618033 entropy_value 5.8146081 glob_norm 0.355347842\n",
      "Iteration 250 L -5.39562654 loss -5.39562654 loss_ordinary 0.419903636 entropy_value 5.81553 glob_norm 0.242771238\n",
      "Iteration 300 L -5.36078119 loss -5.36078119 loss_ordinary 0.452067316 entropy_value 5.81284857 glob_norm 0.292639613\n",
      "Iteration 350 L -5.35519218 loss -5.35519218 loss_ordinary 0.457685202 entropy_value 5.81287718 glob_norm 0.379713327\n",
      "Iteration 400 L -5.36632776 loss -5.36632776 loss_ordinary 0.450076342 entropy_value 5.81640434 glob_norm 0.33607617\n",
      "Iteration 450 L -5.37330532 loss -5.37330532 loss_ordinary 0.437651604 entropy_value 5.81095648 glob_norm 0.37969169\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  48  %  c_excess_power 0 lambd_papr 0 mu 0.0115463622\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Iteration 0 L -5.37475061 loss -5.37475061 loss_ordinary 0.441988707 entropy_value 5.81673956 glob_norm 0.288395077\n",
      "Iteration 50 L -5.37068653 loss -5.37068653 loss_ordinary 0.442808628 entropy_value 5.81349516 glob_norm 0.406882018\n",
      "Iteration 100 L -5.40219975 loss -5.40219975 loss_ordinary 0.411097437 entropy_value 5.81329679 glob_norm 0.260148227\n",
      "Iteration 150 L -5.35807514 loss -5.35807514 loss_ordinary 0.45502454 entropy_value 5.81309938 glob_norm 0.358570248\n",
      "Iteration 200 L -5.36937761 loss -5.36937761 loss_ordinary 0.443972737 entropy_value 5.81335068 glob_norm 0.321117401\n",
      "Iteration 250 L -5.36617565 loss -5.36617565 loss_ordinary 0.446925551 entropy_value 5.81310081 glob_norm 0.582372785\n",
      "Iteration 300 L -5.35374689 loss -5.35374689 loss_ordinary 0.460097432 entropy_value 5.81384468 glob_norm 0.296524882\n",
      "Iteration 350 L -5.33465099 loss -5.33465099 loss_ordinary 0.475650609 entropy_value 5.81030178 glob_norm 0.382758647\n",
      "Iteration 400 L -5.36313105 loss -5.36313105 loss_ordinary 0.449973196 entropy_value 5.81310415 glob_norm 0.389154255\n",
      "Iteration 450 L -5.38234043 loss -5.38234043 loss_ordinary 0.432445288 entropy_value 5.81478548 glob_norm 0.324789792\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Progress  49  %  c_excess_power 0 lambd_papr 0 mu 0.0115810018\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Finished snr_17_papr_8.0\n",
      "ALL EXPERIMENTS FINISHED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting saved data",
   "id": "e10c7e18fc266c2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T20:33:56.159190Z",
     "start_time": "2026-02-04T20:33:54.273535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for snr_db in snr_list:\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "\n",
    "    for papr_db in papr_list:\n",
    "        exp_name = f\"snr_{snr_db}_papr_{papr_db}\"\n",
    "        data = np.load(f\"{RESULTS_DIR}/{exp_name}.npz\")\n",
    "\n",
    "        x = data[\"ccdf_x_db\"]\n",
    "        y = data[\"ccdf_y\"]\n",
    "\n",
    "        plt.plot(x, y, label=f\"PAPR={papr_db} dB\")\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Normalized Power (dB)\")\n",
    "    plt.ylabel(\"CCDF = P(X > x)\")\n",
    "    plt.title(f\"CCDF  SNR = {snr_db} dB\")\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.xlim(2, 10)\n",
    "    plt.ylim(1e-4, 1)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/ccdf_snr_{snr_db}.png\", dpi=300)\n",
    "    plt.show()\n"
   ],
   "id": "fe59aee0b127f6c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting a single plot",
   "id": "737cbba8d569a0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "powers_ccdf = tf.reshape(model.compute_power_to_average_power_samples(),[-1])\n",
    "powers_ccdf_db = 10*tf.math.log(powers_ccdf + 1e-12) / tf.math.log(10.)\n",
    "\n",
    "# Sort data\n",
    "x_sorted = np.sort(powers_ccdf_db.numpy())\n",
    "\n",
    "# CCDF values\n",
    "ccdf = 1.0 - np.arange(1, len(x_sorted) + 1) / len(x_sorted)"
   ],
   "id": "f171a08b49a0185e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T14:43:21.025316Z",
     "start_time": "2026-02-04T14:43:20.692843Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 93,
   "source": [
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(x_sorted, ccdf)\n",
    "# plt.plot(x_sorted2, ccdf2)\n",
    "# plt.plot(x_sorted3, ccdf3)\n",
    "# plt.plot(x_sorted4, ccdf4)\n",
    "plt.xlabel(\"Normalized Power (dB)\")\n",
    "plt.xlim(2,10)\n",
    "plt.ylabel(\"CCDF = P(X > x)\")\n",
    "plt.yscale(\"log\")   # optional, very common\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "6b7741c9ccdbe054"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T19:30:27.640702Z",
     "start_time": "2026-02-03T19:30:27.634954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking trainable parameters of the model\n",
    "\n",
    "for v in model.trainable_weights:\n",
    "    print(v.path, v.shape)"
   ],
   "id": "b6b8b7bfe6f35006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_to_end_system_bitwise_11/sampling_mechanism_10/dense_38/kernel (1, 128)\n",
      "end_to_end_system_bitwise_11/sampling_mechanism_10/dense_38/bias (128,)\n",
      "end_to_end_system_bitwise_11/sampling_mechanism_10/dense_39/kernel (128, 16)\n",
      "end_to_end_system_bitwise_11/sampling_mechanism_10/dense_39/bias (16,)\n",
      "end_to_end_system_bitwise_11/modulator_6/constellation_real (64,)\n",
      "end_to_end_system_bitwise_11/modulator_6/constellation_imag (64,)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_40/kernel (3, 128)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_40/bias (128,)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_41/kernel (128, 128)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_41/bias (128,)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_42/kernel (128, 6)\n",
      "end_to_end_system_bitwise_11/demodulator_bitwise_6/dense_42/bias (6,)\n"
     ]
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
